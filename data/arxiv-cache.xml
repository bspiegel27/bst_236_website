<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-11-11T00:57:32Z -->
<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acausal%20inference%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:causal inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/SsRksLzRb0LuVhSmQ+N8WbAs+f8</id>
  <updated>2025-11-10T00:00:00-05:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">125629</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">10</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2511.05487v1</id>
    <updated>2025-11-07T18:56:18Z</updated>
    <published>2025-11-07T18:56:18Z</published>
    <title>Function on Scalar Regression with Complex Survey Designs</title>
    <summary>  Large health surveys increasingly collect high-dimensional functional data
from wearable devices, and function on scalar regression (FoSR) is often used
to quantify the relationship between these functional outcomes and scalar
covariates such as age and sex. However, existing methods for FoSR fail to
account for complex survey design. We introduce inferential methods for FoSR
for studies with complex survey designs. The method combines fast univariate
inference (FUI) developed for functional data outcomes and survey sampling
inferential methods developed for scalar outcomes. Our approach consists of
three steps: (1) fit survey weighted GLMs at each point along the functional
domain, (2) smooth coefficients along the functional domain, and (3) use
balanced repeated replication (BRR) or the Rao-Wu-Yue-Beaumont (RWYB) bootstrap
to obtain pointwise and joint confidence bands for the functional coefficients.
The method is motivated by association studies between continuous physical
activity data and covariates collected in the National Health and Nutrition
Examination Survey (NHANES). A first-of-its-kind analytical simulation study
and empirical simulation using the NHANES data demonstrates that our method
performs better than existing methods that do not account for the survey
structure. Finally, application of the method in NHANES shows the practical
implications of accounting for survey structure. The method is implemented in
the R package svyfosr.
</summary>
    <author>
      <name>Lily Koffman</name>
    </author>
    <author>
      <name>Sunan Gao</name>
    </author>
    <author>
      <name>Xinkai Zhou</name>
    </author>
    <author>
      <name>Andrew Leroux</name>
    </author>
    <author>
      <name>Ciprian Crainiceanu</name>
    </author>
    <author>
      <name>John Muschelli III</name>
    </author>
    <link href="http://arxiv.org/abs/2511.05487v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2511.05487v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2511.05484v1</id>
    <updated>2025-11-07T18:53:39Z</updated>
    <published>2025-11-07T18:53:39Z</published>
    <title>Non-Gaussian Galaxy Stochasticity and the Noise-Field Formulation</title>
    <summary>  We revisit the stochastic, or noise, contributions to the galaxy density
field within the effective field theory (EFT) of large-scale structure.
Starting from the general, all-order expression of the EFT partition function,
we elucidate how the stochastic contributions can be described by local
nonlinear couplings of a single Gaussian noise field. We introduce an
alternative formulation of the partition function in terms of such a noise
field, and derive the corresponding field-level likelihood for biased tracers.
This noise-field formulation can capture the complete set of stochastic
contributions to the galaxy density at the field level in a normalized,
positive-definite probability density which is suitable for numerical sampling.
We illustrate this by presenting the first results of EFT-based field-level
inference with non-Gaussian and density-dependent stochasticity on dark matter
halos using LEFTfield.
</summary>
    <author>
      <name>Henrique Rubira</name>
    </author>
    <author>
      <name>Fabian Schmidt</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">33 pages, 2 figures; comments welcome</arxiv:comment>
    <link href="http://arxiv.org/abs/2511.05484v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2511.05484v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2511.05479v1</id>
    <updated>2025-11-07T18:44:50Z</updated>
    <published>2025-11-07T18:44:50Z</published>
    <title>FPGA-Based Real-Time Waveform Classification</title>
    <summary>  For self-triggered readout of SiPM sum signals, a waveform classification can
aid a simple threshold trigger to reliably extract calorimetric particle hit
information online at an early stage and thus reduce the volume of transmitted
data. Typically, the ADC data acquisition is based on FPGAs for edge data
processing. In this study, we consider look-up-table-based neural-networks and
address challenges of binary multi-layer neural networks' layout, footprint,
performance and training. We show that these structures can be trained using a
genetic algorithm and achieve the inference latency compatible with dead-time
free processing online.
</summary>
    <author>
      <name>Alperen Aksoy</name>
    </author>
    <author>
      <name>Ilja Bekman</name>
    </author>
    <author>
      <name>Chimezie Eguzo</name>
    </author>
    <author>
      <name>Christian Grewing</name>
    </author>
    <author>
      <name>Andre Zambanini</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">TWEPP25 proceedings paper pre-print</arxiv:comment>
    <link href="http://arxiv.org/abs/2511.05479v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2511.05479v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ins-det" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2511.05476v1</id>
    <updated>2025-11-07T18:38:54Z</updated>
    <published>2025-11-07T18:38:54Z</published>
    <title>A Metamorphic Testing Perspective on Knowledge Distillation for Language
  Models of Code: Does the Student Deeply Mimic the Teacher?</title>
    <summary>  Transformer-based language models of code have achieved state-of-the-art
performance across a wide range of software analytics tasks, but their
practical deployment remains limited due to high computational costs, slow
inference speeds, and significant environmental impact. To address these
challenges, recent research has increasingly explored knowledge distillation as
a method for compressing a large language model of code (the teacher) into a
smaller model (the student) while maintaining performance. However, the degree
to which a student model deeply mimics the predictive behavior and internal
representations of its teacher remains largely unexplored, as current
accuracy-based evaluation provides only a surface-level view of model quality
and often fails to capture more profound discrepancies in behavioral fidelity
between the teacher and student models. To address this gap, we empirically
show that the student model often fails to deeply mimic the teacher model,
resulting in up to 285% greater performance drop under adversarial attacks,
which is not captured by traditional accuracy-based evaluation. Therefore, we
propose MetaCompress, a metamorphic testing framework that systematically
evaluates behavioral fidelity by comparing the outputs of teacher and student
models under a set of behavior-preserving metamorphic relations. We evaluate
MetaCompress on two widely studied tasks, using compressed versions of popular
language models of code, obtained via three different knowledge distillation
techniques: Compressor, AVATAR, and MORPH. The results show that MetaCompress
identifies up to 62% behavioral discrepancies in student models, underscoring
the need for behavioral fidelity evaluation within the knowledge distillation
pipeline and establishing MetaCompress as a practical framework for testing
compressed language models of code derived through knowledge distillation.
</summary>
    <author>
      <name>Md. Abdul Awal</name>
    </author>
    <author>
      <name>Mrigank Rochan</name>
    </author>
    <author>
      <name>Chanchal K. Roy</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The paper is currently under review at a peer-reviewed journal</arxiv:comment>
    <link href="http://arxiv.org/abs/2511.05476v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2511.05476v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2511.05471v1</id>
    <updated>2025-11-07T18:33:40Z</updated>
    <published>2025-11-07T18:33:40Z</published>
    <title>Precipitation nowcasting of satellite data using physically conditioned
  neural networks</title>
    <summary>  Accurate short-term precipitation forecasts predominantly rely on dense
weather-radar networks, limiting operational value in places most exposed to
climate extremes. We present TUPANN (Transferable and Universal Physics-Aligned
Nowcasting Network), a satellite-only model trained on GOES-16 RRQPE. Unlike
most deep learning models for nowcasting, TUPANN decomposes the forecast into
physically meaningful components: a variational encoder-decoder infers motion
and intensity fields from recent imagery under optical-flow supervision, a
lead-time-conditioned MaxViT evolves the latent state, and a differentiable
advection operator reconstructs future frames. We evaluate TUPANN on both
GOES-16 and IMERG data, in up to four distinct climates (Rio de Janeiro,
Manaus, Miami, La Paz) at 10-180min lead times using the CSI and HSS metrics
over 4-64 mm/h thresholds. Comparisons against optical-flow, deep learning and
hybrid baselines show that TUPANN achieves the best or second-best skill in
most settings, with pronounced gains at higher thresholds. Training on multiple
cities further improves performance, while cross-city experiments show modest
degradation and occasional gains for rare heavy-rain regimes. The model
produces smooth, interpretable motion fields aligned with numerical optical
flow and runs in near real time due to the low latency of GOES-16. These
results indicate that physically aligned learning can provide nowcasts that are
skillful, transferable and global.
</summary>
    <author>
      <name>Antônio Catão</name>
    </author>
    <author>
      <name>Melvin Poveda</name>
    </author>
    <author>
      <name>Leonardo Voltarelli</name>
    </author>
    <author>
      <name>Paulo Orenstein</name>
    </author>
    <link href="http://arxiv.org/abs/2511.05471v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2511.05471v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2511.05470v1</id>
    <updated>2025-11-07T18:30:44Z</updated>
    <published>2025-11-07T18:30:44Z</published>
    <title>$\texttt{unimpeded}$: A Public Nested Sampling Database for Bayesian
  Cosmology</title>
    <summary>  Bayesian inference is central to modern cosmology. While parameter estimation
is achievable with unnormalised posteriors traditionally obtained via MCMC
methods, comprehensive model comparison and tension quantification require
Bayesian evidences and normalised posteriors, which remain computationally
prohibitive for many researchers. To address this, we present
$\texttt{unimpeded}$, a publicly available Python library and data repository
providing DiRAC-funded (DP192 and 264) pre-computed nested sampling and MCMC
chains with their normalised posterior samples, computed using
$\texttt{Cobaya}$ and the Boltzmann solver $\texttt{CAMB}$.
$\texttt{unimpeded}$ delivers systematic analysis across a grid of eight
cosmological models (including $\Lambda$CDM and seven extensions) and 39 modern
cosmological datasets (comprising individual probes and their pairwise
combinations). The built-in tension statistics calculator enables rapid
computation of six tension quantification metrics. All chains are hosted on
Zenodo with permanent access via the unimpeded API, analogous to the renowned
Planck Legacy Archive but utilising nested sampling in addition to traditional
MCMC methods.
</summary>
    <author>
      <name>Dily Duan Yi Ong</name>
    </author>
    <author>
      <name>Will Handley</name>
    </author>
    <link href="http://arxiv.org/abs/2511.05470v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2511.05470v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2511.05464v1</id>
    <updated>2025-11-07T18:08:04Z</updated>
    <published>2025-11-07T18:08:04Z</published>
    <title>Photo Dating by Facial Age Aggregation</title>
    <summary>  We introduce a novel method for Photo Dating which estimates the year a
photograph was taken by leveraging information from the faces of people present
in the image. To facilitate this research, we publicly release CSFD-1.6M, a new
dataset containing over 1.6 million annotated faces, primarily from movie
stills, with identity and birth year annotations. Uniquely, our dataset
provides annotations for multiple individuals within a single image, enabling
the study of multi-face information aggregation. We propose a probabilistic
framework that formally combines visual evidence from modern face recognition
and age estimation models, and career-based temporal priors to infer the photo
capture year. Our experiments demonstrate that aggregating evidence from
multiple faces consistently improves the performance and the approach
significantly outperforms strong, scene-based baselines, particularly for
images containing several identifiable individuals.
</summary>
    <author>
      <name>Jakub Paplham</name>
    </author>
    <author>
      <name>Vojtech Franc</name>
    </author>
    <link href="http://arxiv.org/abs/2511.05464v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2511.05464v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2511.05449v1</id>
    <updated>2025-11-07T17:38:01Z</updated>
    <published>2025-11-07T17:38:01Z</published>
    <title>How Many Tokens Do 3D Point Cloud Transformer Architectures Really Need?</title>
    <summary>  Recent advances in 3D point cloud transformers have led to state-of-the-art
results in tasks such as semantic segmentation and reconstruction. However,
these models typically rely on dense token representations, incurring high
computational and memory costs during training and inference. In this work, we
present the finding that tokens are remarkably redundant, leading to
substantial inefficiency. We introduce gitmerge3D, a globally informed graph
token merging method that can reduce the token count by up to 90-95% while
maintaining competitive performance. This finding challenges the prevailing
assumption that more tokens inherently yield better performance and highlights
that many current models are over-tokenized and under-optimized for
scalability. We validate our method across multiple 3D vision tasks and show
consistent improvements in computational efficiency. This work is the first to
assess redundancy in large-scale 3D transformer models, providing insights into
the development of more efficient 3D foundation architectures. Our code and
checkpoints are publicly available at https://gitmerge3d.github.io
</summary>
    <author>
      <name>Tuan Anh Tran</name>
    </author>
    <author>
      <name>Duy M. H. Nguyen</name>
    </author>
    <author>
      <name>Hoai-Chau Tran</name>
    </author>
    <author>
      <name>Michael Barz</name>
    </author>
    <author>
      <name>Khoa D. Doan</name>
    </author>
    <author>
      <name>Roger Wattenhofer</name>
    </author>
    <author>
      <name>Ngo Anh Vien</name>
    </author>
    <author>
      <name>Mathias Niepert</name>
    </author>
    <author>
      <name>Daniel Sonntag</name>
    </author>
    <author>
      <name>Paul Swoboda</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at NeurIPS 2025</arxiv:comment>
    <link href="http://arxiv.org/abs/2511.05449v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2511.05449v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2511.05442v1</id>
    <updated>2025-11-07T17:20:32Z</updated>
    <published>2025-11-07T17:20:32Z</published>
    <title>APP: Accelerated Path Patching with Task-Specific Pruning</title>
    <summary>  Circuit discovery is a key step in many mechanistic interpretability
pipelines. Current methods, such as Path Patching, are computationally
expensive and have limited in-depth circuit analysis for smaller models. In
this study, we propose Accelerated Path Patching (APP), a hybrid approach
leveraging our novel contrastive attention head pruning method to drastically
reduce the search space of circuit discovery methods. Our Contrastive-FLAP
pruning algorithm uses techniques from causal mediation analysis to assign
higher pruning scores to task-specific attention heads, leading to higher
performing sparse models compared to traditional pruning techniques. Although
Contrastive-FLAP is successful at preserving task-specific heads that existing
pruning algorithms remove at low sparsity ratios, the circuits found by
Contrastive-FLAP alone are too large to satisfy the minimality constraint
required in circuit analysis. APP first applies Contrastive-FLAP to reduce the
search space on required for circuit discovery algorithms by, on average, 56\%.
Next, APP, applies traditional Path Patching on the remaining attention heads,
leading to a speed up of 59.63\%-93.27\% compared to Path Patching applied to
the dense model. Despite the substantial computational saving that APP
provides, circuits obtained from APP exhibit substantial overlap and similar
performance to previously established Path Patching circuits
</summary>
    <author>
      <name>Frauke Andersen</name>
    </author>
    <author>
      <name>William Rudman</name>
    </author>
    <author>
      <name>Ruochen Zhang</name>
    </author>
    <author>
      <name>Carsten Eickhoff</name>
    </author>
    <link href="http://arxiv.org/abs/2511.05442v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2511.05442v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68Uxx" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7; I.2.6; I.2.m" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2511.05432v1</id>
    <updated>2025-11-07T17:07:56Z</updated>
    <published>2025-11-07T17:07:56Z</published>
    <title>Shared Latent Representation for Joint Text-to-Audio-Visual Synthesis</title>
    <summary>  We propose a text-to-talking-face synthesis framework leveraging latent
speech representations from HierSpeech++. A Text-to-Vec module generates
Wav2Vec2 embeddings from text, which jointly condition speech and face
generation. To handle distribution shifts between clean and TTS-predicted
features, we adopt a two-stage training: pretraining on Wav2Vec2 embeddings and
finetuning on TTS outputs. This enables tight audio-visual alignment, preserves
speaker identity, and produces natural, expressive speech and synchronized
facial motion without ground-truth audio at inference. Experiments show that
conditioning on TTS-predicted latent features outperforms cascaded pipelines,
improving both lip-sync and visual realism.
</summary>
    <author>
      <name>Dogucan Yaman</name>
    </author>
    <author>
      <name>Seymanur Akti</name>
    </author>
    <author>
      <name>Fevziye Irem Eyiokur</name>
    </author>
    <author>
      <name>Alexander Waibel</name>
    </author>
    <link href="http://arxiv.org/abs/2511.05432v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2511.05432v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
