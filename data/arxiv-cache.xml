<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-03-06T00:51:23Z -->
<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acausal%20inference%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:causal inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/SsRksLzRb0LuVhSmQ+N8WbAs+f8</id>
  <updated>2025-03-05T00:00:00-05:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">108163</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">10</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2503.02872v1</id>
    <updated>2025-03-04T18:51:07Z</updated>
    <published>2025-03-04T18:51:07Z</published>
    <title>Riemannian flow techniques on totally geodesic null hypersurfaces</title>
    <summary>  We study the influence of the existence of totally geodesic null hypersurface
on the properties of a Lorentzian manifold. By coupling the rigging technique
with the existence of a null foliation we prove the existence of a Riemann flow
structure which allows us to use powerful results to show how curvature
conditions on the spacetime restricts its causal structure. We also study the
existence of periodic null or spacelike geodesic.
</summary>
    <author>
      <name>Manuel Guti√©rrez</name>
    </author>
    <author>
      <name>Raymond A. Hounnonkpe</name>
    </author>
    <link href="http://arxiv.org/abs/2503.02872v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2503.02872v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.DG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="53C50 (Primary), 53B30, 53C40 (Secondary)" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2503.02866v1</id>
    <updated>2025-03-04T18:45:40Z</updated>
    <published>2025-03-04T18:45:40Z</published>
    <title>Optimal Power Management for Large-Scale Battery Energy Storage Systems
  via Bayesian Inference</title>
    <summary>  Large-scale battery energy storage systems (BESS) have found ever-increasing
use across industry and society to accelerate clean energy transition and
improve energy supply reliability and resilience. However, their optimal power
management poses significant challenges: the underlying high-dimensional
nonlinear nonconvex optimization lacks computational tractability in real-world
implementation, and the uncertainty of the exogenous power demand makes exact
optimization difficult. This paper presents a new solution framework to address
these bottlenecks. The solution pivots on introducing power-sharing ratios to
specify each cell's power quota from the output power demand. To find the
optimal power-sharing ratios, we formulate a nonlinear model predictive control
(NMPC) problem to achieve power-loss-minimizing BESS operation while complying
with safety, cell balancing, and power supply-demand constraints. We then
propose a parameterized control policy for the power-sharing ratios, which
utilizes only three parameters, to reduce the computational demand in solving
the NMPC problem. This policy parameterization allows us to translate the NMPC
problem into a Bayesian inference problem for the sake of 1) computational
tractability, and 2) overcoming the nonconvexity of the optimization problem.
We leverage the ensemble Kalman inversion technique to solve the parameter
estimation problem. Concurrently, a low-level control loop is developed to
seamlessly integrate our proposed approach with the BESS to ensure practical
implementation. This low-level controller receives the optimal power-sharing
ratios, generates output power references for the cells, and maintains a
balance between power supply and demand despite uncertainty in output power. We
conduct extensive simulations and experiments on a 20-cell prototype to
validate the proposed approach.
</summary>
    <author>
      <name>Amir Farakhor</name>
    </author>
    <author>
      <name>Iman Askari</name>
    </author>
    <author>
      <name>Di Wu</name>
    </author>
    <author>
      <name>Yebin Wang</name>
    </author>
    <author>
      <name>Huazhen Fang</name>
    </author>
    <link href="http://arxiv.org/abs/2503.02866v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2503.02866v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2503.02862v1</id>
    <updated>2025-03-04T18:40:38Z</updated>
    <published>2025-03-04T18:40:38Z</published>
    <title>Privacy and Accuracy-Aware AI/ML Model Deduplication</title>
    <summary>  With the growing adoption of privacy-preserving machine learning algorithms,
such as Differentially Private Stochastic Gradient Descent (DP-SGD), training
or fine-tuning models on private datasets has become increasingly prevalent.
This shift has led to the need for models offering varying privacy guarantees
and utility levels to satisfy diverse user requirements. However, managing
numerous versions of large models introduces significant operational
challenges, including increased inference latency, higher resource consumption,
and elevated costs. Model deduplication is a technique widely used by many
model serving and database systems to support high-performance and low-cost
inference queries and model diagnosis queries. However, none of the existing
model deduplication works has considered privacy, leading to unbounded
aggregation of privacy costs for certain deduplicated models and inefficiencies
when applied to deduplicate DP-trained models. We formalize the problems of
deduplicating DP-trained models for the first time and propose a novel privacy-
and accuracy-aware deduplication mechanism to address the problems. We
developed a greedy strategy to select and assign base models to target models
to minimize storage and privacy costs. When deduplicating a target model, we
dynamically schedule accuracy validations and apply the Sparse Vector Technique
to reduce the privacy costs associated with private validation data. Compared
to baselines that do not provide privacy guarantees, our approach improved the
compression ratio by up to $35\times$ for individual models (including large
language models and vision transformers). We also observed up to $43\times$
inference speedup due to the reduction of I/O operations.
</summary>
    <author>
      <name>Hong Guan</name>
    </author>
    <author>
      <name>Lei Yu</name>
    </author>
    <author>
      <name>Lixi Zhou</name>
    </author>
    <author>
      <name>Li Xiong</name>
    </author>
    <author>
      <name>Kanchan Chowdhury</name>
    </author>
    <author>
      <name>Lulu Xie</name>
    </author>
    <author>
      <name>Xusheng Xiao</name>
    </author>
    <author>
      <name>Jia Zou</name>
    </author>
    <link href="http://arxiv.org/abs/2503.02862v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2503.02862v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2503.02819v1</id>
    <updated>2025-03-04T17:46:51Z</updated>
    <published>2025-03-04T17:46:51Z</published>
    <title>Feynman-Kac Correctors in Diffusion: Annealing, Guidance, and Product of
  Experts</title>
    <summary>  While score-based generative models are the model of choice across diverse
domains, there are limited tools available for controlling inference-time
behavior in a principled manner, e.g. for composing multiple pretrained models.
Existing classifier-free guidance methods use a simple heuristic to mix
conditional and unconditional scores to approximately sample from conditional
distributions. However, such methods do not approximate the intermediate
distributions, necessitating additional 'corrector' steps. In this work, we
provide an efficient and principled method for sampling from a sequence of
annealed, geometric-averaged, or product distributions derived from pretrained
score-based models. We derive a weighted simulation scheme which we call
Feynman-Kac Correctors (FKCs) based on the celebrated Feynman-Kac formula by
carefully accounting for terms in the appropriate partial differential
equations (PDEs). To simulate these PDEs, we propose Sequential Monte Carlo
(SMC) resampling algorithms that leverage inference-time scaling to improve
sampling quality. We empirically demonstrate the utility of our methods by
proposing amortized sampling via inference-time temperature annealing,
improving multi-objective molecule generation using pretrained models, and
improving classifier-free guidance for text-to-image generation. Our code is
available at https://github.com/martaskrt/fkc-diffusion.
</summary>
    <author>
      <name>Marta Skreta</name>
    </author>
    <author>
      <name>Tara Akhound-Sadegh</name>
    </author>
    <author>
      <name>Viktor Ohanesian</name>
    </author>
    <author>
      <name>Roberto Bondesan</name>
    </author>
    <author>
      <name>Al√°n Aspuru-Guzik</name>
    </author>
    <author>
      <name>Arnaud Doucet</name>
    </author>
    <author>
      <name>Rob Brekelmans</name>
    </author>
    <author>
      <name>Alexander Tong</name>
    </author>
    <author>
      <name>Kirill Neklyudov</name>
    </author>
    <link href="http://arxiv.org/abs/2503.02819v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2503.02819v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2503.02797v1</id>
    <updated>2025-03-04T17:15:31Z</updated>
    <published>2025-03-04T17:15:31Z</published>
    <title>A Causal Framework for Aligning Image Quality Metrics and Deep Neural
  Network Robustness</title>
    <summary>  Image quality plays an important role in the performance of deep neural
networks (DNNs) and DNNs have been widely shown to exhibit sensitivity to
changes in imaging conditions. Large-scale datasets often contain images under
a wide range of conditions prompting a need to quantify and understand their
underlying quality distribution in order to better characterize DNN performance
and robustness. Aligning the sensitivities of image quality metrics and DNNs
ensures that estimates of quality can act as proxies for image/dataset
difficulty independent of the task models trained/evaluated on the data.
Conventional image quality assessment (IQA) seeks to measure and align quality
relative to human perceptual judgments, but here we seek a quality measure that
is not only sensitive to imaging conditions but also well-aligned with DNN
sensitivities. We first ask whether conventional IQA metrics are also
informative of DNN performance. In order to answer this question, we reframe
IQA from a causal perspective and examine conditions under which quality
metrics are predictive of DNN performance. We show theoretically and
empirically that current IQA metrics are weak predictors of DNN performance in
the context of classification. We then use our causal framework to provide an
alternative formulation and a new image quality metric that is more strongly
correlated with DNN performance and can act as a prior on performance without
training new task models. Our approach provides a means to directly estimate
the quality distribution of large-scale image datasets towards characterizing
the relationship between dataset composition and DNN performance.
</summary>
    <author>
      <name>Nathan Drenkow</name>
    </author>
    <author>
      <name>Mathias Unberath</name>
    </author>
    <link href="http://arxiv.org/abs/2503.02797v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2503.02797v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2503.02794v1</id>
    <updated>2025-03-04T17:11:16Z</updated>
    <published>2025-03-04T17:11:16Z</published>
    <title>Social hierarchy shapes foraging decisions</title>
    <summary>  Social foraging is a widespread form of animal foraging in which groups of
individuals coordinate their decisions to exploit resources in the environment.
Animals show a variety of social structures from egalitarian to hierarchical.
In this study, we examine how different forms of social hierarchy shape
foraging decisions. We developed a mechanistic analytically tractable model to
study the underlying processes of social foraging, tying the microscopic
individual to the macroscopic group levels. Based on a stochastic evidence
accumulation framework, we developed a model of patch-leaving decisions in a
large hierarchical group with leading and following individuals. Across a
variety of information sharing mechanisms, we were able to analytically
quantify emergent collective dynamics. We found that follower-leader dynamics
through observations of leader movements or through counting the number of
individuals in a patch confers, for most conditions, a benefit for the
following individuals by increasing their accuracy in inferring patch richness.
On the other hand, misinformation, through the communication of false beliefs
about food rewards or patch quality, shows to be detrimental to following
individuals, but paradoxically may lead to increased group cohesion. In an era
where there is a huge amount of animal foraging data collected, our model
provides a systematic way to conceptualize and understand those data by
uncovering hidden mechanisms underlying social foraging decisions.
</summary>
    <author>
      <name>Lisa Blum Moyse</name>
    </author>
    <author>
      <name>Ahmed El Hady</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:2412.02381</arxiv:comment>
    <link href="http://arxiv.org/abs/2503.02794v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2503.02794v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2503.02779v1</id>
    <updated>2025-03-04T16:52:07Z</updated>
    <published>2025-03-04T16:52:07Z</published>
    <title>Selective electron-phonon coupling strength from nonequilibrium optical
  spectroscopy: The case of MgB$_2$</title>
    <summary>  The coupling between quasiparticles and bosonic excitations rules the energy
transfer pathways in condensed matter systems. The possibility of inferring the
strength of specific coupling channels from their characteristic time scales
measured in nonequilibrium experiments is still an open question. Here, we
investigate MgB$_2$, in which conventional superconductivity at temperatures as
high as 39 K is mediated by the strong coupling between the conduction
electrons and the E$_{2g}$ phonon mode. By means of broadband time-resolved
optical spectroscopy, we show that this selective electron-phonon coupling
dictates the nonequilibrium optical response of MgB$_2$ at early times (&lt;100
fs) after photoexcitation. Furthermore, based on an effective temperature model
analysis, we estimate its contribution to the total electron-boson coupling
function extracted from complementary equilibrium spectroscopy approaches,
namely optical reflectivity and ARPES. The coupling strength with the E$_{2g}$
phonon modes is thus estimated to be $\lambda$ ~ 0.56, which is approximately
half of the total coupling constant, in agreement with ab-initio calculations
from the literature. As a benchmark, broadband time-resolved optical
spectroscopy is performed also on the isostructural and non-superconducting
compound AlB$_2$, showing that the nonequilibrium optical response relaxes on a
slower timescale due to the lack of strongly-coupled phonon modes. Our findings
demonstrate the possibility to resolve and quantify selective electron-phonon
coupling from nonequilibrium optical spectroscopy.
</summary>
    <author>
      <name>S. Mor</name>
    </author>
    <author>
      <name>F. Boschini</name>
    </author>
    <author>
      <name>E. Razzoli</name>
    </author>
    <author>
      <name>M. Zonno</name>
    </author>
    <author>
      <name>M. Michiardi</name>
    </author>
    <author>
      <name>G. Levy</name>
    </author>
    <author>
      <name>N. D. Zhigadlo</name>
    </author>
    <author>
      <name>P. C. Canfield</name>
    </author>
    <author>
      <name>G. Cerullo</name>
    </author>
    <author>
      <name>A. Damascelli</name>
    </author>
    <author>
      <name>C. Giannetti</name>
    </author>
    <author>
      <name>S. Dal Conte</name>
    </author>
    <link href="http://arxiv.org/abs/2503.02779v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2503.02779v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.supr-con" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.supr-con" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2503.02773v1</id>
    <updated>2025-03-04T16:42:46Z</updated>
    <published>2025-03-04T16:42:46Z</published>
    <title>Prime Convolutional Model: Breaking the Ground for Theoretical
  Explainability</title>
    <summary>  In this paper, we propose a new theoretical approach to Explainable AI.
Following the Scientific Method, this approach consists in formulating on the
basis of empirical evidence, a mathematical model to explain and predict the
behaviors of Neural Networks. We apply the method to a case study created in a
controlled environment, which we call Prime Convolutional Model (p-Conv for
short). p-Conv operates on a dataset consisting of the first one million
natural numbers and is trained to identify the congruence classes modulo a
given integer $m$. Its architecture uses a convolutional-type neural network
that contextually processes a sequence of $B$ consecutive numbers to each
input. We take an empirical approach and exploit p-Conv to identify the
congruence classes of numbers in a validation set using different values for
$m$ and $B$. The results show that the different behaviors of p-Conv (i.e.,
whether it can perform the task or not) can be modeled mathematically in terms
of $m$ and $B$. The inferred mathematical model reveals interesting patterns
able to explain when and why p-Conv succeeds in performing task and, if not,
which error pattern it follows.
</summary>
    <author>
      <name>Francesco Panelli</name>
    </author>
    <author>
      <name>Doaa Almhaithawi</name>
    </author>
    <author>
      <name>Tania Cerquitelli</name>
    </author>
    <author>
      <name>Alessandro Bellini</name>
    </author>
    <link href="http://arxiv.org/abs/2503.02773v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2503.02773v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2503.02745v1</id>
    <updated>2025-03-04T16:10:42Z</updated>
    <published>2025-03-04T16:10:42Z</published>
    <title>ArcPro: Architectural Programs for Structured 3D Abstraction of Sparse
  Points</title>
    <summary>  We introduce ArcPro, a novel learning framework built on architectural
programs to recover structured 3D abstractions from highly sparse and
low-quality point clouds. Specifically, we design a domain-specific language
(DSL) to hierarchically represent building structures as a program, which can
be efficiently converted into a mesh. We bridge feedforward and inverse
procedural modeling by using a feedforward process for training data synthesis,
allowing the network to make reverse predictions. We train an encoder-decoder
on the points-program pairs to establish a mapping from unstructured point
clouds to architectural programs, where a 3D convolutional encoder extracts
point cloud features and a transformer decoder autoregressively predicts the
programs in a tokenized form. Inference by our method is highly efficient and
produces plausible and faithful 3D abstractions. Comprehensive experiments
demonstrate that ArcPro outperforms both traditional architectural proxy
reconstruction and learning-based abstraction methods. We further explore its
potential to work with multi-view image and natural language inputs.
</summary>
    <author>
      <name>Qirui Huang</name>
    </author>
    <author>
      <name>Runze Zhang</name>
    </author>
    <author>
      <name>Kangjun Liu</name>
    </author>
    <author>
      <name>Minglun Gong</name>
    </author>
    <author>
      <name>Hao Zhang</name>
    </author>
    <author>
      <name>Hui Huang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">CVPR 2025 (Patent Protected); Project page:
  https://vcc.tech/research/2025/ArcPro</arxiv:comment>
    <link href="http://arxiv.org/abs/2503.02745v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2503.02745v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2503.02741v1</id>
    <updated>2025-03-04T16:05:13Z</updated>
    <published>2025-03-04T16:05:13Z</published>
    <title>Seeded Poisson Factorization: Leveraging domain knowledge to fit topic
  models</title>
    <summary>  Topic models are widely used for discovering latent thematic structures in
large text corpora, yet traditional unsupervised methods often struggle to
align with predefined conceptual domains. This paper introduces Seeded Poisson
Factorization (SPF), a novel approach that extends the Poisson Factorization
framework by incorporating domain knowledge through seed words. SPF enables a
more interpretable and structured topic discovery by modifying the prior
distribution of topic-specific term intensities, assigning higher initial rates
to predefined seed words. The model is estimated using variational inference
with stochastic gradient optimization, ensuring scalability to large datasets.
  We apply SPF to an Amazon customer feedback dataset, leveraging predefined
product categories as guiding structures. Our evaluation demonstrates that SPF
achieves superior classification performance compared to alternative guided
topic models, particularly in terms of computational efficiency and predictive
performance. Furthermore, robustness checks highlight SPF's ability to
adaptively balance domain knowledge and data-driven topic discovery, even in
cases of imperfect seed word selection. These results establish SPF as a
powerful and scalable alternative for integrating expert knowledge into topic
modeling, enhancing both interpretability and efficiency in real-world
applications.
</summary>
    <author>
      <name>Bernd Prostmaier</name>
    </author>
    <author>
      <name>Jan V√°vra</name>
    </author>
    <author>
      <name>Bettina Gr√ºn</name>
    </author>
    <author>
      <name>Paul Hofmarcher</name>
    </author>
    <link href="http://arxiv.org/abs/2503.02741v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2503.02741v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="econ.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
