<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-08-15T00:59:37Z -->
<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acausal%20inference%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:causal inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/SsRksLzRb0LuVhSmQ+N8WbAs+f8</id>
  <updated>2025-08-14T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">118887</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">10</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2508.09982v1</id>
    <updated>2025-08-13T17:55:31Z</updated>
    <published>2025-08-13T17:55:31Z</published>
    <title>2D bilayer electron-hole superfluidity with unequal and anisotropic
  masses</title>
    <summary>  We investigate the stability of electron-hole superfluidity in
two-dimensional bilayers with unequal and anisotropic effective masses. Using a
zero-temperature, self-consistent Hartree-Fock approach, we study two
experimentally relevant deviations from the ideal equal-mass isotropic case:
(i) isotropic but unequal conduction and valence band masses ($m_c^* \neq
m_v^*$), and (ii) equal average masses with orthogonal in-plane anisotropies
$(m_{c,x}^*, m^*_{c,y}) = (m_1^*, m_2^*)$ and $(m^*_{v,x}, m^*_{v,y}) = (m_2^*,
m_1^*)$. For both scenarios, we compute the order parameter and analyze the
BEC-BCS crossover as a function of layer separation and mass ratio. We find
that both mass imbalance and mass anisotropy reduce the pairing strength and
suppress the inferred critical temperature $T_c$ by breaking perfect Fermi
surface nesting, and shift the BEC-BCS crossover. Despite these effects,
superfluidity remains robust across the full range of densities and interlayer
separations considered, with no transition to an unpaired plasma state in the
absence of screening. Our results provide a baseline for understanding the
interplay of mass mismatch and anisotropy in current and emerging bilayer
platforms, including van der Waals heterostructures and anisotropic
two-dimensional semiconductors. Our work also establishes that Fermi surface
nesting is not a key ingredient for the bilayer superfluidity, which is always
the ground state for all electron-hole bilayers although the resultant $T_c$
depends on the parameter details and may very well be unmeasurably low for
large interlayer separations.
</summary>
    <author>
      <name>Jihang Zhu</name>
    </author>
    <author>
      <name>Sankar Das Sarma</name>
    </author>
    <link href="http://arxiv.org/abs/2508.09982v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.09982v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.supr-con" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.supr-con" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.str-el" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.09971v1</id>
    <updated>2025-08-13T17:39:09Z</updated>
    <published>2025-08-13T17:39:09Z</published>
    <title>Vision-driven River Following of UAV via Safe Reinforcement Learning
  using Semantic Dynamics Model</title>
    <summary>  Vision-driven autonomous river following by Unmanned Aerial Vehicles is
critical for applications such as rescue, surveillance, and environmental
monitoring, particularly in dense riverine environments where GPS signals are
unreliable. We formalize river following as a coverage control problem in which
the reward function is submodular, yielding diminishing returns as more unique
river segments are visited, thereby framing the task as a Submodular Markov
Decision Process. First, we introduce Marginal Gain Advantage Estimation, which
refines the reward advantage function by using a sliding window baseline
computed from historical episodic returns, thus aligning the advantage
estimation with the agent's evolving recognition of action value in
non-Markovian settings. Second, we develop a Semantic Dynamics Model based on
patchified water semantic masks that provides more interpretable and
data-efficient short-term prediction of future observations compared to latent
vision dynamics models. Third, we present the Constrained Actor Dynamics
Estimator architecture, which integrates the actor, the cost estimator, and SDM
for cost advantage estimation to form a model-based SafeRL framework capable of
solving partially observable Constrained Submodular Markov Decision Processes.
Simulation results demonstrate that MGAE achieves faster convergence and
superior performance over traditional critic-based methods like Generalized
Advantage Estimation. SDM provides more accurate short-term state predictions
that enable the cost estimator to better predict potential violations. Overall,
CADE effectively integrates safety regulation into model-based RL, with the
Lagrangian approach achieving the soft balance of reward and safety during
training, while the safety layer enhances performance during inference by hard
action overlay.
</summary>
    <author>
      <name>Zihan Wang</name>
    </author>
    <author>
      <name>Nina Mahmoudian</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to Robotics and Autonomous Systems (RAS) journal</arxiv:comment>
    <link href="http://arxiv.org/abs/2508.09971v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.09971v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.09968v1</id>
    <updated>2025-08-13T17:33:37Z</updated>
    <published>2025-08-13T17:33:37Z</published>
    <title>Noise Hypernetworks: Amortizing Test-Time Compute in Diffusion Models</title>
    <summary>  The new paradigm of test-time scaling has yielded remarkable breakthroughs in
Large Language Models (LLMs) (e.g. reasoning models) and in generative vision
models, allowing models to allocate additional computation during inference to
effectively tackle increasingly complex problems. Despite the improvements of
this approach, an important limitation emerges: the substantial increase in
computation time makes the process slow and impractical for many applications.
Given the success of this paradigm and its growing usage, we seek to preserve
its benefits while eschewing the inference overhead. In this work we propose
one solution to the critical problem of integrating test-time scaling knowledge
into a model during post-training. Specifically, we replace reward guided
test-time noise optimization in diffusion models with a Noise Hypernetwork that
modulates initial input noise. We propose a theoretically grounded framework
for learning this reward-tilted distribution for distilled generators, through
a tractable noise-space objective that maintains fidelity to the base model
while optimizing for desired characteristics. We show that our approach
recovers a substantial portion of the quality gains from explicit test-time
optimization at a fraction of the computational cost. Code is available at
https://github.com/ExplainableML/HyperNoise
</summary>
    <author>
      <name>Luca Eyring</name>
    </author>
    <author>
      <name>Shyamgopal Karthik</name>
    </author>
    <author>
      <name>Alexey Dosovitskiy</name>
    </author>
    <author>
      <name>Nataniel Ruiz</name>
    </author>
    <author>
      <name>Zeynep Akata</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Project page: https://noisehypernetworks.github.io/</arxiv:comment>
    <link href="http://arxiv.org/abs/2508.09968v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.09968v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.09965v1</id>
    <updated>2025-08-13T17:32:14Z</updated>
    <published>2025-08-13T17:32:14Z</published>
    <title>GW231123: a Possible Primordial Black Hole Origin</title>
    <summary>  GW231123, the heaviest binary black hole merger detected by the
LIGO-Virgo-KAGRA collaboration to date, lies in the pair-instability mass gap
and exhibits unusually high component spins. In this letter, we show that both
merging black holes may have a primordial origin with smaller initial masses.
The observed masses and, crucially, the spins of GW231123 are naturally
accommodated within the most vanilla primordial black hole framework, once
cosmological accretion is taken into account. Interestingly, the parameter
space needed to explain the inferred GW231123 rate is at the edge of the
exclusion region from Xray and CMB observations, suggesting that this
interpretation can be either confirmed or ruled out. The upcoming O5 observing
run by the collaboration should detect ${\cal O}(20)$ similar events, testing
their mass-spin correlation, while next-generation detectors would be capable
of observing high redshift events, as predicted in this scenario.
</summary>
    <author>
      <name>Valerio De Luca</name>
    </author>
    <author>
      <name>Gabriele Franciolini</name>
    </author>
    <author>
      <name>Antonio Riotto</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2508.09965v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.09965v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.HE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="gr-qc" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.09951v1</id>
    <updated>2025-08-13T17:11:25Z</updated>
    <published>2025-08-13T17:11:25Z</published>
    <title>Tight correlation of star formation with [Ci] and CO lines across cosmic
  time</title>
    <summary>  Context. Cold molecular gas tracers, such as CI and CO lines, have been
widely used to infer specific characteristics of the ISM and to derive
star-formation relations among galaxies. Aims. However, there is still a lack
of systematic studies of the star-formation scaling relation of CO and [CI]
lines across cosmic time on multiple physical scales. Methods. We used
observations of the ground state transitions of [CI], CO, and [CII], for 885
sources collected from the literature, to infer possible correlations between
line luminosities of $\rm L^{'}_{[CI](1-0)}, \rm L^{'}_{CO(1-0)}$, and $\rm
L^{'}_{[CII]}$ with star formation rates (SFR). With linear regression, we fit
the relations between SFR and molecular mass derived from CO, CI, and CII
lines. Results. The relation between [CI] and CO-based total molecular masses
is weakly superlinear. Nevertheless, they can be calibrated against each other.
For $\rm \alpha_{CO} = 0.8$ and $4.0\ \rm
{M}_{\odot}\,({K}\,{km}\,{s}^{-1}\,{pc}^2)^{-1}$ we derive $\alpha_{\rm [CI]} =
3.9$ and $\sim$$17\ \rm {M}_{\odot}\,({K}\,{km}\,{s}^{-1}\,{pc}^2)^{-1}$ ,
respectively. Using the \emph{lmfit} package, we derived relation slopes of
SFR--$\rm L^{'}_{[CI](1-0)}$, SFR--$\rm L^{'}_{CO(1-0)}$, and SFR--$\rm
L^{'}_{[CII](1-0)}$ to be $\rm \beta$ = 1.06 $\pm$ 0.02, 1.24 $\pm$ 0.02, and
0.74 $\pm$ 0.02, respectively. With a Bayesian-inference \emph{linmix} method,
we find consistent results. Conclusions. Our relations for [CI](1-0) and
CO(1-0) indicate that they trace similar molecular gas contents, across
different redshifts and different types of galaxies. This suggests that these
correlations do not have strong evolution with cosmic time.
</summary>
    <author>
      <name>Theodoros Topkaras</name>
    </author>
    <author>
      <name>Thomas G. Bisbas</name>
    </author>
    <author>
      <name>Zhi-Yu Zhang</name>
    </author>
    <author>
      <name>V. Ossenkopf-Okada</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 5 figure, Accepted for publication in A&amp;A</arxiv:comment>
    <link href="http://arxiv.org/abs/2508.09951v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.09951v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.GA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.GA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.09950v1</id>
    <updated>2025-08-13T17:11:20Z</updated>
    <published>2025-08-13T17:11:20Z</published>
    <title>PPL: Point Cloud Supervised Proprioceptive Locomotion Reinforcement
  Learning for Legged Robots in Crawl Spaces</title>
    <summary>  The legged locomotion in spatially constrained structures (called crawl
spaces) is challenging. In crawl spaces, current exteroceptive locomotion
learning methods are limited by large noises and errors of the sensors in
possible low visibility conditions, and current proprioceptive locomotion
learning methods are difficult in traversing crawl spaces because only ground
features are inferred. In this study, a point cloud supervised proprioceptive
locomotion reinforcement learning method for legged robots in crawl spaces is
proposed. A state estimation network is designed to estimate the robot's
surrounding ground and spatial features as well as the robot's collision states
using historical proprioceptive sensor data. The point cloud is represented in
polar coordinate frame and a point cloud processing method is proposed to
efficiently extract the ground and spatial features that are used to supervise
the state estimation network learning. Comprehensive reward functions that
guide the robot to traverse through crawl spaces after collisions are designed.
Experiments demonstrate that, compared to existing methods, our method exhibits
more agile locomotion in crawl spaces. This study enhances the ability of
legged robots to traverse spatially constrained environments without requiring
exteroceptive sensors.
</summary>
    <author>
      <name>Bida Ma</name>
    </author>
    <author>
      <name>Nuo Xu</name>
    </author>
    <author>
      <name>Chenkun Qi</name>
    </author>
    <author>
      <name>Xin Liu</name>
    </author>
    <author>
      <name>Yule Mo</name>
    </author>
    <author>
      <name>Jinkai Wang</name>
    </author>
    <author>
      <name>Chunpeng Lu</name>
    </author>
    <link href="http://arxiv.org/abs/2508.09950v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.09950v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.09949v1</id>
    <updated>2025-08-13T17:08:22Z</updated>
    <published>2025-08-13T17:08:22Z</published>
    <title>Stable Diffusion Models are Secretly Good at Visual In-Context Learning</title>
    <summary>  Large language models (LLM) in natural language processing (NLP) have
demonstrated great potential for in-context learning (ICL) -- the ability to
leverage a few sets of example prompts to adapt to various tasks without having
to explicitly update the model weights. ICL has recently been explored for
computer vision tasks with promising early outcomes. These approaches involve
specialized training and/or additional data that complicate the process and
limit its generalizability. In this work, we show that off-the-shelf Stable
Diffusion models can be repurposed for visual in-context learning (V-ICL).
Specifically, we formulate an in-place attention re-computation within the
self-attention layers of the Stable Diffusion architecture that explicitly
incorporates context between the query and example prompts. Without any
additional fine-tuning, we show that this repurposed Stable Diffusion model is
able to adapt to six different tasks: foreground segmentation, single object
detection, semantic segmentation, keypoint detection, edge detection, and
colorization. For example, the proposed approach improves the mean intersection
over union (mIoU) for the foreground segmentation task on Pascal-5i dataset by
8.9% and 3.2% over recent methods such as Visual Prompting and IMProv,
respectively. Additionally, we show that the proposed method is able to
effectively leverage multiple prompts through ensembling to infer the task
better and further improve the performance.
</summary>
    <author>
      <name>Trevine Oorloff</name>
    </author>
    <author>
      <name>Vishwanath Sindagi</name>
    </author>
    <author>
      <name>Wele Gedara Chaminda Bandara</name>
    </author>
    <author>
      <name>Ali Shafahi</name>
    </author>
    <author>
      <name>Amin Ghiasi</name>
    </author>
    <author>
      <name>Charan Prakash</name>
    </author>
    <author>
      <name>Reza Ardekani</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to ICCV 2025</arxiv:comment>
    <link href="http://arxiv.org/abs/2508.09949v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.09949v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.09943v1</id>
    <updated>2025-08-13T16:57:49Z</updated>
    <published>2025-08-13T16:57:49Z</published>
    <title>AST-n: A Fast Sampling Approach for Low-Dose CT Reconstruction using
  Diffusion Models</title>
    <summary>  Low-dose CT (LDCT) protocols reduce radiation exposure but increase image
noise, compromising diagnostic confidence. Diffusion-based generative models
have shown promise for LDCT denoising by learning image priors and performing
iterative refinement. In this work, we introduce AST-n, an accelerated
inference framework that initiates reverse diffusion from intermediate noise
levels, and integrate high-order ODE solvers within conditioned models to
further reduce sampling steps. We evaluate two acceleration paradigms--AST-n
sampling and standard scheduling with high-order solvers -- on the Low Dose CT
Grand Challenge dataset, covering head, abdominal, and chest scans at 10-25 %
of standard dose. Conditioned models using only 25 steps (AST-25) achieve peak
signal-to-noise ratio (PSNR) above 38 dB and structural similarity index (SSIM)
above 0.95, closely matching standard baselines while cutting inference time
from ~16 seg to under 1 seg per slice. Unconditional sampling suffers
substantial quality loss, underscoring the necessity of conditioning. We also
assess DDIM inversion, which yields marginal PSNR gains at the cost of doubling
inference time, limiting its clinical practicality. Our results demonstrate
that AST-n with high-order samplers enables rapid LDCT reconstruction without
significant loss of image fidelity, advancing the feasibility of
diffusion-based methods in clinical workflows.
</summary>
    <author>
      <name>Tomás de la Sotta</name>
    </author>
    <author>
      <name>José M. Saavedra</name>
    </author>
    <author>
      <name>Héctor Henríquez</name>
    </author>
    <author>
      <name>Violeta Chang</name>
    </author>
    <author>
      <name>Aline Xavier</name>
    </author>
    <link href="http://arxiv.org/abs/2508.09943v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.09943v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.09937v1</id>
    <updated>2025-08-13T16:42:01Z</updated>
    <published>2025-08-13T16:42:01Z</published>
    <title>A Comprehensive Evaluation framework of Alignment Techniques for LLMs</title>
    <summary>  As Large Language Models (LLMs) become increasingly integrated into
real-world applications, ensuring their outputs align with human values and
safety standards has become critical. The field has developed diverse alignment
approaches including traditional fine-tuning methods (RLHF, instruction
tuning), post-hoc correction systems, and inference-time interventions, each
with distinct advantages and limitations. However, the lack of unified
evaluation frameworks makes it difficult to systematically compare these
paradigms and guide deployment decisions. This paper introduces a
multi-dimensional evaluation of alignment techniques for LLMs, a comprehensive
evaluation framework that provides a systematic comparison across all major
alignment paradigms. Our framework assesses methods along four key dimensions:
alignment detection, alignment quality, computational efficiency, and
robustness. Through experiments across diverse base models and alignment
strategies, we demonstrate the utility of our framework in identifying
strengths and limitations of current state-of-the-art models, providing
valuable insights for future research directions.
</summary>
    <author>
      <name>Muneeza Azmat</name>
    </author>
    <author>
      <name>Momin Abbas</name>
    </author>
    <author>
      <name>Maysa Malfiza Garcia de Macedo</name>
    </author>
    <author>
      <name>Marcelo Carpinette Grave</name>
    </author>
    <author>
      <name>Luan Soares de Souza</name>
    </author>
    <author>
      <name>Tiago Machado</name>
    </author>
    <author>
      <name>Rogerio A de Paula</name>
    </author>
    <author>
      <name>Raya Horesh</name>
    </author>
    <author>
      <name>Yixin Chen</name>
    </author>
    <author>
      <name>Heloisa Caroline de Souza Pereira Candello</name>
    </author>
    <author>
      <name>Rebecka Nordenlow</name>
    </author>
    <author>
      <name>Aminat Adebiyi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.48550/arXiv.2508.09937</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.48550/arXiv.2508.09937" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In submission</arxiv:comment>
    <link href="http://arxiv.org/abs/2508.09937v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.09937v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.09926v1</id>
    <updated>2025-08-13T16:24:15Z</updated>
    <published>2025-08-13T16:24:15Z</published>
    <title>Towards Comprehensive Cellular Characterisation of H&amp;E slides</title>
    <summary>  Cell detection, segmentation and classification are essential for analyzing
tumor microenvironments (TME) on hematoxylin and eosin (H&amp;E) slides. Existing
methods suffer from poor performance on understudied cell types (rare or not
present in public datasets) and limited cross-domain generalization. To address
these shortcomings, we introduce HistoPLUS, a state-of-the-art model for cell
analysis, trained on a novel curated pan-cancer dataset of 108,722 nuclei
covering 13 cell types. In external validation across 4 independent cohorts,
HistoPLUS outperforms current state-of-the-art models in detection quality by
5.2% and overall F1 classification score by 23.7%, while using 5x fewer
parameters. Notably, HistoPLUS unlocks the study of 7 understudied cell types
and brings significant improvements on 8 of 13 cell types. Moreover, we show
that HistoPLUS robustly transfers to two oncology indications unseen during
training. To support broader TME biomarker research, we release the model
weights and inference code at https://github.com/owkin/histoplus/.
</summary>
    <author>
      <name>Benjamin Adjadj</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Owkin</arxiv:affiliation>
    </author>
    <author>
      <name>Pierre-Antoine Bannier</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Owkin</arxiv:affiliation>
    </author>
    <author>
      <name>Guillaume Horent</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Owkin</arxiv:affiliation>
    </author>
    <author>
      <name>Sebastien Mandela</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Owkin</arxiv:affiliation>
    </author>
    <author>
      <name>Aurore Lyon</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Owkin</arxiv:affiliation>
    </author>
    <author>
      <name>Kathryn Schutte</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Owkin</arxiv:affiliation>
    </author>
    <author>
      <name>Ulysse Marteau</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Owkin</arxiv:affiliation>
    </author>
    <author>
      <name>Valentin Gaury</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Owkin</arxiv:affiliation>
    </author>
    <author>
      <name>Laura Dumont</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Owkin</arxiv:affiliation>
    </author>
    <author>
      <name>Thomas Mathieu</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Owkin</arxiv:affiliation>
    </author>
    <author>
      <name>Reda Belbahri</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Owkin</arxiv:affiliation>
    </author>
    <author>
      <name>Benoît Schmauch</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Owkin</arxiv:affiliation>
    </author>
    <author>
      <name>Eric Durand</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Owkin</arxiv:affiliation>
    </author>
    <author>
      <name>Katharina Von Loga</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Owkin</arxiv:affiliation>
    </author>
    <author>
      <name>Lucie Gillet</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Owkin</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">33 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2508.09926v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.09926v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.10; I.4.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
