<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-06-27T00:59:01Z -->
<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acausal%20inference%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:causal inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/SsRksLzRb0LuVhSmQ+N8WbAs+f8</id>
  <updated>2025-06-26T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">115772</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">10</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2506.20657v1</id>
    <updated>2025-06-25T17:52:26Z</updated>
    <published>2025-06-25T17:52:26Z</published>
    <title>SuperSONIC: Cloud-Native Infrastructure for ML Inferencing</title>
    <summary>  The increasing computational demand from growing data rates and complex
machine learning (ML) algorithms in large-scale scientific experiments has
driven the adoption of the Services for Optimized Network Inference on
Coprocessors (SONIC) approach. SONIC accelerates ML inference by offloading it
to local or remote coprocessors to optimize resource utilization. Leveraging
its portability to different types of coprocessors, SONIC enhances data
processing and model deployment efficiency for cutting-edge research in high
energy physics (HEP) and multi-messenger astrophysics (MMA). We developed the
SuperSONIC project, a scalable server infrastructure for SONIC, enabling the
deployment of computationally intensive tasks to Kubernetes clusters equipped
with graphics processing units (GPUs). Using NVIDIA Triton Inference Server,
SuperSONIC decouples client workflows from server infrastructure, standardizing
communication, optimizing throughput, load balancing, and monitoring.
SuperSONIC has been successfully deployed for the CMS and ATLAS experiments at
the CERN Large Hadron Collider (LHC), the IceCube Neutrino Observatory
(IceCube), and the Laser Interferometer Gravitational-Wave Observatory (LIGO)
and tested on Kubernetes clusters at Purdue University, the National Research
Platform (NRP), and the University of Chicago. SuperSONIC addresses the
challenges of the Cloud-native era by providing a reusable, configurable
framework that enhances the efficiency of accelerator-based inference
deployment across diverse scientific domains and industries.
</summary>
    <author>
      <name>Dmitry Kondratyev</name>
    </author>
    <author>
      <name>Benedikt Riedel</name>
    </author>
    <author>
      <name>Yuan-Tang Chou</name>
    </author>
    <author>
      <name>Miles Cochran-Branson</name>
    </author>
    <author>
      <name>Noah Paladino</name>
    </author>
    <author>
      <name>David Schultz</name>
    </author>
    <author>
      <name>Mia Liu</name>
    </author>
    <author>
      <name>Javier Duarte</name>
    </author>
    <author>
      <name>Philip Harris</name>
    </author>
    <author>
      <name>Shih-Chieh Hsu</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3708035.3736049</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3708035.3736049" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submission to PEARC25 Conference</arxiv:comment>
    <link href="http://arxiv.org/abs/2506.20657v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.20657v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-ex" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ins-det" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.20639v2</id>
    <updated>2025-06-26T15:46:40Z</updated>
    <published>2025-06-25T17:35:47Z</published>
    <title>DiffuCoder: Understanding and Improving Masked Diffusion Models for Code
  Generation</title>
    <summary>  Diffusion large language models (dLLMs) are compelling alternatives to
autoregressive (AR) models because their denoising models operate over the
entire sequence. The global planning and iterative refinement features of dLLMs
are particularly useful for code generation. However, current training and
inference mechanisms for dLLMs in coding are still under-explored. To demystify
the decoding behavior of dLLMs and unlock their potential for coding, we
systematically investigate their denoising processes and reinforcement learning
(RL) methods. We train a 7B dLLM, \textbf{DiffuCoder}, on 130B tokens of code.
Using this model as a testbed, we analyze its decoding behavior, revealing how
it differs from that of AR models: (1) dLLMs can decide how causal their
generation should be without relying on semi-AR decoding, and (2) increasing
the sampling temperature diversifies not only token choices but also their
generation order. This diversity creates a rich search space for RL rollouts.
For RL training, to reduce the variance of token log-likelihood estimates and
maintain training efficiency, we propose \textbf{coupled-GRPO}, a novel
sampling scheme that constructs complementary mask noise for completions used
in training. In our experiments, coupled-GRPO significantly improves
DiffuCoder's performance on code generation benchmarks (+4.4\% on EvalPlus) and
reduces reliance on AR bias during decoding. Our work provides deeper insight
into the machinery of dLLM generation and offers an effective, diffusion-native
RL training framework. https://github.com/apple/ml-diffucoder.
</summary>
    <author>
      <name>Shansan Gong</name>
    </author>
    <author>
      <name>Ruixiang Zhang</name>
    </author>
    <author>
      <name>Huangjie Zheng</name>
    </author>
    <author>
      <name>Jiatao Gu</name>
    </author>
    <author>
      <name>Navdeep Jaitly</name>
    </author>
    <author>
      <name>Lingpeng Kong</name>
    </author>
    <author>
      <name>Yizhe Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">minor update</arxiv:comment>
    <link href="http://arxiv.org/abs/2506.20639v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.20639v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.20596v1</id>
    <updated>2025-06-25T16:36:02Z</updated>
    <published>2025-06-25T16:36:02Z</published>
    <title>Inference for Error-Prone Count Data: Estimation under a Binomial
  Convolution Framework</title>
    <summary>  Measurement error in count data is common but underexplored in the
literature, particularly in contexts where observed scores are bounded and
arise from discrete scoring processes. Motivated by applications in oral
reading fluency assessment, we propose a binomial convolution framework that
extends binary misclassification models to settings where only the aggregate
number of correct responses is observed, and errors may involve both
overcounting and undercounting the number of events. The model accommodates
distinct true positive and true negative accuracy rates and preserves the
bounded nature of the data.
  Assuming the availability of both contaminated and error-free scores on a
subset of items, we develop and compare three estimation strategies: maximum
likelihood estimation (MLE), linear regression, and generalized method of
moments (GMM). Extensive simulations show that MLE is most accurate when the
model is correctly specified but is computationally intensive and less robust
to misspecification. Regression is simple and stable but less precise, while
GMM offers a compromise in model dependence, though it is sensitive to
outliers.
  In practice, this framework supports improved inference in unsupervised
settings where contaminated scores serve as inputs to downstream analyses. By
quantifying accuracy rates, the model enables score corrections even when no
specific outcome is yet defined. We demonstrate its utility using real oral
reading fluency data, comparing human and AI-generated scores. Findings
highlight the practical implications of estimator choice and underscore the
importance of explicitly modeling asymmetric measurement error in count data.
</summary>
    <author>
      <name>Yuqiu Yang</name>
    </author>
    <author>
      <name>Christina Vu</name>
    </author>
    <author>
      <name>Cornelis J. Potgieter</name>
    </author>
    <author>
      <name>Xinlei Wang</name>
    </author>
    <author>
      <name>Akihito Kamata</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">40 pages, 6 figures, 3 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2506.20596v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.20596v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.20586v1</id>
    <updated>2025-06-25T16:26:55Z</updated>
    <published>2025-06-25T16:26:55Z</published>
    <title>Learning-Based Distance Estimation for 360° Single-Sensor Setups</title>
    <summary>  Accurate distance estimation is a fundamental challenge in robotic
perception, particularly in omnidirectional imaging, where traditional
geometric methods struggle with lens distortions and environmental variability.
In this work, we propose a neural network-based approach for monocular distance
estimation using a single 360{\deg} fisheye lens camera. Unlike classical
trigonometric techniques that rely on precise lens calibration, our method
directly learns and infers the distance of objects from raw omnidirectional
inputs, offering greater robustness and adaptability across diverse conditions.
We evaluate our approach on three 360{\deg} datasets (LOAF, ULM360, and a newly
captured dataset Boat360), each representing distinct environmental and sensor
setups. Our experimental results demonstrate that the proposed learning-based
model outperforms traditional geometry-based methods and other learning
baselines in both accuracy and robustness. These findings highlight the
potential of deep learning for real-time omnidirectional distance estimation,
making our approach particularly well-suited for low-cost applications in
robotics, autonomous navigation, and surveillance.
</summary>
    <author>
      <name>Yitong Quan</name>
    </author>
    <author>
      <name>Benjamin Kiefer</name>
    </author>
    <author>
      <name>Martin Messmer</name>
    </author>
    <author>
      <name>Andreas Zell</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to ECMR 2025</arxiv:comment>
    <link href="http://arxiv.org/abs/2506.20586v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.20586v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.20585v1</id>
    <updated>2025-06-25T16:26:01Z</updated>
    <published>2025-06-25T16:26:01Z</published>
    <title>On the Impact of Sybil-based Attacks on Mobile Crowdsensing for
  Transportation</title>
    <summary>  Mobile Crowd-Sensing (MCS) enables users with personal mobile devices (PMDs)
to gain information on their surroundings. Users collect and contribute data on
different phenomena using their PMD sensors, and the MCS system processes this
data to extract valuable information for end users. Navigation MCS-based
applications (N-MCS) are prevalent and important for transportation: users
share their location and speed while driving and, in return, find efficient
routes to their destinations. However, N-MCS are currently vulnerable to
malicious contributors, often termed Sybils: submitting falsified data,
seemingly from many devices that are not truly present on target roads, falsely
reporting congestion when there is none, thus changing the road status the
N-MCS infers. The attack effect is that the N-MCS returns suboptimal routes to
users, causing late arrival and, overall, deteriorating road traffic flow. We
investigate exactly the impact of Sybil-based attacks on N-MCS: we design an
N-MCS system that offers efficient routing on top of the vehicular simulator
SUMO, using the InTAS road network as our scenario. We design experiments
attacking an individual N-MCS user as well as a larger population of users,
selecting the adversary targets based on graph-theoretical arguments. Our
experiments show that the resources required for a successful attack depend on
the location of the attack (i.e., the surrounding road network and traffic) and
the extent of Sybil contributed data for the targeted road(s). We demonstrate
that Sybil attacks can alter the route of N-MCS users, increasing average
travel time by 20% with Sybils 3% of the N-MCS user population.
</summary>
    <author>
      <name>Alexander Söderhäll</name>
    </author>
    <author>
      <name>Zahra Alimadadi</name>
    </author>
    <author>
      <name>Panos Papadimitratos</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/PerComWorkshops65533.2025.00113</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/PerComWorkshops65533.2025.00113" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 5 figures, 2 tables, TrustSense workshop of PerCom 2025</arxiv:comment>
    <link href="http://arxiv.org/abs/2506.20585v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.20585v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.20582v1</id>
    <updated>2025-06-25T16:17:36Z</updated>
    <published>2025-06-25T16:17:36Z</published>
    <title>Causal Representation Learning with Observational Grouping for CXR
  Classification</title>
    <summary>  Identifiable causal representation learning seeks to uncover the true causal
relationships underlying a data generation process. In medical imaging, this
presents opportunities to improve the generalisability and robustness of
task-specific latent features. This work introduces the concept of grouping
observations to learn identifiable representations for disease classification
in chest X-rays via an end-to-end framework. Our experiments demonstrate that
these causal representations improve generalisability and robustness across
multiple classification tasks when grouping is used to enforce invariance w.r.t
race, sex, and imaging views.
</summary>
    <author>
      <name>Rajat Rasal</name>
    </author>
    <author>
      <name>Avinash Kori</name>
    </author>
    <author>
      <name>Ben Glocker</name>
    </author>
    <link href="http://arxiv.org/abs/2506.20582v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.20582v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.20579v1</id>
    <updated>2025-06-25T16:14:17Z</updated>
    <published>2025-06-25T16:14:17Z</published>
    <title>Communication-Aware Map Compression for Online Path-Planning: A
  Rate-Distortion Approach</title>
    <summary>  This paper addresses the problem of collaborative navigation in an unknown
environment, where two robots, referred to in the sequel as the Seeker and the
Supporter, traverse the space simultaneously. The Supporter assists the Seeker
by transmitting a compressed representation of its local map under bandwidth
constraints to support the Seeker's path-planning task. We introduce a bit-rate
metric based on the expected binary codeword length to quantify communication
cost. Using this metric, we formulate the compression design problem as a
rate-distortion optimization problem that determines when to communicate, which
regions of the map should be included in the compressed representation, and at
what resolution (i.e., quantization level) they should be encoded. Our
formulation allows different map regions to be encoded at varying quantization
levels based on their relevance to the Seeker's path-planning task. We
demonstrate that the resulting optimization problem is convex, and admits a
closed-form solution known in the information theory literature as reverse
water-filling, enabling efficient, low-computation, and real-time
implementation. Additionally, we show that the Seeker can infer the compression
decisions of the Supporter independently, requiring only the encoded map
content and not the encoding policy itself to be transmitted, thereby reducing
communication overhead. Simulation results indicate that our method effectively
constructs compressed, task-relevant map representations, both in content and
resolution, that guide the Seeker's planning decisions even under tight
bandwidth limitations.
</summary>
    <author>
      <name>Ali Reza Pedram</name>
    </author>
    <author>
      <name>Evangelos Psomiadis</name>
    </author>
    <author>
      <name>Dipankar Maity</name>
    </author>
    <author>
      <name>Panagiotis Tsiotras</name>
    </author>
    <link href="http://arxiv.org/abs/2506.20579v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.20579v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.20576v1</id>
    <updated>2025-06-25T16:10:20Z</updated>
    <published>2025-06-25T16:10:20Z</published>
    <title>Vulnerability Disclosure through Adaptive Black-Box Adversarial Attacks
  on NIDS</title>
    <summary>  Adversarial attacks, wherein slight inputs are carefully crafted to mislead
intelligent models, have attracted increasing attention. However, a critical
gap persists between theoretical advancements and practical application,
particularly in structured data like network traffic, where interdependent
features complicate effective adversarial manipulations. Moreover, ambiguity in
current approaches restricts reproducibility and limits progress in this field.
Hence, existing defenses often fail to handle evolving adversarial attacks.
This paper proposes a novel approach for black-box adversarial attacks, that
addresses these limitations. Unlike prior work, which often assumes system
access or relies on repeated probing, our method strictly respect black-box
constraints, reducing interaction to avoid detection and better reflect
real-world scenarios. We present an adaptive feature selection strategy using
change-point detection and causality analysis to identify and target sensitive
features to perturbations. This lightweight design ensures low computational
cost and high deployability. Our comprehensive experiments show the attack's
effectiveness in evading detection with minimal interaction, enhancing its
adaptability and applicability in real-world scenarios. By advancing the
understanding of adversarial attacks in network traffic, this work lays a
foundation for developing robust defenses.
</summary>
    <author>
      <name>Sabrine Ennaji</name>
    </author>
    <author>
      <name>Elhadj Benkhelifa</name>
    </author>
    <author>
      <name>Luigi V. Mancini</name>
    </author>
    <link href="http://arxiv.org/abs/2506.20576v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.20576v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.20573v1</id>
    <updated>2025-06-25T16:07:59Z</updated>
    <published>2025-06-25T16:07:59Z</published>
    <title>LARP: Learner-Agnostic Robust Data Prefiltering</title>
    <summary>  The widespread availability of large public datasets is a key factor behind
the recent successes of statistical inference and machine learning methods.
However, these datasets often contain some low-quality or contaminated data, to
which many learning procedures are sensitive. Therefore, the question of
whether and how public datasets should be prefiltered to facilitate accurate
downstream learning arises. On a technical level this requires the construction
of principled data prefiltering methods which are learner-agnostic robust, in
the sense of provably protecting a set of pre-specified downstream learners
from corrupted data. In this work, we formalize the problem of Learner-Agnostic
Robust data Prefiltering (LARP), which aims at finding prefiltering procedures
that minimize a worst-case loss over a pre-specified set of learners. We first
instantiate our framework in the context of scalar mean estimation with Huber
estimators under the Huber data contamination model. We provide a hardness
result on a specific problem instance and analyze several natural prefiltering
procedures. Our theoretical results indicate that performing LARP on a
heterogeneous set of learners leads to some loss in model performance compared
to the alternative of prefiltering data for each learner/use-case individually.
We explore the resulting utility loss and its dependence on the problem
parameters via extensive experiments on real-world image and tabular data,
observing statistically significant reduction in utility. Finally, we model the
trade-off between the utility drop and the cost of repeated (learner-specific)
prefiltering within a game-theoretic framework and showcase benefits of LARP
for large datasets.
</summary>
    <author>
      <name>Kristian Minchev</name>
    </author>
    <author>
      <name>Dimitar Iliev Dimitrov</name>
    </author>
    <author>
      <name>Nikola Konstantinov</name>
    </author>
    <link href="http://arxiv.org/abs/2506.20573v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.20573v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.20558v1</id>
    <updated>2025-06-25T15:56:07Z</updated>
    <published>2025-06-25T15:56:07Z</published>
    <title>CCISolver: End-to-End Detection and Repair of Method-Level Code-Comment
  Inconsistency</title>
    <summary>  Comments within code serve as a crucial foundation for software
documentation, facilitating developers to communicate and understand the code
effectively. However, code-comment inconsistency (CCI) can negatively affect
software development, testing, and maintenance. Recent efforts to mitigate this
issue have emerged, but existing studies often suffer from inaccurate datasets
and inadequate solutions, weakening their practical effectiveness. In this
study, we first conduct a quantitative analysis of existing datasets, revealing
a substantial portion of sampled data are mislabeled. To address these data
limitations, we introduce CCIBench, a refined dataset comprising high-quality
data, to support the training and evaluation of method-level CCI methods.
Furthermore, we present an innovative end-to-end LLM-based framework,
CCISolver, designed to improve code quality by identifying and rectifying CCIs.
Comprehensive evaluations demonstrate CCISolver's superior performance. For
detection, it establishes a new state-of-the-art with an F1-score of 89.54%. In
fixing task, it achieves a remarkable 18.84% relative improvement in GLEU score
over the strongest baseline. This superiority is confirmed by human evaluation,
where CCISolver's fixing success rate of 0.6533 significantly surpasses
existing methods. Critically, in a practical end-to-end setting, CCISolver's
innovative architecture is approximately 36% faster for inference than the
baseline model, underscoring its scalability and real-world applicability.
</summary>
    <author>
      <name>Renyi Zhong</name>
    </author>
    <author>
      <name>Yintong Huo</name>
    </author>
    <author>
      <name>Wenwei Gu</name>
    </author>
    <author>
      <name>Jinxi Kuang</name>
    </author>
    <author>
      <name>Zhihan Jiang</name>
    </author>
    <author>
      <name>Guangba Yu</name>
    </author>
    <author>
      <name>Yichen Li</name>
    </author>
    <author>
      <name>David Lo</name>
    </author>
    <author>
      <name>Michael R. Lyu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This manuscript is under review</arxiv:comment>
    <link href="http://arxiv.org/abs/2506.20558v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.20558v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
