<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-11-17T00:58:04Z -->
<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/" xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns="http://www.w3.org/2005/Atom">
  <id>https://arxiv.org/api/p6EyKyP4fMY/66n9Ev8E79F7KlI</id>
  <title>arXiv Query: search_query=all:causal OR all:inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <updated>2025-11-17T00:58:04Z</updated>
  <link href="https://arxiv.org/api/query?search_query=all:causal+OR+all:inference&amp;start=0&amp;max_results=10&amp;id_list=" type="application/atom+xml"/>
  <opensearch:itemsPerPage>10</opensearch:itemsPerPage>
  <opensearch:totalResults>126099</opensearch:totalResults>
  <opensearch:startIndex>0</opensearch:startIndex>
  <entry>
    <id>http://arxiv.org/abs/2511.10645v1</id>
    <title>ParoQuant: Pairwise Rotation Quantization for Efficient Reasoning LLM Inference</title>
    <updated>2025-11-13T18:59:24Z</updated>
    <link href="https://arxiv.org/abs/2511.10645v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2511.10645v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Weight-only post-training quantization (PTQ) compresses the weights of Large Language Models (LLMs) into low-precision representations to reduce memory footprint and accelerate inference. However, the presence of outliers in weights and activations often leads to large quantization errors and severe accuracy degradation, especially in recent reasoning LLMs where errors accumulate across long chains of thought. Existing PTQ methods either fail to sufficiently suppress outliers or introduce significant overhead during inference. In this paper, we propose Pairwise Rotation Quantization (ParoQuant), a weight-only PTQ method that combines hardware-efficient and optimizable independent Givens rotations with channel-wise scaling to even out the magnitude across channels and narrow the dynamic range within each quantization group. We further co-design the inference kernel to fully exploit GPU parallelism and keep the rotations and scaling lightweight at runtime. ParoQuant achieves an average 2.4% accuracy improvement over AWQ on reasoning tasks with less than 10% overhead. This paves the way for more efficient and accurate deployment of reasoning LLMs.</summary>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-11-13T18:59:24Z</published>
    <arxiv:primary_category term="cs.CL"/>
    <author>
      <name>Yesheng Liang</name>
    </author>
    <author>
      <name>Haisheng Chen</name>
    </author>
    <author>
      <name>Song Han</name>
    </author>
    <author>
      <name>Zhijian Liu</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2511.10640v1</id>
    <title>Flexible Simulation Based Inference for Galaxy Photometric Fitting with Synthesizer</title>
    <updated>2025-11-13T18:56:48Z</updated>
    <link href="https://arxiv.org/abs/2511.10640v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2511.10640v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>We introduce Synference, a new, flexible Python framework for galaxy SED fitting using simulation-based inference (SBI). Synference leverages the Synthesizer package for flexible forward-modelling of galaxy SEDs and integrates the LtU-ILI package to ensure best practices in model training and validation. In this work we demonstrate Synference by training a neural posterior estimator on $10^6$ simulated galaxies, based on a flexible 8-parameter physical model, to infer galaxy properties from 14-band HST and JWST photometry. We validate this model, demonstrating excellent parameter recovery (e.g. R$^2&gt;$0.99 for M$_\star$) and accurate posterior calibration against nested sampling results. We apply our trained model to 3,088 spectroscopically-confirmed galaxies in the JADES GOODS-South field. The amortized inference is exceptionally fast, having nearly fixed cost per posterior evaluation and processing the entire sample in $\sim$3 minutes on a single CPU (18 galaxies/CPU/sec), a $\sim$1700$\times$ speedup over traditional nested sampling or MCMC techniques. We demonstrate Synference's ability to simultaneously infer photometric redshifts and physical parameters, and highlight its utility for rapid Bayesian model comparison by demonstrating systematic stellar mass differences between two commonly used stellar population synthesis models. Synference is a powerful, scalable tool poised to maximise the scientific return of next-generation galaxy surveys.</summary>
    <category term="astro-ph.GA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-11-13T18:56:48Z</published>
    <arxiv:comment>23 pages, 12 figures. Submitted to MNRAS. The Synference package is available at https://github.com/synthesizer-project/synference/</arxiv:comment>
    <arxiv:primary_category term="astro-ph.GA"/>
    <author>
      <name>Thomas Harvey</name>
    </author>
    <author>
      <name>Christopher C. Lovell</name>
    </author>
    <author>
      <name>Sophie Newman</name>
    </author>
    <author>
      <name>Christopher J. Conselice</name>
    </author>
    <author>
      <name>Duncan Austin</name>
    </author>
    <author>
      <name>Aswin P. Vijayan</name>
    </author>
    <author>
      <name>Stephen M. Wilkins</name>
    </author>
    <author>
      <name>Vadim Rusakov</name>
    </author>
    <author>
      <name>Qiong Li</name>
    </author>
    <author>
      <name>Nathan Adams</name>
    </author>
    <author>
      <name>Kai Magdwick</name>
    </author>
    <author>
      <name>Matthew Ho</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2511.10635v1</id>
    <title>Robot Crash Course: Learning Soft and Stylized Falling</title>
    <updated>2025-11-13T18:55:34Z</updated>
    <link href="https://arxiv.org/abs/2511.10635v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2511.10635v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Despite recent advances in robust locomotion, bipedal robots operating in the real world remain at risk of falling. While most research focuses on preventing such events, we instead concentrate on the phenomenon of falling itself. Specifically, we aim to reduce physical damage to the robot while providing users with control over a robot's end pose. To this end, we propose a robot agnostic reward function that balances the achievement of a desired end pose with impact minimization and the protection of critical robot parts during reinforcement learning. To make the policy robust to a broad range of initial falling conditions and to enable the specification of an arbitrary and unseen end pose at inference time, we introduce a simulation-based sampling strategy of initial and end poses. Through simulated and real-world experiments, our work demonstrates that even bipedal robots can perform controlled, soft falls.</summary>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-11-13T18:55:34Z</published>
    <arxiv:primary_category term="cs.RO"/>
    <author>
      <name>Pascal Strauch</name>
    </author>
    <author>
      <name>David Müller</name>
    </author>
    <author>
      <name>Sammy Christen</name>
    </author>
    <author>
      <name>Agon Serifi</name>
    </author>
    <author>
      <name>Ruben Grandia</name>
    </author>
    <author>
      <name>Espen Knoop</name>
    </author>
    <author>
      <name>Moritz Bächer</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2511.10634v1</id>
    <title>Baryonic Feedback across Halo Mass: Impact on the Matter Power Spectrum</title>
    <updated>2025-11-13T18:55:17Z</updated>
    <link href="https://arxiv.org/abs/2511.10634v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2511.10634v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Upcoming weak-lensing surveys will probe the matter distribution at a few percent level on nonlinear scales (k &gt; 1 h/Mpc) where baryonic feedback from galaxy formation modifies the clustering of matter. Using the IllustrisTNG hydrodynamical simulations, we quantify the mass and radial dependence of baryonic suppression of the matter power spectrum by selectively replacing halos in the collisionless run with their full-physics counterparts. We find that group-scale halos with log $M_{200m}/h^{-1} M_{sun}$ in [13, 14] dominate the suppression, contributing a large fraction of the total reduction in power at k ~ 5-30 h/Mpc. The suppression is smaller on either side of this mass bin. Correctly reproducing the full suppression of the power spectrum requires accounting for matter redistribution (while enforcing mass conservation) beyond the virial radius of each halo. Crucially, the same group-scale regime produces the strongest and most detectable deviations in group-galaxy lensing, making stacked group lensing a powerful observational test of feedback models. Our results motivate emulators that jointly predict the matter power spectrum and halo-matter correlations including baryonic effects, enabling unbiased cosmological inference from small scales.</summary>
    <category term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-11-13T18:55:17Z</published>
    <arxiv:comment>19 pages, 5 figures</arxiv:comment>
    <arxiv:primary_category term="astro-ph.CO"/>
    <author>
      <name>Kyle Miller</name>
    </author>
    <author>
      <name>Surhud More</name>
    </author>
    <author>
      <name>Bhuvnesh Jain</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2511.10625v1</id>
    <title>Model-oriented Graph Distances via Partially Ordered Sets</title>
    <updated>2025-11-13T18:50:21Z</updated>
    <link href="https://arxiv.org/abs/2511.10625v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2511.10625v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>A well-defined distance on the parameter space is key to evaluating estimators, ensuring consistency, and building confidence sets. While there are typically standard distances to adopt in a continuous space, this is not the case for combinatorial parameters such as graphs that represent statistical models. Existing proposals like the structural Hamming distance are defined on the graphs rather than the models they represent and can hence lead to undesirable behaviors. We propose a model-oriented framework for defining the distance between graphs that is applicable across many different graph classes. Our approach treats each graph as a statistical model and organizes the graphs in a partially ordered set based on model inclusion. This induces a neighborhood structure, from which we define the model-oriented distance as the length of a shortest path through neighbors, yielding a metric in the space of graphs. We apply this framework to both probabilistic graphical models (e.g., undirected graphs and completed partially directed acyclic graphs) and causal graphical models (e.g., directed acyclic graphs and maximally oriented partially directed acyclic graphs). We analyze the theoretical and empirical behaviors of model-oriented distances. Algorithmic tools are also developed for computing and bounding these distances.</summary>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-11-13T18:50:21Z</published>
    <arxiv:primary_category term="math.ST"/>
    <author>
      <name>Armeen Taeb</name>
    </author>
    <author>
      <name>F. Richard Guo</name>
    </author>
    <author>
      <name>Leonard Henckel</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2511.10618v1</id>
    <title>Know Your Limits: Entropy Estimation Modeling for Compression and Generalization</title>
    <updated>2025-11-13T18:46:42Z</updated>
    <link href="https://arxiv.org/abs/2511.10618v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2511.10618v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Language prediction is constrained by informational entropy intrinsic to language, such that there exists a limit to how accurate any language model can become and equivalently a lower bound to language compression. The most efficient language compression algorithms today are causal (next token prediction) large language models, but the use of these models to form accurate estimates of language entropy is currently computationally infeasible. We introduce encoder-augmented causal decoder model architectures that exhibit superior training efficiency characteristics and achieve higher compression than causal transformers even when trained on modest hardware. We demonstrate how entropy estimates can be obtained on a per-token basis, and show that the generalization of models trained to approach the entropy of their training data necessarily exceeds the generalization of models trained to minimize loss beyond this value. We show empirically that causal models trained to approach but not exceed estimated per-token entropies exhibit greater generalization than models trained without taking entropy into account.</summary>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-11-13T18:46:42Z</published>
    <arxiv:primary_category term="cs.CL"/>
    <author>
      <name>Benjamin L. Badger</name>
    </author>
    <author>
      <name>Matthew Neligeorge</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2511.10599v1</id>
    <title>The $L_p$-error rate for randomized quasi-Monte Carlo self-normalized importance sampling of unbounded integrands</title>
    <updated>2025-11-13T18:37:00Z</updated>
    <link href="https://arxiv.org/abs/2511.10599v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2511.10599v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Self-normalized importance sampling (SNIS) is a fundamental tool in Bayesian inference when the posterior distribution involves an unknown normalizing constant. Although $L_1$-error (bias) and $L_2$-error (root mean square error) estimates of SNIS are well established for bounded integrands, results for unbounded integrands remain limited, especially under randomized quasi-Monte Carlo (RQMC) sampling. In this work, we derive $L_p$-error rate $(p\ge1)$ for RQMC-based SNIS (RQMC-SNIS) estimators with unbounded integrands on unbounded domains. A key step in our analysis is to first establish the $L_p$-error rate for plain RQMC integration. Our results allow for a broader class of transport maps used to generate samples from RQMC points. Under mild function boundary growth conditions, we further establish \(L_p\)-error rate of order \(\mathcal{O}(N^{-β+ ε})\) for RQMC-SNIS estimators, where $ε&gt;0$ is arbitrarily small, $N$ is the sample size, and \(β\in (0,1]\) depends on the boundary growth rate of the resulting integrand. Numerical experiments validate the theoretical results.</summary>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-11-13T18:37:00Z</published>
    <arxiv:primary_category term="math.NA"/>
    <author>
      <name>Jiarui Du</name>
    </author>
    <author>
      <name>Zhijian He</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2511.10596v1</id>
    <title>The Resonance Principle: Empirical Evidence for Emergent Phase Synchronization in Human Causal Reasoning</title>
    <updated>2025-11-13T18:34:06Z</updated>
    <link href="https://arxiv.org/abs/2511.10596v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2511.10596v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Current artificial intelligence systems excel at correlational pattern matching but fail to achieve genuine causal understanding, a limitation often described as the "Kepler versus Newton" problem. We argue that this limitation is inherent to deterministic digital architectures. We introduce the Resonance Principle, a theoretical framework proposing that causal understanding emerges only in stochastic, bounded agents with intrinsic cost functions. The agent's substrate is modeled as a network of weakly coupled oscillators, where action proposals arise as stable resonant modes excited by intrinsic noise. We hypothesize that the brain, a stochastic and resonant system, operates according to this principle. To test this, we analyzed high-density EEG data (25 recordings, 500 trials) from a P300 BCI task. We computed the Kuramoto Order Parameter (R) to measure global phase synchronization (resonance) and compared it to the Event-Related Potential (ERP) voltage. Global resonance and voltage were statistically uncorrelated (r = 0.048), yet trial-level analysis revealed a strong correlation (r = 0.590, p &lt; 0.0001). This suggests that resonance is a hidden mechanism coordinating neural firing, giving rise to measurable ERPs. We conclude that phase synchronization is not a byproduct but a fundamental signature of emergent causal understanding.</summary>
    <category term="eess.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-11-13T18:34:06Z</published>
    <arxiv:primary_category term="eess.SY"/>
    <author>
      <name>Ahmed Gamal Eldin</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2511.10587v1</id>
    <title>The relationship between warm and hot gas-phase metallicity in massive elliptical galaxies and the influence of AGN feedback</title>
    <updated>2025-11-13T18:25:57Z</updated>
    <link href="https://arxiv.org/abs/2511.10587v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2511.10587v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Warm ionized gas is ubiquitous at the centers of X-ray bright elliptical galaxies. While it is believed to play a key role in the feeding and feedback processes of supermassive black holes, its origins remain under debate. Existing studies have primarily focused on the morphology and kinematics of warm ionized gas. This work aims to provide a new perspective on warm (10,000 K) ionized gas and its connection to X-ray-emitting hot gas (&gt;10^6 K) by measuring and comparing their metallicities. We conducted a joint analysis of 13 massive elliptical galaxies using MUSE/VLT and Chandra observations. Emission-line ratios were measured for the warm ionized gas using MUSE observation, and used to infer the ionization mechanisms and derive metallicities of the warm ionized gas using HII, and LIN(E)R calibrations. We also computed the warm phase metallicity using X-ray/EUV, and pAGB stars models. For two sources at higher redshift, direct Te method was also used to measure warm gas metallicities. Our observations reveal that most sources exhibit composite ionization, with contributions from both star formation and LINER-like emission. A positive linear correlation was found between the gas-phase metallicities of the warm and hot phases, ranging from 0.3 to 1.5 Zsun, and suggest the intimate connection between the two gas phases, likely driven by gas cooling and/or mixing. In some sources the warm gas metallicity shows a central drop. A similar radial trend has been reported for the hot gas metallicity in some galaxy clusters. The ionization mechanisms of cooling flow elliptical galaxies are diverse, suggesting multiple channels for powering the warm ionized gas. The large variation in the warm gas metallicity further suggests that cold gas mass derived under the assumption of solar metallicity for the CO-to-H2 conversion factor needs to be revised by approximately an order of magnitude.</summary>
    <category term="astro-ph.GA" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-11-13T18:25:57Z</published>
    <arxiv:comment>19 pages, 7 figures. Accepted for publication in Astronomy and Astrophysics</arxiv:comment>
    <arxiv:primary_category term="astro-ph.GA"/>
    <author>
      <name>Valeria Olivares</name>
    </author>
    <author>
      <name>Yuanyuan Su</name>
    </author>
    <author>
      <name>Pasquale Temi</name>
    </author>
    <author>
      <name>Ryan Eskenasy</name>
    </author>
    <author>
      <name>Helen Russell</name>
    </author>
    <author>
      <name>Massimo Gaspari</name>
    </author>
    <author>
      <name>Philippe Salome</name>
    </author>
    <author>
      <name>Francoise Combes</name>
    </author>
    <author>
      <name>Ming Sun</name>
    </author>
    <author>
      <name>Ezequiel Treister</name>
    </author>
    <author>
      <name>Kevin Fogarty</name>
    </author>
    <author>
      <name>Ana Jimenez-Gallardo</name>
    </author>
    <author>
      <name>Patricio Lagos</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2511.10560v1</id>
    <title>OmniVGGT: Omni-Modality Driven Visual Geometry Grounded</title>
    <updated>2025-11-13T17:59:01Z</updated>
    <link href="https://arxiv.org/abs/2511.10560v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2511.10560v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>General 3D foundation models have started to lead the trend of unifying diverse vision tasks, yet most assume RGB-only inputs and ignore readily available geometric cues (e.g., camera intrinsics, poses, and depth maps). To address this issue, we introduce OmniVGGT, a novel framework that can effectively benefit from an arbitrary number of auxiliary geometric modalities during both training and inference. In our framework, a GeoAdapter is proposed to encode depth and camera intrinsics/extrinsics into a spatial foundation model. It employs zero-initialized convolutions to progressively inject geometric information without disrupting the foundation model's representation space. This design ensures stable optimization with negligible overhead, maintaining inference speed comparable to VGGT even with multiple additional inputs. Additionally, a stochastic multimodal fusion regimen is proposed, which randomly samples modality subsets per instance during training. This enables an arbitrary number of modality inputs during testing and promotes learning robust spatial representations instead of overfitting to auxiliary cues. Comprehensive experiments on monocular/multi-view depth estimation, multi-view stereo, and camera pose estimation demonstrate that OmniVGGT outperforms prior methods with auxiliary inputs and achieves state-of-the-art results even with RGB-only input. To further highlight its practical utility, we integrated OmniVGGT into vision-language-action (VLA) models. The enhanced VLA model by OmniVGGT not only outperforms the vanilla point-cloud-based baseline on mainstream benchmarks, but also effectively leverages accessible auxiliary inputs to achieve consistent gains on robotic tasks.</summary>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-11-13T17:59:01Z</published>
    <arxiv:comment>Project Page: https://livioni.github.io/OmniVGGT-offcial/</arxiv:comment>
    <arxiv:primary_category term="cs.CV"/>
    <author>
      <name>Haosong Peng</name>
    </author>
    <author>
      <name>Hao Li</name>
    </author>
    <author>
      <name>Yalun Dai</name>
    </author>
    <author>
      <name>Yushi Lan</name>
    </author>
    <author>
      <name>Yihang Luo</name>
    </author>
    <author>
      <name>Tianyu Qi</name>
    </author>
    <author>
      <name>Zhengshen Zhang</name>
    </author>
    <author>
      <name>Yufeng Zhan</name>
    </author>
    <author>
      <name>Junfei Zhang</name>
    </author>
    <author>
      <name>Wenchao Xu</name>
    </author>
    <author>
      <name>Ziwei Liu</name>
    </author>
  </entry>
</feed>
