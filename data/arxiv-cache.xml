<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-03-04T00:51:19Z -->
<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acausal%20inference%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:causal inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/SsRksLzRb0LuVhSmQ+N8WbAs+f8</id>
  <updated>2025-03-03T00:00:00-05:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">107926</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">10</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2502.21321v1</id>
    <updated>2025-02-28T18:59:54Z</updated>
    <published>2025-02-28T18:59:54Z</published>
    <title>LLM Post-Training: A Deep Dive into Reasoning Large Language Models</title>
    <summary>  Large Language Models (LLMs) have transformed the natural language processing
landscape and brought to life diverse applications. Pretraining on vast
web-scale data has laid the foundation for these models, yet the research
community is now increasingly shifting focus toward post-training techniques to
achieve further breakthroughs. While pretraining provides a broad linguistic
foundation, post-training methods enable LLMs to refine their knowledge,
improve reasoning, enhance factual accuracy, and align more effectively with
user intents and ethical considerations. Fine-tuning, reinforcement learning,
and test-time scaling have emerged as critical strategies for optimizing LLMs
performance, ensuring robustness, and improving adaptability across various
real-world tasks. This survey provides a systematic exploration of
post-training methodologies, analyzing their role in refining LLMs beyond
pretraining, addressing key challenges such as catastrophic forgetting, reward
hacking, and inference-time trade-offs. We highlight emerging directions in
model alignment, scalable adaptation, and inference-time reasoning, and outline
future research directions. We also provide a public repository to continually
track developments in this fast-evolving field:
https://github.com/mbzuai-oryx/Awesome-LLM-Post-training.
</summary>
    <author>
      <name>Komal Kumar</name>
    </author>
    <author>
      <name>Tajamul Ashraf</name>
    </author>
    <author>
      <name>Omkar Thawakar</name>
    </author>
    <author>
      <name>Rao Muhammad Anwer</name>
    </author>
    <author>
      <name>Hisham Cholakkal</name>
    </author>
    <author>
      <name>Mubarak Shah</name>
    </author>
    <author>
      <name>Ming-Hsuan Yang</name>
    </author>
    <author>
      <name>Phillip H. S. Torr</name>
    </author>
    <author>
      <name>Salman Khan</name>
    </author>
    <author>
      <name>Fahad Shahbaz Khan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">31 pages, 7 figures, 3 tables, 375 references</arxiv:comment>
    <link href="http://arxiv.org/abs/2502.21321v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2502.21321v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2502.21297v1</id>
    <updated>2025-02-28T18:28:16Z</updated>
    <published>2025-02-28T18:28:16Z</published>
    <title>Persuasion Should be Double-Blind: A Multi-Domain Dialogue Dataset With
  Faithfulness Based on Causal Theory of Mind</title>
    <summary>  Persuasive dialogue plays a pivotal role in human communication, influencing
various domains. Recent persuasive dialogue datasets often fail to align with
real-world interpersonal interactions, leading to unfaithful representations.
For instance, unrealistic scenarios may arise, such as when the persuadee
explicitly instructs the persuader on which persuasion strategies to employ,
with each of the persuadee's questions corresponding to a specific strategy for
the persuader to follow. This issue can be attributed to a violation of the
"Double Blind" condition, where critical information is fully shared between
participants. In actual human interactions, however, key information such as
the mental state of the persuadee and the persuasion strategies of the
persuader is not directly accessible. The persuader must infer the persuadee's
mental state using Theory of Mind capabilities and construct arguments that
align with the persuadee's motivations. To address this gap, we introduce
ToMMA, a novel multi-agent framework for dialogue generation that is guided by
causal Theory of Mind. This framework ensures that information remains
undisclosed between agents, preserving "double-blind" conditions, while causal
ToM directs the persuader's reasoning, enhancing alignment with human-like
persuasion dynamics. Consequently, we present CToMPersu, a multi-domain,
multi-turn persuasive dialogue dataset that tackles both double-blind and
logical coherence issues, demonstrating superior performance across multiple
metrics and achieving better alignment with real human dialogues. Our dataset
and prompts are available at https://github.com/DingyiZhang/ToMMA-CToMPersu .
</summary>
    <author>
      <name>Dingyi Zhang</name>
    </author>
    <author>
      <name>Deyu Zhou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2502.21297v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2502.21297v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2502.21295v1</id>
    <updated>2025-02-28T18:26:40Z</updated>
    <published>2025-02-28T18:26:40Z</published>
    <title>Quantum arrival times in free fall</title>
    <summary>  The probability distribution of a time measurement $T_x$ at position $x$ can
be inferred from the probability distribution of a position measurement $X_t$
at time $t$ as given by the Born rule [Time-of-arrival distributions for
continuous quantum systems and application to quantum backflow, Phys. Rev. A
110, 052217 (2024)]. In an application to free-fall, this finding has been used
to predict the existence of a mass-dependent positive relative shift with
respect to the classical time-of-arrival in the long time-of-flight regime for
dropped quantum particles [M. Beau and L. Martellini, Quantum delay in the time
of arrival of free-falling atoms, Phys. Rev. A 109, 012216 (2024).]. The
present paper extends these results in two important directions. We first show
that for a Gaussian quantum particle of mass $m$ dropped in a uniform
gravitational field $g$, the uncertainties about time and position measurements
are related by the relation $ \Delta T_x \Delta X_t \geq \frac{\hbar}{2mg} . $
This novel form of uncertainty relation suggests that choosing the initial
state so as to obtain a lower uncertainty in the measured position leads to a
higher uncertainty in the measured arrival time. Secondly, we examine the case
of a free-falling particle starting from a non-Gaussian initial superposed
state, for which we predict the presence of gravitationally induced
interferences and oscillations in the mean time-of-arrival as a function of the
detector's position that can be interpreted as the signature of a
Zitterbewegung-like effect.
</summary>
    <author>
      <name>Mathieu Beau</name>
    </author>
    <author>
      <name>Timothey Szczepanski</name>
    </author>
    <author>
      <name>Rafael Martellini</name>
    </author>
    <author>
      <name>Lionel Martellini</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages + 2 pages supplementary material, 8 figures. arXiv admin
  note: substantial text overlap with arXiv:2403.06057</arxiv:comment>
    <link href="http://arxiv.org/abs/2502.21295v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2502.21295v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="gr-qc" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.MP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2502.21282v1</id>
    <updated>2025-02-28T18:01:23Z</updated>
    <published>2025-02-28T18:01:23Z</published>
    <title>Large Sample Inference with Dynamic Information Borrowing</title>
    <summary>  Large sample behavior of dynamic information borrowing (DIB) estimators is
investigated. Asymptotic properties of several DIB approaches (adaptive risk
minimization, adaptive LASSO, Bayesian procedures with empirical power prior,
fully Bayesian procedures, and a Bayes-frequentist compromise) are explored
against shrinking to zero alternatives. As shown theoretically and with
simulations, local asymptotic distributions of DIB estimators are often
non-normal. A simple Gaussian setting with external information borrowing
illustrates that none of the considered DIB methods outperforms others in terms
of mean squared error (MSE): at different conflict values, the MSEs of DIBs are
changing between the MSEs of the maximum likelihood estimators based on the
current and pooled data. To uniquely determine an optimality criterion for DIB,
a prior distribution on the conflict needs be either implicitly or explicitly
determined using data independent considerations. Data independent assumptions
on the conflict are also needed for DIB-based hypothesis testing. New families
of DIB estimators parameterized by a sensitivity-to-conflict parameter S are
suggested and their use is illustrated in an infant mortality example. The
choice of S is determined in a data-independent manner by a cost-benefit
compromise associated with the use of external data.
</summary>
    <author>
      <name>Sergey Tarima</name>
    </author>
    <author>
      <name>Silvia Calderazzo</name>
    </author>
    <author>
      <name>Mary Homan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2502.21282v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2502.21282v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2502.21265v1</id>
    <updated>2025-02-28T17:41:27Z</updated>
    <published>2025-02-28T17:41:27Z</published>
    <title>Token-level Ensembling of Models with Different Vocabularies</title>
    <summary>  Model ensembling is a technique to combine the predicted distributions of two
or more models, often leading to improved robustness and performance. For
ensembling in text generation, the next token's probability distribution is
derived from a weighted sum of the distributions of each individual model. This
requires the underlying models to share the same subword vocabulary, limiting
the applicability of ensembling, since many open-sourced models have distinct
vocabularies. In research settings, experimentation or upgrades to vocabularies
may introduce multiple vocabulary sizes. This paper proposes an inference-time
only algorithm that allows for ensembling models with different vocabularies,
without the need to learn additional parameters or alter the underlying models.
Instead, the algorithm ensures that tokens generated by the ensembled models
\textit{agree} in their surface form. We apply this technique to combinations
of traditional encoder-decoder models and decoder-only LLMs and evaluate on
machine translation. In addition to expanding to model pairs that were
previously incapable of token-level ensembling, our algorithm frequently
improves translation performance over either model individually.
</summary>
    <author>
      <name>Rachel Wicks</name>
    </author>
    <author>
      <name>Kartik Ravisankar</name>
    </author>
    <author>
      <name>Xinchen Yang</name>
    </author>
    <author>
      <name>Philipp Koehn</name>
    </author>
    <author>
      <name>Matt Post</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Under review</arxiv:comment>
    <link href="http://arxiv.org/abs/2502.21265v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2502.21265v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2502.21262v1</id>
    <updated>2025-02-28T17:39:55Z</updated>
    <published>2025-02-28T17:39:55Z</published>
    <title>Modeling Human Beliefs about AI Behavior for Scalable Oversight</title>
    <summary>  Contemporary work in AI alignment often relies on human feedback to teach AI
systems human preferences and values. Yet as AI systems grow more capable,
human feedback becomes increasingly unreliable. This raises the problem of
scalable oversight: How can we supervise AI systems that exceed human
capabilities? In this work, we propose to model the human evaluator's beliefs
about the AI system's behavior to better interpret the human's feedback. We
formalize human belief models and theoretically analyze their role in inferring
human values. We then characterize the remaining ambiguity in this inference
and conditions for which the ambiguity disappears. To mitigate reliance on
exact belief models, we then introduce the relaxation of human belief model
covering. Finally, we propose using foundation models to construct covering
belief models, providing a new potential approach to scalable oversight.
</summary>
    <author>
      <name>Leon Lang</name>
    </author>
    <author>
      <name>Patrick Forré</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">53 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2502.21262v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2502.21262v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2502.21259v1</id>
    <updated>2025-02-28T17:35:14Z</updated>
    <published>2025-02-28T17:35:14Z</published>
    <title>Optimizing and Exploring System Performance in Compact
  Processing-in-Memory-based Chips</title>
    <summary>  Processing-in-memory (PIM) is a promising computing paradigm to tackle the
"memory wall" challenge. However, PIM system-level benefits over traditional
von Neumann architecture can be reduced when the memory array cannot fully
store all the neural network (NN) weights. The NN size is increasing while the
PIM design size cannot scale up accordingly due to area constraints. Therefore,
this work targets the system performance optimization and exploration for
compact PIM designs. We first analyze the impact of data movement on compact
designs. Then, we propose a novel pipeline method that maximizes the reuse of
NN weights to improve the throughput and energy efficiency of inference in
compact chips. To further boost throughput, we introduce a scheduling algorithm
to mitigate the pipeline bubble problem. Moreover, we investigate the trade-off
between the network size and system performance for a compact PIM chip.
Experimental results show that the proposed algorithm achieves 2.35x and 0.5%
improvement in throughput and energy efficiency, respectively. Compared to the
area-unlimited design, our compact chip achieves approximately 56.5% of the
throughput and 58.6% of the energy efficiency while using only one-third of the
chip area, along with 1.3x improvement in area efficiency. Our compact design
also outperforms the modern GPU with 4.56x higher throughput and 157x better
energy efficiency. Besides, our compact design uses less than 20% of the system
energy for data movement as batch size scales up.
</summary>
    <author>
      <name>Peilin Chen</name>
    </author>
    <author>
      <name>Xiaoxuan Yang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to AICAS 2025</arxiv:comment>
    <link href="http://arxiv.org/abs/2502.21259v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2502.21259v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2502.21234v1</id>
    <updated>2025-02-28T17:03:09Z</updated>
    <published>2025-02-28T17:03:09Z</published>
    <title>Quantum information elements in Quantum Gravity states and processes</title>
    <summary>  We summarize basic features of quantum gravity states and processes, common
to a number of related quantum gravity formalisms, and sharing a purely
combinatorial and algebraic language, and a discrete geometric interpretation.
We emphasize how, in this context, entanglement is a seed of topological and
geometric properties, and how a pre-geometric, discrete notion of quantum
causality can be implemented, as well as some recent results (based on random
tensor network techniques) on the conditions for information transmission and
holographic behaviour in quantum gravity states. Together, these features
indicate that quantum information concepts and tools play a key role in
defining the fundamental structure of quantum spacetime.
</summary>
    <author>
      <name>Daniele Oriti</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages. To appear in D. Rickles, X. Arsiwalla, and H. Elshatlawy
  (eds.), Quantum Gravity and Computation (Routledge)</arxiv:comment>
    <link href="http://arxiv.org/abs/2502.21234v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2502.21234v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="gr-qc" scheme="http://arxiv.org/schemas/atom"/>
    <category term="gr-qc" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-th" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2502.21208v1</id>
    <updated>2025-02-28T16:28:13Z</updated>
    <published>2025-02-28T16:28:13Z</published>
    <title>ARIES: Autonomous Reasoning with LLMs on Interactive Thought Graph
  Environments</title>
    <summary>  Recent research has shown that LLM performance on reasoning tasks can be
enhanced by scaling test-time compute. One promising approach, particularly
with decomposable problems, involves arranging intermediate solutions as a
graph on which transformations are performed to explore the solution space.
However, prior works rely on pre-determined, task-specific transformation
schedules which are subject to a set of searched hyperparameters. In this work,
we view thought graph transformations as actions in a Markov decision process,
and implement policy agents to drive effective action policies for the
underlying reasoning LLM agent. In particular, we investigate the ability for
another LLM to act as a policy agent on thought graph environments and
introduce ARIES, a multi-agent architecture for reasoning with LLMs. In ARIES,
reasoning LLM agents solve decomposed subproblems, while policy LLM agents
maintain visibility of the thought graph states, and dynamically adapt the
problem-solving strategy. Through extensive experiments, we observe that using
off-the-shelf LLMs as policy agents with no supervised fine-tuning (SFT) can
yield up to $29\%$ higher accuracy on HumanEval relative to static
transformation schedules, as well as reducing inference costs by $35\%$ and
avoid any search requirements. We also conduct a thorough analysis of observed
failure modes, highlighting that limitations on LLM sizes and the depth of
problem decomposition can be seen as challenges to scaling LLM-guided
reasoning.
</summary>
    <author>
      <name>Pedro Gimenes</name>
    </author>
    <author>
      <name>Zeyu Cao</name>
    </author>
    <author>
      <name>Jeffrey Wong</name>
    </author>
    <author>
      <name>Yiren Zhao</name>
    </author>
    <link href="http://arxiv.org/abs/2502.21208v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2502.21208v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2502.21198v1</id>
    <updated>2025-02-28T16:15:20Z</updated>
    <published>2025-02-28T16:15:20Z</published>
    <title>AI-Enhanced Self-Triggering for Extensive Air Showers: Performance and
  FPGA Feasibility</title>
    <summary>  Cosmic-ray detection with radio antennas has traditionally depended on
external triggers from particle detectors, constraining sensitivity and
increasing complexity. Previous attempts at fully standalone, radio-only
triggers have often failed under intense radio frequency interference, making
genuine air-shower signals difficult to isolate. We present a
proof-of-principle artificial intelligence-based self-triggering system that
overcomes these limitations. By training a deep learning model on both real
noise data and injected cosmic-ray-like pulses, we achieve an exceptionally low
false-positive rate alongside high detection efficiency. Configurable operating
points can suppress false positives below 0.01\% while retaining more than 88\%
of genuine signals, and can even eliminate false positives entirely at a modest
reduction in signal efficiency. This flexibility makes single-station
cosmic-ray detection feasible without requiring external trigger inputs.
Applying our approach to real-world noise conditions reduces the initial
false-positive event rate by several orders of magnitude, supporting
large-scale deployments. Extrapolation to dedicated hardware implementations,
such as FPGAs, indicates that sub-\SI{}{\micro\second} inference times are
achievable, enabling real-time autonomous triggering. These results highlight
the transformative potential of artificial intelligence for enhancing radio
detection sensitivity and inaugurate a new generation of fully self-triggered
cosmic-ray observatories.
</summary>
    <author>
      <name>Qader Dorosti</name>
    </author>
    <link href="http://arxiv.org/abs/2502.21198v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2502.21198v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ins-det" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
