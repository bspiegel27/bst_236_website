<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-08-29T00:53:45Z -->
<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acausal%20inference%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:causal inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/SsRksLzRb0LuVhSmQ+N8WbAs+f8</id>
  <updated>2025-08-28T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">119806</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">10</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2508.20074v1</id>
    <updated>2025-08-27T17:40:41Z</updated>
    <published>2025-08-27T17:40:41Z</published>
    <title>X-ray view of a massive node of the Cosmic Web at z=3 II. Discovery of
  extended X-ray emission around a hyperluminous QSO</title>
    <summary>  While the warm, ionized gas in the CGM at z&gt;3 is now routinely observed
around bright QSOs in Lya emission, little is known about the CGM hot phase due
to its expected faintness in the X-ray band, often referred to as the ICM.
Here, we report the analysis of 634 ks of Chandra X-ray observations in the
MQN01 Cosmic Node, a region containing one of the brightest Lya nebulae and the
largest galaxy overdensity discovered so far at z&gt;3. We detect 66 net counts of
X-ray emission in the 0.5-2 keV band extending to at least 30 kpc from the
brightest QSO in MQN01. The morphology and spectrum are consistent with thermal
emission from hot plasma in CIE. Photoionization is negligible, and IC is
disfavored. A joint spatial and spectral MCMC analysis provides consistency
with a beta-model with a steep density profile and a gas temperature kT~1.8 keV
and virial halo mass Mvir~3e13 Mo. The inferred hot gas mass is
Mhot(&lt;Rvir)~2.6e12 Mo, which is ~8.3% of Mvir, or ~56% of the theoretical
cosmological baryon budget of the halo. The hot gas also emits an exceptionally
high Lx, with a measured L2-10~2.3e45 erg/s within the central 30 kpc. This
system is a clear outlier in the Lx-Tx plane, indicating a thermodynamic state
distinct from that of evolved lower-redshift hot halos. The cooling time in the
inner 15-30 kpc is comparable to the local dynamical time, suggesting that the
gas could become locally unstable in the absence of heating or feedback.
Moreover, the thermal pressure associated with the detected CGM hot phase is
large enough to confine the cold and dense clumps, which are required to
reproduce the high Lya emission associated with the inner regions of the MQN01
structure. Although limited to a single system, our results provide unique
information on the multi-phase properties of the CGM and a view of the nascent
thermal hot gas phase observed in local galaxy clusters.
</summary>
    <author>
      <name>Andrea Travascio</name>
    </author>
    <author>
      <name>Sebastiano Cantalupo</name>
    </author>
    <author>
      <name>Gabriele Pezzulli</name>
    </author>
    <author>
      <name>Paolo Tozzi</name>
    </author>
    <author>
      <name>Luca Di Mascolo</name>
    </author>
    <author>
      <name>Michela Esposito</name>
    </author>
    <author>
      <name>Titouan Lazeyras</name>
    </author>
    <author>
      <name>Marika Lepore</name>
    </author>
    <author>
      <name>Stefano Borgani</name>
    </author>
    <author>
      <name>Martin Elvis</name>
    </author>
    <author>
      <name>Giuseppina Fabbiano</name>
    </author>
    <author>
      <name>Marta Galbiati</name>
    </author>
    <author>
      <name>Nicholas Ledos</name>
    </author>
    <author>
      <name>Riccardo Middei</name>
    </author>
    <author>
      <name>Antonio Pensabene</name>
    </author>
    <author>
      <name>Enrico Piconcelli</name>
    </author>
    <author>
      <name>Giada Quadri</name>
    </author>
    <author>
      <name>Fabio Vito</name>
    </author>
    <author>
      <name>Weichen Wang</name>
    </author>
    <author>
      <name>Luca Zappacosta</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 14 figures, 2 tables, 4 appendices. Submitted to A&amp;A</arxiv:comment>
    <link href="http://arxiv.org/abs/2508.20074v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.20074v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.GA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.GA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.20065v1</id>
    <updated>2025-08-27T17:18:33Z</updated>
    <published>2025-08-27T17:18:33Z</published>
    <title>Joint Analysis of HI Absorption Zeeman Measurements and the Morphology
  of Filamentary HI Emission</title>
    <summary>  We present a joint analysis of HI absorption Zeeman measurements and the
morphology of filamentary HI emission to investigate the three-dimensional
structure of the magnetic field in the diffuse neutral interstellar medium
(ISM). Our analysis is based on the Arecibo Millennium Survey and new data from
the Five-hundred-meter Aperture Spherical radio Telescope (FAST) toward radio
sources 3C 75, 3C 207, and 3C 409. Toward 3C 409, we make a 4$\sigma$ Zeeman
detection and infer $B_{LOS}$ = 9.1 +/- 1.9$\mu$G, in agreement with Arecibo
results. We quantify the dispersion of HI filaments at the locations and
velocities of Zeeman components using GALFA-HI narrow-channel emission maps.
Focusing on a subsample of 42 spectrally distinct components, we find a weak
but statistically significant positive correlation (Spearman r = 0.3, $p =
0.01$) between $|B_{LOS}|$ and the circular variance of HI filament orientation
angles. To examine its origin, we characterize the environments probed by HI
absorption using dust emission, 3D dust maps, OH absorption, and CO emission.
We find evidence that existing HI absorption Zeeman measurements trace magnetic
fields that are coherent on parsec scales, probe primarily local gas
($100$-$500$ pc, often at distances consistent with the Local Bubble wall), and
exhibit systematic differences in the magnitude of $B_{LOS}$. We attribute the
correlation between Zeeman measurements and filamentary HI morphology to
large-scale variations in magnetic field strength and/or inclination angle
across different Galactic environments, which could arise due to the Local
Bubble geometry or enhanced total field strength in denser regions.
</summary>
    <author>
      <name>Marta Nowotka</name>
    </author>
    <author>
      <name>Susan E. Clark</name>
    </author>
    <author>
      <name>Blakesley Burkhart</name>
    </author>
    <author>
      <name>Laura Fissel</name>
    </author>
    <author>
      <name>Tao-Chung Ching</name>
    </author>
    <author>
      <name>Timothy Robishaw</name>
    </author>
    <author>
      <name>Carl Heiles</name>
    </author>
    <link href="http://arxiv.org/abs/2508.20065v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.20065v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.GA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.GA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.20063v1</id>
    <updated>2025-08-27T17:17:00Z</updated>
    <published>2025-08-27T17:17:00Z</published>
    <title>OpenM3D: Open Vocabulary Multi-view Indoor 3D Object Detection without
  Human Annotations</title>
    <summary>  Open-vocabulary (OV) 3D object detection is an emerging field, yet its
exploration through image-based methods remains limited compared to 3D point
cloud-based methods. We introduce OpenM3D, a novel open-vocabulary multi-view
indoor 3D object detector trained without human annotations. In particular,
OpenM3D is a single-stage detector adapting the 2D-induced voxel features from
the ImGeoNet model. To support OV, it is jointly trained with a class-agnostic
3D localization loss requiring high-quality 3D pseudo boxes and a
voxel-semantic alignment loss requiring diverse pre-trained CLIP features. We
follow the training setting of OV-3DET where posed RGB-D images are given but
no human annotations of 3D boxes or classes are available. We propose a 3D
Pseudo Box Generation method using a graph embedding technique that combines 2D
segments into coherent 3D structures. Our pseudo-boxes achieve higher precision
and recall than other methods, including the method proposed in OV-3DET. We
further sample diverse CLIP features from 2D segments associated with each
coherent 3D structure to align with the corresponding voxel feature. The key to
training a highly accurate single-stage detector requires both losses to be
learned toward high-quality targets. At inference, OpenM3D, a highly efficient
detector, requires only multi-view images for input and demonstrates superior
accuracy and speed (0.3 sec. per scene) on ScanNet200 and ARKitScenes indoor
benchmarks compared to existing methods. We outperform a strong two-stage
method that leverages our class-agnostic detector with a ViT CLIP-based OV
classifier and a baseline incorporating multi-view depth estimator on both
accuracy and speed.
</summary>
    <author>
      <name>Peng-Hao Hsu</name>
    </author>
    <author>
      <name>Ke Zhang</name>
    </author>
    <author>
      <name>Fu-En Wang</name>
    </author>
    <author>
      <name>Tao Tu</name>
    </author>
    <author>
      <name>Ming-Feng Li</name>
    </author>
    <author>
      <name>Yu-Lun Liu</name>
    </author>
    <author>
      <name>Albert Y. C. Chen</name>
    </author>
    <author>
      <name>Min Sun</name>
    </author>
    <author>
      <name>Cheng-Hao Kuo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICCV2025</arxiv:comment>
    <link href="http://arxiv.org/abs/2508.20063v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.20063v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.20028v1</id>
    <updated>2025-08-27T16:33:03Z</updated>
    <published>2025-08-27T16:33:03Z</published>
    <title>Microscopic Origin of Domain Wall Reconfiguration Dynamics in a Quantum
  Material via Quantum Simulation</title>
    <summary>  Understanding how quantum materials relax from metastable states poses a
fundamental challenge in condensed matter physics. In the layered
dichalcogenide 1T-TaS$_2$, domain-wall-rich polaronic textures evolve toward a
uniform ground state through reconfiguration events that exhibit a crossover
from thermally activated to temperature-independent behavior-indicative of
quantum tunneling. Here, we employ quantum simulation of a two-dimensional
transverse-field Ising model (TFIM) with longitudinal bias to uncover the
microscopic processes underlying this relaxation. Using a Schrieffer-Wolff
transformation, we map the TFIM to a hardcore boson model, revealing that
single-polaron tunneling events, rather than collective multi-particle
transitions, dominate domain wall motion. A scaling analysis of reconfiguration
rates across varying transverse fields $h_x$ shows collapse when temperature is
rescaled as $T \to h_x^n T$ with $n \approx 1.2$, confirming the dominance of
first- and second-order single-particle processes. This enables us to
reconstruct a microscopic relaxation pathway consisting of cyclical polaron
leakage followed by cascades of tunneling events. Our results establish quantum
simulation as a powerful tool for inferring real-space mechanisms in strongly
correlated systems and demonstrate a concrete strategy for bridging effective
spin models with the non-equilibrium dynamics of quantum materials.
</summary>
    <author>
      <name>Jaka Vodeb</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 4 figures, comments are welcome</arxiv:comment>
    <link href="http://arxiv.org/abs/2508.20028v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.20028v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.str-el" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.20013v1</id>
    <updated>2025-08-27T16:16:12Z</updated>
    <published>2025-08-27T16:16:12Z</published>
    <title>Cross-Platform E-Commerce Product Categorization and Recategorization: A
  Multimodal Hierarchical Classification Approach</title>
    <summary>  This study addresses critical industrial challenges in e-commerce product
categorization, namely platform heterogeneity and the structural limitations of
existing taxonomies, by developing and deploying a multimodal hierarchical
classification framework. Using a dataset of 271,700 products from 40
international fashion e-commerce platforms, we integrate textual features
(RoBERTa), visual features (ViT), and joint vision--language representations
(CLIP). We investigate fusion strategies, including early, late, and
attention-based fusion within a hierarchical architecture enhanced by dynamic
masking to ensure taxonomic consistency. Results show that CLIP embeddings
combined via an MLP-based late-fusion strategy achieve the highest hierarchical
F1 (98.59\%), outperforming unimodal baselines. To address shallow or
inconsistent categories, we further introduce a self-supervised ``product
recategorization'' pipeline using SimCLR, UMAP, and cascade clustering, which
discovered new, fine-grained categories (e.g., subtypes of ``Shoes'') with
cluster purities above 86\%. Cross-platform experiments reveal a
deployment-relevant trade-off: complex late-fusion methods maximize accuracy
with diverse training data, while simpler early-fusion methods generalize more
effectively to unseen platforms. Finally, we demonstrate the framework's
industrial scalability through deployment in EURWEB's commercial transaction
intelligence platform via a two-stage inference pipeline, combining a
lightweight RoBERTa stage with a GPU--accelerated multimodal stage to balance
cost and accuracy.
</summary>
    <author>
      <name>Lotte Gross</name>
    </author>
    <author>
      <name>Rebecca Walter</name>
    </author>
    <author>
      <name>Nicole Zoppi</name>
    </author>
    <author>
      <name>Adrien Justus</name>
    </author>
    <author>
      <name>Alessandro Gambetti</name>
    </author>
    <author>
      <name>Qiwei Han</name>
    </author>
    <author>
      <name>Maximilian Kaiser</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 5 figures, 3 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2508.20013v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.20013v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.19999v1</id>
    <updated>2025-08-27T15:59:47Z</updated>
    <published>2025-08-27T15:59:47Z</published>
    <title>Linear-Time Demonstration Selection for In-Context Learning via Gradient
  Estimation</title>
    <summary>  This paper introduces an algorithm to select demonstration examples for
in-context learning of a query set. Given a set of $n$ examples, how can we
quickly select $k$ out of $n$ to best serve as the conditioning for downstream
inference? This problem has broad applications in prompt tuning and
chain-of-thought reasoning. Since model weights remain fixed during in-context
learning, previous work has sought to design methods based on the similarity of
token embeddings. This work proposes a new approach based on gradients of the
output taken in the input embedding space. Our approach estimates model outputs
through a first-order approximation using the gradients. Then, we apply this
estimation to multiple randomly sampled subsets. Finally, we aggregate the
sampled subset outcomes to form an influence score for each demonstration, and
select $k$ most relevant examples. This procedure only requires pre-computing
model outputs and gradients once, resulting in a linear-time algorithm relative
to model and training set sizes. Extensive experiments across various models
and datasets validate the efficiency of our approach. We show that the gradient
estimation procedure yields approximations of full inference with less than
$\mathbf{1}\%$ error across six datasets. This allows us to scale up subset
selection that would otherwise run full inference by up to
$\mathbf{37.7}\times$ on models with up to $34$ billion parameters, and
outperform existing selection methods based on input embeddings by
$\mathbf{11}\%$ on average.
</summary>
    <author>
      <name>Ziniu Zhang</name>
    </author>
    <author>
      <name>Zhenshuo Zhang</name>
    </author>
    <author>
      <name>Dongyue Li</name>
    </author>
    <author>
      <name>Lu Wang</name>
    </author>
    <author>
      <name>Jennifer Dy</name>
    </author>
    <author>
      <name>Hongyang R. Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages. To appear in EMNLP'25</arxiv:comment>
    <link href="http://arxiv.org/abs/2508.19999v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.19999v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.19994v1</id>
    <updated>2025-08-27T15:51:30Z</updated>
    <published>2025-08-27T15:51:30Z</published>
    <title>The Coherent Multiplex: Scalable Real-Time Wavelet Coherence
  Architecture</title>
    <summary>  The Coherent Multiplex is formalized and validated as a scalable, real-time
system for identifying, analyzing, and visualizing coherence among multiple
time series. Its architecture comprises a fast spectral similarity layer based
on cosine similarity metrics of Fourier-transformed signals, and a sparse
time-frequency layer for wavelet coherence. The system constructs and evolves a
multilayer graph representing inter-signal relationships, enabling low-latency
inference and monitoring. A simulation prototype demonstrates functionality
across 8 synthetic channels with a high similarity threshold for further
computation, with additional opportunities for scaling the architecture up to
support thousands of input signals with constrained hardware. Applications
discussed include neuroscience, finance, and biomedical signal analysis.
</summary>
    <author>
      <name>Noah Shore</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to International Symposium for Signal Processing 2025</arxiv:comment>
    <link href="http://arxiv.org/abs/2508.19994v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.19994v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.MF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.19988v1</id>
    <updated>2025-08-27T15:47:19Z</updated>
    <published>2025-08-27T15:47:19Z</published>
    <title>AgentCoMa: A Compositional Benchmark Mixing Commonsense and Mathematical
  Reasoning in Real-World Scenarios</title>
    <summary>  Large Language Models (LLMs) have achieved high accuracy on complex
commonsense and mathematical problems that involve the composition of multiple
reasoning steps. However, current compositional benchmarks testing these skills
tend to focus on either commonsense or math reasoning, whereas LLM agents
solving real-world tasks would require a combination of both. In this work, we
introduce an Agentic Commonsense and Math benchmark (AgentCoMa), where each
compositional task requires a commonsense reasoning step and a math reasoning
step. We test it on 61 LLMs of different sizes, model families, and training
strategies. We find that LLMs can usually solve both steps in isolation, yet
their accuracy drops by ~30% on average when the two are combined. This is a
substantially greater performance gap than the one we observe in prior
compositional benchmarks that combine multiple steps of the same reasoning
type. In contrast, non-expert human annotators can solve the compositional
questions and the individual steps in AgentCoMa with similarly high accuracy.
Furthermore, we conduct a series of interpretability studies to better
understand the performance gap, examining neuron patterns, attention maps and
membership inference. Our work underscores a substantial degree of model
brittleness in the context of mixed-type compositional reasoning and offers a
test bed for future improvement.
</summary>
    <author>
      <name>Lisa Alazraki</name>
    </author>
    <author>
      <name>Lihu Chen</name>
    </author>
    <author>
      <name>Ana Brassard</name>
    </author>
    <author>
      <name>Joe Stacey</name>
    </author>
    <author>
      <name>Hossein A. Rahmani</name>
    </author>
    <author>
      <name>Marek Rei</name>
    </author>
    <link href="http://arxiv.org/abs/2508.19988v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.19988v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.19982v1</id>
    <updated>2025-08-27T15:40:25Z</updated>
    <published>2025-08-27T15:40:25Z</published>
    <title>Diffusion Language Models Know the Answer Before Decoding</title>
    <summary>  Diffusion language models (DLMs) have recently emerged as an alternative to
autoregressive approaches, offering parallel sequence generation and flexible
token orders. However, their inference remains slower than that of
autoregressive models, primarily due to the cost of bidirectional attention and
the large number of refinement steps required for high quality outputs. In this
work, we highlight and leverage an overlooked property of DLMs early answer
convergence: in many cases, the correct answer can be internally identified by
half steps before the final decoding step, both under semi-autoregressive and
random remasking schedules. For example, on GSM8K and MMLU, up to 97% and 99%
of instances, respectively, can be decoded correctly using only half of the
refinement steps. Building on this observation, we introduce Prophet, a
training-free fast decoding paradigm that enables early commit decoding.
Specifically, Prophet dynamically decides whether to continue refinement or to
go "all-in" (i.e., decode all remaining tokens in one step), using the
confidence gap between the top-2 prediction candidates as the criterion. It
integrates seamlessly into existing DLM implementations, incurs negligible
overhead, and requires no additional training. Empirical evaluations of
LLaDA-8B and Dream-7B across multiple tasks show that Prophet reduces the
number of decoding steps by up to 3.4x while preserving high generation
quality. These results recast DLM decoding as a problem of when to stop
sampling, and demonstrate that early decode convergence provides a simple yet
powerful mechanism for accelerating DLM inference, complementary to existing
speedup techniques. Our code is publicly available at
https://github.com/pixeli99/Prophet.
</summary>
    <author>
      <name>Pengxiang Li</name>
    </author>
    <author>
      <name>Yefan Zhou</name>
    </author>
    <author>
      <name>Dilxat Muhtar</name>
    </author>
    <author>
      <name>Lu Yin</name>
    </author>
    <author>
      <name>Shilin Yan</name>
    </author>
    <author>
      <name>Li Shen</name>
    </author>
    <author>
      <name>Yi Liang</name>
    </author>
    <author>
      <name>Soroush Vosoughi</name>
    </author>
    <author>
      <name>Shiwei Liu</name>
    </author>
    <link href="http://arxiv.org/abs/2508.19982v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.19982v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.19967v1</id>
    <updated>2025-08-27T15:21:31Z</updated>
    <published>2025-08-27T15:21:31Z</published>
    <title>Assessing the Geolocation Capabilities, Limitations and Societal Risks
  of Generative Vision-Language Models</title>
    <summary>  Geo-localization is the task of identifying the location of an image using
visual cues alone. It has beneficial applications, such as improving disaster
response, enhancing navigation, and geography education. Recently,
Vision-Language Models (VLMs) are increasingly demonstrating capabilities as
accurate image geo-locators. This brings significant privacy risks, including
those related to stalking and surveillance, considering the widespread uses of
AI models and sharing of photos on social media. The precision of these models
is likely to improve in the future. Despite these risks, there is little work
on systematically evaluating the geolocation precision of Generative VLMs,
their limits and potential for unintended inferences. To bridge this gap, we
conduct a comprehensive assessment of the geolocation capabilities of 25
state-of-the-art VLMs on four benchmark image datasets captured in diverse
environments. Our results offer insight into the internal reasoning of VLMs and
highlight their strengths, limitations, and potential societal risks. Our
findings indicate that current VLMs perform poorly on generic street-level
images yet achieve notably high accuracy (61\%) on images resembling social
media content, raising significant and urgent privacy concerns.
</summary>
    <author>
      <name>Oliver Grainge</name>
    </author>
    <author>
      <name>Sania Waheed</name>
    </author>
    <author>
      <name>Jack Stilgoe</name>
    </author>
    <author>
      <name>Michael Milford</name>
    </author>
    <author>
      <name>Shoaib Ehsan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to AAAI Fall Symposium 2025 on AI Trustworthiness and Risk
  Assessment for Challenging Contexts (ATRACC)</arxiv:comment>
    <link href="http://arxiv.org/abs/2508.19967v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.19967v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
