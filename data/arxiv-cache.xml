<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-07-04T00:58:18Z -->
<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acausal%20inference%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:causal inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/SsRksLzRb0LuVhSmQ+N8WbAs+f8</id>
  <updated>2025-07-03T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">116231</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">10</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2507.01960v1</id>
    <updated>2025-07-02T17:59:54Z</updated>
    <published>2025-07-02T17:59:54Z</published>
    <title>Resolving Individual Stars in Nearby Large Galaxies with the Habitable
  Worlds Observatory</title>
    <summary>  The varied and dynamic evolutionary histories of galaxies give rise to the
stunning diversity in their properties that we observe in the present-day
universe. HST, and now JWST, have pioneered the study of resolved individual
stars in the Milky Way and other members of the Local Group, uncovering the
drivers of their morphological, star formation, and chemical evolution. HWO
will constitute a paradigm shift: introducing the ability to panchromatically
resolve the main bodies of every galaxy in the Local Volume into their
constituent stars. In this science case, we summarize the breakthrough progress
that HWO will advance in the field of galaxy evolution through resolved stellar
populations. HWO will transform our understanding of galaxies in three distance
regimes: (1) in the nearest galaxies ($\sim$5 Mpc), where it will resolve stars
below the oldest Main Sequence Turnoff, enabling precision stellar astrophysics
and star formation history (SFH) inferences to the earliest cosmic times; (2)
in the greater Local Volume ($\sim$20 Mpc), where it will resolve stars below
the Red Clump, providing access to accurate SFHs for hundreds of galaxies,
spanning the entire Hubble Sequence; and (3) out to cosmological volumes
($\sim$50+ Mpc), providing access to the luminous stellar populations in
thousands of galaxies, enabling unprecedented views of their morphology,
stellar abundances, and dust content. The principal technological requirement
advanced by this science case is a camera with a resolution of
$\leqslant$0.015'' that is diffraction-limited, and Nyquist-sampled (0.01'' per
pixel), to at least 550 nm $-$ comparable to the High Definition Imager from
the LUVOIR concept.
</summary>
    <author>
      <name>Adam Smercina</name>
    </author>
    <author>
      <name>Tara Fetherolf</name>
    </author>
    <author>
      <name>Eric W. Koch</name>
    </author>
    <author>
      <name>Silvia Martocchia</name>
    </author>
    <author>
      <name>Chris Mihos</name>
    </author>
    <author>
      <name>Benjamin F. Williams</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Evolution of the Elements SCDD, to be presented at HWO2025 and
  submitted to ASP following community comments. If interested in endorsing, or
  giving feedback and being included as a co-author, please use the form linked
  on the Community Science Case Portal
  (https://outerspace.stsci.edu/display/HWOCOMMUNITYSCI/HWO+Community+Science+Case+Portal)</arxiv:comment>
    <link href="http://arxiv.org/abs/2507.01960v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2507.01960v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.GA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.GA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2507.01946v1</id>
    <updated>2025-07-02T17:55:53Z</updated>
    <published>2025-07-02T17:55:53Z</published>
    <title>Characterizing control between interacting subsystems with deep Jacobian
  estimation</title>
    <summary>  Biological function arises through the dynamical interactions of multiple
subsystems, including those between brain areas, within gene regulatory
networks, and more. A common approach to understanding these systems is to
model the dynamics of each subsystem and characterize communication between
them. An alternative approach is through the lens of control theory: how the
subsystems control one another. This approach involves inferring the
directionality, strength, and contextual modulation of control between
subsystems. However, methods for understanding subsystem control are typically
linear and cannot adequately describe the rich contextual effects enabled by
nonlinear complex systems. To bridge this gap, we devise a data-driven
nonlinear control-theoretic framework to characterize subsystem interactions
via the Jacobian of the dynamics. We address the challenge of learning
Jacobians from time-series data by proposing the JacobianODE, a deep learning
method that leverages properties of the Jacobian to directly estimate it for
arbitrary dynamical systems from data alone. We show that JacobianODEs
outperform existing Jacobian estimation methods on challenging systems,
including high-dimensional chaos. Applying our approach to a multi-area
recurrent neural network (RNN) trained on a working memory selection task, we
show that the "sensory" area gains greater control over the "cognitive" area
over learning. Furthermore, we leverage the JacobianODE to directly control the
trained RNN, enabling precise manipulation of its behavior. Our work lays the
foundation for a theoretically grounded and data-driven understanding of
interactions among biological subsystems.
</summary>
    <author>
      <name>Adam J. Eisen</name>
    </author>
    <author>
      <name>Mitchell Ostrow</name>
    </author>
    <author>
      <name>Sarthak Chandra</name>
    </author>
    <author>
      <name>Leo Kozachkov</name>
    </author>
    <author>
      <name>Earl K. Miller</name>
    </author>
    <author>
      <name>Ila R. Fiete</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2507.01946v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2507.01946v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2507.01945v1</id>
    <updated>2025-07-02T17:55:50Z</updated>
    <published>2025-07-02T17:55:50Z</published>
    <title>LongAnimation: Long Animation Generation with Dynamic Global-Local
  Memory</title>
    <summary>  Animation colorization is a crucial part of real animation industry
production. Long animation colorization has high labor costs. Therefore,
automated long animation colorization based on the video generation model has
significant research value. Existing studies are limited to short-term
colorization. These studies adopt a local paradigm, fusing overlapping features
to achieve smooth transitions between local segments. However, the local
paradigm neglects global information, failing to maintain long-term color
consistency. In this study, we argue that ideal long-term color consistency can
be achieved through a dynamic global-local paradigm, i.e., dynamically
extracting global color-consistent features relevant to the current generation.
Specifically, we propose LongAnimation, a novel framework, which mainly
includes a SketchDiT, a Dynamic Global-Local Memory (DGLM), and a Color
Consistency Reward. The SketchDiT captures hybrid reference features to support
the DGLM module. The DGLM module employs a long video understanding model to
dynamically compress global historical features and adaptively fuse them with
the current generation features. To refine the color consistency, we introduce
a Color Consistency Reward. During inference, we propose a color consistency
fusion to smooth the video segment transition. Extensive experiments on both
short-term (14 frames) and long-term (average 500 frames) animations show the
effectiveness of LongAnimation in maintaining short-term and long-term color
consistency for open-domain animation colorization task. The code can be found
at https://cn-makers.github.io/long_animation_web/.
</summary>
    <author>
      <name>Nan Chen</name>
    </author>
    <author>
      <name>Mengqi Huang</name>
    </author>
    <author>
      <name>Yihao Meng</name>
    </author>
    <author>
      <name>Zhendong Mao</name>
    </author>
    <link href="http://arxiv.org/abs/2507.01945v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2507.01945v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2507.01942v1</id>
    <updated>2025-07-02T17:53:11Z</updated>
    <published>2025-07-02T17:53:11Z</published>
    <title>Morphology and stellar populations of a candidate ultra-diffuse galaxy
  in early Euclid and Rubin imaging</title>
    <summary>  We present multi-wavelength imaging and analysis of a low surface brightness
(LSB) dwarf galaxy in the Extended Chandra Deep Field South (ECDFS),
SMDG0333094-280938, with particular emphasis on data from the Euclid space
telescope and from the Vera C.\ Rubin Observatory. The galaxy is clumpy and
blue, and appears to host globular clusters (GCs), suggesting a distance of
~50-60 Mpc which would make the dwarf an ultra-diffuse galaxy (UDG). We carry
out spectral energy distribution (SED) fitting from the far-ultraviolet to the
near-infrared, in order to estimate the galaxy age and metallicity. We infer a
recent peak of star formation that may have led to the formation of the UDG
through feedback-driven expansion. This early analysis illustrates how Euclid
and Rubin are poised to identify and characterize many thousands of UDGs and
other LSB galaxies in the near future, including their GCs and stellar
populations.
</summary>
    <author>
      <name>Aaron J. Romanowsky</name>
    </author>
    <author>
      <name>Yimeng Tang</name>
    </author>
    <author>
      <name>Kevin A. Bundy</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">submitted to RNAAS; 3 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/2507.01942v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2507.01942v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.GA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.GA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2507.01934v1</id>
    <updated>2025-07-02T17:46:11Z</updated>
    <published>2025-07-02T17:46:11Z</published>
    <title>Deterministic Equations for Feedback Control of Open Quantum Systems</title>
    <summary>  Feedback control in open quantum dynamics is crucial for the advancement of
various coherent platforms. For a proper theoretical description, however, most
feedback schemes rely on stochastic trajectories, which require significant
statistical sampling and lack analytical insight. Currently, only a handful of
deterministic feedback master equations exist in the literature. In this letter
we derive a set of deterministic equations for describing feedback schemes
based on generic causal signals. Our formulation is phrased in terms of
sequentially applied quantum instruments, and is therefore extremely general,
recovering various known results in the literature as particular cases. We then
specialize this result to the case of quantum jumps and derive a new
deterministic equation that allows for feedback based on the channel of the
last jump, as well as the time since the last jump occurred. The strength of
this formalism is illustrated with a detailed study of population inversion of
a qubit using coherent drive and feedback, where our formalism allows all
calculations to be performed analytically.
</summary>
    <author>
      <name>Alberto J. B. Rosal</name>
    </author>
    <author>
      <name>Patrick P. Potts</name>
    </author>
    <author>
      <name>Gabriel T. Landi</name>
    </author>
    <link href="http://arxiv.org/abs/2507.01934v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2507.01934v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2507.01908v1</id>
    <updated>2025-07-02T17:22:21Z</updated>
    <published>2025-07-02T17:22:21Z</published>
    <title>Reasoning to Edit: Hypothetical Instruction-Based Image Editing with
  Visual Reasoning</title>
    <summary>  Instruction-based image editing (IIE) has advanced rapidly with the success
of diffusion models. However, existing efforts primarily focus on simple and
explicit instructions to execute editing operations such as adding, deleting,
moving, or swapping objects. They struggle to handle more complex implicit
hypothetical instructions that require deeper reasoning to infer plausible
visual changes and user intent. Additionally, current datasets provide limited
support for training and evaluating reasoning-aware editing capabilities.
Architecturally, these methods also lack mechanisms for fine-grained detail
extraction that support such reasoning. To address these limitations, we
propose Reason50K, a large-scale dataset specifically curated for training and
evaluating hypothetical instruction reasoning image editing, along with
ReasonBrain, a novel framework designed to reason over and execute implicit
hypothetical instructions across diverse scenarios. Reason50K includes over 50K
samples spanning four key reasoning scenarios: Physical, Temporal, Causal, and
Story reasoning. ReasonBrain leverages Multimodal Large Language Models (MLLMs)
for editing guidance generation and a diffusion model for image synthesis,
incorporating a Fine-grained Reasoning Cue Extraction (FRCE) module to capture
detailed visual and textual semantics essential for supporting instruction
reasoning. To mitigate the semantic loss, we further introduce a Cross-Modal
Enhancer (CME) that enables rich interactions between the fine-grained cues and
MLLM-derived features. Extensive experiments demonstrate that ReasonBrain
consistently outperforms state-of-the-art baselines on reasoning scenarios
while exhibiting strong zero-shot generalization to conventional IIE tasks. Our
dataset and code will be released publicly.
</summary>
    <author>
      <name>Qingdong He</name>
    </author>
    <author>
      <name>Xueqin Chen</name>
    </author>
    <author>
      <name>Chaoyi Wang</name>
    </author>
    <author>
      <name>Yanjie Pan</name>
    </author>
    <author>
      <name>Xiaobin Hu</name>
    </author>
    <author>
      <name>Zhenye Gan</name>
    </author>
    <author>
      <name>Yabiao Wang</name>
    </author>
    <author>
      <name>Chengjie Wang</name>
    </author>
    <author>
      <name>Xiangtai Li</name>
    </author>
    <author>
      <name>Jiangning Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/2507.01908v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2507.01908v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2507.01907v1</id>
    <updated>2025-07-02T17:22:00Z</updated>
    <published>2025-07-02T17:22:00Z</published>
    <title>Spacetime reconstruction by order and number</title>
    <summary>  We show that the random adjacency matrices induced by the chronological
relations and i.i.d. samples of two spacetimes coincide in law if and only if
the spacetimes in question are smoothly isometric. A similar result holds for
weighted spacetimes. In the smooth framework of our article, this relaxes the
hypotheses of the recent Gromov reconstruction theorem in Lorentzian signature
by Braun-S\"amann from a.s. isometry of the respective time separation
functions to a.s. order isometry. In a probabilistic way, our result makes a
key paradigm of causal set theory rigorous: spacetime can be recovered by only
knowing "order" and "number" of its points. It confirms a weak version of
Bombelli's conjecture; therefore, it contributes to recent efforts of
formalizing the Hauptvermutung (viz. fundamental conjecture) of causal set
theory.
</summary>
    <author>
      <name>Mathias Braun</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages. Comments welcome</arxiv:comment>
    <link href="http://arxiv.org/abs/2507.01907v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2507.01907v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="gr-qc" scheme="http://arxiv.org/schemas/atom"/>
    <category term="gr-qc" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.MP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="Primary 51G05, 51K10, 53C23, Secondary 60A10, 60B20, 60G55, 83C99" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2507.01900v1</id>
    <updated>2025-07-02T17:15:05Z</updated>
    <published>2025-07-02T17:15:05Z</published>
    <title>High-Layer Attention Pruning with Rescaling</title>
    <summary>  Pruning is a highly effective approach for compressing large language models
(LLMs), significantly reducing inference latency. However, conventional
training-free structured pruning methods often employ a heuristic metric that
indiscriminately removes some attention heads across all pruning layers,
without considering their positions within the network architecture. In this
work, we propose a novel pruning algorithm that strategically prunes attention
heads in the model's higher layers. Since the removal of attention heads can
alter the magnitude of token representations, we introduce an adaptive
rescaling parameter that calibrates the representation scale post-pruning to
counteract this effect. We conduct comprehensive experiments on a wide range of
LLMs, including LLaMA3.1-8B, Mistral-7B-v0.3, Qwen2-7B, and Gemma2-9B. Our
evaluation includes both generation and discriminative tasks across 27
datasets. The results consistently demonstrate that our method outperforms
existing structured pruning methods. This improvement is particularly notable
in generation tasks, where our approach significantly outperforms existing
baselines.
</summary>
    <author>
      <name>Songtao Liu</name>
    </author>
    <author>
      <name>Peng Liu</name>
    </author>
    <link href="http://arxiv.org/abs/2507.01900v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2507.01900v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2507.01888v1</id>
    <updated>2025-07-02T16:57:46Z</updated>
    <published>2025-07-02T16:57:46Z</published>
    <title>Perceptual Ratings Predict Speech Inversion Articulatory Kinematics in
  Childhood Speech Sound Disorders</title>
    <summary>  Purpose: This study evaluated whether articulatory kinematics, inferred by
Articulatory Phonology speech inversion neural networks, aligned with
perceptual ratings of /r/ and /s/ in the speech of children with speech sound
disorders.
  Methods: Articulatory Phonology vocal tract variables were inferred for 5,961
utterances from 118 children and 3 adults, aged 2.25-45 years. Perceptual
ratings were standardized using the novel 5-point PERCEPT Rating Scale and
training protocol. Two research questions examined if the articulatory patterns
of inferred vocal tract variables aligned with the perceptual error category
for the phones investigated (e.g., tongue tip is more anterior in dentalized
/s/ productions than in correct /s/). A third research question examined if
gradient PERCEPT Rating Scale scores predicted articulatory proximity to
correct productions.
  Results: Estimated marginal means from linear mixed models supported 17 of 18
/r/ hypotheses, involving tongue tip and tongue body constrictions. For /s/,
estimated marginal means from a second linear mixed model supported 7 of 15
hypotheses, particularly those related to the tongue tip. A third linear mixed
model revealed that PERCEPT Rating Scale scores significantly predicted
articulatory proximity of errored phones to correct productions.
  Conclusion: Inferred vocal tract variables differentiated category and
magnitude of articulatory errors for /r/, and to a lesser extent for /s/,
aligning with perceptual judgments. These findings support the clinical
interpretability of speech inversion vocal tract variables and the PERCEPT
Rating Scale in quantifying articulatory proximity to the target sound,
particularly for /r/.
</summary>
    <author>
      <name>Nina R. Benway</name>
    </author>
    <author>
      <name>Saba Tabatabaee</name>
    </author>
    <author>
      <name>Dongliang Wang</name>
    </author>
    <author>
      <name>Benjamin Munson</name>
    </author>
    <author>
      <name>Jonathan L. Preston</name>
    </author>
    <author>
      <name>Carol Espy-Wilson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This manuscript is in submission for publication. It has not yet been
  peer reviewed</arxiv:comment>
    <link href="http://arxiv.org/abs/2507.01888v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2507.01888v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2507.01880v1</id>
    <updated>2025-07-02T16:50:49Z</updated>
    <published>2025-07-02T16:50:49Z</published>
    <title>Evolving HPC services to enable ML workloads on HPE Cray EX</title>
    <summary>  The Alps Research Infrastructure leverages GH200 technology at scale,
featuring 10,752 GPUs. Accessing Alps provides a significant computational
advantage for researchers in Artificial Intelligence (AI) and Machine Learning
(ML). While Alps serves a broad range of scientific communities, traditional
HPC services alone are not sufficient to meet the dynamic needs of the ML
community. This paper presents an initial investigation into extending HPC
service capabilities to better support ML workloads. We identify key challenges
and gaps we have observed since the early-access phase (2023) of Alps by the
Swiss AI community and propose several technological enhancements. These
include a user environment designed to facilitate the adoption of HPC for ML
workloads, balancing performance with flexibility; a utility for rapid
performance screening of ML applications during development; observability
capabilities and data products for inspecting ongoing large-scale ML workloads;
a utility to simplify the vetting of allocated nodes for compute readiness; a
service plane infrastructure to deploy various types of workloads, including
support and inference services; and a storage infrastructure tailored to the
specific needs of ML workloads. These enhancements aim to facilitate the
execution of ML workloads on HPC systems, increase system usability and
resilience, and better align with the needs of the ML community. We also
discuss our current approach to security aspects. This paper concludes by
placing these proposals in the broader context of changes in the communities
served by HPC infrastructure like ours.
</summary>
    <author>
      <name>Stefano Schuppli</name>
    </author>
    <author>
      <name>Fawzi Mohamed</name>
    </author>
    <author>
      <name>Henrique Mendonça</name>
    </author>
    <author>
      <name>Nina Mujkanovic</name>
    </author>
    <author>
      <name>Elia Palme</name>
    </author>
    <author>
      <name>Dino Conciatore</name>
    </author>
    <author>
      <name>Lukas Drescher</name>
    </author>
    <author>
      <name>Miguel Gila</name>
    </author>
    <author>
      <name>Pim Witlox</name>
    </author>
    <author>
      <name>Joost VandeVondele</name>
    </author>
    <author>
      <name>Maxime Martinasso</name>
    </author>
    <author>
      <name>Thomas C. Schulthess</name>
    </author>
    <author>
      <name>Torsten Hoefler</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at the Cray User Group 2025 (CUG'25)</arxiv:comment>
    <link href="http://arxiv.org/abs/2507.01880v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2507.01880v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
