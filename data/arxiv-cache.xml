<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2026-02-13T01:20:46Z -->
<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/" xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns="http://www.w3.org/2005/Atom">
  <id>https://arxiv.org/api/p6EyKyP4fMY/66n9Ev8E79F7KlI</id>
  <title>arXiv Query: search_query=all:causal OR all:inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <updated>2026-02-13T01:20:47Z</updated>
  <link href="https://arxiv.org/api/query?search_query=all:causal+OR+all:inference&amp;start=0&amp;max_results=10&amp;id_list=" type="application/atom+xml"/>
  <opensearch:itemsPerPage>10</opensearch:itemsPerPage>
  <opensearch:totalResults>133848</opensearch:totalResults>
  <opensearch:startIndex>0</opensearch:startIndex>
  <entry>
    <id>http://arxiv.org/abs/2602.11146v1</id>
    <title>Beyond VLM-Based Rewards: Diffusion-Native Latent Reward Modeling</title>
    <updated>2026-02-11T18:57:29Z</updated>
    <link href="https://arxiv.org/abs/2602.11146v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.11146v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Preference optimization for diffusion and flow-matching models relies on reward functions that are both discriminatively robust and computationally efficient. Vision-Language Models (VLMs) have emerged as the primary reward provider, leveraging their rich multimodal priors to guide alignment. However, their computation and memory cost can be substantial, and optimizing a latent diffusion generator through a pixel-space reward introduces a domain mismatch that complicates alignment. In this paper, we propose DiNa-LRM, a diffusion-native latent reward model that formulates preference learning directly on noisy diffusion states. Our method introduces a noise-calibrated Thurstone likelihood with diffusion-noise-dependent uncertainty. DiNa-LRM leverages a pretrained latent diffusion backbone with a timestep-conditioned reward head, and supports inference-time noise ensembling, providing a diffusion-native mechanism for test-time scaling and robust rewarding. Across image alignment benchmarks, DiNa-LRM substantially outperforms existing diffusion-based reward baselines and achieves performance competitive with state-of-the-art VLMs at a fraction of the computational cost. In preference optimization, we demonstrate that DiNa-LRM improves preference optimization dynamics, enabling faster and more resource-efficient model alignment.</summary>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-11T18:57:29Z</published>
    <arxiv:comment>Code: https://github.com/HKUST-C4G/diffusion-rm</arxiv:comment>
    <arxiv:primary_category term="cs.CV"/>
    <author>
      <name>Gongye Liu</name>
    </author>
    <author>
      <name>Bo Yang</name>
    </author>
    <author>
      <name>Yida Zhi</name>
    </author>
    <author>
      <name>Zhizhou Zhong</name>
    </author>
    <author>
      <name>Lei Ke</name>
    </author>
    <author>
      <name>Didan Deng</name>
    </author>
    <author>
      <name>Han Gao</name>
    </author>
    <author>
      <name>Yongxiang Huang</name>
    </author>
    <author>
      <name>Kaihao Zhang</name>
    </author>
    <author>
      <name>Hongbo Fu</name>
    </author>
    <author>
      <name>Wenhan Luo</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.11144v1</id>
    <title>GENIUS: Generative Fluid Intelligence Evaluation Suite</title>
    <updated>2026-02-11T18:55:54Z</updated>
    <link href="https://arxiv.org/abs/2602.11144v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.11144v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Unified Multimodal Models (UMMs) have shown remarkable progress in visual generation. Yet, existing benchmarks predominantly assess $\textit{Crystallized Intelligence}$, which relies on recalling accumulated knowledge and learned schemas. This focus overlooks $\textit{Generative Fluid Intelligence (GFI)}$: the capacity to induce patterns, reason through constraints, and adapt to novel scenarios on the fly. To rigorously assess this capability, we introduce $\textbf{GENIUS}$ ($\textbf{GEN}$ Fluid $\textbf{I}$ntelligence Eval$\textbf{U}$ation $\textbf{S}$uite). We formalize $\textit{GFI}$ as a synthesis of three primitives. These include $\textit{Inducing Implicit Patterns}$ (e.g., inferring personalized visual preferences), $\textit{Executing Ad-hoc Constraints}$ (e.g., visualizing abstract metaphors), and $\textit{Adapting to Contextual Knowledge}$ (e.g., simulating counter-intuitive physics). Collectively, these primitives challenge models to solve problems grounded entirely in the immediate context. Our systematic evaluation of 12 representative models reveals significant performance deficits in these tasks. Crucially, our diagnostic analysis disentangles these failure modes. It demonstrates that deficits stem from limited context comprehension rather than insufficient intrinsic generative capability. To bridge this gap, we propose a training-free attention intervention strategy. Ultimately, $\textbf{GENIUS}$ establishes a rigorous standard for $\textit{GFI}$, guiding the field beyond knowledge utilization toward dynamic, general-purpose reasoning. Our dataset and code will be released at: $\href{https://github.com/arctanxarc/GENIUS}{https://github.com/arctanxarc/GENIUS}$.</summary>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-11T18:55:54Z</published>
    <arxiv:primary_category term="cs.LG"/>
    <author>
      <name>Ruichuan An</name>
    </author>
    <author>
      <name>Sihan Yang</name>
    </author>
    <author>
      <name>Ziyu Guo</name>
    </author>
    <author>
      <name>Wei Dai</name>
    </author>
    <author>
      <name>Zijun Shen</name>
    </author>
    <author>
      <name>Haodong Li</name>
    </author>
    <author>
      <name>Renrui Zhang</name>
    </author>
    <author>
      <name>Xinyu Wei</name>
    </author>
    <author>
      <name>Guopeng Li</name>
    </author>
    <author>
      <name>Wenshan Wu</name>
    </author>
    <author>
      <name>Wentao Zhang</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.11139v1</id>
    <title>TabICLv2: A better, faster, scalable, and open tabular foundation model</title>
    <updated>2026-02-11T18:51:02Z</updated>
    <link href="https://arxiv.org/abs/2602.11139v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.11139v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Tabular foundation models, such as TabPFNv2 and TabICL, have recently dethroned gradient-boosted trees at the top of predictive benchmarks, demonstrating the value of in-context learning for tabular data. We introduce TabICLv2, a new state-of-the-art foundation model for regression and classification built on three pillars: (1) a novel synthetic data generation engine designed for high pretraining diversity; (2) various architectural innovations, including a new scalable softmax in attention improving generalization to larger datasets without prohibitive long-sequence pretraining; and (3) optimized pretraining protocols, notably replacing AdamW with the Muon optimizer. On the TabArena and TALENT benchmarks, TabICLv2 without any tuning surpasses the performance of the current state of the art, RealTabPFN-2.5 (hyperparameter-tuned, ensembled, and fine-tuned on real data). With only moderate pretraining compute, TabICLv2 generalizes effectively to million-scale datasets under 50GB GPU memory while being markedly faster than RealTabPFN-2.5. We provide extensive ablation studies to quantify these contributions and commit to open research by first releasing inference code and model weights at https://github.com/soda-inria/tabicl, with synthetic data engine and pretraining code to follow.</summary>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-11T18:51:02Z</published>
    <arxiv:primary_category term="cs.LG"/>
    <author>
      <name>Jingang Qu</name>
    </author>
    <author>
      <name>David Holzmüller</name>
    </author>
    <author>
      <name>Gaël Varoquaux</name>
    </author>
    <author>
      <name>Marine Le Morvan</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.11132v1</id>
    <title>A New Look at Bayesian Testing</title>
    <updated>2026-02-11T18:43:13Z</updated>
    <link href="https://arxiv.org/abs/2602.11132v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.11132v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>We develop a unified framework for Bayesian hypothesis testing through the theory of moderate deviations, providing explicit asymptotic expansions for Bayes risk and optimal test statistics. Our analysis reveals that Bayesian test cutoffs operate on the moderate deviation scale $\sqrt{\log n/n}$, in sharp contrast to the sample-size-invariant calibrations of classical testing. This fundamental difference explains the Lindley paradox and establishes the risk-theoretic superiority of Bayesian procedures over fixed-$α$ Neyman-Pearson tests. We extend the seminal Rubin (1965) program to contemporary settings including high-dimensional sparse inference, goodness-of-fit testing, and model selection. The framework unifies several classical results: Jeffreys' $\sqrt{\log n}$ threshold, the BIC penalty $(d/2)\log n$, and the Chernoff-Stein error exponents all emerge naturally from moderate deviation analysis of Bayes risk. Our results provide theoretical foundations for adaptive significance levels and connect Bayesian testing to information theory through gambling-based interpretations.</summary>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-11T18:43:13Z</published>
    <arxiv:primary_category term="math.ST"/>
    <author>
      <name>Jyotishka Datta</name>
    </author>
    <author>
      <name>Nicholas G. Polson</name>
    </author>
    <author>
      <name>Vadim Sokolov</name>
    </author>
    <author>
      <name>Daniel Zantedeschi</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.11124v1</id>
    <title>PhyCritic: Multimodal Critic Models for Physical AI</title>
    <updated>2026-02-11T18:35:39Z</updated>
    <link href="https://arxiv.org/abs/2602.11124v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.11124v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>With the rapid development of large multimodal models, reliable judge and critic models have become essential for open-ended evaluation and preference alignment, providing pairwise preferences, numerical scores, and explanatory justifications for assessing model-generated responses. However, existing critics are primarily trained in general visual domains such as captioning or image question answering, leaving physical AI tasks involving perception, causal reasoning, and planning largely underexplored. We introduce PhyCritic, a multimodal critic model optimized for physical AI through a two-stage RLVR pipeline: a physical skill warmup stage that enhances physically oriented perception and reasoning, followed by self-referential critic finetuning, where the critic generates its own prediction as an internal reference before judging candidate responses, improving judgment stability and physical correctness. Across both physical and general-purpose multimodal judge benchmarks, PhyCritic achieves strong performance gains over open-source baselines and, when applied as a policy model, further improves perception and reasoning in physically grounded tasks.</summary>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-11T18:35:39Z</published>
    <arxiv:primary_category term="cs.CV"/>
    <author>
      <name>Tianyi Xiong</name>
    </author>
    <author>
      <name>Shihao Wang</name>
    </author>
    <author>
      <name>Guilin Liu</name>
    </author>
    <author>
      <name>Yi Dong</name>
    </author>
    <author>
      <name>Ming Li</name>
    </author>
    <author>
      <name>Heng Huang</name>
    </author>
    <author>
      <name>Jan Kautz</name>
    </author>
    <author>
      <name>Zhiding Yu</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.11118v1</id>
    <title>A Doubly Robust Machine Learning Approach for Disentangling Treatment Effect Heterogeneity with Functional Outcomes</title>
    <updated>2026-02-11T18:31:59Z</updated>
    <link href="https://arxiv.org/abs/2602.11118v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.11118v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Causal inference is paramount for understanding the effects of interventions, yet extracting personalized insights from increasingly complex data remains a significant challenge for modern machine learning. This is the case, in particular, when considering functional outcomes observed over a continuous domain (e.g., time, or space). Estimation of heterogeneous treatment effects, known as CATE, has emerged as a crucial tool for personalized decision-making, but existing meta-learning frameworks are largely limited to scalar outcomes, failing to provide satisfying results in scientific applications that leverage the rich, continuous information encoded in functional data. Here, we introduce FOCaL (Functional Outcome Causal Learning), a novel, doubly robust meta-learner specifically engineered to estimate a functional heterogeneous treatment effect (F-CATE). FOCaL integrates advanced functional regression techniques for both outcome modeling and functional pseudo-outcome reconstruction, thereby enabling the direct and robust estimation of F-CATE. We provide a rigorous theoretical derivation of FOCaL, demonstrate its performance and robustness compared to existing non-robust functional methods through comprehensive simulation studies, and illustrate its practical utility on diverse real-world functional datasets. FOCaL advances the capabilities of machine intelligence to infer nuanced, individualized causal effects from complex data, paving the way for more precise and trustworthy AI systems in personalized medicine, adaptive policy design, and fundamental scientific discovery.</summary>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-11T18:31:59Z</published>
    <arxiv:comment>20 pages, 4 figures</arxiv:comment>
    <arxiv:primary_category term="stat.ME"/>
    <author>
      <name>Filippo Salmaso</name>
    </author>
    <author>
      <name>Lorenzo Testa</name>
    </author>
    <author>
      <name>Francesca Chiaromonte</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.11105v1</id>
    <title>FastFlow: Accelerating The Generative Flow Matching Models with Bandit Inference</title>
    <updated>2026-02-11T18:21:11Z</updated>
    <link href="https://arxiv.org/abs/2602.11105v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.11105v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Flow-matching models deliver state-of-the-art fidelity in image and video generation, but the inherent sequential denoising process renders them slower. Existing acceleration methods like distillation, trajectory truncation, and consistency approaches are static, require retraining, and often fail to generalize across tasks. We propose FastFlow, a plug-and-play adaptive inference framework that accelerates generation in flow matching models. FastFlow identifies denoising steps that produce only minor adjustments to the denoising path and approximates them without using the full neural network models used for velocity predictions. The approximation utilizes finite-difference velocity estimates from prior predictions to efficiently extrapolate future states, enabling faster advancements along the denoising path at zero compute cost. This enables skipping computation at intermediary steps. We model the decision of how many steps to safely skip before requiring a full model computation as a multi-armed bandit problem. The bandit learns the optimal skips to balance speed with performance. FastFlow integrates seamlessly with existing pipelines and generalizes across image generation, video generation, and editing tasks. Experiments demonstrate a speedup of over 2.6x while maintaining high-quality outputs. The source code for this work can be found at https://github.com/Div290/FastFlow.</summary>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-11T18:21:11Z</published>
    <arxiv:comment>Accepted at International Conference on Learning Representations (ICLR) 2026</arxiv:comment>
    <arxiv:primary_category term="cs.CV"/>
    <author>
      <name>Divya Jyoti Bajpai</name>
    </author>
    <author>
      <name>Dhruv Bhardwaj</name>
    </author>
    <author>
      <name>Soumya Roy</name>
    </author>
    <author>
      <name>Tejas Duseja</name>
    </author>
    <author>
      <name>Harsh Agarwal</name>
    </author>
    <author>
      <name>Aashay Sandansing</name>
    </author>
    <author>
      <name>Manjesh Kumar Hanawal</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.11102v1</id>
    <title>WHEREIS: IP Address Registration Geo-Consistency</title>
    <updated>2026-02-11T18:13:59Z</updated>
    <link href="https://arxiv.org/abs/2602.11102v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.11102v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>The five Regional Internet Registries (RIRs) provide the critical function of IP address resource del egation and registration. The accuracy of registration data directly impacts Internet operation, management, security, and optimization. In addition, the scarcity of IP addresses has brought into focus conflicts between RIR policy and IP registration ownership and use. The tension between a free-market based approach to address allocation versus policies to promote fairness and regional equity has resulted in court litigation that threatens the very existence of the RIR system.
  We develop WHEREIS, a measurement-based approach to geolocate delegated IPv4 and IPv6 prefixes at an RIR-region granularity and systematically study where addresses are used post-allocation and the extent to which registration information is accurate. We define a taxonomy of registration ``geo-consistency'' that compares a prefix's measured geolocation to the allocating RIR's coverage region as well as the registered organization's location. While in aggregate over 98% of the prefixes we examine are consistent with our geolocation inferences, there is substantial variation across RIRs and we focus on AFRINIC as a case study. IPv6 registrations are no more consistent than IPv4, suggesting that structural, rather than technical, issues play an important role in allocations. We solicit additional information on inconsistent prefixes from network operators, IP leasing providers, and collaborate with three RIRs to obtain validation. We further show that the inconsistencies we discover manifest in three commercial geolocation databases. By improving the transparency around post-allocation prefix use, we hope to improve applications that use IP registration data and inform ongoing discussions over in-region address use and policy.</summary>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-11T18:13:59Z</published>
    <arxiv:comment>arXiv admin note: text overlap with arXiv:2308.12436</arxiv:comment>
    <arxiv:primary_category term="cs.NI"/>
    <author>
      <name>Robert Beverly</name>
    </author>
    <author>
      <name>Amreesh Phokeer</name>
    </author>
    <author>
      <name>Oliver Gasser</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.11096v1</id>
    <title>Safety Recovery in Reasoning Models Is Only a Few Early Steering Steps Away</title>
    <updated>2026-02-11T18:09:17Z</updated>
    <link href="https://arxiv.org/abs/2602.11096v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.11096v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Reinforcement learning (RL) based post-training for explicit chain-of-thought (e.g., GRPO) improves the reasoning ability of multimodal large-scale reasoning models (MLRMs). But recent evidence shows that it can simultaneously degrade safety alignment and increase jailbreak success rates. We propose SafeThink, a lightweight inference-time defense that treats safety recovery as a satisficing constraint rather than a maximization objective. SafeThink monitors the evolving reasoning trace with a safety reward model and conditionally injects an optimized short corrective prefix ("Wait, think safely") only when the safety threshold is violated. In our evaluations across six open-source MLRMs and four jailbreak benchmarks (JailbreakV-28K, Hades, FigStep, and MM-SafetyBench), SafeThink reduces attack success rates by 30-60% (e.g., LlamaV-o1: 63.33% to 5.74% on JailbreakV-28K, R1-Onevision: 69.07% to 5.65% on Hades) while preserving reasoning performance (MathVista accuracy: 65.20% to 65.00%). A key empirical finding from our experiments is that safety recovery is often only a few steering steps away: intervening in the first 1-3 reasoning steps typically suffices to redirect the full generation toward safe completions.</summary>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-11T18:09:17Z</published>
    <arxiv:primary_category term="cs.CL"/>
    <author>
      <name>Soumya Suvra Ghosal</name>
    </author>
    <author>
      <name>Souradip Chakraborty</name>
    </author>
    <author>
      <name>Vaibhav Singh</name>
    </author>
    <author>
      <name>Furong Huang</name>
    </author>
    <author>
      <name>Dinesh Manocha</name>
    </author>
    <author>
      <name>Amrit Singh Bedi</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.11088v1</id>
    <title>Vulnerabilities in Partial TEE-Shielded LLM Inference with Precomputed Noise</title>
    <updated>2026-02-11T17:56:05Z</updated>
    <link href="https://arxiv.org/abs/2602.11088v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.11088v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>The deployment of large language models (LLMs) on third-party devices requires new ways to protect model intellectual property. While Trusted Execution Environments (TEEs) offer a promising solution, their performance limits can lead to a critical compromise: using a precomputed, static secret basis to accelerate cryptographic operations. We demonstrate that this mainstream design pattern introduces a classic cryptographic flaw, the reuse of secret keying material, into the system's protocol. We prove its vulnerability with two distinct attacks: First, our attack on a model confidentiality system achieves a full confidentiality break by recovering its secret permutations and model weights. Second, our integrity attack completely bypasses the integrity checks of systems like Soter and TSQP. We demonstrate the practicality of our attacks against state-of-the-art LLMs, recovering a layer's secrets from a LLaMA-3 8B model in about 6 minutes and showing the attack scales to compromise 405B-parameter LLMs across a variety of configurations.</summary>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-11T17:56:05Z</published>
    <arxiv:primary_category term="cs.CR"/>
    <author>
      <name>Abhishek Saini</name>
    </author>
    <author>
      <name>Haolin Jiang</name>
    </author>
    <author>
      <name>Hang Liu</name>
    </author>
  </entry>
</feed>
