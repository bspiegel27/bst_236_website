<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-10-14T00:53:08Z -->
<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acausal%20inference%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:causal inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/SsRksLzRb0LuVhSmQ+N8WbAs+f8</id>
  <updated>2025-10-13T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">123395</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">10</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2510.09608v1</id>
    <updated>2025-10-10T17:59:58Z</updated>
    <published>2025-10-10T17:59:58Z</published>
    <title>StreamingVLM: Real-Time Understanding for Infinite Video Streams</title>
    <summary>  Vision-language models (VLMs) could power real-time assistants and autonomous
agents, but they face a critical challenge: understanding near-infinite video
streams without escalating latency and memory usage. Processing entire videos
with full attention leads to quadratic computational costs and poor performance
on long videos. Meanwhile, simple sliding window methods are also flawed, as
they either break coherence or suffer from high latency due to redundant
recomputation. In this paper, we introduce StreamingVLM, a model designed for
real-time, stable understanding of infinite visual input. Our approach is a
unified framework that aligns training with streaming inference. During
inference, we maintain a compact KV cache by reusing states of attention sinks,
a short window of recent vision tokens, and a long window of recent text
tokens. This streaming ability is instilled via a simple supervised fine-tuning
(SFT) strategy that applies full attention on short, overlapped video chunks,
which effectively mimics the inference-time attention pattern without training
on prohibitively long contexts. For evaluation, we build Inf-Streams-Eval, a
new benchmark with videos averaging over two hours that requires dense,
per-second alignment between frames and text. On Inf-Streams-Eval, StreamingVLM
achieves a 66.18% win rate against GPT-4O mini and maintains stable, real-time
performance at up to 8 FPS on a single NVIDIA H100. Notably, our SFT strategy
also enhances general VQA abilities without any VQA-specific fine-tuning,
improving performance on LongVideoBench by +4.30 and OVOBench Realtime by
+5.96. Code is available at https://github.com/mit-han-lab/streaming-vlm.
</summary>
    <author>
      <name>Ruyi Xu</name>
    </author>
    <author>
      <name>Guangxuan Xiao</name>
    </author>
    <author>
      <name>Yukang Chen</name>
    </author>
    <author>
      <name>Liuning He</name>
    </author>
    <author>
      <name>Kelly Peng</name>
    </author>
    <author>
      <name>Yao Lu</name>
    </author>
    <author>
      <name>Song Han</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The first two authors contributed equally to this work</arxiv:comment>
    <link href="http://arxiv.org/abs/2510.09608v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.09608v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.09602v1</id>
    <updated>2025-10-10T17:59:02Z</updated>
    <published>2025-10-10T17:59:02Z</published>
    <title>Anchoring the Universe with Characteristic Redshifts using Raychaudhuri
  Equation Informed Reconstruction Algorithm (REIRA)</title>
    <summary>  We study the robustness and physical implications of a set of characteristic
redshifts that capture key features of the late-time Universe. Using both
model-independent reconstructions as well as different dark energy (DE)
parameterizations, we show that these redshifts remain stable across
cosmological models and reconstruction algorithm, making them reliable
geometric anchors of the expansion history. Moreover, the Alcock-Paczy\'nski
corrections at these redshift anchors are found to be unity with high
statistical significance, making them natural isotropy points in the comoving
distance-redshift relation. We also find that certain redshifts anchors $(z &lt;
1)$ coincide with epochs where strong deviations from the Planck $\Lambda$CDM
baseline are apparent irrespective of DE parametrisation like CPL or
reconstruction algorithm, indicating their potential as probes of new physics
in cosmological evolution. Finally, we demonstrate, for the first time, that a
Raychaudhuri Equation Informed Reconstruction Algorithm, substantially enhances
the precision of the inferred distance measures and the Hubble expansion rate
as well as results tighter constraints in the DE parameter space. These results
demonstrate that combining geometric reconstruction with physics-informed
kinematic information offers a powerful and consistent algorithm to probe new
physics in the late-time dynamics of our Universe.
</summary>
    <author>
      <name>Shibendu Gupta Choudhury</name>
    </author>
    <author>
      <name>Purba Mukherjee</name>
    </author>
    <author>
      <name>Anjan Ananda Sen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 5 sets of figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2510.09602v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.09602v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="gr-qc" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.09599v1</id>
    <updated>2025-10-10T17:57:04Z</updated>
    <published>2025-10-10T17:57:04Z</published>
    <title>Prompting Test-Time Scaling Is A Strong LLM Reasoning Data Augmentation</title>
    <summary>  Large language models (LLMs) have demonstrated impressive reasoning
capabilities when provided with chain-of-thought exemplars, but curating large
reasoning datasets remains laborious and resource-intensive. In this work, we
introduce Prompting Test-Time Scaling (P-TTS), a simple yet effective
inference-time data augmentation strategy for enhancing LLM reasoning through
finetuning. Rather than collecting thousands or even millions of examples,
P-TTS leverages a small pool of only 90 manually selected reasoning instances
and systematically varies exemplar augmentation through principled instruction
prompting intensities at test time to synthesize diverse reasoning trajectory
contexts. Then we finetune the various sizes of Qwen-2.5 models on P-TTS data.
Across a suite of mathematical reasoning AIME2024 &amp; 25, MATH500, and
GPQA-Diamond, our P-TTS-7B and 32B models outperform the prior competitive
baselines like S1 and S1.1 (1K-shot), achieving absolute accuracy gains of
+26.66% and +30.00% on AIME'24 (7B), and +13.34% and +6.67% on AIME'25 (7B);
P-TTS-32B yields gains of +23.33% and +16.63% on AIME'24, and +26.63% and
+3.33% on AIME'25 (vs. S1 and S1.1, respectively), with comparable or better
performance on MATH500 and GPQA-Diamond. We further show that P-TTS enhances
zero-shot generalization accuracy on out-of-domain reasoning benchmarks of
Gaokao, Kaoyan, OlympiadBench, AMC23, GradeSchoolMath, and Minerva. Our
analysis suggests that test-time scaling effectively explores the latent space
of reasoning patterns, amplifying LLM problem-solving with minimal annotation
overhead, and further unlocking the reasoning potential and capabilities of
LLMs. Prompting Test-Time Scaling offers a practical, low-cost way to elicit
LLM reasoning in resource-constrained or rapidly evolving domains.
</summary>
    <author>
      <name>Sondos Mahmoud Bsharat</name>
    </author>
    <author>
      <name>Zhiqiang Shen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Our code and data are available at https://github.com/VILA-Lab/PTTS</arxiv:comment>
    <link href="http://arxiv.org/abs/2510.09599v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.09599v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.09598v1</id>
    <updated>2025-10-10T17:55:28Z</updated>
    <published>2025-10-10T17:55:28Z</published>
    <title>Defensive Model Expansion for Robust Bayesian Inference</title>
    <summary>  Some applied researchers hesitate to use nonparametric methods, worrying that
they will lose power in small samples or overfit the data when simpler models
are sufficient. We argue that at least some of these concerns are unfounded
when nonparametric models are strongly shrunk towards parametric submodels. We
consider expanding a parametric model with a nonparametric component that is
heavily shrunk toward zero. This construction allows the model to adapt
automatically: if the parametric model is correct, the nonparametric component
disappears, recovering parametric efficiency, while if it is misspecified, the
flexible component activates to capture the missing signal. We show that this
adaptive behavior follows from simple and general conditions. Specifically, we
prove that Bayesian nonparametric models anchored to linear regression,
including variants of Gaussian processes regression and Bayesian additive
regression trees, consistently identify the correct parametric submodel when it
holds and give asymptotically efficient inference for regression coefficients.
In simulations, we find that the "general BART" model performs identically to
correctly specified linear regression when the parametric model holds, and
substantially outperform it when nonlinear effects are present. This suggests a
practical paradigm: "defensive model expansion" as a safeguard against model
misspecification.
</summary>
    <author>
      <name>Antonio R. Linero</name>
    </author>
    <link href="http://arxiv.org/abs/2510.09598v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.09598v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.09583v1</id>
    <updated>2025-10-10T17:38:40Z</updated>
    <published>2025-10-10T17:38:40Z</published>
    <title>FSP-DETR: Few-Shot Prototypical Parasitic Ova Detection</title>
    <summary>  Object detection in biomedical settings is fundamentally constrained by the
scarcity of labeled data and the frequent emergence of novel or rare
categories. We present FSP-DETR, a unified detection framework that enables
robust few-shot detection, open-set recognition, and generalization to unseen
biomedical tasks within a single model. Built upon a class-agnostic DETR
backbone, our approach constructs class prototypes from original support images
and learns an embedding space using augmented views and a lightweight
transformer decoder. Training jointly optimizes a prototype matching loss, an
alignment-based separation loss, and a KL divergence regularization to improve
discriminative feature learning and calibration under scarce supervision.
Unlike prior work that tackles these tasks in isolation, FSP-DETR enables
inference-time flexibility to support unseen class recognition, background
rejection, and cross-task adaptation without retraining. We also introduce a
new ova species detection benchmark with 20 parasite classes and establish
standardized evaluation protocols. Extensive experiments across ova, blood
cell, and malaria detection tasks demonstrate that FSP-DETR significantly
outperforms prior few-shot and prototype-based detectors, especially in
low-shot and open-set scenarios.
</summary>
    <author>
      <name>Shubham Trehan</name>
    </author>
    <author>
      <name>Udhav Ramachandran</name>
    </author>
    <author>
      <name>Akash Rao</name>
    </author>
    <author>
      <name>Ruth Scimeca</name>
    </author>
    <author>
      <name>Sathyanarayanan N. Aakur</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 3 Figures, 5 Tables. Under Review</arxiv:comment>
    <link href="http://arxiv.org/abs/2510.09583v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.09583v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.09574v1</id>
    <updated>2025-10-10T17:28:12Z</updated>
    <published>2025-10-10T17:28:12Z</published>
    <title>Zero-shot Structure Learning and Planning for Autonomous Robot
  Navigation using Active Inference</title>
    <summary>  Autonomous navigation in unfamiliar environments requires robots to
simultaneously explore, localise, and plan under uncertainty, without relying
on predefined maps or extensive training. We present a biologically inspired,
Active Inference-based framework, Active Inference MAPping and Planning
(AIMAPP). This model unifies mapping, localisation, and decision-making within
a single generative model. Inspired by hippocampal navigation, it uses
topological reasoning, place-cell encoding, and episodic memory to guide
behaviour. The agent builds and updates a sparse topological map online, learns
state transitions dynamically, and plans actions by minimising Expected Free
Energy. This allows it to balance goal-directed and exploratory behaviours. We
implemented a ROS-compatible navigation system that is sensor and
robot-agnostic, capable of integrating with diverse hardware configurations. It
operates in a fully self-supervised manner, is resilient to drift, and supports
both exploration and goal-directed navigation without any pre-training. We
demonstrate robust performance in large-scale real and simulated environments
against state-of-the-art planning models, highlighting the system's
adaptability to ambiguous observations, environmental changes, and sensor
noise. The model offers a biologically inspired, modular solution to scalable,
self-supervised navigation in unstructured settings. AIMAPP is available at
https://github.com/decide-ugent/AIMAPP.
</summary>
    <author>
      <name>Daria de tinguy</name>
    </author>
    <author>
      <name>Tim Verbelen</name>
    </author>
    <author>
      <name>Emilio Gamba</name>
    </author>
    <author>
      <name>Bart Dhoedt</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">yet to be submitted</arxiv:comment>
    <link href="http://arxiv.org/abs/2510.09574v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.09574v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.09557v1</id>
    <updated>2025-10-10T17:07:48Z</updated>
    <published>2025-10-10T17:07:48Z</published>
    <title>Doc2Query++: Topic-Coverage based Document Expansion and its Application
  to Dense Retrieval via Dual-Index Fusion</title>
    <summary>  Document expansion (DE) via query generation tackles vocabulary mismatch in
sparse retrieval, yet faces limitations: uncontrolled generation producing
hallucinated or redundant queries with low diversity; poor generalization from
in-domain training (e.g., MS MARCO) to out-of-domain data like BEIR; and noise
from concatenation harming dense retrieval. While Large Language Models (LLMs)
enable cross-domain query generation, basic prompting lacks control, and
taxonomy-based methods rely on domain-specific structures, limiting
applicability. To address these challenges, we introduce Doc2Query++, a DE
framework that structures query generation by first inferring a document's
latent topics via unsupervised topic modeling for cross-domain applicability,
then using hybrid keyword selection to create a diverse and relevant keyword
set per document. This guides LLM not only to leverage keywords, which ensure
comprehensive topic representation, but also to reduce redundancy through
diverse, relevant terms. To prevent noise from query appending in dense
retrieval, we propose Dual-Index Fusion strategy that isolates text and query
signals, boosting performance in dense settings. Extensive experiments show
Doc2Query++ significantly outperforms state-of-the-art baselines, achieving
substantial gains in MAP, nDCG@10 and Recall@100 across diverse datasets on
both sparse and dense retrieval.
</summary>
    <author>
      <name>Tzu-Lin Kuo</name>
    </author>
    <author>
      <name>Wei-Ning Chiu</name>
    </author>
    <author>
      <name>Wei-Yun Ma</name>
    </author>
    <author>
      <name>Pu-Jen Cheng</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2510.09557v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.09557v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.09556v1</id>
    <updated>2025-10-10T17:07:45Z</updated>
    <published>2025-10-10T17:07:45Z</published>
    <title>WUGNECTIVES: Novel Entity Inferences of Language Models from Discourse
  Connectives</title>
    <summary>  The role of world knowledge has been particularly crucial to predict the
discourse connective that marks the discourse relation between two arguments,
with language models (LMs) being generally successful at this task. We flip
this premise in our work, and instead study the inverse problem of
understanding whether discourse connectives can inform LMs about the world. To
this end, we present WUGNECTIVES, a dataset of 8,880 stimuli that evaluates
LMs' inferences about novel entities in contexts where connectives link the
entities to particular attributes. On investigating 17 different LMs at various
scales, and training regimens, we found that tuning an LM to show reasoning
behavior yields noteworthy improvements on most connectives. At the same time,
there was a large variation in LMs' overall performance across connective type,
with all models systematically struggling on connectives that express a
concessive meaning. Our findings pave the way for more nuanced investigations
into the functional role of language cues as captured by LMs. We release
WUGNECTIVES at https://github.com/sheffwb/wugnectives.
</summary>
    <author>
      <name>Daniel Brubaker</name>
    </author>
    <author>
      <name>William Sheffield</name>
    </author>
    <author>
      <name>Junyi Jessy Li</name>
    </author>
    <author>
      <name>Kanishka Misra</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages total, 9 pages main; 7 figures total, 4 figures main; 8
  tables total, 4 tables main</arxiv:comment>
    <link href="http://arxiv.org/abs/2510.09556v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.09556v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.09544v1</id>
    <updated>2025-10-10T16:58:14Z</updated>
    <published>2025-10-10T16:58:14Z</published>
    <title>Beyond Surface Reasoning: Unveiling the True Long Chain-of-Thought
  Capacity of Diffusion Large Language Models</title>
    <summary>  Recently, Diffusion Large Language Models (DLLMs) have offered high
throughput and effective sequential reasoning, making them a competitive
alternative to autoregressive LLMs (ALLMs). However, parallel decoding, which
enables simultaneous token updates, conflicts with the causal order often
required for rigorous reasoning. We first identify this conflict as the core
Parallel-Sequential Contradiction (PSC). Behavioral analyses in both simple and
complex reasoning tasks show that DLLMs exhibit genuine parallelism only for
directly decidable outputs. As task difficulty increases, they revert to
autoregressive-like behavior, a limitation exacerbated by autoregressive
prompting, which nearly doubles the number of decoding steps with remasking
without improving quality. Moreover, PSC restricts DLLMs' self-reflection,
reasoning depth, and exploratory breadth. To further characterize PSC, we
introduce three scaling dimensions for DLLMs: parallel, diffusion, and
sequential. Empirically, while parallel scaling yields consistent improvements,
diffusion and sequential scaling are constrained by PSC. Based on these
findings, we propose several practical mitigations, parallel-oriented
prompting, diffusion early stopping, and parallel scaling, to reduce
PSC-induced ineffectiveness and inefficiencies.
</summary>
    <author>
      <name>Qiguang Chen</name>
    </author>
    <author>
      <name>Hanjing Li</name>
    </author>
    <author>
      <name>Libo Qin</name>
    </author>
    <author>
      <name>Dengyun Peng</name>
    </author>
    <author>
      <name>Jinhao Liu</name>
    </author>
    <author>
      <name>Jiangyi Wang</name>
    </author>
    <author>
      <name>Chengyue Wu</name>
    </author>
    <author>
      <name>Xie Chen</name>
    </author>
    <author>
      <name>Yantao Du</name>
    </author>
    <author>
      <name>Wanxiang Che</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Preprint</arxiv:comment>
    <link href="http://arxiv.org/abs/2510.09544v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.09544v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.09536v1</id>
    <updated>2025-10-10T16:49:12Z</updated>
    <published>2025-10-10T16:49:12Z</published>
    <title>Evaluating Robustness of Large Language Models Against Multilingual
  Typographical Errors</title>
    <summary>  Large language models (LLMs) are increasingly deployed in multilingual,
real-world applications with user inputs -- naturally introducing typographical
errors (typos). Yet most benchmarks assume clean input, leaving the robustness
of LLMs to typos across languages largely underexplored. To address this gap,
we introduce MulTypo, a multilingual typo generation algorithm that simulates
human-like errors based on language-specific keyboard layouts and typing
behavior. We evaluate 18 open-source LLMs across three model families and five
downstream tasks spanning language inference, multi-choice question answering,
mathematical reasoning, and machine translation tasks. Our results show that
typos consistently degrade performance, particularly in generative tasks and
those requiring reasoning -- while the natural language inference task is
comparatively more robust. Instruction tuning improves clean-input performance
but may increase brittleness under noise. We also observe language-dependent
robustness: high-resource languages are generally more robust than low-resource
ones, and translation from English is more robust than translation into
English. Our findings underscore the need for noise-aware training and
multilingual robustness evaluation. We make our code and data publicly
available.
</summary>
    <author>
      <name>Yihong Liu</name>
    </author>
    <author>
      <name>Raoyuan Zhao</name>
    </author>
    <author>
      <name>Lena Altinger</name>
    </author>
    <author>
      <name>Hinrich Sch√ºtze</name>
    </author>
    <author>
      <name>Michael A. Hedderich</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">preprint</arxiv:comment>
    <link href="http://arxiv.org/abs/2510.09536v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.09536v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
