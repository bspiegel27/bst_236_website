<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-04-18T00:53:13Z -->
<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acausal%20inference%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:causal inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/SsRksLzRb0LuVhSmQ+N8WbAs+f8</id>
  <updated>2025-04-17T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">110776</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">10</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2504.12285v1</id>
    <updated>2025-04-16T17:51:43Z</updated>
    <published>2025-04-16T17:51:43Z</published>
    <title>BitNet b1.58 2B4T Technical Report</title>
    <summary>  We introduce BitNet b1.58 2B4T, the first open-source, native 1-bit Large
Language Model (LLM) at the 2-billion parameter scale. Trained on a corpus of 4
trillion tokens, the model has been rigorously evaluated across benchmarks
covering language understanding, mathematical reasoning, coding proficiency,
and conversational ability. Our results demonstrate that BitNet b1.58 2B4T
achieves performance on par with leading open-weight, full-precision LLMs of
similar size, while offering significant advantages in computational
efficiency, including substantially reduced memory footprint, energy
consumption, and decoding latency. To facilitate further research and adoption,
the model weights are released via Hugging Face along with open-source
inference implementations for both GPU and CPU architectures.
</summary>
    <author>
      <name>Shuming Ma</name>
    </author>
    <author>
      <name>Hongyu Wang</name>
    </author>
    <author>
      <name>Shaohan Huang</name>
    </author>
    <author>
      <name>Xingxing Zhang</name>
    </author>
    <author>
      <name>Ying Hu</name>
    </author>
    <author>
      <name>Ting Song</name>
    </author>
    <author>
      <name>Yan Xia</name>
    </author>
    <author>
      <name>Furu Wei</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Work in progress</arxiv:comment>
    <link href="http://arxiv.org/abs/2504.12285v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.12285v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.12282v1</id>
    <updated>2025-04-16T17:44:56Z</updated>
    <published>2025-04-16T17:44:56Z</published>
    <title>Quantum Area Fluctuations from Gravitational Phase Space</title>
    <summary>  We study the gravitational phase space associated to a stretched horizon
within a finite-sized causal diamond in $(d+2)$-dimensional spacetimes. By
imposing the Raychaudhuri equation, we obtain its constrained symplectic form
using the covariant phase space formalism and derive the relevant quantum
commutators by inverting the symplectic form and quantizing. Finally, we
compute the area fluctuations of the causal diamond by taking a Carrollian
limit of the stretched horizon in pure Minkowski spacetime, and derive the
relationship $\langle (\Delta A)^2 \rangle \geq \frac{2\pi G}{d}\langle A
\rangle$, showing that the variance of the area fluctuations is proportional to
the area itself.
</summary>
    <author>
      <name>Luca Ciambelli</name>
    </author>
    <author>
      <name>Temple He</name>
    </author>
    <author>
      <name>Kathryn M. Zurek</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">28 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/2504.12282v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.12282v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="hep-th" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-th" scheme="http://arxiv.org/schemas/atom"/>
    <category term="gr-qc" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.12279v1</id>
    <updated>2025-04-16T17:41:19Z</updated>
    <published>2025-04-16T17:41:19Z</published>
    <title>Dysarthria Normalization via Local Lie Group Transformations for Robust
  ASR</title>
    <summary>  We present a geometry-driven method for normalizing dysarthric speech using
local Lie group transformations of spectrograms. Time, frequency, and amplitude
distortions are modeled as smooth, invertible deformations, parameterized by
scalar fields and applied via exponential maps. A neural network is trained to
infer these fields from synthetic distortions of typical speech-without using
any pathological data. At test time, the model applies an approximate inverse
to real dysarthric inputs. Despite zero-shot generalization, we observe
substantial ASR gains, including up to 16 percentage points WER reduction on
challenging TORGO samples, with no degradation on clean speech. This work
introduces a principled, interpretable approach for robust speech recognition
under motor speech disorders
</summary>
    <author>
      <name>Mikhail Osipov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Preprint. 11 pages, 3 figures, 2 tables, 8 appendices. Code and data
  available upon request</arxiv:comment>
    <link href="http://arxiv.org/abs/2504.12279v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.12279v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.12268v1</id>
    <updated>2025-04-16T17:30:36Z</updated>
    <published>2025-04-16T17:30:36Z</published>
    <title>HLS-Eval: A Benchmark and Framework for Evaluating LLMs on High-Level
  Synthesis Design Tasks</title>
    <summary>  The rapid scaling of large language model (LLM) training and inference has
driven their adoption in semiconductor design across academia and industry.
While most prior work evaluates LLMs on hardware description language (HDL)
tasks, particularly Verilog, designers are increasingly using high-level
synthesis (HLS) to build domain-specific accelerators and complex hardware
systems. However, benchmarks and tooling to comprehensively evaluate LLMs for
HLS design tasks remain scarce.
  To address this, we introduce HLS-Eval, the first complete benchmark and
evaluation framework for LLM-driven HLS design. HLS-Eval targets two core
tasks: (1) generating HLS code from natural language descriptions, and (2)
performing HLS-specific code edits to optimize performance and hardware
efficiency. The benchmark includes 94 unique designs drawn from standard HLS
benchmarks and novel sources. Each case is prepared via a semi-automated flow
that produces a natural language description and a paired testbench for
C-simulation and synthesis validation, ensuring each task is "LLM-ready."
  Beyond the benchmark, HLS-Eval offers a modular Python framework for
automated, parallel evaluation of both local and hosted LLMs. It includes a
parallel evaluation engine, direct HLS tool integration, and abstractions for
to support different LLM interaction paradigms, enabling rapid prototyping of
new benchmarks, tasks, and LLM methods.
  We demonstrate HLS-Eval through baseline evaluations of open-source LLMs on
Vitis HLS, measuring outputs across four key metrics - parseability,
compilability, runnability, and synthesizability - reflecting the iterative HLS
design cycle. We also report pass@k metrics, establishing clear baselines and
reusable infrastructure for the broader LLM-for-hardware community.
  All benchmarks, framework code, and results are open-sourced at
https://github.com/stefanpie/hls-eval.
</summary>
    <author>
      <name>Stefan Abi-Karam</name>
    </author>
    <author>
      <name>Cong Hao</name>
    </author>
    <link href="http://arxiv.org/abs/2504.12268v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.12268v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.12267v1</id>
    <updated>2025-04-16T17:28:53Z</updated>
    <published>2025-04-16T17:28:53Z</published>
    <title>New Constraints on DMS and DMDS in the Atmosphere of K2-18 b from JWST
  MIRI</title>
    <summary>  The sub-Neptune frontier has opened a new window into the rich diversity of
planetary environments beyond the solar system. The possibility of hycean
worlds, with planet-wide oceans and H$_2$-rich atmospheres, significantly
expands and accelerates the search for habitable environments elsewhere. Recent
JWST transmission spectroscopy of the candidate hycean world K2-18 b in the
near-infrared led to the first detections of carbon-bearing molecules CH$_4$
and CO$_2$ in its atmosphere, with a composition consistent with predictions
for hycean conditions. The observations also provided a tentative hint of
dimethyl sulfide (DMS), a possible biosignature gas, but the inference was of
low statistical significance. We report a mid-infrared transmission spectrum of
K2-18 b obtained using the JWST MIRI LRS instrument in the ~6-12 $\mu$m range.
The spectrum shows distinct features and is inconsistent with a featureless
spectrum at 3.4-$\sigma$ significance compared to our canonical model. We find
that the spectrum cannot be explained by most molecules predicted for K2-18 b
with the exception of DMS and dimethyl disulfide (DMDS), also a potential
biosignature gas. We report new independent evidence for DMS and/or DMDS in the
atmosphere at 3-$\sigma$ significance, with high abundance ($\gtrsim$10 ppmv)
of at least one of the two molecules. More observations are needed to increase
the robustness of the findings and resolve the degeneracy between DMS and DMDS.
The results also highlight the need for additional experimental and theoretical
work to determine accurate cross sections of important biosignature gases and
identify potential abiotic sources. We discuss the implications of the present
findings for the possibility of biological activity on K2-18 b.
</summary>
    <author>
      <name>Nikku Madhusudhan</name>
    </author>
    <author>
      <name>Savvas Constantinou</name>
    </author>
    <author>
      <name>Måns Holmberg</name>
    </author>
    <author>
      <name>Subhajit Sarkar</name>
    </author>
    <author>
      <name>Anjali A. A. Piette</name>
    </author>
    <author>
      <name>Julianne I. Moses</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication in ApJL</arxiv:comment>
    <link href="http://arxiv.org/abs/2504.12267v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.12267v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.EP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.EP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.12266v1</id>
    <updated>2025-04-16T17:27:52Z</updated>
    <published>2025-04-16T17:27:52Z</published>
    <title>Semiparametric Dynamic Copula Models for Portfolio Optimization</title>
    <summary>  The mean-variance portfolio model, based on the risk-return trade-off for
optimal asset allocation, remains foundational in portfolio optimization.
However, its reliance on restrictive assumptions about asset return
distributions limits its applicability to real-world data. Parametric copula
structures provide a novel way to overcome these limitations by accounting for
asymmetry, heavy tails, and time-varying dependencies. Existing methods have
been shown to rely on fixed or static dependence structures, thus overlooking
the dynamic nature of the financial market. In this study, a semiparametric
model is proposed that combines non-parametrically estimated copulas with
parametrically estimated marginals to allow all parameters to dynamically
evolve over time. A novel framework was developed that integrates time-varying
dependence modeling with flexible empirical beta copula structures. Marginal
distributions were modeled using the Skewed Generalized T family. This
effectively captures asymmetry and heavy tails and makes the model suitable for
predictive inferences in real world scenarios. Furthermore, the model was
applied to rolling windows of financial returns from the USA, India and Hong
Kong economies to understand the influence of dynamic market conditions. The
approach addresses the limitations of models that rely on parametric
assumptions. By accounting for asymmetry, heavy tails, and cross-correlated
asset prices, the proposed method offers a robust solution for optimizing
diverse portfolios in an interconnected financial market. Through adaptive
modeling, it allows for better management of risk and return across varying
economic conditions, leading to more efficient asset allocation and improved
portfolio performance.
</summary>
    <author>
      <name>Savita Pareek</name>
    </author>
    <author>
      <name>Sujit K. Ghosh</name>
    </author>
    <link href="http://arxiv.org/abs/2504.12266v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.12266v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.12264v1</id>
    <updated>2025-04-16T17:21:55Z</updated>
    <published>2025-04-16T17:21:55Z</published>
    <title>Towards Learning to Complete Anything in Lidar</title>
    <summary>  We propose CAL (Complete Anything in Lidar) for Lidar-based shape-completion
in-the-wild. This is closely related to Lidar-based semantic/panoptic scene
completion. However, contemporary methods can only complete and recognize
objects from a closed vocabulary labeled in existing Lidar datasets. Different
to that, our zero-shot approach leverages the temporal context from multi-modal
sensor sequences to mine object shapes and semantic features of observed
objects. These are then distilled into a Lidar-only instance-level completion
and recognition model. Although we only mine partial shape completions, we find
that our distilled model learns to infer full object shapes from multiple such
partial observations across the dataset. We show that our model can be prompted
on standard benchmarks for Semantic and Panoptic Scene Completion, localize
objects as (amodal) 3D bounding boxes, and recognize objects beyond fixed class
vocabularies. Our project page is
https://research.nvidia.com/labs/dvl/projects/complete-anything-lidar
</summary>
    <author>
      <name>Ayca Takmaz</name>
    </author>
    <author>
      <name>Cristiano Saltori</name>
    </author>
    <author>
      <name>Neehar Peri</name>
    </author>
    <author>
      <name>Tim Meinhardt</name>
    </author>
    <author>
      <name>Riccardo de Lutio</name>
    </author>
    <author>
      <name>Laura Leal-Taixé</name>
    </author>
    <author>
      <name>Aljoša Ošep</name>
    </author>
    <link href="http://arxiv.org/abs/2504.12264v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.12264v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.12240v1</id>
    <updated>2025-04-16T16:45:19Z</updated>
    <published>2025-04-16T16:45:19Z</published>
    <title>Cobra: Efficient Line Art COlorization with BRoAder References</title>
    <summary>  The comic production industry requires reference-based line art colorization
with high accuracy, efficiency, contextual consistency, and flexible control. A
comic page often involves diverse characters, objects, and backgrounds, which
complicates the coloring process. Despite advancements in diffusion models for
image generation, their application in line art colorization remains limited,
facing challenges related to handling extensive reference images,
time-consuming inference, and flexible control. We investigate the necessity of
extensive contextual image guidance on the quality of line art colorization. To
address these challenges, we introduce Cobra, an efficient and versatile method
that supports color hints and utilizes over 200 reference images while
maintaining low latency. Central to Cobra is a Causal Sparse DiT architecture,
which leverages specially designed positional encodings, causal sparse
attention, and Key-Value Cache to effectively manage long-context references
and ensure color identity consistency. Results demonstrate that Cobra achieves
accurate line art colorization through extensive contextual reference,
significantly enhancing inference speed and interactivity, thereby meeting
critical industrial demands. We release our codes and models on our project
page: https://zhuang2002.github.io/Cobra/.
</summary>
    <author>
      <name>Junhao Zhuang</name>
    </author>
    <author>
      <name>Lingen Li</name>
    </author>
    <author>
      <name>Xuan Ju</name>
    </author>
    <author>
      <name>Zhaoyang Zhang</name>
    </author>
    <author>
      <name>Chun Yuan</name>
    </author>
    <author>
      <name>Ying Shan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Project page with code: https://zhuang2002.github.io/Cobra/</arxiv:comment>
    <link href="http://arxiv.org/abs/2504.12240v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.12240v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.12187v1</id>
    <updated>2025-04-16T15:42:33Z</updated>
    <published>2025-04-16T15:42:33Z</published>
    <title>What Do Large Language Models Know? Tacit Knowledge as a Potential
  Causal-Explanatory Structure</title>
    <summary>  It is sometimes assumed that Large Language Models (LLMs) know language, or
for example that they know that Paris is the capital of France. But what -- if
anything -- do LLMs actually know? In this paper, I argue that LLMs can acquire
tacit knowledge as defined by Martin Davies (1990). Whereas Davies himself
denies that neural networks can acquire tacit knowledge, I demonstrate that
certain architectural features of LLMs satisfy the constraints of semantic
description, syntactic structure, and causal systematicity. Thus, tacit
knowledge may serve as a conceptual framework for describing, explaining, and
intervening on LLMs and their behavior.
</summary>
    <author>
      <name>Céline Budding</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1017/psa.2025.19</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1017/psa.2025.19" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication in Philosophy of Science</arxiv:comment>
    <link href="http://arxiv.org/abs/2504.12187v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.12187v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.12185v1</id>
    <updated>2025-04-16T15:40:10Z</updated>
    <published>2025-04-16T15:40:10Z</published>
    <title>SALAD: Improving Robustness and Generalization through Contrastive
  Learning with Structure-Aware and LLM-Driven Augmented Data</title>
    <summary>  In various natural language processing (NLP) tasks, fine-tuning Pre-trained
Language Models (PLMs) often leads to the issue of spurious correlations, which
negatively impacts performance, particularly when dealing with
out-of-distribution data. To address this problem, we propose SALAD}(Structure
Aware and LLM-driven Augmented Data), a novel approach designed to enhance
model robustness and generalization by generating structure-aware and
counterfactually augmented data for contrastive learning. Our method leverages
a tagging-based approach to generate structure-aware positive samples and
utilizes large language models (LLMs) to generate counterfactual negative
samples with diverse sentence patterns. By applying contrastive learning, SALAD
enables the model to focus on learning the structural relationships between key
sentence components while minimizing reliance on spurious correlations. We
validate our approach through experiments on three tasks: Sentiment
Classification, Sexism Detection, and Natural Language Inference. The results
demonstrate that SALAD not only improves model robustness and performance
across different environments but also enhances generalization to
out-of-distribution datasets and cross-domain scenarios.
</summary>
    <author>
      <name>Suyoung Bae</name>
    </author>
    <author>
      <name>Hyojun Kim</name>
    </author>
    <author>
      <name>YunSeok Choi</name>
    </author>
    <author>
      <name>Jee-Hyong Lee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to NAACL 2025 main. 15 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2504.12185v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.12185v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
