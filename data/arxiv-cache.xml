<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-09-26T00:52:15Z -->
<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acausal%20inference%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:causal inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/SsRksLzRb0LuVhSmQ+N8WbAs+f8</id>
  <updated>2025-09-25T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">121723</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">10</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2509.20359v1</id>
    <updated>2025-09-24T17:59:19Z</updated>
    <published>2025-09-24T17:59:19Z</published>
    <title>Stars and ionized gas in UGCA 320: a nearby gas-rich, dwarf Irregular
  galaxy</title>
    <summary>  UGCA 320 is a gas-rich dwarf irregular galaxy which belongs to a nearby,
relatively isolated group of dwarf galaxies. Here, we combine multi-band HST
imaging data with deep long-slit SALT/RSS and integral-field VLT/MUSE spectral
data to study the stellar and ionized gas components of UGCA 320. Our imaging
data analysis reveals a very blue (V-I~0.1 mag), flattened radial colour
profile. We detect an abundance of ionized gas in UGCA 320 powered mostly by
recent star formation. The stellar disc in UGCA 320 is populated predominantly
by young (~120 Myr) and metal-poor (~15-30 per cent solar metallicity) stars
and it rotates in the same sense as the ionized gas disc but with higher
rotation velocities, and possibly in different planes. Our analysis reveals a
sharp transition in the kinematic properties of the discs at radius ~10" (~0.3
kpc) and distortions in the outer disc region. We show that these features are
consistent with a recent tidal interaction most likely with its close neighbour
- UGCA 319. We discuss our results in the context of interacting dwarf galaxies
and also show that similar inferences can be made independently from the
long-slit data analysis as with the integral-field data.
</summary>
    <author>
      <name>Adebusola B. Alabi</name>
    </author>
    <author>
      <name>S. Ilani Loubser</name>
    </author>
    <author>
      <name>Moses K. Mogotsi</name>
    </author>
    <author>
      <name>N. Zabel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication in MNRAS</arxiv:comment>
    <link href="http://arxiv.org/abs/2509.20359v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.20359v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.GA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.GA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.20345v1</id>
    <updated>2025-09-24T17:37:14Z</updated>
    <published>2025-09-24T17:37:14Z</published>
    <title>Statistical Inference Leveraging Synthetic Data with Distribution-Free
  Guarantees</title>
    <summary>  The rapid proliferation of high-quality synthetic data -- generated by
advanced AI models or collected as auxiliary data from related tasks --
presents both opportunities and challenges for statistical inference. This
paper introduces a GEneral Synthetic-Powered Inference (GESPI) framework that
wraps around any statistical inference procedure to safely enhance sample
efficiency by combining synthetic and real data. Our framework leverages
high-quality synthetic data to boost statistical power, yet adaptively defaults
to the standard inference method using only real data when synthetic data is of
low quality. The error of our method remains below a user-specified bound
without any distributional assumptions on the synthetic data, and decreases as
the quality of the synthetic data improves. This flexibility enables seamless
integration with conformal prediction, risk control, hypothesis testing, and
multiple testing procedures, all without modifying the base inference method.
We demonstrate the benefits of our method on challenging tasks with limited
labeled data, including AlphaFold protein structure prediction, and comparing
large reasoning models on complex math problems.
</summary>
    <author>
      <name>Meshi Bashari</name>
    </author>
    <author>
      <name>Yonghoon Lee</name>
    </author>
    <author>
      <name>Roy Maor Lotan</name>
    </author>
    <author>
      <name>Edgar Dobriban</name>
    </author>
    <author>
      <name>Yaniv Romano</name>
    </author>
    <link href="http://arxiv.org/abs/2509.20345v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.20345v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.20339v1</id>
    <updated>2025-09-24T17:32:24Z</updated>
    <published>2025-09-24T17:32:24Z</published>
    <title>Spatio-Temporal Directed Graph Learning for Account Takeover Fraud
  Detection</title>
    <summary>  Account Takeover (ATO) fraud poses a significant challenge in consumer
banking, requiring high recall under strict latency while minimizing friction
for legitimate users. Production systems typically rely on tabular
gradient-boosted decision trees (e.g., XGBoost) that score sessions
independently, overlooking the relational and temporal structure of online
activity that characterizes coordinated attacks and "fraud rings." We introduce
ATLAS (Account Takeover Learning Across Spatio-Temporal Directed Graph), a
framework that reformulates ATO detection as spatio-temporal node
classification on a time-respecting directed session graph. ATLAS links
entities via shared identifiers (account, device, IP) and regulates
connectivity with time-window and recency constraints, enabling causal,
time-respecting message passing and latency-aware label propagation that uses
only labels available at scoring time, non-anticipative and leakage-free. We
operationalize ATLAS with inductive GraphSAGE variants trained via neighbor
sampling, at scale on a sessions graph with more than 100M nodes and around 1B
edges. On a high-risk digital product at Capital One, ATLAS delivers 6.38
percent AUC improvement and more than 50 percent reduction in customer
friction, improving fraud capture while reducing user friction.
</summary>
    <author>
      <name>Mohsen Nayebi Kerdabadi</name>
    </author>
    <author>
      <name>William Andrew Byron</name>
    </author>
    <author>
      <name>Xin Sun</name>
    </author>
    <author>
      <name>Amirfarrokh Iranitalab</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been accepted at NeurIPS 2025 workshop New Perspective
  in Graph Machine Learning (NPGML)</arxiv:comment>
    <link href="http://arxiv.org/abs/2509.20339v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.20339v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.20324v1</id>
    <updated>2025-09-24T17:11:35Z</updated>
    <published>2025-09-24T17:11:35Z</published>
    <title>RAG Security and Privacy: Formalizing the Threat Model and Attack
  Surface</title>
    <summary>  Retrieval-Augmented Generation (RAG) is an emerging approach in natural
language processing that combines large language models (LLMs) with external
document retrieval to produce more accurate and grounded responses. While RAG
has shown strong potential in reducing hallucinations and improving factual
consistency, it also introduces new privacy and security challenges that differ
from those faced by traditional LLMs. Existing research has demonstrated that
LLMs can leak sensitive information through training data memorization or
adversarial prompts, and RAG systems inherit many of these vulnerabilities. At
the same time, reliance of RAG on an external knowledge base opens new attack
surfaces, including the potential for leaking information about the presence or
content of retrieved documents, or for injecting malicious content to
manipulate model behavior. Despite these risks, there is currently no formal
framework that defines the threat landscape for RAG systems. In this paper, we
address a critical gap in the literature by proposing, to the best of our
knowledge, the first formal threat model for retrieval-RAG systems. We
introduce a structured taxonomy of adversary types based on their access to
model components and data, and we formally define key threat vectors such as
document-level membership inference and data poisoning, which pose serious
privacy and integrity risks in real-world deployments. By establishing formal
definitions and attack models, our work lays the foundation for a more rigorous
and principled understanding of privacy and security in RAG systems.
</summary>
    <author>
      <name>Atousa Arzanipour</name>
    </author>
    <author>
      <name>Rouzbeh Behnia</name>
    </author>
    <author>
      <name>Reza Ebrahimi</name>
    </author>
    <author>
      <name>Kaushik Dutta</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at the 5th ICDM Workshop on September 20, 2025</arxiv:comment>
    <link href="http://arxiv.org/abs/2509.20324v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.20324v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.20318v1</id>
    <updated>2025-09-24T17:01:50Z</updated>
    <published>2025-09-24T17:01:50Z</published>
    <title>A Comprehensive Evaluation of YOLO-based Deer Detection Performance on
  Edge Devices</title>
    <summary>  The escalating economic losses in agriculture due to deer intrusion,
estimated to be in the hundreds of millions of dollars annually in the U.S.,
highlight the inadequacy of traditional mitigation strategies since these
methods are often labor-intensive, costly, and ineffective for modern farming
systems. To overcome this, there is a critical need for intelligent, autonomous
solutions which require accurate and efficient deer detection. But the progress
in this field is impeded by a significant gap in the literature, mainly the
lack of a domain-specific, practical dataset and limited study on the on-field
deployability of deer detection systems. Addressing this gap, this study
presents a comprehensive evaluation of state-of-the-art deep learning models
for deer detection in challenging real-world scenarios. The contributions of
this work are threefold. First, we introduce a curated, publicly available
dataset of 3,095 annotated images with bounding-box annotations of deer,
derived from the Idaho Cameratraps project. Second, we provide an extensive
comparative analysis of 12 model variants across four recent YOLO
architectures(v8, v9, v10, and v11). Finally, we benchmarked performance on a
high-end NVIDIA RTX 5090 GPU and evaluated on two representative edge computing
platforms: Raspberry Pi 5 and NVIDIA Jetson AGX Xavier. Results show that the
real-time detection is not feasible in Raspberry Pi without hardware-specific
model optimization, while NVIDIA Jetson provides greater than 30 FPS with
GPU-accelerated inference on 's' and 'n' series models. This study also reveals
that smaller, architecturally advanced models such as YOLOv11n, YOLOv8s, and
YOLOv9s offer the optimal balance of high accuracy (AP@.5 &gt; 0.85) and
computational efficiency (FPS &gt; 30). To support further research, both the
source code and datasets are publicly available at
https://github.com/WinnerBishal/track-the-deer.
</summary>
    <author>
      <name>Bishal Adhikari</name>
    </author>
    <author>
      <name>Jiajia Li</name>
    </author>
    <author>
      <name>Eric S. Michel</name>
    </author>
    <author>
      <name>Jacob Dykes</name>
    </author>
    <author>
      <name>Te-Ming Paul Tseng</name>
    </author>
    <author>
      <name>Mary Love Tagert</name>
    </author>
    <author>
      <name>Dong Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2509.20318v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.20318v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.20317v2</id>
    <updated>2025-09-25T12:17:01Z</updated>
    <published>2025-09-24T17:01:32Z</published>
    <title>SIM-CoT: Supervised Implicit Chain-of-Thought</title>
    <summary>  Implicit Chain-of-Thought (CoT) methods offer a token-efficient alternative
to explicit CoT reasoning in Large Language Models (LLMs), but a persistent
performance gap has limited their adoption. We identify a core latent
instability issue when scaling the computational budget of implicit CoT: as the
number of reasoning tokens increases, training often becomes unstable and
collapses. Our analysis shows that this instability arises from latent
representations becoming homogeneous and losing semantic diversity, caused by
insufficient step-level supervision in current implicit CoT methods. To address
this, we propose SIM-CoT, a plug-and-play training module that introduces
step-level supervision to stabilize and enrich the latent reasoning space.
SIM-CoT employs an auxiliary decoder during training to align each implicit
token with its corresponding explicit reasoning step, ensuring latent states
capture distinct and meaningful information. The auxiliary decoder is removed
at inference, preserving the efficiency of implicit CoT with no added overhead.
It also provides interpretability by projecting each latent token onto an
explicit reasoning vocabulary, enabling per-step visualization and diagnosis.
SIM-CoT significantly improves both in-domain accuracy and out-of-domain
stability of implicit CoT methods, boosting Coconut by +8.2\% on GPT-2 and CODI
by +3.0\% on LLaMA-3.1 8B. It further surpasses the explicit CoT baseline on
GPT-2 by 2.1\% with 2.3$\times$ greater token efficiency, while closing the
performance gap on larger models like LLaMA-3.1 8B. Code:
https://github.com/InternLM/SIM-CoT
</summary>
    <author>
      <name>Xilin Wei</name>
    </author>
    <author>
      <name>Xiaoran Liu</name>
    </author>
    <author>
      <name>Yuhang Zang</name>
    </author>
    <author>
      <name>Xiaoyi Dong</name>
    </author>
    <author>
      <name>Yuhang Cao</name>
    </author>
    <author>
      <name>Jiaqi Wang</name>
    </author>
    <author>
      <name>Xipeng Qiu</name>
    </author>
    <author>
      <name>Dahua Lin</name>
    </author>
    <link href="http://arxiv.org/abs/2509.20317v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.20317v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.20249v1</id>
    <updated>2025-09-24T15:35:26Z</updated>
    <published>2025-09-24T15:35:26Z</published>
    <title>Indirect Statistical Inference with Guaranteed Necessity and Sufficiency</title>
    <summary>  This paper develops a new framework for indirect statistical inference with
guaranteed necessity and sufficiency, applicable to continuous random
variables. We prove that when comparing exponentially transformed order
statistics from an assumed distribution with those from simulated unit
exponential samples, the ranked quotients exhibit distinct asymptotics: the
left segment converges to a non-degenerate distribution, while the middle and
right segments degenerate to one. This yields a necessary and sufficient
condition in probability for two sequences of continuous random variables to
follow the same distribution. Building on this, we propose an optimization
criterion based on relative errors between ordered samples. The criterion
achieves its minimum if and only if the assumed and true distributions
coincide, providing a second necessary and sufficient condition in
optimization. These dual NS properties, rare in the literature, establish a
fundamentally stronger inference framework than existing methods. Unlike
classical approaches based on absolute errors (e.g., Kolmogorov-Smirnov), NSE
exploits relative errors to ensure faster convergence, requires only mild
approximability of the cumulative distribution function, and provides both
point and interval estimates. Simulations and real-data applications confirm
NSE's superior performance in preserving distributional assumptions where
traditional methods fail.
</summary>
    <author>
      <name>Z Zhang</name>
    </author>
    <author>
      <name>X Hu</name>
    </author>
    <author>
      <name>C Lu</name>
    </author>
    <author>
      <name>T Liu</name>
    </author>
    <link href="http://arxiv.org/abs/2509.20249v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.20249v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.20241v1</id>
    <updated>2025-09-24T15:32:01Z</updated>
    <published>2025-09-24T15:32:01Z</published>
    <title>Energy Use of AI Inference: Efficiency Pathways and Test-Time Compute</title>
    <summary>  As AI inference scales to billions of queries and emerging reasoning and
agentic workflows increase token demand, reliable estimates of per-query energy
use are increasingly important for capacity planning, emissions accounting, and
efficiency prioritization. Many public estimates are inconsistent and overstate
energy use, because they extrapolate from limited benchmarks and fail to
reflect efficiency gains achievable at scale. In this perspective, we introduce
a bottom-up methodology to estimate the per-query energy of large-scale LLM
systems based on token throughput. For models running on an H100 node under
realistic workloads, GPU utilization and PUE constraints, we estimate a median
energy per query of 0.34 Wh (IQR: 0.18-0.67) for frontier-scale models (&gt;200
billion parameters). These results are consistent with measurements using
production-scale configurations and show that non-production estimates and
assumptions can overstate energy use by 4-20x. Extending to test-time scaling
scenarios with 15x more tokens per typical query, the median energy rises 13x
to 4.32 Wh, indicating that targeting efficiency in this regime will deliver
the largest fleet-wide savings. We quantify achievable efficiency gains at the
model, serving platform, and hardware levels, finding individual median
reductions of 1.5-3.5x in energy per query, while combined advances can
plausibly deliver 8-20x reductions. To illustrate the system-level impact, we
estimate the baseline daily energy use of a deployment serving 1 billion
queries to be 0.8 GWh/day. If 10% are long queries, demand could grow to 1.8
GWh/day. With targeted efficiency interventions, it falls to 0.9 GWh/day,
similar to the energy footprint of web search at that scale. This echoes how
data centers historically tempered energy growth through efficiency gains
during the internet and cloud build-up.
</summary>
    <author>
      <name>Felipe Oviedo</name>
    </author>
    <author>
      <name>Fiodar Kazhamiaka</name>
    </author>
    <author>
      <name>Esha Choukse</name>
    </author>
    <author>
      <name>Allen Kim</name>
    </author>
    <author>
      <name>Amy Luers</name>
    </author>
    <author>
      <name>Melanie Nakagawa</name>
    </author>
    <author>
      <name>Ricardo Bianchini</name>
    </author>
    <author>
      <name>Juan M. Lavista Ferres</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">A preprint version with DOI is available at Zenodo:
  https://doi.org/10.5281/zenodo.17188770</arxiv:comment>
    <link href="http://arxiv.org/abs/2509.20241v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.20241v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.20238v1</id>
    <updated>2025-09-24T15:28:32Z</updated>
    <published>2025-09-24T15:28:32Z</published>
    <title>Velocity model building from seismic images using a Convolutional Neural
  Operator</title>
    <summary>  The success of building a high-resolution velocity model using machine
learning is hampered by generalization limitations that often limit the success
of the approach on field data. This is especially true when relying on neural
operators for the mapping. Thus, we propose a novel inversion framework that
relies on learning to map the velocity model to a seismic image using a
Convolutional Neural Operator (CNO), and then we use optimization to invert for
the velocity that matches the image. The key to the success of our network is
that we use the initial and true velocity models as input in the training, then
we invert for the true velocity starting from the initial velocity at
inference. Specifically, we first train a neural operator to accurately learn
the forward mapping from seismic velocity models to RTM images, using synthetic
datasets that include high-frequency structural information. Once trained, the
neural operator is embedded into an inversion loop, where its differentiable
nature enables efficient gradient computation via automatic differentiation.
This allows us to progressively inject high-wavenumber information from RTM
images into the background velocity model, thereby improving resolution without
the need for traditional adjoint-state solvers. The proposed framework is
validated on both synthetic and field data. Results demonstrate that the neural
operator generalizes well to real seismic scenarios, maintains high inversion
accuracy, and significantly reduces computational cost. This work highlights
the potential of neural operators as flexible and scalable tools for efficient,
data-driven seismic imaging and inversion.
</summary>
    <author>
      <name>Xiao Ma</name>
    </author>
    <author>
      <name>Tariq Alkhalifah</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages,16 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2509.20238v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.20238v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.20235v1</id>
    <updated>2025-09-24T15:25:11Z</updated>
    <published>2025-09-24T15:25:11Z</published>
    <title>$S_8$ from Tully-Fisher, fundamental plane, and supernova distances
  agree with Planck</title>
    <summary>  Peculiar velocity measurements constrain the parameter combination
$f\sigma_8$, the product of the linear growth rate $f$ and the fluctuation
amplitude $\sigma_8$. Under the approximation that $f$ is a monotonic function
of $\Omega_{\rm m}$, this can be related to $S_8 \equiv \sigma_8
\sqrt{\Omega_{\rm m}/0.3}$, enabling direct comparison with weak lensing and
cosmic microwave background results. We exploit this by using three classes of
direct-distance tracers -- the Tully-Fisher relation, the fundamental plane,
and Type~Ia supernovae -- to infer peculiar velocities. A unified hierarchical
forward model jointly calibrates each distance indicator and a linear theory
reconstruction of the local Universe. This is the first consistent Bayesian
analysis to combine all three major classes of distance indicators within a
common framework, enabling cross-checks of systematics across diverse galaxy
populations. All three tracers yield consistent values of $S_8$ that are also
in agreement with Planck. Our joint constraint is $S_8 = 0.819 \pm 0.030$, with
the uncertainty dominated by the 2M++ galaxy field. These results demonstrate
that peculiar velocity surveys provide a robust, consistent measurement of
$S_8$, and support concordance with the cosmic microwave background.
</summary>
    <author>
      <name>Richard Stiskalek</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 6 figures. To be submitted to MNRAS</arxiv:comment>
    <link href="http://arxiv.org/abs/2509.20235v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.20235v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
