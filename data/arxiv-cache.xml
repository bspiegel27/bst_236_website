<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2026-02-17T01:16:29Z -->
<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/" xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns="http://www.w3.org/2005/Atom">
  <id>https://arxiv.org/api/p6EyKyP4fMY/66n9Ev8E79F7KlI</id>
  <title>arXiv Query: search_query=all:causal OR all:inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <updated>2026-02-17T01:16:29Z</updated>
  <link href="https://arxiv.org/api/query?search_query=all:causal+OR+all:inference&amp;start=0&amp;max_results=10&amp;id_list=" type="application/atom+xml"/>
  <opensearch:itemsPerPage>10</opensearch:itemsPerPage>
  <opensearch:totalResults>134080</opensearch:totalResults>
  <opensearch:startIndex>0</opensearch:startIndex>
  <entry>
    <id>http://arxiv.org/abs/2602.13193v1</id>
    <title>Steerable Vision-Language-Action Policies for Embodied Reasoning and Hierarchical Control</title>
    <updated>2026-02-13T18:57:56Z</updated>
    <link href="https://arxiv.org/abs/2602.13193v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.13193v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Pretrained vision-language models (VLMs) can make semantic and visual inferences across diverse settings, providing valuable common-sense priors for robotic control. However, effectively grounding this knowledge in robot behaviors remains an open challenge. Prior methods often employ a hierarchical approach where VLMs reason over high-level commands to be executed by separate low-level policies, e.g., vision-language-action models (VLAs). The interface between VLMs and VLAs is usually natural language task instructions, which fundamentally limits how much VLM reasoning can steer low-level behavior. We thus introduce Steerable Policies: VLAs trained on rich synthetic commands at various levels of abstraction, like subtasks, motions, and grounded pixel coordinates. By improving low-level controllability, Steerable Policies can unlock pretrained knowledge in VLMs, enabling improved task generalization. We demonstrate this benefit by controlling our Steerable Policies with both a learned high-level embodied reasoner and an off-the-shelf VLM prompted to reason over command abstractions via in-context learning. Across extensive real-world manipulation experiments, these two novel methods outperform prior embodied reasoning VLAs and VLM-based hierarchical baselines, including on challenging generalization and long-horizon tasks.
  Website: steerable-policies.github.io</summary>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-13T18:57:56Z</published>
    <arxiv:primary_category term="cs.RO"/>
    <author>
      <name>William Chen</name>
    </author>
    <author>
      <name>Jagdeep Singh Bhatia</name>
    </author>
    <author>
      <name>Catherine Glossop</name>
    </author>
    <author>
      <name>Nikhil Mathihalli</name>
    </author>
    <author>
      <name>Ria Doshi</name>
    </author>
    <author>
      <name>Andy Tang</name>
    </author>
    <author>
      <name>Danny Driess</name>
    </author>
    <author>
      <name>Karl Pertsch</name>
    </author>
    <author>
      <name>Sergey Levine</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.13184v1</id>
    <title>Profiling systematic uncertainties in Simulation-Based Inference with Factorizable Normalizing Flows</title>
    <updated>2026-02-13T18:48:12Z</updated>
    <link href="https://arxiv.org/abs/2602.13184v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.13184v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Unbinned likelihood fits aim at maximizing the information one can extract from experimental data, yet their application in realistic statistical analyses is often hindered by the computational cost of profiling systematic uncertainties. Additionally, current machine learning-based inference methods are typically limited to estimating scalar parameters in a multidimensional space rather than full differential distributions. We propose a general framework for Simulation-Based Inference (SBI) that efficiently profiles nuisance parameters while measuring multivariate Distributions of Interest (DoI), defined as learnable invertible transformations of the feature space. We introduce Factorizable Normalizing Flows to model systematic variations as parametric deformations of a nominal density, preserving tractability without combinatorial explosion. Crucially, we develop an amortized training strategy that learns the conditional dependence of the DoI on nuisance parameters in a single optimization process, bypassing the need for repetitive training during the likelihood scan. This allows for the simultaneous extraction of the underlying distribution and the robust profiling of nuisances. The method is validated on a synthetic dataset emulating a high-energy physics measurement with multiple systematic sources, demonstrating its potential for unbinned, functional measurements in complex analyses.</summary>
    <category term="hep-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-13T18:48:12Z</published>
    <arxiv:comment>25 pages, 14 figures</arxiv:comment>
    <arxiv:primary_category term="hep-ph"/>
    <author>
      <name>Davide Valsecchi</name>
    </author>
    <author>
      <name>Mauro Donegà</name>
    </author>
    <author>
      <name>Rainer Wallny</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.13172v1</id>
    <title>LongStream: Long-Sequence Streaming Autoregressive Visual Geometry</title>
    <updated>2026-02-13T18:30:51Z</updated>
    <link href="https://arxiv.org/abs/2602.13172v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.13172v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Long-sequence streaming 3D reconstruction remains a significant open challenge. Existing autoregressive models often fail when processing long sequences. They typically anchor poses to the first frame, which leads to attention decay, scale drift, and extrapolation errors. We introduce LongStream, a novel gauge-decoupled streaming visual geometry model for metric-scale scene reconstruction across thousands of frames. Our approach is threefold. First, we discard the first-frame anchor and predict keyframe-relative poses. This reformulates long-range extrapolation into a constant-difficulty local task. Second, we introduce orthogonal scale learning. This method fully disentangles geometry from scale estimation to suppress drift. Finally, we solve Transformer cache issues such as attention-sink reliance and long-term KV-cache contamination. We propose cache-consistent training combined with periodic cache refresh. This approach suppresses attention degradation over ultra-long sequences and reduces the gap between training and inference. Experiments show LongStream achieves state-of-the-art performance. It delivers stable, metric-scale reconstruction over kilometer-scale sequences at 18 FPS. Project Page: https://3dagentworld.github.io/longstream/</summary>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-13T18:30:51Z</published>
    <arxiv:primary_category term="cs.CV"/>
    <author>
      <name>Chong Cheng</name>
    </author>
    <author>
      <name>Xianda Chen</name>
    </author>
    <author>
      <name>Tao Xie</name>
    </author>
    <author>
      <name>Wei Yin</name>
    </author>
    <author>
      <name>Weiqiang Ren</name>
    </author>
    <author>
      <name>Qian Zhang</name>
    </author>
    <author>
      <name>Xiaoyuang Guo</name>
    </author>
    <author>
      <name>Hao Wang</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.13165v1</id>
    <title>Asynchronous Verified Semantic Caching for Tiered LLM Architectures</title>
    <updated>2026-02-13T18:25:00Z</updated>
    <link href="https://arxiv.org/abs/2602.13165v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.13165v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Large language models (LLMs) now sit in the critical path of search, assistance, and agentic workflows, making semantic caching essential for reducing inference cost and latency. Production deployments typically use a tiered static-dynamic design: a static cache of curated, offline vetted responses mined from logs, backed by a dynamic cache populated online. In practice, both tiers are commonly governed by a single embedding similarity threshold, which induces a hard tradeoff: conservative thresholds miss safe reuse opportunities, while aggressive thresholds risk serving semantically incorrect responses. We introduce \textbf{Krites}, an asynchronous, LLM-judged caching policy that expands static coverage without changing serving decisions. On the critical path, Krites behaves exactly like a standard static threshold policy. When the nearest static neighbor of the prompt falls just below the static threshold, Krites asynchronously invokes an LLM judge to verify whether the static response is acceptable for the new prompt. Approved matches are promoted into the dynamic cache, allowing future repeats and paraphrases to reuse curated static answers and expanding static reach over time. In trace-driven simulations on conversational and search workloads, Krites increases the fraction of requests served with curated static answers (direct static hits plus verified promotions) by up to $\textbf{3.9}$ times for conversational traffic and search-style queries relative to tuned baselines, with unchanged critical path latency.</summary>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-13T18:25:00Z</published>
    <arxiv:primary_category term="cs.IR"/>
    <author>
      <name>Asmit Kumar Singh</name>
    </author>
    <author>
      <name>Haozhe Wang</name>
    </author>
    <author>
      <name>Laxmi Naga Santosh Attaluri</name>
    </author>
    <author>
      <name>Tak Chiam</name>
    </author>
    <author>
      <name>Weihua Zhu</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.13164v1</id>
    <title>Early-warning the compact-to-dendritic transition via spatiotemporal learning of two-dimensional growth images</title>
    <updated>2026-02-13T18:23:36Z</updated>
    <link href="https://arxiv.org/abs/2602.13164v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.13164v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Transitions between distinct dynamical regimes are ubiquitous in nonequilibrium systems. As a prototypical example, deposition growth is often accompanied by irreversible morphological instabilities. Forecasting such transitions from pre-transition configurations remains fundamentally challenging, as early precursors are weak, spatially heterogeneous, and masked by inherent fluctuations. Here, we investigate compact-to-dendritic transitions (CDTs) in a two-dimensional particle-based electrodeposition model and formulate a horizon-based early-warning task using trajectory-resolved transition points. We demonstrate that anticipating the CDT is intrinsically a spatiotemporal problem: neither static morphological descriptors nor temporal learning applied to predefined features alone yields reliable predictive signals. In contrast, end-to-end learning of jointly optimized spatial and temporal representations from growth images enables robust anticipation across a wide range of prediction horizons. Analysis of the learned latent dynamics reveals the emergence of a low-dimensional surrogate variable that tracks progressive morphological destabilization and undergoes reorganization near the transition. We further show that the learned spatiotemporal representation exhibits limited but systematic transferability across reaction-rate conditions, with predictive performance degrading as the inference condition departs from the training condition, consistent with changes in the latent-state dynamics. Overall, our results establish a general formulation for forecasting incipient instabilities in nonequilibrium interfacial growth, with implications for the predictive monitoring and control of pattern-forming driven systems.</summary>
    <category term="physics.chem-ph" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-13T18:23:36Z</published>
    <arxiv:comment>20 pages</arxiv:comment>
    <arxiv:primary_category term="physics.chem-ph"/>
    <author>
      <name>Hyunjun Jang</name>
    </author>
    <author>
      <name>Chung Bin Park</name>
    </author>
    <author>
      <name>Jeonghoon Kim</name>
    </author>
    <author>
      <name>Jeongmin Kim</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.13158v1</id>
    <title>A new mixture model for spatiotemporal exceedances with flexible tail dependence</title>
    <updated>2026-02-13T18:12:01Z</updated>
    <link href="https://arxiv.org/abs/2602.13158v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.13158v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>We propose a new model and estimation framework for spatiotemporal streamflow exceedances above a threshold that flexibly captures asymptotic dependence and independence in the tail of the distribution. We model streamflow using a mixture of processes with spatial, temporal and spatiotemporal asymptotic dependence regimes. A censoring mechanism allows us to use only observations above a threshold to estimate marginal and joint probabilities of extreme events. As the likelihood is intractable, we use simulation-based inference powered by random forests to estimate model parameters from summary statistics of the data. Simulations and modeling of streamflow data from the U.S. Geological Survey illustrate the feasibility and practicality of our approach.</summary>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-13T18:12:01Z</published>
    <arxiv:primary_category term="stat.ME"/>
    <author>
      <name>Ryan Li</name>
    </author>
    <author>
      <name>Brian J. Reich</name>
    </author>
    <author>
      <name>Emily C. Hector</name>
    </author>
    <author>
      <name>Reetam Majumder</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.13156v1</id>
    <title>In-Context Autonomous Network Incident Response: An End-to-End Large Language Model Agent Approach</title>
    <updated>2026-02-13T18:09:30Z</updated>
    <link href="https://arxiv.org/abs/2602.13156v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.13156v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Rapidly evolving cyberattacks demand incident response systems that can autonomously learn and adapt to changing threats. Prior work has extensively explored the reinforcement learning approach, which involves learning response strategies through extensive simulation of the incident. While this approach can be effective, it requires handcrafted modeling of the simulator and suppresses useful semantics from raw system logs and alerts. To address these limitations, we propose to leverage large language models' (LLM) pre-trained security knowledge and in-context learning to create an end-to-end agentic solution for incident response planning. Specifically, our agent integrates four functionalities, perception, reasoning, planning, and action, into one lightweight LLM (14b model). Through fine-tuning and chain-of-thought reasoning, our LLM agent is capable of processing system logs and inferring the underlying network state (perception), updating its conjecture of attack models (reasoning), simulating consequences under different response strategies (planning), and generating an effective response (action). By comparing LLM-simulated outcomes with actual observations, the LLM agent repeatedly refines its attack conjecture and corresponding response, thereby demonstrating in-context adaptation. Our agentic approach is free of modeling and can run on commodity hardware. When evaluated on incident logs reported in the literature, our agent achieves recovery up to 23% faster than those of frontier LLMs.</summary>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-13T18:09:30Z</published>
    <arxiv:comment>2026 AAAI Summer Symposium on Human-Aware AI Agents for the Cyber Battlefield</arxiv:comment>
    <arxiv:primary_category term="cs.CR"/>
    <author>
      <name>Yiran Gao</name>
    </author>
    <author>
      <name>Kim Hammar</name>
    </author>
    <author>
      <name>Tao Li</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.13152v1</id>
    <title>Detecting Parameter Instabilities in Functional Concurrent Linear Regression</title>
    <updated>2026-02-13T18:05:03Z</updated>
    <link href="https://arxiv.org/abs/2602.13152v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.13152v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>We develop methodology to detect structural breaks in the slope function of a concurrent functional linear regression model for functional time series in $C[0,1]$. Our test is based on a CUSUM process of regressor-weighted OLS residual functions. To accommodate both global and local changes, we propose $L^2$- and sup-norm versions, with the sup-norm particularly sensitive to spike-like changes. Under Hölder regularity and weak dependence conditions, we establish a functional strong invariance principle, derive the asymptotic null distribution, and show that the resulting tests are consistent against a broad class of alternatives with breaks in the slope function. Simulation studies illustrate finite-sample size and power. We apply the method to sports data obtained via body-worn sensors from running athletes, focusing on hip and knee joint-angle trajectories recorded during a fatiguing run. As fatigue accumulates, runners adapt their movement patterns, and sufficiently pronounced adjustments are expected to appear as a change point in the regression relationship. In this manner, we illustrate how the proposed tests support interpretable inference for biomechanical functional time series.</summary>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-13T18:05:03Z</published>
    <arxiv:primary_category term="stat.ME"/>
    <author>
      <name>Rupsa Basu</name>
    </author>
    <author>
      <name>Sven Otto</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.13151v1</id>
    <title>Quantization-Robust LLM Unlearning via Low-Rank Adaptation</title>
    <updated>2026-02-13T18:01:40Z</updated>
    <link href="https://arxiv.org/abs/2602.13151v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.13151v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Large Language Model (LLM) unlearning aims to remove targeted knowledge from a trained model, but practical deployments often require post-training quantization (PTQ) for efficient inference. However, aggressive low-bit PTQ can mask or erase unlearning updates, causing quantized models to revert to pre-unlearning behavior. We show that standard full-parameter fine-tuning often induce parameter changes that are too small to survive 4-bit quantization. We propose quantization-robust unlearning via low-rank adaptation (LoRA): we freeze the base model and concentrate unlearning into trainable adapters so that the effective update is preserved after quantization. On Llama-2-7B evaluated with MUSE dataset (BOOKS and NEWS), LoRA improves 4-bit utility by up to 7.93 points (NPO+GDR on BOOKS: 50.17 to 58.10) and yields higher 4-bit utility on NEWS for GA+GDR (40.06 to 44.82, increase of 4.76). LoRA also substantially reduces privacy leakage under 4-bit PTQ, e.g., for GA+KLR on BOOKS, PrivLeak moves from -25.68 to -5.86 (closer to ideal 0), while maintaining strong forgetting (VerMem and KnowMem near 0). Thus, using LoRA for Machine Unlearning is beneficial for scenarios where quantization is necessary for model deployment.</summary>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-13T18:01:40Z</published>
    <arxiv:primary_category term="cs.LG"/>
    <author>
      <name>João Vitor Boer Abitante</name>
    </author>
    <author>
      <name>Joana Meneguzzo Pasquali</name>
    </author>
    <author>
      <name>Luan Fonseca Garcia</name>
    </author>
    <author>
      <name>Ewerton de Oliveira</name>
    </author>
    <author>
      <name>Thomas da Silva Paula</name>
    </author>
    <author>
      <name>Rodrigo C. Barros</name>
    </author>
    <author>
      <name>Lucas S. Kupssinskü</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.13143v1</id>
    <title>An updated constraint for the Gravitational Wave Background from the Gamma-ray Pulsar Timing Array</title>
    <updated>2026-02-13T17:52:26Z</updated>
    <link href="https://arxiv.org/abs/2602.13143v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.13143v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Fermi LAT observations of gamma-ray pulsars can be used to build a pulsar timing array (PTA) experiment to search for gravitational wave (GW) signals at nanohertz frequencies. At those frequencies, the dominant signal is expected to be a stochastic gravitational wave background (GWB) produced by the incoherent superposition of the quasi-monochromatic GW emissions from a population of supermassive black hole binaries. While the radio PTAs have recently announced compelling evidence for a GWB signal with a power law spectrum of strain amplitude $\approx2-3\times10^{-15}$ (at the frequency of $1 {\rm yr}^{-1}$), in 2022 an analysis of $12.5$ years of Fermi data for 35 pulsars led to an upper limit of $1\times10^{-14}$ for the GWB amplitude. The analysis was carried out on times-of-arrival (TOAs) obtained by folding from six months up to one year of photon observations. A photon-by-photon approach was also tested to infer constraints on the GWB amplitude from individual pulsars, but without accounting for the cross-pulsar correlations that a GWB would induce. Here, we reanalyse the same dataset using a regularized likelihood method that correctly models cross-pulsar correlations directly from the photons, while additionally marginalising over the uncertain pulse profile shape. While the two methods are not expected to have significant differences in sensitivity, we prove through simulations of gamma-ray PTA datasets that the photon-by-photon method for GWB recoveries is, statistically, more robust. The resulting upper limit obtained for the GWB strain amplitude is $1.2\times10^{-14}$, indicating that the improved method yields a consistent result with the previous analyses.</summary>
    <category term="astro-ph.HE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="gr-qc" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-13T17:52:26Z</published>
    <arxiv:comment>12 pages, 5 figures. Accepted for publication in Physical Review D</arxiv:comment>
    <arxiv:primary_category term="astro-ph.HE"/>
    <author>
      <name>Serena Valtolina</name>
    </author>
    <author>
      <name>Colin J. Clark</name>
    </author>
    <author>
      <name>Rutger van Haasteren</name>
    </author>
    <author>
      <name>Aurélien Chalumeau</name>
    </author>
    <author>
      <name>Thankful Cromartie</name>
    </author>
    <author>
      <name>Matthew Kerr</name>
    </author>
    <author>
      <name>Lars Nieder</name>
    </author>
    <author>
      <name>Aditya Parthasarathy</name>
    </author>
  </entry>
</feed>
