<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-12-30T01:00:37Z -->
<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/" xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns="http://www.w3.org/2005/Atom">
  <id>https://arxiv.org/api/p6EyKyP4fMY/66n9Ev8E79F7KlI</id>
  <title>arXiv Query: search_query=all:causal OR all:inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <updated>2025-12-30T01:00:37Z</updated>
  <link href="https://arxiv.org/api/query?search_query=all:causal+OR+all:inference&amp;start=0&amp;max_results=10&amp;id_list=" type="application/atom+xml"/>
  <opensearch:itemsPerPage>10</opensearch:itemsPerPage>
  <opensearch:totalResults>129566</opensearch:totalResults>
  <opensearch:startIndex>0</opensearch:startIndex>
  <entry>
    <id>http://arxiv.org/abs/2512.22120v1</id>
    <title>See Less, See Right: Bi-directional Perceptual Shaping For Multimodal Reasoning</title>
    <updated>2025-12-26T18:59:47Z</updated>
    <link href="https://arxiv.org/abs/2512.22120v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.22120v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Large vision-language models (VLMs) often benefit from intermediate visual cues, either injected via external tools or generated as latent visual tokens during reasoning, but these mechanisms still overlook fine-grained visual evidence (e.g., polylines in charts), generalize poorly across domains, and incur high inference-time cost. In this paper, we propose Bi-directional Perceptual Shaping (BiPS), which transforms question-conditioned masked views into bidirectional where-to-look signals that shape perception during training. BiPS first applies a KL-consistency constraint between the original image and an evidence-preserving view that keeps only question-relevant regions, encouraging coarse but complete coverage of supporting pixels. It then applies a KL-separation constraint between the original and an evidence-ablated view where critical pixels are masked so the image no longer supports the original answer, discouraging text-only shortcuts (i.e., answering from text alone) and enforcing fine-grained visual reliance. Across eight benchmarks, BiPS boosts Qwen2.5-VL-7B by 8.2% on average and shows strong out-of-domain generalization to unseen datasets and image types.</summary>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-26T18:59:47Z</published>
    <arxiv:primary_category term="cs.CV"/>
    <author>
      <name>Shuoshuo Zhang</name>
    </author>
    <author>
      <name>Yizhen Zhang</name>
    </author>
    <author>
      <name>Jingjing Fu</name>
    </author>
    <author>
      <name>Lei Song</name>
    </author>
    <author>
      <name>Jiang Bian</name>
    </author>
    <author>
      <name>Yujiu Yang</name>
    </author>
    <author>
      <name>Rui Wang</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.22102v1</id>
    <title>Explainable Multimodal Regression via Information Decomposition</title>
    <updated>2025-12-26T18:07:18Z</updated>
    <link href="https://arxiv.org/abs/2512.22102v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.22102v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Multimodal regression aims to predict a continuous target from heterogeneous input sources and typically relies on fusion strategies such as early or late fusion. However, existing methods lack principled tools to disentangle and quantify the individual contributions of each modality and their interactions, limiting the interpretability of multimodal fusion. We propose a novel multimodal regression framework grounded in Partial Information Decomposition (PID), which decomposes modality-specific representations into unique, redundant, and synergistic components. The basic PID framework is inherently underdetermined. To resolve this, we introduce inductive bias by enforcing Gaussianity in the joint distribution of latent representations and the transformed response variable (after inverse normal transformation), thereby enabling analytical computation of the PID terms. Additionally, we derive a closed-form conditional independence regularizer to promote the isolation of unique information within each modality. Experiments on six real-world datasets, including a case study on large-scale brain age prediction from multimodal neuroimaging data, demonstrate that our framework outperforms state-of-the-art methods in both predictive accuracy and interpretability, while also enabling informed modality selection for efficient inference. Implementation is available at https://github.com/zhaozhaoma/PIDReg.</summary>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-26T18:07:18Z</published>
    <arxiv:comment>Project Page: https://github.com/zhaozhaoma/PIDReg</arxiv:comment>
    <arxiv:primary_category term="cs.LG"/>
    <author>
      <name>Zhaozhao Ma</name>
    </author>
    <author>
      <name>Shujian Yu</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.22098v1</id>
    <title>Exact inference via quasi-conjugacy in two-parameter Poisson-Dirichlet hidden Markov models</title>
    <updated>2025-12-26T17:54:58Z</updated>
    <link href="https://arxiv.org/abs/2512.22098v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.22098v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>We introduce a nonparametric model for time-evolving, unobserved probability distributions from discrete-time data consisting of unlabelled partitions. The latent process is a two-parameter Poisson-Dirichlet diffusion, and observations arise via exchangeable sampling. Applications include social and genetic data where only aggregate clustering summaries are observed. To address the intractable likelihood, we develop a tractable inferential framework that avoids label enumeration and direct simulation of the latent state. We exploit a duality between the diffusion and a pure-death process on partitions, together with coagulation operators that encode the effect of new data. These yield closed-form, recursive updates for forward and backward inference. We compute exact posterior distributions of the latent state at arbitrary times and predictive distributions of future or interpolated partitions. This enables online and offline inference and forecasting with full uncertainty quantification, bypassing MCMC and sequential Monte Carlo. Compared to particle filtering, our method achieves higher accuracy, lower variance, and substantial computational gains. We illustrate the methodology with synthetic experiments and a social network application, recovering interpretable patterns in time-varying heterozygosity.</summary>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-26T17:54:58Z</published>
    <arxiv:primary_category term="stat.ME"/>
    <author>
      <name>Marco Dalla Pria</name>
    </author>
    <author>
      <name>Matteo Ruggiero</name>
    </author>
    <author>
      <name>Dario Span√≤</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.22096v1</id>
    <title>Yume-1.5: A Text-Controlled Interactive World Generation Model</title>
    <updated>2025-12-26T17:52:49Z</updated>
    <link href="https://arxiv.org/abs/2512.22096v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.22096v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Recent approaches have demonstrated the promise of using diffusion models to generate interactive and explorable worlds. However, most of these methods face critical challenges such as excessively large parameter sizes, reliance on lengthy inference steps, and rapidly growing historical context, which severely limit real-time performance and lack text-controlled generation capabilities. To address these challenges, we propose \method, a novel framework designed to generate realistic, interactive, and continuous worlds from a single image or text prompt. \method achieves this through a carefully designed framework that supports keyboard-based exploration of the generated worlds. The framework comprises three core components: (1) a long-video generation framework integrating unified context compression with linear attention; (2) a real-time streaming acceleration strategy powered by bidirectional attention distillation and an enhanced text embedding scheme; (3) a text-controlled method for generating world events. We have provided the codebase in the supplementary material.</summary>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-26T17:52:49Z</published>
    <arxiv:primary_category term="cs.CV"/>
    <author>
      <name>Xiaofeng Mao</name>
    </author>
    <author>
      <name>Zhen Li</name>
    </author>
    <author>
      <name>Chuanhao Li</name>
    </author>
    <author>
      <name>Xiaojie Xu</name>
    </author>
    <author>
      <name>Kaining Ying</name>
    </author>
    <author>
      <name>Tong He</name>
    </author>
    <author>
      <name>Jiangmiao Pang</name>
    </author>
    <author>
      <name>Yu Qiao</name>
    </author>
    <author>
      <name>Kaipeng Zhang</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.22080v1</id>
    <title>Classifying Urban Regions by Aggregated Pollutant Weather Correlation Strength: A Spatiotemporal Study</title>
    <updated>2025-12-26T16:48:14Z</updated>
    <link href="https://arxiv.org/abs/2512.22080v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.22080v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Understanding pollutant meteorology interactions is essential for environmental risk assessment. This study develops an entropy-based statistical framework to analyze static and temporal dependencies between urban air pollutants and meteorological variables across multiple Indian cities. Dependence is quantified using complementary linear and nonlinear measures, including Pearson correlation, mutual information, and relative conditional entropy. A key methodological contribution is a PCA based composite indexing framework that integrates these heterogeneous metrics into a unified and interpretable correlation score. For each pollutant meteorological pair within a city, PCA is used to extract a joint variability index, while spatial variability is assessed by aggregating correlations across cities. These indices are further combined to derive a comprehensive city-level correlation score that represents overall pollutant meteorology coupling strength and enables classification of cities into distinct interaction regimes. Sensitivity analysis, performed by systematically excluding individual variable pairs, demonstrates the robustness of the framework, with no single pair exerting disproportionate influence. Temporal dependencies are examined using transfer entropy and time-delayed mutual information. Results indicate that relative humidity generally leads changes in pollutant concentrations, whereas ambient temperature tends to lag, highlighting contrasting causal influences. Mutual information peaks at zero lag and decays rapidly, indicating strong short term interactions with limited persistence. Overall, the proposed framework provides a unified and interpretable approach for assessing complex pollutant meteorology interactions across diverse locations and time.</summary>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-26T16:48:14Z</published>
    <arxiv:comment>28 pages, 6 figures, 13 tables. arXiv admin note: substantial text overlap with arXiv:2508.17453</arxiv:comment>
    <arxiv:primary_category term="physics.soc-ph"/>
    <author>
      <name>Koyena Ghosh</name>
    </author>
    <author>
      <name>Suchismita Banerjee</name>
    </author>
    <author>
      <name>Urna Basu</name>
    </author>
    <author>
      <name>Banasri Basu</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.22075v1</id>
    <title>Primordial black holes and smooth coarse-graining in excursion set theory</title>
    <updated>2025-12-26T16:29:28Z</updated>
    <link href="https://arxiv.org/abs/2512.22075v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.22075v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>The excursion-set formalism enables us to infer the mass distribution of collapsed objects, such as primordial black holes (PBHs), by the language of stochastic processes. Within the framework, this article investigates how a smooth coarse-graining procedure affects the resulting PBH mass function. As a demonstrative example, we employ a Gaussian window function, for which the stochastic noise becomes fully correlated across scales. It is found that these correlated noises result in a mass function of PBHs, whose maximum and its neighbourhood are predominantly determined by the probability that the density contrast exceeds a given threshold at each mass scale. Our results clarify the role of noise correlations induced by smooth coarse-graining and highlight their importance in predicting the abundance of PBHs.</summary>
    <category term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="gr-qc" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-26T16:29:28Z</published>
    <arxiv:comment>25 pages, 6 figures</arxiv:comment>
    <arxiv:primary_category term="astro-ph.CO"/>
    <author>
      <name>Daiki Saito</name>
    </author>
    <author>
      <name>Koki Tokeshi</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.22066v1</id>
    <title>Prefill vs. Decode Bottlenecks: SRAM-Frequency Tradeoffs and the Memory-Bandwidth Ceiling</title>
    <updated>2025-12-26T15:42:29Z</updated>
    <link href="https://arxiv.org/abs/2512.22066v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.22066v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Energy consumption dictates the cost and environmental impact of deploying Large Language Models. This paper investigates the impact of on-chip SRAM size and operating frequency on the energy efficiency and performance of LLM inference, focusing on the distinct behaviors of the compute-bound prefill and memory-bound decode phases. Our simulation methodology combines OpenRAM for energy modeling, LLMCompass for latency simulation, and ScaleSIM for systolic array operational intensity. Our findings show that total energy use is predominantly determined by SRAM size in both phases, with larger buffers significantly increasing static energy due to leakage, which is not offset by corresponding latency benefits. We quantitatively explore the memory-bandwidth bottleneck, demonstrating that while high operating frequencies reduce prefill latency, their positive impact on memory-bound decode latency is capped by the external memory bandwidth. Counter-intuitively, high compute frequency can reduce total energy by reducing execution time and consequently decreasing static energy consumption more than the resulting dynamic power increase. We identify an optimal hardware configuration for the simulated workload: high operating frequencies (1200MHz-1400MHz) and a small local buffer size of 32KB to 64KB. This combination achieves the best energy-delay product, balancing low latency with high energy efficiency. Furthermore, we demonstrate how memory bandwidth acts as a performance ceiling, and that increasing compute frequency only yields performance gains up to the point where the workload becomes memory-bound. This analysis provides concrete architectural insights for designing energy-efficient LLM accelerators, especially for datacenters aiming to minimize their energy overhead.</summary>
    <category term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-26T15:42:29Z</published>
    <arxiv:primary_category term="cs.AR"/>
    <author>
      <name>Hannah Atmer</name>
    </author>
    <author>
      <name>Yuan Yao</name>
    </author>
    <author>
      <name>Thiemo Voigt</name>
    </author>
    <author>
      <name>Stefanos Kaxiras</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.22065v1</id>
    <title>StreamAvatar: Streaming Diffusion Models for Real-Time Interactive Human Avatars</title>
    <updated>2025-12-26T15:41:24Z</updated>
    <link href="https://arxiv.org/abs/2512.22065v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.22065v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Real-time, streaming interactive avatars represent a critical yet challenging goal in digital human research. Although diffusion-based human avatar generation methods achieve remarkable success, their non-causal architecture and high computational costs make them unsuitable for streaming. Moreover, existing interactive approaches are typically limited to head-and-shoulder region, limiting their ability to produce gestures and body motions. To address these challenges, we propose a two-stage autoregressive adaptation and acceleration framework that applies autoregressive distillation and adversarial refinement to adapt a high-fidelity human video diffusion model for real-time, interactive streaming. To ensure long-term stability and consistency, we introduce three key components: a Reference Sink, a Reference-Anchored Positional Re-encoding (RAPR) strategy, and a Consistency-Aware Discriminator. Building on this framework, we develop a one-shot, interactive, human avatar model capable of generating both natural talking and listening behaviors with coherent gestures. Extensive experiments demonstrate that our method achieves state-of-the-art performance, surpassing existing approaches in generation quality, real-time efficiency, and interaction naturalness. Project page: https://streamavatar.github.io .</summary>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-26T15:41:24Z</published>
    <arxiv:comment>Project page: https://streamavatar.github.io</arxiv:comment>
    <arxiv:primary_category term="cs.CV"/>
    <author>
      <name>Zhiyao Sun</name>
    </author>
    <author>
      <name>Ziqiao Peng</name>
    </author>
    <author>
      <name>Yifeng Ma</name>
    </author>
    <author>
      <name>Yi Chen</name>
    </author>
    <author>
      <name>Zhengguang Zhou</name>
    </author>
    <author>
      <name>Zixiang Zhou</name>
    </author>
    <author>
      <name>Guozhen Zhang</name>
    </author>
    <author>
      <name>Youliang Zhang</name>
    </author>
    <author>
      <name>Yuan Zhou</name>
    </author>
    <author>
      <name>Qinglin Lu</name>
    </author>
    <author>
      <name>Yong-Jin Liu</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.22048v1</id>
    <title>Classification and stability of black hole event horizon births: a contact geometry approach</title>
    <updated>2025-12-26T14:55:35Z</updated>
    <link href="https://arxiv.org/abs/2512.22048v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.22048v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>A classical result by Penrose establishes that null geodesics generating a black hole event horizon can only intersect at their entrance to the horizon in ``crossover'' points. This points together with limit points of this set, namely caustics, form the so-called "crease set". Light rays enter into the horizon through the crease set, characterizing the latter as the birth of the horizon. A natural question in this context refers to the classification and stability of the structural possibilities of black hole crease sets. In this work we revisit the strategy adopted by Gadioux &amp; Reall for such a classification in the setting of singularity theory in contact geometry. Specifically, in such contact geometry setting, the event horizon is identified as a component (not connected to null infinity) of a so-called ``BigFront''. The characterization of BigFronts as Legendrian projections of Legendrian submanifolds permits to classify the crease sets and ``cuspidal sets'' (or caustics in Penrose's terminology) by applying classical results established by V.I. Arnol'd. Here we refine the stability discussion presented by Gadioux &amp; Reall of that connected component of the crease set that is not causally connected to null infinity and that constitutes the event horizon birth. In addition, we identify the existence of other components of the crease set that lie in the part of the BigFront that is causally connected to null infinity.</summary>
    <category term="gr-qc" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DG" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-26T14:55:35Z</published>
    <arxiv:comment>4 pages, 2 figures, talk presented in conference 24th International Conference on General Relativity and Gravitation &amp; 16th Edoardo Amaldi Conference on Gravitational Waves</arxiv:comment>
    <arxiv:primary_category term="gr-qc"/>
    <author>
      <name>Oscar Meneses Rojas</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.22044v1</id>
    <title>Inferring Eccentricity of Binary Black Holes from Spin-Orbit Misalignment</title>
    <updated>2025-12-26T14:38:02Z</updated>
    <link href="https://arxiv.org/abs/2512.22044v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.22044v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Orbital eccentricity remains one of the least accessible parameters in observations of binary black hole (BBH) systems, largely erased by gravitational radiation long before detection. We introduce a new method to recover this lost parameter by using a more accessible and routinely measurable quantity: spin-orbit misalignment. In isolated binary evolution, a natal kick from the second supernova both tilts the orbital plane and injects orbital eccentricity, forging a direct and quantifiable connection between spin-tilt and post-supernova eccentricity. By measuring this spin-tilt using gravitational waves, we can not only constrain the natal kick, but we can also reconstruct the binary's formation eccentricity. We apply this method to GW190412 and GW241011, assuming an isolated formation channel, and show how their eccentricity at formation can be constrained even in the absence of direct eccentricity measurements. As more advanced detectors come online, improved signal-to-noise ratios will tighten spin-tilt constraints, allowing more precise and reliable estimates of BBH formation eccentricity. Combining this method with multiband observations from LISA and next-generation (XG) detectors will allow us to recover not only eccentricity but also the binary's orbital separation and redshift at formation, offering a clearer picture of the birth environments of BBH systems and processes that drive their merger.</summary>
    <category term="astro-ph.HE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="gr-qc" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-26T14:38:02Z</published>
    <arxiv:comment>10 pages, 4 figures</arxiv:comment>
    <arxiv:primary_category term="astro-ph.HE"/>
    <author>
      <name>Vishal Baibhav</name>
    </author>
  </entry>
</feed>
