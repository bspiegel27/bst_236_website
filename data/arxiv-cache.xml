<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2026-01-24T01:00:27Z -->
<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/" xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns="http://www.w3.org/2005/Atom">
  <id>https://arxiv.org/api/p6EyKyP4fMY/66n9Ev8E79F7KlI</id>
  <title>arXiv Query: search_query=all:causal OR all:inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <updated>2026-01-24T01:00:34Z</updated>
  <link href="https://arxiv.org/api/query?search_query=all:causal+OR+all:inference&amp;start=0&amp;max_results=10&amp;id_list=" type="application/atom+xml"/>
  <opensearch:itemsPerPage>10</opensearch:itemsPerPage>
  <opensearch:totalResults>131531</opensearch:totalResults>
  <opensearch:startIndex>0</opensearch:startIndex>
  <entry>
    <id>http://arxiv.org/abs/2601.16212v1</id>
    <title>Point Bridge: 3D Representations for Cross Domain Policy Learning</title>
    <updated>2026-01-22T18:59:24Z</updated>
    <link href="https://arxiv.org/abs/2601.16212v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.16212v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Robot foundation models are beginning to deliver on the promise of generalist robotic agents, yet progress remains constrained by the scarcity of large-scale real-world manipulation datasets. Simulation and synthetic data generation offer a scalable alternative, but their usefulness is limited by the visual domain gap between simulation and reality. In this work, we present Point Bridge, a framework that leverages unified, domain-agnostic point-based representations to unlock synthetic datasets for zero-shot sim-to-real policy transfer, without explicit visual or object-level alignment. Point Bridge combines automated point-based representation extraction via Vision-Language Models (VLMs), transformer-based policy learning, and efficient inference-time pipelines to train capable real-world manipulation agents using only synthetic data. With additional co-training on small sets of real demonstrations, Point Bridge further improves performance, substantially outperforming prior vision-based sim-and-real co-training methods. It achieves up to 44% gains in zero-shot sim-to-real transfer and up to 66% with limited real data across both single-task and multitask settings. Videos of the robot are best viewed at: https://pointbridge3d.github.io/</summary>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-22T18:59:24Z</published>
    <arxiv:primary_category term="cs.RO"/>
    <author>
      <name>Siddhant Haldar</name>
    </author>
    <author>
      <name>Lars Johannsmeier</name>
    </author>
    <author>
      <name>Lerrel Pinto</name>
    </author>
    <author>
      <name>Abhishek Gupta</name>
    </author>
    <author>
      <name>Dieter Fox</name>
    </author>
    <author>
      <name>Yashraj Narang</name>
    </author>
    <author>
      <name>Ajay Mandlekar</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.16207v1</id>
    <title>IVRA: Improving Visual-Token Relations for Robot Action Policy with Training-Free Hint-Based Guidance</title>
    <updated>2026-01-22T18:57:13Z</updated>
    <link href="https://arxiv.org/abs/2601.16207v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.16207v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Many Vision-Language-Action (VLA) models flatten image patches into a 1D token sequence, weakening the 2D spatial cues needed for precise manipulation. We introduce IVRA, a lightweight, training-free method that improves spatial understanding by exploiting affinity hints already available in the model's built-in vision encoder, without requiring any external encoder or retraining. IVRA selectively injects these affinity signals into a language-model layer in which instance-level features reside. This inference-time intervention realigns visual-token interactions and better preserves geometric structure while keeping all model parameters fixed. We demonstrate the generality of IVRA by applying it to diverse VLA architectures (LLaRA, OpenVLA, and FLOWER) across simulated benchmarks spanning both 2D and 3D manipulation (VIMA and LIBERO) and on various real-robot tasks. On 2D VIMA, IVRA improves average success by +4.2% over the baseline LLaRA in a low-data regime. On 3D LIBERO, it yields consistent gains over the OpenVLA and FLOWER baselines, including improvements when baseline accuracy is near saturation (96.3% to 97.1%). All code and models will be released publicly. Visualizations are available at: jongwoopark7978.github.io/IVRA</summary>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-22T18:57:13Z</published>
    <arxiv:primary_category term="cs.RO"/>
    <author>
      <name>Jongwoo Park</name>
    </author>
    <author>
      <name>Kanchana Ranasinghe</name>
    </author>
    <author>
      <name>Jinhyeok Jang</name>
    </author>
    <author>
      <name>Cristina Mata</name>
    </author>
    <author>
      <name>Yoo Sung Jang</name>
    </author>
    <author>
      <name>Michael S Ryoo</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.16199v1</id>
    <title>PAL*M: Property Attestation for Large Generative Models</title>
    <updated>2026-01-22T18:51:13Z</updated>
    <link href="https://arxiv.org/abs/2601.16199v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.16199v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Machine learning property attestations allow provers (e.g., model providers or owners) to attest properties of their models/datasets to verifiers (e.g., regulators, customers), enabling accountability towards regulations and policies. But, current approaches do not support generative models or large datasets. We present PAL*M, a property attestation framework for large generative models, illustrated using large language models. PAL*M defines properties across training and inference, leverages confidential virtual machines with security-aware GPUs for coverage of CPU-GPU operations, and proposes using incremental multiset hashing over memory-mapped datasets to efficiently track their integrity. We implement PAL*M on Intel TDX and NVIDIA H100, showing it is efficient, scalable, versatile, and secure.</summary>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-22T18:51:13Z</published>
    <arxiv:primary_category term="cs.CR"/>
    <author>
      <name>Prach Chantasantitam</name>
    </author>
    <author>
      <name>Adam Ilyas Caulfield</name>
    </author>
    <author>
      <name>Vasisht Duddu</name>
    </author>
    <author>
      <name>Lachlan J. Gunn</name>
    </author>
    <author>
      <name>N. Asokan</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.16196v1</id>
    <title>Inference on the Significance of Modalities in Multimodal Generalized Linear Models</title>
    <updated>2026-01-22T18:48:34Z</updated>
    <link href="https://arxiv.org/abs/2601.16196v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.16196v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Despite the popular of multimodal statistical models, there lacks rigorous statistical inference tools for inferring the significance of a single modality within a multimodal model, especially in high-dimensional models. For high-dimensional multimodal generalized linear models, we propose a novel entropy-based metric, called the expected relative entropy, to quantify the information gain of one modality in addition to all other modalities in the model. We propose a deviance-based statistic to estimate the expected relative entropy, prove that it is consistent and its asymptotic distribution can be approximated by a non-central chi-squared distribution. That enables the calculation of confidence intervals and p-values to assess the significance of the expected relative entropy for a given modality. We numerically evaluate the empirical performance of our proposed inference tool by simulations and apply it to a multimodal neuroimaging dataset to demonstrate its good performance on various high-dimensional multimodal generalized linear models.</summary>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-22T18:48:34Z</published>
    <arxiv:primary_category term="stat.ME"/>
    <author>
      <name>Wanting Jin</name>
    </author>
    <author>
      <name>Guorong Wu</name>
    </author>
    <author>
      <name>Quefeng Li</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.16195v1</id>
    <title>Pushing the limits of unconstrained machine-learned interatomic potentials</title>
    <updated>2026-01-22T18:46:58Z</updated>
    <link href="https://arxiv.org/abs/2601.16195v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.16195v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Machine-learned interatomic potentials (MLIPs) are increasingly used to replace computationally demanding electronic-structure calculations to model matter at the atomic scale. The most commonly used model architectures are constrained to fulfill a number of physical laws exactly, from geometric symmetries to energy conservation. Evidence is mounting that relaxing some of these constraints can be beneficial to the efficiency and (somewhat surprisingly) accuracy of MLIPs, even though care should be taken to avoid qualitative failures associated with the breaking of physical symmetries. Given the recent trend of \emph{scaling up} models to larger numbers of parameters and training samples, a very important question is how unconstrained MLIPs behave in this limit. Here we investigate this issue, showing that -- when trained on large datasets -- unconstrained models can be superior in accuracy and speed when compared to physically constrained models. We assess these models both in terms of benchmark accuracy and in terms of usability in practical scenarios, focusing on static simulation workflows such as geometry optimization and lattice dynamics. We conclude that accurate unconstrained models can be applied with confidence, especially since simple inference-time modifications can be used to recover observables that are consistent with the relevant physical symmetries.</summary>
    <category term="physics.chem-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-22T18:46:58Z</published>
    <arxiv:comment>21 pages, 8 figures</arxiv:comment>
    <arxiv:primary_category term="physics.chem-ph"/>
    <author>
      <name>Filippo Bigi</name>
    </author>
    <author>
      <name>Paolo Pegolo</name>
    </author>
    <author>
      <name>Arslan Mazitov</name>
    </author>
    <author>
      <name>Michele Ceriotti</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.16180v1</id>
    <title>Studying energy-resolved transport with wavepacket dynamics on quantum computers</title>
    <updated>2026-01-22T18:30:30Z</updated>
    <link href="https://arxiv.org/abs/2601.16180v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.16180v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Probing energy-dependent transport in quantum simulators requires preparing states with tunable energy and small energy variance. Existing approaches often study quench dynamics of simple initial states, such as computational basis states, which are far from energy eigenstates and therefore limit the achievable energy resolution. In this work, we propose using wavepackets to probe transport properties with improved energy resolution. To demonstrate the utility of this approach, we prepare and evolve wavepackets on Quantinuum's H2-2 quantum computer and identify an energy-dependent localization transition in the Anderson model on an 8x7 lattice--a finite-size mobility edge. We observe that a wavepacket initialized at low energy remains spatially localized under time evolution, while a high-energy wavepacket delocalizes, consistent with the presence of a mobility edge. Crucial to our experiments is an error mitigation strategy that infers the noiseless output bit string distribution using maximum-likelihood estimation. Compared to post-selection, this method removes systematic errors and reduces statistical uncertainty by up to a factor of 5. We extend our methods to the many-particle regime by developing a quantum algorithm for preparing quasiparticle wavepackets in a one-dimensional model of interacting fermions. This technique has modest quantum resource requirements, making wavepacket-based studies of transport in many-body systems a promising application for near-term quantum computers.</summary>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-22T18:30:30Z</published>
    <arxiv:comment>21 pages, 11 figures, 4 tables</arxiv:comment>
    <arxiv:primary_category term="quant-ph"/>
    <author>
      <name>Melody Lee</name>
    </author>
    <author>
      <name>Roland C. Farrell</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.16179v1</id>
    <title>A general spectral solver for the axisymmetric Jeans equations: fast galaxy modelling with arbitrary anisotropy</title>
    <updated>2026-01-22T18:29:48Z</updated>
    <link href="https://arxiv.org/abs/2601.16179v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.16179v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Dynamical modelling is a fundamental tool for measuring galaxy masses and density profiles in the era of large integral-field spectroscopic surveys and Bayesian inference. Solutions based on the Jeans equations are popular due to their robustness and computational efficiency. However, traditional semi-analytic Jeans solvers often require restrictive assumptions about the velocity anisotropy to remain computationally tractable. This paper presents a new spectral solver for the axisymmetric Jeans equations designed to overcome these limitations. I first illustrate, using orbit integrations in realistic potentials, that spherical alignment of the velocity ellipsoid is a physically well-motivated approximation for galaxy modelling. The new method employs a spectral technique to solve the Jeans partial differential equations directly. Two design choices are critical for accuracy and speed: (i) solving for the slowly-varying velocity dispersion rather than the rapidly varying pressure, and (ii) imposing a Robin boundary condition to enforce the asymptotic decay on a finite domain. This formulation supports arbitrary anisotropy distributions beta(r, theta) while simultaneously increasing computational speed by orders of magnitude compared to standard high-accuracy quadratures. Validated against exact analytic benchmarks, the solver recovers intrinsic moments with sub-percent accuracy. The implementation will be included in the public JamPy package and is structured to be optimally suited for massive parallelization on specialized hardware such as GPUs, enabling the rigorous exploration of complex parameter spaces.</summary>
    <category term="astro-ph.GA" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-22T18:29:48Z</published>
    <arxiv:comment>15 pages, 7 figures. LaTeX. Submitted to MNRAS. Implementation will be included in the JamPy package at https://pypi.org/project/jampy/</arxiv:comment>
    <arxiv:primary_category term="astro-ph.GA"/>
    <author>
      <name>Michele Cappellari</name>
      <arxiv:affiliation>University of Oxford</arxiv:affiliation>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.16172v1</id>
    <title>Structured Hints for Sample-Efficient Lean Theorem Proving</title>
    <updated>2026-01-22T18:16:46Z</updated>
    <link href="https://arxiv.org/abs/2601.16172v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.16172v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>State-of-the-art neural theorem provers like DeepSeek-Prover-V1.5 combine large language models with reinforcement learning, achieving impressive results through sophisticated training. We ask: do these highly-trained models still benefit from simple structural guidance at inference time? We evaluate a lightweight intervention -- a fixed prompt schedule over 15 common tactic skeletons -- on the miniF2F benchmark. This simple approach yields 21.7% pass@16 compared to 15.2% for standard sampling from the same model, a 43% relative improvement using the same number of samples (k=16) and same maximum generation length (1024 tokens). Our results suggest that even capable RL-trained provers underutilize structural priors available in the tactic language, and that simple inference-time guidance remains a cheap, complementary boost.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-22T18:16:46Z</published>
    <arxiv:comment>9 pages, 1 figure</arxiv:comment>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Zachary Burton</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.16159v1</id>
    <title>Magnetar fraction in Core-Collapse Supernovae</title>
    <updated>2026-01-22T18:00:26Z</updated>
    <link href="https://arxiv.org/abs/2601.16159v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.16159v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Magnetars are extreme neutron stars powered by ultra-strong magnetic fields ($\sim10^{14}$ Gauss) and are compelling engines for some of the most powerful extragalactic transients such as Super Luminous Supernovae, Gamma-Ray Bursts, and Fast Radio Bursts. Yet their formation rate relative to ordinary neutron stars remains uncertain, often precluding direct comparisons with the rates of these extragalactic transients. Furthermore, magnetars have been recently shown to be evolutionarily related to other neutron star classes, complicating the estimate of the exact magnetar fraction within the neutron star population. We study the magnetar birth fraction in core-collapse supernovae using pulsar population synthesis of all isolated neutron star classes in our Galaxy, incorporating self-consistently the Galactic dynamical evolution, spin-down and magneto-thermal evolution. This approach allows us to derive strong constraints from small close-to-complete observational samples. In particular, looking at the age-limited young ($&lt;$2 kyr) neutron star population in the Milky Way we find 24 detected young neutron stars, with only 10 of them (41%) being classical rotational powered pulsars, while the others (59%) are either magnetars or central compact objects, the latter believed to be equally magnetically powered. We further compare the results with the nearby volume-limited class ($&lt;$500 pc) of X-ray Dim Isolated Neutron stars, old nearby magnetars. We conclude that the observed population of isolated neutron stars in the Galaxy can be reproduced only by assuming a core-collapse supernova rate larger than two, and a larger magnetar fraction than previously inferred. By assuming a bimodal initial magnetic field ($B_0$) distribution at birth, we find that the magnetar class peaks between $B_0\sim 1-2.5\times10^{14}$ Gauss and represents on average $\sim50$% of the entire neutron star population.</summary>
    <category term="astro-ph.HE" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-22T18:00:26Z</published>
    <arxiv:comment>51 pages, 9 figures, 4 tables; Submitted; Comments welcome</arxiv:comment>
    <arxiv:primary_category term="astro-ph.HE"/>
    <author>
      <name>Celsa Pardo-Araujo</name>
    </author>
    <author>
      <name>Nanda Rea</name>
    </author>
    <author>
      <name>Michele Ronchi</name>
    </author>
    <author>
      <name>Vanessa Graber</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.16152v1</id>
    <title>Substrate Stability Under Persistent Disagreement: Structural Constraints for Neutral Ontological Substrates</title>
    <updated>2026-01-22T17:51:02Z</updated>
    <link href="https://arxiv.org/abs/2601.16152v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.16152v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Modern data systems increasingly operate under conditions of persistent legal, political, and analytic disagreement. In such settings, interoperability cannot rely on shared interpretation, negotiated semantics, or centralized authority. Instead, representations must function as neutral substrates that preserve stable reference across incompatible extensions. This paper investigates the structural constraints imposed on ontological design by this requirement. Building on a neutrality framework that treats interpretive non-commitment and stability under extension as explicit design constraints, we ask what minimal ontological structure is forced if accountability relationships are to remain referable and comparable under disagreement. Minimality here is not mere parsimony: a reduction is admissible only if it does not reintroduce stability-critical distinctions as hidden roles, flags, or contextual predicates. We establish a conditional lower-bound result: any ontology capable of supporting accountability under persistent disagreement must realize at least six distinct identity-and-persistence regimes. We further show that a construction with exactly six such regimes is sufficient to satisfy the stated requirements without embedding causal or normative commitments in the substrate. The result is not a proposal for a universal ontology, but a constraint on what is possible when neutrality and stable reference are treated as non-negotiable design goals.</summary>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-22T17:51:02Z</published>
    <arxiv:comment>29 pages</arxiv:comment>
    <arxiv:primary_category term="cs.LO"/>
    <author>
      <name>Denise M. Case</name>
    </author>
  </entry>
</feed>
