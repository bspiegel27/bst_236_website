<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2026-02-09T01:18:12Z -->
<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/" xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns="http://www.w3.org/2005/Atom">
  <id>https://arxiv.org/api/p6EyKyP4fMY/66n9Ev8E79F7KlI</id>
  <title>arXiv Query: search_query=all:causal OR all:inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <updated>2026-02-09T01:18:12Z</updated>
  <link href="https://arxiv.org/api/query?search_query=all:causal+OR+all:inference&amp;start=0&amp;max_results=10&amp;id_list=" type="application/atom+xml"/>
  <opensearch:itemsPerPage>10</opensearch:itemsPerPage>
  <opensearch:totalResults>133197</opensearch:totalResults>
  <opensearch:startIndex>0</opensearch:startIndex>
  <entry>
    <id>http://arxiv.org/abs/2602.06041v1</id>
    <title>Predicting Camera Pose from Perspective Descriptions for Spatial Reasoning</title>
    <updated>2026-02-05T18:59:55Z</updated>
    <link href="https://arxiv.org/abs/2602.06041v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.06041v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Multi-image spatial reasoning remains challenging for current multimodal large language models (MLLMs). While single-view perception is inherently 2D, reasoning over multiple views requires building a coherent scene understanding across viewpoints. In particular, we study perspective taking, where a model must build a coherent 3D understanding from multi-view observations and use it to reason from a new, language-specified viewpoint. We introduce CAMCUE, a pose-aware multi-image framework that uses camera pose as an explicit geometric anchor for cross-view fusion and novel-view reasoning. CAMCUE injects per-view pose into visual tokens, grounds natural-language viewpoint descriptions to a target camera pose, and synthesizes a pose-conditioned imagined target view to support answering. To support this setting, we curate CAMCUE-DATA with 27,668 training and 508 test instances pairing multi-view images and poses with diverse target-viewpoint descriptions and perspective-shift questions. We also include human-annotated viewpoint descriptions in the test split to evaluate generalization to human language. CAMCUE improves overall accuracy by 9.06% and predicts target poses from natural-language viewpoint descriptions with over 90% rotation accuracy within 20Â° and translation accuracy within a 0.5 error threshold. This direct grounding avoids expensive test-time search-and-match, reducing inference time from 256.6s to 1.45s per example and enabling fast, interactive use in real-world scenarios.</summary>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-05T18:59:55Z</published>
    <arxiv:primary_category term="cs.CV"/>
    <author>
      <name>Xuejun Zhang</name>
    </author>
    <author>
      <name>Aditi Tiwari</name>
    </author>
    <author>
      <name>Zhenhailong Wang</name>
    </author>
    <author>
      <name>Heng Ji</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.06036v1</id>
    <title>DFlash: Block Diffusion for Flash Speculative Decoding</title>
    <updated>2026-02-05T18:59:30Z</updated>
    <link href="https://arxiv.org/abs/2602.06036v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.06036v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Autoregressive large language models (LLMs) deliver strong performance but require inherently sequential decoding, leading to high inference latency and poor GPU utilization. Speculative decoding mitigates this bottleneck by using a fast draft model whose outputs are verified in parallel by the target LLM; however, existing methods still rely on autoregressive drafting, which remains sequential and limits practical speedups. Diffusion LLMs offer a promising alternative by enabling parallel generation, but current diffusion models typically underperform compared with autoregressive models. In this paper, we introduce DFlash, a speculative decoding framework that employs a lightweight block diffusion model for parallel drafting. By generating draft tokens in a single forward pass and conditioning the draft model on context features extracted from the target model, DFlash enables efficient drafting with high-quality outputs and higher acceptance rates. Experiments show that DFlash achieves over 6x lossless acceleration across a range of models and tasks, delivering up to 2.5x higher speedup than the state-of-the-art speculative decoding method EAGLE-3.</summary>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-05T18:59:30Z</published>
    <arxiv:primary_category term="cs.CL"/>
    <author>
      <name>Jian Chen</name>
    </author>
    <author>
      <name>Yesheng Liang</name>
    </author>
    <author>
      <name>Zhijian Liu</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.06030v1</id>
    <title>PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling</title>
    <updated>2026-02-05T18:59:01Z</updated>
    <link href="https://arxiv.org/abs/2602.06030v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.06030v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Large language model (LLM)-based multi-agent systems enable expressive agent reasoning but are expensive to scale and poorly calibrated for timestep-aligned state-transition simulation, while classical agent-based models (ABMs) offer interpretability but struggle to integrate rich individual-level signals and non-stationary behaviors. We propose PhysicsAgentABM, which shifts inference to behaviorally coherent agent clusters: state-specialized symbolic agents encode mechanistic transition priors, a multimodal neural transition model captures temporal and interaction dynamics, and uncertainty-aware epistemic fusion yields calibrated cluster-level transition distributions. Individual agents then stochastically realize transitions under local constraints, decoupling population inference from entity-level variability. We further introduce ANCHOR, an LLM agent-driven clustering strategy based on cross-contextual behavioral responses and a novel contrastive loss, reducing LLM calls by up to 6-8 times. Experiments across public health, finance, and social sciences show consistent gains in event-time accuracy and calibration over mechanistic, neural, and LLM baselines. By re-architecting generative ABM around population-level inference with uncertainty-aware neuro-symbolic fusion, PhysicsAgentABM establishes a new paradigm for scalable and calibrated simulation with LLMs.</summary>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-05T18:59:01Z</published>
    <arxiv:primary_category term="cs.MA"/>
    <author>
      <name>Kavana Venkatesh</name>
    </author>
    <author>
      <name>Yinhan He</name>
    </author>
    <author>
      <name>Jundong Li</name>
    </author>
    <author>
      <name>Jiaming Cui</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.06029v1</id>
    <title>Curiosity is Knowledge: Self-Consistent Learning and No-Regret Optimization with Active Inference</title>
    <updated>2026-02-05T18:58:32Z</updated>
    <link href="https://arxiv.org/abs/2602.06029v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.06029v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Active inference (AIF) unifies exploration and exploitation by minimizing the Expected Free Energy (EFE), balancing epistemic value (information gain) and pragmatic value (task performance) through a curiosity coefficient. Yet it has been unclear when this balance yields both coherent learning and efficient decision-making: insufficient curiosity can drive myopic exploitation and prevent uncertainty resolution, while excessive curiosity can induce unnecessary exploration and regret. We establish the first theoretical guarantee for EFE-minimizing agents, showing that a single requirement--sufficient curiosity--simultaneously ensures self-consistent learning (Bayesian posterior consistency) and no-regret optimization (bounded cumulative regret). Our analysis characterizes how this mechanism depends on initial uncertainty, identifiability, and objective alignment, thereby connecting AIF to classical Bayesian experimental design and Bayesian optimization within one theoretical framework. We further translate these theories into practical design guidelines for tuning the epistemic-pragmatic trade-off in hybrid learning-optimization problems, validated through real-world experiments.</summary>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-05T18:58:32Z</published>
    <arxiv:primary_category term="cs.LG"/>
    <author>
      <name>Yingke Li</name>
    </author>
    <author>
      <name>Anjali Parashar</name>
    </author>
    <author>
      <name>Enlu Zhou</name>
    </author>
    <author>
      <name>Chuchu Fan</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.06025v1</id>
    <title>Learning Query-Aware Budget-Tier Routing for Runtime Agent Memory</title>
    <updated>2026-02-05T18:57:09Z</updated>
    <link href="https://arxiv.org/abs/2602.06025v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.06025v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Memory is increasingly central to Large Language Model (LLM) agents operating beyond a single context window, yet most existing systems rely on offline, query-agnostic memory construction that can be inefficient and may discard query-critical information. Although runtime memory utilization is a natural alternative, prior work often incurs substantial overhead and offers limited explicit control over the performance-cost trade-off. In this work, we present \textbf{BudgetMem}, a runtime agent memory framework for explicit, query-aware performance-cost control. BudgetMem structures memory processing as a set of memory modules, each offered in three budget tiers (i.e., \textsc{Low}/\textsc{Mid}/\textsc{High}). A lightweight router performs budget-tier routing across modules to balance task performance and memory construction cost, which is implemented as a compact neural policy trained with reinforcement learning. Using BudgetMem as a unified testbed, we study three complementary strategies for realizing budget tiers: implementation (method complexity), reasoning (inference behavior), and capacity (module model size). Across LoCoMo, LongMemEval, and HotpotQA, BudgetMem surpasses strong baselines when performance is prioritized (i.e., high-budget setting), and delivers better accuracy-cost frontiers under tighter budgets. Moreover, our analysis disentangles the strengths and weaknesses of different tiering strategies, clarifying when each axis delivers the most favorable trade-offs under varying budget regimes.</summary>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-05T18:57:09Z</published>
    <arxiv:comment>Code is available at https://github.com/ViktorAxelsen/BudgetMem</arxiv:comment>
    <arxiv:primary_category term="cs.CL"/>
    <author>
      <name>Haozhen Zhang</name>
    </author>
    <author>
      <name>Haodong Yue</name>
    </author>
    <author>
      <name>Tao Feng</name>
    </author>
    <author>
      <name>Quanyu Long</name>
    </author>
    <author>
      <name>Jianzhu Bao</name>
    </author>
    <author>
      <name>Bowen Jin</name>
    </author>
    <author>
      <name>Weizhi Zhang</name>
    </author>
    <author>
      <name>Xiao Li</name>
    </author>
    <author>
      <name>Jiaxuan You</name>
    </author>
    <author>
      <name>Chengwei Qin</name>
    </author>
    <author>
      <name>Wenya Wang</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.06022v1</id>
    <title>Correctness-Optimized Residual Activation Lens (CORAL): Transferrable and Calibration-Aware Inference-Time Steering</title>
    <updated>2026-02-05T18:55:56Z</updated>
    <link href="https://arxiv.org/abs/2602.06022v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.06022v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Large language models (LLMs) exhibit persistent miscalibration, especially after instruction tuning and preference alignment. Modified training objectives can improve calibration, but retraining is expensive. Inference-time steering offers a lightweight alternative, yet most existing methods optimize proxies for correctness rather than correctness itself. We introduce CORAL (Correctness-Optimized Residual Activation Lens), a regularized inference-time steering method that captures distributed correctness signals from model internal activations using weight-decay MLP probes. We evaluate CORAL across three 7B-parameter models and find that it consistently improves accuracy by 10\% and expected calibration error (ECE) by 50\% on average. We additionally demonstrate that these gains transfer without retraining to the complete published test sets of four held-out benchmarks (ARC-Challenge, HellaSwag, Math-MC, OpenBookQA), averaging 14\% accuracy improvements and 49\% ECE improvements. Our results support the hypothesis that distributed information in model internals can be extracted using regularized probes when individual neurons are insufficient. CORAL thus provides a compute-efficient, transferable, and calibration-aware approach to improve MCQA performance during inference.</summary>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-05T18:55:56Z</published>
    <arxiv:primary_category term="cs.LG"/>
    <author>
      <name>Miranda Muqing Miao</name>
    </author>
    <author>
      <name>Young-Min Cho</name>
    </author>
    <author>
      <name>Lyle Ungar</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.06021v1</id>
    <title>Diffusion Model's Generalization Can Be Characterized by Inductive Biases toward a Data-Dependent Ridge Manifold</title>
    <updated>2026-02-05T18:55:03Z</updated>
    <link href="https://arxiv.org/abs/2602.06021v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.06021v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>When a diffusion model is not memorizing the training data set, how does it generalize exactly? A quantitative understanding of the distribution it generates would be beneficial to, for example, an assessment of the model's performance for downstream applications. We thus explicitly characterize what diffusion model generates, by proposing a log-density ridge manifold and quantifying how the generated data relate to this manifold as inference dynamics progresses. More precisely, inference undergoes a reach-align-slide process centered around the ridge manifold: trajectories first reach a neighborhood of the manifold, then align as being pushed toward or away from the manifold in normal directions, and finally slide along the manifold in tangent directions. Within the scope of this general behavior, different training errors will lead to different normal and tangent motions, which can be quantified, and these detailed motions characterize when inter-mode generations emerge. More detailed understanding of training dynamics will lead to more accurate quantification of the generation inductive bias, and an example of random feature model will be considered, for which we can explicitly illustrate how diffusion model's inductive biases originate as a composition of architectural bias and training accuracy, and how they evolve with the inference dynamics. Experiments on synthetic multimodal distributions and MNIST latent diffusion support the predicted directional effects, in both low- and high-dimensions.</summary>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-05T18:55:03Z</published>
    <arxiv:primary_category term="stat.ML"/>
    <author>
      <name>Ye He</name>
    </author>
    <author>
      <name>Yitong Qiu</name>
    </author>
    <author>
      <name>Molei Tao</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.06020v1</id>
    <title>Mechanisms of AI Protein Folding in ESMFold</title>
    <updated>2026-02-05T18:54:54Z</updated>
    <link href="https://arxiv.org/abs/2602.06020v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.06020v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>How do protein structure prediction models fold proteins? We investigate this question by tracing how ESMFold folds a beta hairpin, a prevalent structural motif. Through counterfactual interventions on model latents, we identify two computational stages in the folding trunk. In the first stage, early blocks initialize pairwise biochemical signals: residue identities and associated biochemical features such as charge flow from sequence representations into pairwise representations. In the second stage, late blocks develop pairwise spatial features: distance and contact information accumulate in the pairwise representation. We demonstrate that the mechanisms underlying structural decisions of ESMFold can be localized, traced through interpretable representations, and manipulated with strong causal effects.</summary>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.BM" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-05T18:54:54Z</published>
    <arxiv:comment>Our code, data, and results are available at https://folding.baulab.info</arxiv:comment>
    <arxiv:primary_category term="cs.LG"/>
    <author>
      <name>Kevin Lu</name>
    </author>
    <author>
      <name>Jannik Brinkmann</name>
    </author>
    <author>
      <name>Stefan Huber</name>
    </author>
    <author>
      <name>Aaron Mueller</name>
    </author>
    <author>
      <name>Yonatan Belinkov</name>
    </author>
    <author>
      <name>David Bau</name>
    </author>
    <author>
      <name>Chris Wendler</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.06019v1</id>
    <title>Multi-Token Prediction via Self-Distillation</title>
    <updated>2026-02-05T18:54:48Z</updated>
    <link href="https://arxiv.org/abs/2602.06019v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.06019v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Existing techniques for accelerating language model inference, such as speculative decoding, require training auxiliary speculator models and building and deploying complex inference pipelines. We consider a new approach for converting a pretrained autoregressive language model from a slow single next token prediction model into a fast standalone multi-token prediction model using a simple online distillation objective. The final model retains the exact same implementation as the pretrained initial checkpoint and is deployable without the addition of any auxiliary verifier or other specialized inference code. On GSM8K, our method produces models that can decode more than $3\times$ faster on average at $&lt;5\%$ drop in accuracy relative to single token decoding performance.</summary>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-05T18:54:48Z</published>
    <arxiv:comment>8 pages and 5 figures in the main body</arxiv:comment>
    <arxiv:primary_category term="cs.CL"/>
    <author>
      <name>John Kirchenbauer</name>
    </author>
    <author>
      <name>Abhimanyu Hans</name>
    </author>
    <author>
      <name>Brian Bartoldson</name>
    </author>
    <author>
      <name>Micah Goldblum</name>
    </author>
    <author>
      <name>Ashwinee Panda</name>
    </author>
    <author>
      <name>Tom Goldstein</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.06014v1</id>
    <title>Optimism Stabilizes Thompson Sampling for Adaptive Inference</title>
    <updated>2026-02-05T18:52:54Z</updated>
    <link href="https://arxiv.org/abs/2602.06014v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.06014v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Thompson sampling (TS) is widely used for stochastic multi-armed bandits, yet its inferential properties under adaptive data collection are subtle. Classical asymptotic theory for sample means can fail because arm-specific sample sizes are random and coupled with the rewards through the action-selection rule. We study this phenomenon in the $K$-armed Gaussian bandit and identify \emph{optimism} as a key mechanism for restoring \emph{stability}, a sufficient condition for valid asymptotic inference requiring each arm's pull count to concentrate around a deterministic scale. First, we prove that variance-inflated TS \citep{halder2025stable} is stable for any $K \ge 2$, including the challenging regime where multiple arms are optimal. This resolves the open question raised by \citet{halder2025stable} through extending their results from the two-armed setting to the general $K$-armed setting. Second, we analyze an alternative optimistic modification that keeps the posterior variance unchanged but adds an explicit mean bonus to posterior mean, and establish the same stability conclusion. In summary, suitably implemented optimism stabilizes Thompson sampling and enables asymptotically valid inference in multi-armed bandits, while incurring only a mild additional regret cost.</summary>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-05T18:52:54Z</published>
    <arxiv:primary_category term="cs.LG"/>
    <author>
      <name>Shunxing Yan</name>
    </author>
    <author>
      <name>Han Zhong</name>
    </author>
  </entry>
</feed>
