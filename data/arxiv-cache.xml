<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-10-30T00:57:39Z -->
<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acausal%20inference%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:causal inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/SsRksLzRb0LuVhSmQ+N8WbAs+f8</id>
  <updated>2025-10-29T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">124857</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">10</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2510.24717v1</id>
    <updated>2025-10-28T17:59:57Z</updated>
    <published>2025-10-28T17:59:57Z</published>
    <title>Uniform Discrete Diffusion with Metric Path for Video Generation</title>
    <summary>  Continuous-space video generation has advanced rapidly, while discrete
approaches lag behind due to error accumulation and long-context inconsistency.
In this work, we revisit discrete generative modeling and present Uniform
discRete diffuSion with metric pAth (URSA), a simple yet powerful framework
that bridges the gap with continuous approaches for the scalable video
generation. At its core, URSA formulates the video generation task as an
iterative global refinement of discrete spatiotemporal tokens. It integrates
two key designs: a Linearized Metric Path and a Resolution-dependent Timestep
Shifting mechanism. These designs enable URSA to scale efficiently to
high-resolution image synthesis and long-duration video generation, while
requiring significantly fewer inference steps. Additionally, we introduce an
asynchronous temporal fine-tuning strategy that unifies versatile tasks within
a single model, including interpolation and image-to-video generation.
Extensive experiments on challenging video and image generation benchmarks
demonstrate that URSA consistently outperforms existing discrete methods and
achieves performance comparable to state-of-the-art continuous diffusion
methods. Code and models are available at https://github.com/baaivision/URSA
</summary>
    <author>
      <name>Haoge Deng</name>
    </author>
    <author>
      <name>Ting Pan</name>
    </author>
    <author>
      <name>Fan Zhang</name>
    </author>
    <author>
      <name>Yang Liu</name>
    </author>
    <author>
      <name>Zhuoyan Luo</name>
    </author>
    <author>
      <name>Yufeng Cui</name>
    </author>
    <author>
      <name>Wenxuan Wang</name>
    </author>
    <author>
      <name>Chunhua Shen</name>
    </author>
    <author>
      <name>Shiguang Shan</name>
    </author>
    <author>
      <name>Zhaoxiang Zhang</name>
    </author>
    <author>
      <name>Xinlong Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 10 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2510.24717v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.24717v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.24714v1</id>
    <updated>2025-10-28T17:59:15Z</updated>
    <published>2025-10-28T17:59:15Z</published>
    <title>Machine-Learning-Assisted Comparison of Regression Functions</title>
    <summary>  We revisit the classical problem of comparing regression functions, a
fundamental question in statistical inference with broad relevance to modern
applications such as data integration, transfer learning, and causal inference.
Existing approaches typically rely on smoothing techniques and are thus
hindered by the curse of dimensionality. We propose a generalized notion of
kernel-based conditional mean dependence that provides a new characterization
of the null hypothesis of equal regression functions. Building on this
reformulation, we develop two novel tests that leverage modern machine learning
methods for flexible estimation. We establish the asymptotic properties of the
test statistics, which hold under both fixed- and high-dimensional regimes.
Unlike existing methods that often require restrictive distributional
assumptions, our framework only imposes mild moment conditions. The efficacy of
the proposed tests is demonstrated through extensive numerical studies.
</summary>
    <author>
      <name>Jian Yan</name>
    </author>
    <author>
      <name>Zhuoxi Li</name>
    </author>
    <author>
      <name>Yang Ning</name>
    </author>
    <author>
      <name>Yong Chen</name>
    </author>
    <link href="http://arxiv.org/abs/2510.24714v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.24714v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="econ.EM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.24670v2</id>
    <updated>2025-10-29T14:41:45Z</updated>
    <published>2025-10-28T17:36:51Z</published>
    <title>Pearl: A Foundation Model for Placing Every Atom in the Right Location</title>
    <summary>  Accurately predicting the three-dimensional structures of protein-ligand
complexes remains a fundamental challenge in computational drug discovery that
limits the pace and success of therapeutic design. Deep learning methods have
recently shown strong potential as structural prediction tools, achieving
promising accuracy across diverse biomolecular systems. However, their
performance and utility are constrained by scarce experimental data,
inefficient architectures, physically invalid poses, and the limited ability to
exploit auxiliary information available at inference. To address these issues,
we introduce Pearl (Placing Every Atom in the Right Location), a foundation
model for protein-ligand cofolding at scale. Pearl addresses these challenges
with three key innovations: (1) training recipes that include large-scale
synthetic data to overcome data scarcity; (2) architectures that incorporate an
SO(3)-equivariant diffusion module to inherently respect 3D rotational
symmetries, improving generalization and sample efficiency, and (3)
controllable inference, including a generalized multi-chain templating system
supporting both protein and non-polymeric components as well as dual
unconditional/conditional modes. Pearl establishes a new state-of-the-art
performance in protein-ligand cofolding. On the key metric of generating
accurate (RMSD &lt; 2 \r{A}) and physically valid poses, Pearl surpasses AlphaFold
3 and other open source baselines on the public Runs N' Poses and PoseBusters
benchmarks, delivering 14.5% and 14.2% improvements, respectively, over the
next best model. In the pocket-conditional cofolding regime, Pearl delivers
$3.6\times$ improvement on a proprietary set of challenging, real-world drug
targets at the more rigorous RMSD &lt; 1 \r{A} threshold. Finally, we demonstrate
that model performance correlates directly with synthetic dataset size used in
training.
</summary>
    <author>
      <name> Genesis Research Team</name>
    </author>
    <author>
      <name>Alejandro Dobles</name>
    </author>
    <author>
      <name>Nina Jovic</name>
    </author>
    <author>
      <name>Kenneth Leidal</name>
    </author>
    <author>
      <name>Pranav Murugan</name>
    </author>
    <author>
      <name>David C. Williams</name>
    </author>
    <author>
      <name>Drausin Wulsin</name>
    </author>
    <author>
      <name>Nate Gruver</name>
    </author>
    <author>
      <name>Christina X. Ji</name>
    </author>
    <author>
      <name>Korrawat Pruegsanusak</name>
    </author>
    <author>
      <name>Gianluca Scarpellini</name>
    </author>
    <author>
      <name>Ansh Sharma</name>
    </author>
    <author>
      <name>Wojciech Swiderski</name>
    </author>
    <author>
      <name>Andrea Bootsma</name>
    </author>
    <author>
      <name>Richard Strong Bowen</name>
    </author>
    <author>
      <name>Charlotte Chen</name>
    </author>
    <author>
      <name>Jamin Chen</name>
    </author>
    <author>
      <name>Marc André Dämgen</name>
    </author>
    <author>
      <name>Benjamin DiFrancesco</name>
    </author>
    <author>
      <name>J. D. Fishman</name>
    </author>
    <author>
      <name>Alla Ivanova</name>
    </author>
    <author>
      <name>Zach Kagin</name>
    </author>
    <author>
      <name>David Li-Bland</name>
    </author>
    <author>
      <name>Zuli Liu</name>
    </author>
    <author>
      <name>Igor Morozov</name>
    </author>
    <author>
      <name>Jeffrey Ouyang-Zhang</name>
    </author>
    <author>
      <name>Frank C. Pickard IV</name>
    </author>
    <author>
      <name>Kushal S. Shah</name>
    </author>
    <author>
      <name>Ben Shor</name>
    </author>
    <author>
      <name>Gabriel Monteiro da Silva</name>
    </author>
    <author>
      <name>Roy Tal</name>
    </author>
    <author>
      <name>Maxx Tessmer</name>
    </author>
    <author>
      <name>Carl Tilbury</name>
    </author>
    <author>
      <name>Cyr Vetcher</name>
    </author>
    <author>
      <name>Daniel Zeng</name>
    </author>
    <author>
      <name>Maruan Al-Shedivat</name>
    </author>
    <author>
      <name>Aleksandra Faust</name>
    </author>
    <author>
      <name>Evan N. Feinberg</name>
    </author>
    <author>
      <name>Michael V. LeVine</name>
    </author>
    <author>
      <name>Matteus Pan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">technical report</arxiv:comment>
    <link href="http://arxiv.org/abs/2510.24670v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.24670v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.24639v1</id>
    <updated>2025-10-28T17:06:15Z</updated>
    <published>2025-10-28T17:06:15Z</published>
    <title>Causal Ordering for Structure Learning From Time Series</title>
    <summary>  Predicting causal structure from time series data is crucial for
understanding complex phenomena in physiology, brain connectivity, climate
dynamics, and socio-economic behaviour. Causal discovery in time series is
hindered by the combinatorial complexity of identifying true causal
relationships, especially as the number of variables and time points grow. A
common approach to simplify the task is the so-called ordering-based methods.
Traditional ordering methods inherently limit the representational capacity of
the resulting model. In this work, we fix this issue by leveraging multiple
valid causal orderings, instead of a single one as standard practice. We
propose DOTS (Diffusion Ordered Temporal Structure), using diffusion-based
causal discovery for temporal data. By integrating multiple orderings, DOTS
effectively recovers the transitive closure of the underlying directed acyclic
graph, mitigating spurious artifacts inherent in single-ordering approaches. We
formalise the problem under standard assumptions such as stationarity and the
additive noise model, and leverage score matching with diffusion processes to
enable efficient Hessian estimation. Extensive experiments validate the
approach. Empirical evaluations on synthetic and real-world datasets
demonstrate that DOTS outperforms state-of-the-art baselines, offering a
scalable and robust approach to temporal causal discovery. On synthetic
benchmarks ($d{=}\!3-\!6$ variables, $T{=}200\!-\!5{,}000$ samples), DOTS
improves mean window-graph $F1$ from $0.63$ (best baseline) to $0.81$. On the
CausalTime real-world benchmark ($d{=}20\!-\!36$), while baselines remain the
best on individual datasets, DOTS attains the highest average summary-graph
$F1$ while halving runtime relative to graph-optimisation methods. These
results establish DOTS as a scalable and accurate solution for temporal causal
discovery.
</summary>
    <author>
      <name>Pedro P. Sanchez</name>
    </author>
    <author>
      <name>Damian Machlanski</name>
    </author>
    <author>
      <name>Steven McDonagh</name>
    </author>
    <author>
      <name>Sotirios A. Tsaftaris</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">32 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2510.24639v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.24639v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.24637v1</id>
    <updated>2025-10-28T17:03:33Z</updated>
    <published>2025-10-28T17:03:33Z</published>
    <title>All in one timestep: Enhancing Sparsity and Energy efficiency in
  Multi-level Spiking Neural Networks</title>
    <summary>  Spiking Neural Networks (SNNs) are one of the most promising bio-inspired
neural networks models and have drawn increasing attention in recent years. The
event-driven communication mechanism of SNNs allows for sparse and
theoretically low-power operations on dedicated neuromorphic hardware. However,
the binary nature of instantaneous spikes also leads to considerable
information loss in SNNs, resulting in accuracy degradation. To address this
issue, we propose a multi-level spiking neuron model able to provide both
low-quantization error and minimal inference latency while approaching the
performance of full precision Artificial Neural Networks (ANNs). Experimental
results with popular network architectures and datasets, show that multi-level
spiking neurons provide better information compression, allowing therefore a
reduction in latency without performance loss. When compared to binary SNNs on
image classification scenarios, multi-level SNNs indeed allow reducing by 2 to
3 times the energy consumption depending on the number of quantization
intervals. On neuromorphic data, our approach allows us to drastically reduce
the inference latency to 1 timestep, which corresponds to a compression factor
of 10 compared to previously published results. At the architectural level, we
propose a new residual architecture that we call Sparse-ResNet. Through a
careful analysis of the spikes propagation in residual connections we highlight
a spike avalanche effect, that affects most spiking residual architectures.
Using our Sparse-ResNet architecture, we can provide state-of-the-art accuracy
results in image classification while reducing by more than 20% the network
activity compared to the previous spiking ResNets.
</summary>
    <author>
      <name>Andrea Castagnetti</name>
    </author>
    <author>
      <name>Alain Pegatoquet</name>
    </author>
    <author>
      <name>Benoît Miramond</name>
    </author>
    <link href="http://arxiv.org/abs/2510.24637v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.24637v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.24636v2</id>
    <updated>2025-10-29T16:06:18Z</updated>
    <published>2025-10-28T17:02:46Z</published>
    <title>OpenReward: Learning to Reward Long-form Agentic Tasks via Reinforcement
  Learning</title>
    <summary>  Reward models (RMs) have become essential for aligning large language models
(LLMs), serving as scalable proxies for human evaluation in both training and
inference. However, existing RMs struggle on knowledge-intensive and long-form
tasks, where evaluating correctness requires grounding beyond the model's
internal knowledge. This limitation hinders them from reliably discriminating
subtle quality differences, especially when external evidence is necessary. To
address this, we introduce OpenRM, a tool-augmented long-form reward model that
systematically judges open-ended responses by invoking external tools to gather
relevant evidence. We train OpenRM with Group Relative Policy Optimization
(GRPO) on over 27K synthesized pairwise examples generated through a
controllable data synthesis framework. The training objective jointly
supervises intermediate tool usage and final outcome accuracy, incentivizing
our reward model to learn effective evidence-based judgment strategies.
Extensive experiments on three newly-collected datasets and two widely-used
benchmarks demonstrate that OpenRM substantially outperforms existing reward
modeling approaches. As a further step, we integrate OpenRM into both
inference-time response selection and training-time data selection. This yields
consistent gains in downstream LLM alignment tasks, highlighting the potential
of tool-augmented reward models for scaling reliable long-form evaluation.
</summary>
    <author>
      <name>Ziyou Hu</name>
    </author>
    <author>
      <name>Zhengliang Shi</name>
    </author>
    <author>
      <name>Minghang Zhu</name>
    </author>
    <author>
      <name>Haitao Li</name>
    </author>
    <author>
      <name>Teng Sun</name>
    </author>
    <author>
      <name>Pengjie Ren</name>
    </author>
    <author>
      <name>Suzan Verberne</name>
    </author>
    <author>
      <name>Zhaochun Ren</name>
    </author>
    <link href="http://arxiv.org/abs/2510.24636v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.24636v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.24631v1</id>
    <updated>2025-10-28T16:59:42Z</updated>
    <published>2025-10-28T16:59:42Z</published>
    <title>Bridging Simulators with Conditional Optimal Transport</title>
    <summary>  We propose a new field-level emulator that bridges two simulators using
unpaired simulation datasets. Our method leverages a flow-based approach to
learn the likelihood transport from one simulator to the other. Since multiple
transport maps exist, we employ Conditional Optimal Transport Flow Matching
(COT-FM) to ensure that the transformation minimally distorts the underlying
structure of the data. We demonstrate the effectiveness of this approach by
bridging weak lensing simulators: a Lagrangian Perturbation Theory (LPT) to a
N-body Particle-Mesh (PM). We demonstrate that our emulator captures the full
correction between the simulators by showing that it enables full-field
inference to accurately recover the true posterior, validating its accuracy
beyond traditional summary statistics.
</summary>
    <author>
      <name>Justine Zeghal</name>
    </author>
    <author>
      <name>Benjamin Remy</name>
    </author>
    <author>
      <name>Yashar Hezaveh</name>
    </author>
    <author>
      <name>Francois Lanusse</name>
    </author>
    <author>
      <name>Laurence Perreault Levasseur</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at the 2025 Workshop on Machine Learning for Astrophysics,
  10 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2510.24631v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.24631v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.24605v1</id>
    <updated>2025-10-28T16:32:43Z</updated>
    <published>2025-10-28T16:32:43Z</published>
    <title>Diffusion LLM with Native Variable Generation Lengths: Let [EOS] Lead
  the Way</title>
    <summary>  Diffusion-based large language models (dLLMs) have exhibited substantial
potential for parallel text generation, which may enable more efficient
generation compared to autoregressive models. However, current dLLMs suffer
from fixed generation lengths, which indicates the generation lengths of dLLMs
have to be determined before decoding as a hyper-parameter, leading to issues
in efficiency and flexibility. To solve these problems, in this work, we
propose to train a diffusion LLM with native variable generation lengths,
abbreviated as dLLM-Var. Concretely, we aim to train a model to accurately
predict the [EOS] token in the generated text, which makes a dLLM be able to
natively infer in a block diffusion manner, while still maintaining the ability
of global bi-directional (full) attention and high parallelism. Experiments on
standard benchmarks demonstrate that our method achieves a 30.1x speedup over
traditional dLLM inference paradigms and a 2.4x speedup relative to
autoregressive models such as Qwen and Llama. Our method achieves higher
accuracy and faster inference, elevating dLLMs beyond mere academic novelty and
supporting their practical use in real-world applications. Codes and models
have been released.
</summary>
    <author>
      <name>Yicun Yang</name>
    </author>
    <author>
      <name>Cong Wang</name>
    </author>
    <author>
      <name>Shaobo Wang</name>
    </author>
    <author>
      <name>Zichen Wen</name>
    </author>
    <author>
      <name>Biqing Qi</name>
    </author>
    <author>
      <name>Hanlin Xu</name>
    </author>
    <author>
      <name>Linfeng Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/2510.24605v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.24605v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.24593v1</id>
    <updated>2025-10-28T16:22:55Z</updated>
    <published>2025-10-28T16:22:55Z</published>
    <title>Brownian motion on spaces of discrete regular curves</title>
    <summary>  We introduce and study Brownian motion on spaces of discrete regular curves
in Euclidean space equipped with discrete Sobolev-type metrics. It has been
established that these spaces of discrete regular curves are geodesically
complete if and only if the Sobolev-type metric is of order two or higher. By
relying on a general result by Grigor'yan and controlling the volume growth of
geodesic balls, we show that all spaces of discrete regular curves that are
geodesically complete are also stochastically complete, that is, the associated
Brownian motion exists for all times. This provides a rigorous footing for
performing data statistics, such as data inference and data imputation, on
these spaces. Our result is the first stochastic completeness result in shape
analysis that applies to the full shape space of interest. For illustrative
purposes, we include simulations for sample paths of Brownian motion on spaces
of discrete regular curves. For the space of triangles in the plane modulo
rotation, translation and scaling, we further provide heuristics which suggest
that this space remains stochastically complete even for Sobolev-type metrics
of order zero and one.
</summary>
    <author>
      <name>Karen Habermann</name>
    </author>
    <author>
      <name>Emmanuel Hartman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2510.24593v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.24593v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="58J65, 60J65, 62R30" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.24551v1</id>
    <updated>2025-10-28T15:47:44Z</updated>
    <published>2025-10-28T15:47:44Z</published>
    <title>Generative AI for Healthcare: Fundamentals, Challenges, and Perspectives</title>
    <summary>  Generative Artificial Intelligence (GenAI) is taking the world by storm. It
promises transformative opportunities for advancing and disrupting existing
practices, including healthcare. From large language models (LLMs) for clinical
note synthesis and conversational assistance to multimodal systems that
integrate medical imaging, electronic health records, and genomic data for
decision support, GenAI is transforming the practice of medicine and the
delivery of healthcare, such as diagnosis and personalized treatments, with
great potential in reducing the cognitive burden on clinicians, thereby
improving overall healthcare delivery. However, GenAI deployment in healthcare
requires an in-depth understanding of healthcare tasks and what can and cannot
be achieved. In this paper, we propose a data-centric paradigm in the design
and deployment of GenAI systems for healthcare. Specifically, we reposition the
data life cycle by making the medical data ecosystem as the foundational
substrate for generative healthcare systems. This ecosystem is designed to
sustainably support the integration, representation, and retrieval of diverse
medical data and knowledge. With effective and efficient data processing
pipelines, such as semantic vector search and contextual querying, it enables
GenAI-powered operations for upstream model components and downstream clinical
applications. Ultimately, it not only supplies foundation models with
high-quality, multimodal data for large-scale pretraining and domain-specific
fine-tuning, but also serves as a knowledge retrieval backend to support
task-specific inference via the agentic layer. The ecosystem enables the
deployment of GenAI for high-quality and effective healthcare delivery.
</summary>
    <author>
      <name>Gang Chen</name>
    </author>
    <author>
      <name>Changshuo Liu</name>
    </author>
    <author>
      <name>Gene Anne Ooi</name>
    </author>
    <author>
      <name>Marcus Tan</name>
    </author>
    <author>
      <name>Zhongle Xie</name>
    </author>
    <author>
      <name>Jianwei Yin</name>
    </author>
    <author>
      <name>James Wei Luen Yip</name>
    </author>
    <author>
      <name>Wenqiao Zhang</name>
    </author>
    <author>
      <name>Jiaqi Zhu</name>
    </author>
    <author>
      <name>Beng Chin Ooi</name>
    </author>
    <link href="http://arxiv.org/abs/2510.24551v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.24551v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
