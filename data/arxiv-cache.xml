<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-10-23T00:54:51Z -->
<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acausal%20inference%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:causal inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/SsRksLzRb0LuVhSmQ+N8WbAs+f8</id>
  <updated>2025-10-22T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">124292</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">10</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2510.18873v1</id>
    <updated>2025-10-21T17:59:36Z</updated>
    <published>2025-10-21T17:59:36Z</published>
    <title>DSI-Bench: A Benchmark for Dynamic Spatial Intelligence</title>
    <summary>  Reasoning about dynamic spatial relationships is essential, as both observers
and objects often move simultaneously. Although vision-language models (VLMs)
and visual expertise models excel in 2D tasks and static scenarios, their
ability to fully understand dynamic 3D scenarios remains limited. We introduce
Dynamic Spatial Intelligence and propose DSI-Bench, a benchmark with nearly
1,000 dynamic videos and over 1,700 manually annotated questions covering nine
decoupled motion patterns of observers and objects. Spatially and temporally
symmetric designs reduce biases and enable systematic evaluation of models'
reasoning about self-motion and object motion. Our evaluation of 14 VLMs and
expert models reveals key limitations: models often conflate observer and
object motion, exhibit semantic biases, and fail to accurately infer relative
relationships in dynamic scenarios. Our DSI-Bench provides valuable findings
and insights about the future development of general and expertise models with
dynamic spatial intelligence.
</summary>
    <author>
      <name>Ziang Zhang</name>
    </author>
    <author>
      <name>Zehan Wang</name>
    </author>
    <author>
      <name>Guanghao Zhang</name>
    </author>
    <author>
      <name>Weilong Dai</name>
    </author>
    <author>
      <name>Yan Xia</name>
    </author>
    <author>
      <name>Ziang Yan</name>
    </author>
    <author>
      <name>Minjie Hong</name>
    </author>
    <author>
      <name>Zhou Zhao</name>
    </author>
    <link href="http://arxiv.org/abs/2510.18873v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.18873v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.18871v1</id>
    <updated>2025-10-21T17:59:05Z</updated>
    <published>2025-10-21T17:59:05Z</published>
    <title>How Do LLMs Use Their Depth?</title>
    <summary>  Growing evidence suggests that large language models do not use their depth
uniformly, yet we still lack a fine-grained understanding of their layer-wise
prediction dynamics. In this paper, we trace the intermediate representations
of several open-weight models during inference and reveal a structured and
nuanced use of depth. Specifically, we propose a "Guess-then-Refine" framework
that explains how LLMs internally structure their computations to make
predictions. We first show that the top-ranked predictions in early LLM layers
are composed primarily of high-frequency tokens, which act as statistical
guesses proposed by the model early on due to the lack of appropriate
contextual information. As contextual information develops deeper into the
model, these initial guesses get refined into contextually appropriate tokens.
Even high-frequency token predictions from early layers get refined &gt;70% of the
time, indicating that correct token prediction is not "one-and-done". We then
go beyond frequency-based prediction to examine the dynamic usage of layer
depth across three case studies. (i) Part-of-speech analysis shows that
function words are, on average, the earliest to be predicted correctly. (ii)
Fact recall task analysis shows that, in a multi-token answer, the first token
requires more computational depth than the rest. (iii) Multiple-choice task
analysis shows that the model identifies the format of the response within the
first half of the layers, but finalizes its response only toward the end.
Together, our results provide a detailed view of depth usage in LLMs, shedding
light on the layer-by-layer computations that underlie successful predictions
and providing insights for future works to improve computational efficiency in
transformer-based models.
</summary>
    <author>
      <name>Akshat Gupta</name>
    </author>
    <author>
      <name>Jay Yeung</name>
    </author>
    <author>
      <name>Gopala Anumanchipalli</name>
    </author>
    <author>
      <name>Anna Ivanova</name>
    </author>
    <link href="http://arxiv.org/abs/2510.18871v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.18871v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.18870v1</id>
    <updated>2025-10-21T17:59:02Z</updated>
    <published>2025-10-21T17:59:02Z</published>
    <title>Triangle Multiplication Is All You Need For Biomolecular Structure
  Representations</title>
    <summary>  AlphaFold has transformed protein structure prediction, but emerging
applications such as virtual ligand screening, proteome-wide folding, and de
novo binder design demand predictions at a massive scale, where runtime and
memory costs become prohibitive. A major bottleneck lies in the Pairformer
backbone of AlphaFold3-style models, which relies on computationally expensive
triangular primitives-especially triangle attention-for pairwise reasoning. We
introduce Pairmixer, a streamlined alternative that eliminates triangle
attention while preserving higher-order geometric reasoning capabilities that
are critical for structure prediction. Pairmixer substantially improves
computational efficiency, matching state-of-the-art structure predictors across
folding and docking benchmarks, delivering up to 4x faster inference on long
sequences while reducing training cost by 34%. Its efficiency alleviates the
computational burden of downstream applications such as modeling large protein
complexes, high-throughput ligand and binder screening, and hallucination-based
design. Within BoltzDesign, for example, Pairmixer delivers over 2x faster
sampling and scales to sequences ~30% longer than the memory limits of
Pairformer.
</summary>
    <author>
      <name>Jeffrey Ouyang-Zhang</name>
    </author>
    <author>
      <name>Pranav Murugan</name>
    </author>
    <author>
      <name>Daniel J. Diaz</name>
    </author>
    <author>
      <name>Gianluca Scarpellini</name>
    </author>
    <author>
      <name>Richard Strong Bowen</name>
    </author>
    <author>
      <name>Nate Gruver</name>
    </author>
    <author>
      <name>Adam Klivans</name>
    </author>
    <author>
      <name>Philipp Krähenbühl</name>
    </author>
    <author>
      <name>Aleksandra Faust</name>
    </author>
    <author>
      <name>Maruan Al-Shedivat</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Preprint</arxiv:comment>
    <link href="http://arxiv.org/abs/2510.18870v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.18870v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.18867v1</id>
    <updated>2025-10-21T17:58:21Z</updated>
    <published>2025-10-21T17:58:21Z</published>
    <title>Reexamining Evidence of a Pair-Instability Mass Gap in the Binary Black
  Hole Population</title>
    <summary>  The fourth gravitational wave transient catalog~(GWTC-4) has enabled
empirical probes of the theorized pair-instability gap in the higher end of the
binary black hole~(BBH) mass-spectrum. In this letter, using flexibly
parametrized models, we show that at present there is no evidence of a sharp
drop-off in the spectrum of black hole masses near $~40-50M_{\odot}$. We
simultaneously characterize the transition in the distribution of BBH
mass-ratios, effective aligned and effective precessing spins using our
flexible models. From the transitions in our inferred spin and mass-ratio
distributions, we find that the high-mass broad-spin sub-population has a
significant fraction~($52^{+18}_{-23}\%$) of systems with mass ratios in the
range $0.6-1$. This suggests that alternatives to the hypothesis of 2G+1G
hierarchical systems dominating BBH formation above $\sim 40-50 M_{\odot}$ are
more consistent with the GWTC-4 detection sample. By comparing with the
predictions of star cluster simulations, we further show that contributions
from (2G+2G) systems are not abundant enough to alleviate this discrepancy. We
also demonstrate the effects of strong model assumptions on this inference,
which can lead to biased astrophysical interpretation from restricted priors.
We note that our results do not exclude that a high-mass gap may be identified
as our sample size increases. We constrain the lower bound on the location of a
possible PISN cutoff still allowed within measurement uncertainties to be
$(57^{+17}_{-10}M_{\odot})$ and discuss its implications on the S factor of
$^{12}\mathrm{C}(\alpha, \gamma)^{16}O$ at 300 kev.
</summary>
    <author>
      <name>Anarya Ray</name>
    </author>
    <author>
      <name>Vicky Kalogera</name>
    </author>
    <link href="http://arxiv.org/abs/2510.18867v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.18867v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.HE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.HE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="gr-qc" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.18866v1</id>
    <updated>2025-10-21T17:58:17Z</updated>
    <published>2025-10-21T17:58:17Z</published>
    <title>LightMem: Lightweight and Efficient Memory-Augmented Generation</title>
    <summary>  Despite their remarkable capabilities, Large Language Models (LLMs) struggle
to effectively leverage historical interaction information in dynamic and
complex environments. Memory systems enable LLMs to move beyond stateless
interactions by introducing persistent information storage, retrieval, and
utilization mechanisms. However, existing memory systems often introduce
substantial time and computational overhead. To this end, we introduce a new
memory system called LightMem, which strikes a balance between the performance
and efficiency of memory systems. Inspired by the Atkinson-Shiffrin model of
human memory, LightMem organizes memory into three complementary stages. First,
cognition-inspired sensory memory rapidly filters irrelevant information
through lightweight compression and groups information according to their
topics. Next, topic-aware short-term memory consolidates these topic-based
groups, organizing and summarizing content for more structured access. Finally,
long-term memory with sleep-time update employs an offline procedure that
decouples consolidation from online inference. Experiments on LongMemEval with
GPT and Qwen backbones show that LightMem outperforms strong baselines in
accuracy (up to 10.9% gains) while reducing token usage by up to 117x, API
calls by up to 159x, and runtime by over 12x. The code is available at
https://github.com/zjunlp/LightMem.
</summary>
    <author>
      <name>Jizhan Fang</name>
    </author>
    <author>
      <name>Xinle Deng</name>
    </author>
    <author>
      <name>Haoming Xu</name>
    </author>
    <author>
      <name>Ziyan Jiang</name>
    </author>
    <author>
      <name>Yuqi Tang</name>
    </author>
    <author>
      <name>Ziwen Xu</name>
    </author>
    <author>
      <name>Shumin Deng</name>
    </author>
    <author>
      <name>Yunzhi Yao</name>
    </author>
    <author>
      <name>Mengru Wang</name>
    </author>
    <author>
      <name>Shuofei Qiao</name>
    </author>
    <author>
      <name>Huajun Chen</name>
    </author>
    <author>
      <name>Ningyu Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Work in progress</arxiv:comment>
    <link href="http://arxiv.org/abs/2510.18866v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.18866v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.18863v1</id>
    <updated>2025-10-21T17:55:39Z</updated>
    <published>2025-10-21T17:55:39Z</published>
    <title>EffiReasonTrans: RL-Optimized Reasoning for Code Translation</title>
    <summary>  Code translation is a crucial task in software development and maintenance.
While recent advancements in large language models (LLMs) have improved
automated code translation accuracy, these gains often come at the cost of
increased inference latency, hindering real-world development workflows that
involve human-in-the-loop inspection. To address this trade-off, we propose
EffiReasonTrans, a training framework designed to improve translation accuracy
while balancing inference latency. We first construct a high-quality
reasoning-augmented dataset by prompting a stronger language model,
DeepSeek-R1, to generate intermediate reasoning and target translations. Each
(source code, reasoning, target code) triplet undergoes automated syntax and
functionality checks to ensure reliability. Based on this dataset, we employ a
two-stage training strategy: supervised fine-tuning on reasoning-augmented
samples, followed by reinforcement learning to further enhance accuracy and
balance inference latency. We evaluate EffiReasonTrans on six translation
pairs. Experimental results show that it consistently improves translation
accuracy (up to +49.2% CA and +27.8% CodeBLEU compared to the base model) while
reducing the number of generated tokens (up to -19.3%) and lowering inference
latency in most cases (up to -29.0%). Ablation studies further confirm the
complementary benefits of the two-stage training framework. Additionally,
EffiReasonTrans demonstrates improved translation accuracy when integrated into
agent-based frameworks. Our code and data are available at
https://github.com/DeepSoftwareAnalytics/EffiReasonTrans.
</summary>
    <author>
      <name>Yanlin Wang</name>
    </author>
    <author>
      <name>Rongyi Ou</name>
    </author>
    <author>
      <name>Yanli Wang</name>
    </author>
    <author>
      <name>Mingwei Liu</name>
    </author>
    <author>
      <name>Jiachi Chen</name>
    </author>
    <author>
      <name>Ensheng Shi</name>
    </author>
    <author>
      <name>Xilin Liu</name>
    </author>
    <author>
      <name>Yuchi Ma</name>
    </author>
    <author>
      <name>Zibin Zheng</name>
    </author>
    <link href="http://arxiv.org/abs/2510.18863v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.18863v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.18855v1</id>
    <updated>2025-10-21T17:46:14Z</updated>
    <published>2025-10-21T17:46:14Z</published>
    <title>Every Step Evolves: Scaling Reinforcement Learning for Trillion-Scale
  Thinking Model</title>
    <summary>  We present Ring-1T, the first open-source, state-of-the-art thinking model
with a trillion-scale parameter. It features 1 trillion total parameters and
activates approximately 50 billion per token. Training such models at a
trillion-parameter scale introduces unprecedented challenges, including
train-inference misalignment, inefficiencies in rollout processing, and
bottlenecks in the RL system. To address these, we pioneer three interconnected
innovations: (1) IcePop stabilizes RL training via token-level discrepancy
masking and clipping, resolving instability from training-inference mismatches;
(2) C3PO++ improves resource utilization for long rollouts under a token budget
by dynamically partitioning them, thereby obtaining high time efficiency; and
(3) ASystem, a high-performance RL framework designed to overcome the systemic
bottlenecks that impede trillion-parameter model training. Ring-1T delivers
breakthrough results across critical benchmarks: 93.4 on AIME-2025, 86.72 on
HMMT-2025, 2088 on CodeForces, and 55.94 on ARC-AGI-v1. Notably, it attains a
silver medal-level result on the IMO-2025, underscoring its exceptional
reasoning capabilities. By releasing the complete 1T parameter MoE model to the
community, we provide the research community with direct access to cutting-edge
reasoning capabilities. This contribution marks a significant milestone in
democratizing large-scale reasoning intelligence and establishes a new baseline
for open-source model performance.
</summary>
    <author>
      <name> Ling Team</name>
    </author>
    <author>
      <name>Anqi Shen</name>
    </author>
    <author>
      <name>Baihui Li</name>
    </author>
    <author>
      <name>Bin Hu</name>
    </author>
    <author>
      <name>Bin Jing</name>
    </author>
    <author>
      <name>Cai Chen</name>
    </author>
    <author>
      <name>Chao Huang</name>
    </author>
    <author>
      <name>Chao Zhang</name>
    </author>
    <author>
      <name>Chaokun Yang</name>
    </author>
    <author>
      <name>Cheng Lin</name>
    </author>
    <author>
      <name>Chengyao Wen</name>
    </author>
    <author>
      <name>Congqi Li</name>
    </author>
    <author>
      <name>Deng Zhao</name>
    </author>
    <author>
      <name>Dingbo Yuan</name>
    </author>
    <author>
      <name>Donghai You</name>
    </author>
    <author>
      <name>Fagui Mao</name>
    </author>
    <author>
      <name>Fanzhuang Meng</name>
    </author>
    <author>
      <name>Feng Xu</name>
    </author>
    <author>
      <name>Guojie Li</name>
    </author>
    <author>
      <name>Guowei Wang</name>
    </author>
    <author>
      <name>Hao Dai</name>
    </author>
    <author>
      <name>Haonan Zheng</name>
    </author>
    <author>
      <name>Hong Liu</name>
    </author>
    <author>
      <name>Jia Guo</name>
    </author>
    <author>
      <name>Jiaming Liu</name>
    </author>
    <author>
      <name>Jian Liu</name>
    </author>
    <author>
      <name>Jianhao Fu</name>
    </author>
    <author>
      <name>Jiannan Shi</name>
    </author>
    <author>
      <name>Jianwen Wang</name>
    </author>
    <author>
      <name>Jianxin Lai</name>
    </author>
    <author>
      <name>Jin Yang</name>
    </author>
    <author>
      <name>Jun Mei</name>
    </author>
    <author>
      <name>Jun Zhou</name>
    </author>
    <author>
      <name>Junbo Zhao</name>
    </author>
    <author>
      <name>Junping Zhao</name>
    </author>
    <author>
      <name>Kuan Xu</name>
    </author>
    <author>
      <name>Le Su</name>
    </author>
    <author>
      <name>Lei Chen</name>
    </author>
    <author>
      <name>Li Tang</name>
    </author>
    <author>
      <name>Liang Jiang</name>
    </author>
    <author>
      <name>Liangcheng Fu</name>
    </author>
    <author>
      <name>Lianhao Xu</name>
    </author>
    <author>
      <name>Linfeng Shi</name>
    </author>
    <author>
      <name>Lisha Liao</name>
    </author>
    <author>
      <name>Longfei Zheng</name>
    </author>
    <author>
      <name>Meng Li</name>
    </author>
    <author>
      <name>Mingchun Chen</name>
    </author>
    <author>
      <name>Qi Zuo</name>
    </author>
    <author>
      <name>Qiang Cheng</name>
    </author>
    <author>
      <name>Qianggang Cao</name>
    </author>
    <author>
      <name>Qitao Shi</name>
    </author>
    <author>
      <name>Quanrui Guo</name>
    </author>
    <author>
      <name>Senlin Zhu</name>
    </author>
    <author>
      <name>Shaofei Wang</name>
    </author>
    <author>
      <name>Shaomian Zheng</name>
    </author>
    <author>
      <name>Shuaicheng Li</name>
    </author>
    <author>
      <name>Shuwei Gu</name>
    </author>
    <author>
      <name>Siba Chen</name>
    </author>
    <author>
      <name>Tao Wu</name>
    </author>
    <author>
      <name>Tao Zhang</name>
    </author>
    <author>
      <name>Tianyu Zhang</name>
    </author>
    <author>
      <name>Tianyu Zhou</name>
    </author>
    <author>
      <name>Tiwei Bie</name>
    </author>
    <author>
      <name>Tongkai Yang</name>
    </author>
    <author>
      <name>Wang Hong</name>
    </author>
    <author>
      <name>Wang Ren</name>
    </author>
    <author>
      <name>Weihua Chen</name>
    </author>
    <author>
      <name>Wenbo Yu</name>
    </author>
    <author>
      <name>Wengang Zheng</name>
    </author>
    <author>
      <name>Xiangchun Wang</name>
    </author>
    <author>
      <name>Xiaodong Yan</name>
    </author>
    <author>
      <name>Xiaopei Wan</name>
    </author>
    <author>
      <name>Xin Zhao</name>
    </author>
    <author>
      <name>Xinyu Kong</name>
    </author>
    <author>
      <name>Xinyu Tang</name>
    </author>
    <author>
      <name>Xudong Han</name>
    </author>
    <author>
      <name>Xudong Wang</name>
    </author>
    <author>
      <name>Xuemin Yang</name>
    </author>
    <author>
      <name>Xueyu Hu</name>
    </author>
    <author>
      <name>Yalin Zhang</name>
    </author>
    <author>
      <name>Yan Sun</name>
    </author>
    <author>
      <name>Yicheng Shan</name>
    </author>
    <author>
      <name>Yilong Wang</name>
    </author>
    <author>
      <name>Yingying Xu</name>
    </author>
    <author>
      <name>Yongkang Liu</name>
    </author>
    <author>
      <name>Yongzhen Guo</name>
    </author>
    <author>
      <name>Yuanyuan Wang</name>
    </author>
    <author>
      <name>Yuchen Yan</name>
    </author>
    <author>
      <name>Yuefan Wang</name>
    </author>
    <author>
      <name>Yuhong Guo</name>
    </author>
    <author>
      <name>Zehuan Li</name>
    </author>
    <author>
      <name>Zhankai Xu</name>
    </author>
    <author>
      <name>Zhe Li</name>
    </author>
    <author>
      <name>Zhenduo Zhang</name>
    </author>
    <author>
      <name>Zhengke Gui</name>
    </author>
    <author>
      <name>Zhenxuan Pan</name>
    </author>
    <author>
      <name>Zhenyu Huang</name>
    </author>
    <author>
      <name>Zhenzhong Lan</name>
    </author>
    <author>
      <name>Zhiqiang Ding</name>
    </author>
    <author>
      <name>Zhiqiang Zhang</name>
    </author>
    <author>
      <name>Zhixun Li</name>
    </author>
    <author>
      <name>Zhizhen Liu</name>
    </author>
    <author>
      <name>Zihao Wang</name>
    </author>
    <author>
      <name>Zujie Wen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Technical Report</arxiv:comment>
    <link href="http://arxiv.org/abs/2510.18855v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.18855v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.18854v1</id>
    <updated>2025-10-21T17:45:13Z</updated>
    <published>2025-10-21T17:45:13Z</published>
    <title>AT2025ulz and S250818k: zooming in with the Hubble Space Telescope</title>
    <summary>  AT2025ulz is an optical/near-infrared transient discovered during follow-up
of the candidate gravitational wave (GW) event S250818k. Its young age
($\lesssim$1 d), rapid decline and strong color evolution over the first 48 hr
classify it as a potential kilonova candidate. In this work, we present the
results of our observing campaign, carried out with the Gran Telescopio
Canarias (GTC) and the Hubble Space Telescope (HST). Although the early time
evolution of AT2025ulz resembles some aspects of a kilonova, its rapid onset
($\sim$3 hr after the GW trigger) and luminosity (a factor of $\sim5$ brighter
than AT2017gfo in $g$-band) are difficult to reproduce. Only a small subset of
our kilonova models matches its multi-color light curve, and the inferred
ejecta mass is uncomfortably large given the low chirp mass ($\lesssim\!0.87\!$
M$_{\odot}$) of the GW candidate. HST observations place the transient within a
nearby ($z=0.08489$) spiral galaxy with on-going star-formation and measure a
color ($F336W-F160W\!\approx\!1.4$ mag) that is too blue to match with a
kilonova. Our data support the classification of AT2025ulz as a supernova,
initially undergoing a shock-cooling phase and later entering its photospheric
phase, and spectroscopically identified via its broad absorption features.
</summary>
    <author>
      <name>Yu-Han Yang</name>
    </author>
    <author>
      <name>Eleonora Troja</name>
    </author>
    <author>
      <name>Marko Ristić</name>
    </author>
    <author>
      <name>Muskan Yadav</name>
    </author>
    <author>
      <name>Massine El Kabir</name>
    </author>
    <author>
      <name>Rubén Sánchez-Ramírez</name>
    </author>
    <author>
      <name>Rosa L. Becerra</name>
    </author>
    <author>
      <name>Chris L. Fryer</name>
    </author>
    <author>
      <name>Brendan O'Connor</name>
    </author>
    <author>
      <name>Simone Dichiara</name>
    </author>
    <author>
      <name>Alberto J. Castro-Tirado</name>
    </author>
    <author>
      <name>Camila Angulo-Valdez</name>
    </author>
    <author>
      <name>Josefa Becerra González</name>
    </author>
    <author>
      <name>José A. Font</name>
    </author>
    <author>
      <name>Ori Fox</name>
    </author>
    <author>
      <name>Lei Hu</name>
    </author>
    <author>
      <name>Youdong Hu</name>
    </author>
    <author>
      <name>William H. Lee</name>
    </author>
    <author>
      <name>Margarita Pereyra</name>
    </author>
    <author>
      <name>Alicia M. Sintes</name>
    </author>
    <author>
      <name>Alan M. Watson</name>
    </author>
    <author>
      <name>López Mendoza K. Océlotl C</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 5 figures, 2 tables. Submitted to ApJL</arxiv:comment>
    <link href="http://arxiv.org/abs/2510.18854v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.18854v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.HE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.HE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.18843v1</id>
    <updated>2025-10-21T17:35:33Z</updated>
    <published>2025-10-21T17:35:33Z</published>
    <title>Inference on Local Variable Importance Measures for Heterogeneous
  Treatment Effects</title>
    <summary>  We provide an inferential framework to assess variable importance for
heterogeneous treatment effects. This assessment is especially useful in
high-risk domains such as medicine, where decision makers hesitate to rely on
black-box treatment recommendation algorithms. The variable importance measures
we consider are local in that they may differ across individuals, while the
inference is global in that it tests whether a given variable is important for
any individual. Our approach builds on recent developments in semiparametric
theory for function-valued parameters, and is valid even when statistical
machine learning algorithms are employed to quantify treatment effect
heterogeneity. We demonstrate the applicability of our method to infectious
disease prevention strategies.
</summary>
    <author>
      <name>Pawel Morzywolek</name>
    </author>
    <author>
      <name>Peter B. Gilbert</name>
    </author>
    <author>
      <name>Alex Luedtke</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">40 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2510.18843v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.18843v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.18841v1</id>
    <updated>2025-10-21T17:35:12Z</updated>
    <published>2025-10-21T17:35:12Z</published>
    <title>A Hybrid Enumeration Framework for Optimal Counterfactual Generation in
  Post-Acute COVID-19 Heart Failure</title>
    <summary>  Counterfactual inference provides a mathematical framework for reasoning
about hypothetical outcomes under alternative interventions, bridging causal
reasoning and predictive modeling. We present a counterfactual inference
framework for individualized risk estimation and intervention analysis,
illustrated through a clinical application to post-acute sequelae of COVID-19
(PASC) among patients with pre-existing heart failure (HF). Using longitudinal
diagnosis, laboratory, and medication data from a large health-system cohort,
we integrate regularized predictive modeling with counterfactual search to
identify actionable pathways to PASC-related HF hospital admissions. The
framework combines exact enumeration with optimization-based methods, including
the Nearest Instance Counterfactual Explanations (NICE) and Multi-Objective
Counterfactuals (MOC) algorithms, to efficiently explore high-dimensional
intervention spaces. Applied to more than 2700 individuals with confirmed
SARS-CoV-2 infection and prior HF, the model achieved strong discriminative
performance (AUROC: 0.88, 95% CI: 0.84-0.91) and generated interpretable,
patient-specific counterfactuals that quantify how modifying comorbidity
patterns or treatment factors could alter predicted outcomes. This work
demonstrates how counterfactual reasoning can be formalized as an optimization
problem over predictive functions, offering a rigorous, interpretable, and
computationally efficient approach to personalized inference in complex
biomedical systems.
</summary>
    <author>
      <name>Jingya Cheng</name>
    </author>
    <author>
      <name>Alaleh Azhir</name>
    </author>
    <author>
      <name>Jiazi Tian</name>
    </author>
    <author>
      <name>Hossein Estiri</name>
    </author>
    <link href="http://arxiv.org/abs/2510.18841v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.18841v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
