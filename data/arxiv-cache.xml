<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2026-01-28T01:02:55Z -->
<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/" xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns="http://www.w3.org/2005/Atom">
  <id>https://arxiv.org/api/p6EyKyP4fMY/66n9Ev8E79F7KlI</id>
  <title>arXiv Query: search_query=all:causal OR all:inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <updated>2026-01-28T01:02:56Z</updated>
  <link href="https://arxiv.org/api/query?search_query=all:causal+OR+all:inference&amp;start=0&amp;max_results=10&amp;id_list=" type="application/atom+xml"/>
  <opensearch:itemsPerPage>10</opensearch:itemsPerPage>
  <opensearch:totalResults>131778</opensearch:totalResults>
  <opensearch:startIndex>0</opensearch:startIndex>
  <entry>
    <id>http://arxiv.org/abs/2601.18795v1</id>
    <title>Reuse your FLOPs: Scaling RL on Hard Problems by Conditioning on Very Off-Policy Prefixes</title>
    <updated>2026-01-26T18:57:00Z</updated>
    <link href="https://arxiv.org/abs/2601.18795v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.18795v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Typical reinforcement learning (RL) methods for LLM reasoning waste compute on hard problems, where correct on-policy traces are rare, policy gradients vanish, and learning stalls. To bootstrap more efficient RL, we consider reusing old sampling FLOPs (from prior inference or RL training) in the form of off-policy traces. Standard off-policy methods supervise against off-policy data, causing instabilities during RL optimization. We introduce PrefixRL, where we condition on the prefix of successful off-policy traces and run on-policy RL to complete them, side-stepping off-policy instabilities. PrefixRL boosts the learning signal on hard problems by modulating the difficulty of the problem through the off-policy prefix length. We prove that the PrefixRL objective is not only consistent with the standard RL objective but also more sample efficient. Empirically, we discover back-generalization: training only on prefixed problems generalizes to out-of-distribution unprefixed performance, with learned strategies often differing from those in the prefix. In our experiments, we source the off-policy traces by rejection sampling with the base model, creating a self-improvement loop. On hard reasoning problems, PrefixRL reaches the same training reward 2x faster than the strongest baseline (SFT on off-policy data then RL), even after accounting for the compute spent on the initial rejection sampling, and increases the final reward by 3x. The gains transfer to held-out benchmarks, and PrefixRL is still effective when off-policy traces are derived from a different model family, validating its flexibility in practical settings.</summary>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-26T18:57:00Z</published>
    <arxiv:primary_category term="cs.LG"/>
    <author>
      <name>Amrith Setlur</name>
    </author>
    <author>
      <name>Zijian Wang</name>
    </author>
    <author>
      <name>Andrew Cohen</name>
    </author>
    <author>
      <name>Paria Rashidinejad</name>
    </author>
    <author>
      <name>Sang Michael Xie</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.18787v1</id>
    <title>A Novel Lensed Point Source Modeling Pipeline using GIGA-Lens with Application to SN Zwicky and SN iPTF16geu</title>
    <updated>2026-01-26T18:52:04Z</updated>
    <link href="https://arxiv.org/abs/2601.18787v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.18787v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>We introduce a novel modeling pipeline for strongly lensed point sources, using the GIGA-Lens framework, running on four A100 GPUs via the JAX platform. Using simulations, we demonstrate accurate and precise recovery of image positions, fluxes, and time delays, together with inference of complex lens mass distributions -- including the mass density slope, $γ$ -- from images of lensed point sources alone. We further show that we can achieve statistical uncertainty of $\sim 3.6\%$ ($\sim 2.5\, \mathrm{km\, s^{-1}/Mpc}$) on $H_0$ from a single system, with full forward modeling, i.e., simultaneous inference of all lens model parameters together with $H_0$. We apply our pipeline to two well-studied lensed SNe Ia, Zwicky and iPTF16geu. For SN iPTF16geu, unlike previous modeling efforts, we model only the images of the lensed point source (the SN) and do not use the lensed images of the extended host-galaxy. Nevertheless, we are able to infer all of the mass parameters modeled in earlier studies, and our best-fit values, including $γ$, are fully consistent with published results. In the case of SN Zwicky, taking the same approach, however, we obtain an alternative best-fit model compared to published results, underscoring the importance of fully exploring the model parameter space.</summary>
    <category term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.GA" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-26T18:52:04Z</published>
    <arxiv:comment>35 pages, 16 figures, 4 tables</arxiv:comment>
    <arxiv:primary_category term="astro-ph.CO"/>
    <author>
      <name>Saul Baltasar</name>
    </author>
    <author>
      <name>Nicolas Ratier-Werbin</name>
    </author>
    <author>
      <name>Xiaosheng Huang</name>
    </author>
    <author>
      <name>W. Sheu</name>
    </author>
    <author>
      <name>C. J. Storfer</name>
    </author>
    <author>
      <name>Y. -M. Hsu</name>
    </author>
    <author>
      <name>Sean Xu</name>
    </author>
    <author>
      <name>David J. Schlegel</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.18777v1</id>
    <title>PRECISE: Reducing the Bias of LLM Evaluations Using Prediction-Powered Ranking Estimation</title>
    <updated>2026-01-26T18:46:49Z</updated>
    <link href="https://arxiv.org/abs/2601.18777v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.18777v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Evaluating the quality of search, ranking and RAG systems traditionally requires a significant number of human relevance annotations. In recent times, several deployed systems have explored the usage of Large Language Models (LLMs) as automated judges for this task while their inherent biases prevent direct use for metric estimation. We present a statistical framework extending Prediction-Powered Inference (PPI) that combines minimal human annotations with LLM judgments to produce reliable estimates of metrics which require sub-instance annotations. Our method requires as few as 100 human-annotated queries and 10,000 unlabeled examples, reducing annotation requirements significantly compared to traditional approaches. We formulate our proposed framework (PRECISE) for inference of relevance uplift for an LLM-based query reformulation application, extending PPI to sub-instance annotations at the query-document level. By reformulating the metric-integration space, we reduced the computational complexity from O(2^|C|) to O(2^K), where |C| represents corpus size (in order of millions). Detailed experiments across prominent retrieval datasets demonstrate that our method reduces the variance of estimates for the business-critical Precision@K metric, while effectively correcting for LLM bias in low-resource settings.</summary>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-26T18:46:49Z</published>
    <arxiv:comment>Accepted at AAAI 2026 - Innovative Applications of AI (IAAI-26)</arxiv:comment>
    <arxiv:primary_category term="cs.LG"/>
    <author>
      <name>Abhishek Divekar</name>
    </author>
    <author>
      <name>Anirban Majumder</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.18769v1</id>
    <title>The Role of Intrinsic Temperature and Vertical Mixing in Characterizing Sub-Neptune Atmospheres</title>
    <updated>2026-01-26T18:38:20Z</updated>
    <link href="https://arxiv.org/abs/2601.18769v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.18769v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Sub-Neptune planets are often modeled with a dense rocky or metal-rich interior beneath a thick hydrogen/helium (H/He) atmosphere; though their bulk densities could also be explained by a water-rich interior with a thin H/He atmosphere. Atmospheric composition provides a key mechanism to break this degeneracy between competing interior models. However, the overall composition of sub-Neptunes inferred from spectra obtained with the James Webb Space Telescope, remains debated in part due to differences in modeling assumptions. While previous studies explored parameter spaces such as stellar spectra, atmospheric metallicities, and carbon-to-oxygen ratios, they often assumed fixed intrinsic temperatures (Tint) and vertical eddy diffusion coefficients (Kzz) - two critical, yet poorly constrained, drivers of atmospheric chemistry. To address this, we present a self-consistent grid of models that covers the full plausible range of Tint (60 - 450 K) and Kzz (10^{5} - 10^{12} cm^2/s) using the open-source PICASO and VULCAN packages to better characterize sub-Neptune atmospheres. Focusing on K2-18b analogs, we demonstrate that Tint and Kzz significantly impact CH4, CO2, CO, NH3 and HCN abundances, with H2O being largely unaffected. Our work demonstrates that comprehensive parameter space exploration of thermal and mixing parameters is essential for accurate interpretation of sub-Neptune spectra, and that single-parameter assumptions can lead to misclassification of planetary interiors. We provide a diagnostic framework using multi-molecule observations to distinguish between competing atmospheric models and advance robust characterization of sub-Neptunes.</summary>
    <category term="astro-ph.EP" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-26T18:38:20Z</published>
    <arxiv:comment>Submitted to AAS Journals (26 pages)</arxiv:comment>
    <arxiv:primary_category term="astro-ph.EP"/>
    <author>
      <name>Neha Dushyantha Kumar</name>
    </author>
    <author>
      <name>Jessica E. Libby-Roberts</name>
    </author>
    <author>
      <name>Caleb I. Canas</name>
    </author>
    <author>
      <name>Nicholas F. Wogan</name>
    </author>
    <author>
      <name>Suvrath Mahadevan</name>
    </author>
    <author>
      <name>Sagnick Mukherjee</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.18753v1</id>
    <title>HalluGuard: Demystifying Data-Driven and Reasoning-Driven Hallucinations in LLMs</title>
    <updated>2026-01-26T18:23:09Z</updated>
    <link href="https://arxiv.org/abs/2601.18753v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.18753v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>The reliability of Large Language Models (LLMs) in high-stakes domains such as healthcare, law, and scientific discovery is often compromised by hallucinations. These failures typically stem from two sources: data-driven hallucinations and reasoning-driven hallucinations. However, existing detection methods usually address only one source and rely on task-specific heuristics, limiting their generalization to complex scenarios. To overcome these limitations, we introduce the Hallucination Risk Bound, a unified theoretical framework that formally decomposes hallucination risk into data-driven and reasoning-driven components, linked respectively to training-time mismatches and inference-time instabilities. This provides a principled foundation for analyzing how hallucinations emerge and evolve. Building on this foundation, we introduce HalluGuard, an NTK-based score that leverages the induced geometry and captured representations of the NTK to jointly identify data-driven and reasoning-driven hallucinations. We evaluate HalluGuard on 10 diverse benchmarks, 11 competitive baselines, and 9 popular LLM backbones, consistently achieving state-of-the-art performance in detecting diverse forms of LLM hallucinations.</summary>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-26T18:23:09Z</published>
    <arxiv:comment>Have been accepted by ICLR'26</arxiv:comment>
    <arxiv:primary_category term="cs.LG"/>
    <author>
      <name>Xinyue Zeng</name>
    </author>
    <author>
      <name>Junhong Lin</name>
    </author>
    <author>
      <name>Yujun Yan</name>
    </author>
    <author>
      <name>Feng Guo</name>
    </author>
    <author>
      <name>Liang Shi</name>
    </author>
    <author>
      <name>Jun Wu</name>
    </author>
    <author>
      <name>Dawei Zhou</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.18734v1</id>
    <title>Self-Distilled Reasoner: On-Policy Self-Distillation for Large Language Models</title>
    <updated>2026-01-26T17:56:50Z</updated>
    <link href="https://arxiv.org/abs/2601.18734v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.18734v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Knowledge distillation improves large language model (LLM) reasoning by compressing the knowledge of a teacher LLM to train smaller LLMs. On-policy distillation advances this approach by having the student sample its own trajectories while a teacher LLM provides dense token-level supervision, addressing the distribution mismatch between training and inference in off-policy distillation methods. However, on-policy distillation typically requires a separate, often larger, teacher LLM and does not explicitly leverage ground-truth solutions available in reasoning datasets. Inspired by the intuition that a sufficiently capable LLM can rationalize external privileged reasoning traces and teach its weaker self (i.e., the version without access to privileged information), we introduce On-Policy Self-Distillation (OPSD), a framework where a single model acts as both teacher and student by conditioning on different contexts. The teacher policy conditions on privileged information (e.g., verified reasoning traces) while the student policy sees only the question; training minimizes the per-token divergence between these distributions over the student's own rollouts. We demonstrate the efficacy of our method on multiple mathematical reasoning benchmarks, achieving 4-8x token efficiency compared to reinforcement learning methods such as GRPO and superior performance over off-policy distillation methods.</summary>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-26T17:56:50Z</published>
    <arxiv:comment>13 pages</arxiv:comment>
    <arxiv:primary_category term="cs.LG"/>
    <author>
      <name>Siyan Zhao</name>
    </author>
    <author>
      <name>Zhihui Xie</name>
    </author>
    <author>
      <name>Mengchen Liu</name>
    </author>
    <author>
      <name>Jing Huang</name>
    </author>
    <author>
      <name>Guan Pang</name>
    </author>
    <author>
      <name>Feiyu Chen</name>
    </author>
    <author>
      <name>Aditya Grover</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.18730v1</id>
    <title>Reflect: Transparent Principle-Guided Reasoning for Constitutional Alignment at Scale</title>
    <updated>2026-01-26T17:54:54Z</updated>
    <link href="https://arxiv.org/abs/2601.18730v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.18730v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>The constitutional framework of alignment aims to align large language models (LLMs) with value-laden principles written in natural language (such as to avoid using biased language). Prior work has focused on parameter fine-tuning techniques, such as reinforcement learning from human feedback (RLHF), to instill these principles. However, these approaches are computationally demanding, require careful engineering and tuning, and often require difficult-to-obtain human annotation data. We propose \textsc{reflect}, an inference-time framework for constitutional alignment that does not require any training or data, providing a plug-and-play approach for aligning an instruction-tuned model to a set of principles. \textsc{reflect} operates entirely in-context, combining a (i) constitution-conditioned base response with post-generation (ii) self-evaluation, (iii)(a) self-critique, and (iii)(b) final revision. \textsc{reflect}'s technique of explicit in-context reasoning over principles during post-generation outperforms standard few-shot prompting and provides transparent reasoning traces. Our results demonstrate that \textsc{reflect} significantly improves LLM conformance to diverse and complex principles, including principles quite distinct from those emphasized in the model's original parameter fine-tuning, without sacrificing factual reasoning. \textsc{reflect} is particularly effective at reducing the rate of rare but significant violations of principles, thereby improving safety and robustness in the tail end of the distribution of generations. Finally, we show that \textsc{reflect} naturally generates useful training data for traditional parameter fine-tuning techniques, allowing for efficient scaling and the reduction of inference-time computational overhead in long-term deployment scenarios.</summary>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-26T17:54:54Z</published>
    <arxiv:primary_category term="cs.CL"/>
    <author>
      <name>Henry Bell</name>
    </author>
    <author>
      <name>Caroline Zhang</name>
    </author>
    <author>
      <name>Mohammed Mobasserul Haque</name>
    </author>
    <author>
      <name>Dhaval Potdar</name>
    </author>
    <author>
      <name>Samia Zaman</name>
    </author>
    <author>
      <name>Brandon Fain</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.18728v1</id>
    <title>Riemannian AmbientFlow: Towards Simultaneous Manifold Learning and Generative Modeling from Corrupted Data</title>
    <updated>2026-01-26T17:51:52Z</updated>
    <link href="https://arxiv.org/abs/2601.18728v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.18728v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Modern generative modeling methods have demonstrated strong performance in learning complex data distributions from clean samples. In many scientific and imaging applications, however, clean samples are unavailable, and only noisy or linearly corrupted measurements can be observed. Moreover, latent structures, such as manifold geometries, present in the data are important to extract for further downstream scientific analysis. In this work, we introduce Riemannian AmbientFlow, a framework for simultaneously learning a probabilistic generative model and the underlying, nonlinear data manifold directly from corrupted observations. Building on the variational inference framework of AmbientFlow, our approach incorporates data-driven Riemannian geometry induced by normalizing flows, enabling the extraction of manifold structure through pullback metrics and Riemannian Autoencoders. We establish theoretical guarantees showing that, under appropriate geometric regularization and measurement conditions, the learned model recovers the underlying data distribution up to a controllable error and yields a smooth, bi-Lipschitz manifold parametrization. We further show that the resulting smooth decoder can serve as a principled generative prior for inverse problems with recovery guarantees. We empirically validate our approach on low-dimensional synthetic manifolds and on MNIST.</summary>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-26T17:51:52Z</published>
    <arxiv:primary_category term="cs.LG"/>
    <author>
      <name>Willem Diepeveen</name>
    </author>
    <author>
      <name>Oscar Leong</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.18702v1</id>
    <title>From Fuzzy to Exact: The Halo Architecture for Infinite-Depth Reasoning via Rational Arithmetic</title>
    <updated>2026-01-26T17:24:34Z</updated>
    <link href="https://arxiv.org/abs/2601.18702v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.18702v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Current paradigms in Deep Learning prioritize computational throughput over numerical precision, relying on the assumption that intelligence emerges from statistical correlation at scale. In this paper, we challenge this orthodoxy. We propose the Exactness Hypothesis: that General Intelligence (AGI), specifically high-order causal inference, requires a computational substrate capable of Arbitrary Precision Arithmetic. We argue that the "hallucinations" and logical incoherence seen in current Large Language Models (LLMs) are artifacts of IEEE 754 floating-point approximation errors accumulating over deep compositional functions. To mitigate this, we introduce the Halo Architecture, a paradigm shift to Rational Arithmetic ($\mathbb{Q}$) supported by a novel Exact Inference Unit (EIU). Empirical validation on the Huginn-0125 prototype demonstrates that while 600B-parameter scale BF16 baselines collapse in chaotic systems, Halo maintains zero numerical divergence indefinitely. This work establishes exact arithmetic as a prerequisite for reducing logical uncertainty in System 2 AGI.</summary>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-26T17:24:34Z</published>
    <arxiv:comment>8 pages, 6 figures. Submitted to UAI 2026</arxiv:comment>
    <arxiv:primary_category term="cs.LG"/>
    <author>
      <name>Hansheng Ren</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.18683v1</id>
    <title>Learned harmonic mean estimation of the marginal likelihood for multimodal posteriors with flow matching</title>
    <updated>2026-01-26T17:00:08Z</updated>
    <link href="https://arxiv.org/abs/2601.18683v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.18683v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>The marginal likelihood, or Bayesian evidence, is a crucial quantity for Bayesian model comparison but its computation can be challenging for complex models, even in parameters space of moderate dimension. The learned harmonic mean estimator has been shown to provide accurate and robust estimates of the marginal likelihood simply using posterior samples. It is agnostic to the sampling strategy, meaning that the samples can be obtained using any method. This enables marginal likelihood calculation and model comparison with whatever sampling is most suitable for the task. However, the internal density estimators considered previously for the learned harmonic mean can struggle with highly multimodal posteriors. In this work we introduce flow matching-based continuous normalizing flows as a powerful architecture for the internal density estimation of the learned harmonic mean. We demonstrate the ability to handle challenging multimodal posteriors, including an example in 20 parameter dimensions, showcasing the method's ability to handle complex posteriors without the need for fine-tuning or heuristic modifications to the base distribution.</summary>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-26T17:00:08Z</published>
    <arxiv:comment>Submitted to 44th International Workshop on Bayesian Inference and Maximum Entropy Methods in Science and Engineering</arxiv:comment>
    <arxiv:primary_category term="stat.ME"/>
    <author>
      <name>Alicja Polanska</name>
    </author>
    <author>
      <name>Jason D. McEwen</name>
    </author>
  </entry>
</feed>
