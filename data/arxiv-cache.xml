<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-12-18T00:57:13Z -->
<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/" xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns="http://www.w3.org/2005/Atom">
  <id>https://arxiv.org/api/p6EyKyP4fMY/66n9Ev8E79F7KlI</id>
  <title>arXiv Query: search_query=all:causal OR all:inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <updated>2025-12-18T00:57:13Z</updated>
  <link href="https://arxiv.org/api/query?search_query=all:causal+OR+all:inference&amp;start=0&amp;max_results=10&amp;id_list=" type="application/atom+xml"/>
  <opensearch:itemsPerPage>10</opensearch:itemsPerPage>
  <opensearch:totalResults>128840</opensearch:totalResults>
  <opensearch:startIndex>0</opensearch:startIndex>
  <entry>
    <id>http://arxiv.org/abs/2512.14695v1</id>
    <title>JWST Observations of the Double Nucleus in NGC 4486B: Possible Evidence for a Recent Binary SMBH Merger and Recoil</title>
    <updated>2025-12-16T18:59:37Z</updated>
    <link href="https://arxiv.org/abs/2512.14695v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.14695v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>A recent study of the compact elliptical galaxy NGC 4486B using JWST-NIRSpec IFU kinematics confirmed a supermassive black hole (SMBH) of mass $M_{BH}=3.6\pm0.7\times10^8$ (~8% of the stellar mass). In addition to its double nucleus, the nuclear kinematics show pronounced asymmetries: a velocity-dispersion peak displaced by 6 pc from the galaxy center and a ~16 km/s offset in the mean stellar line-of-sight velocity near the SMBH. We examine the origin of the 12 pc double nucleus and these asymmetries and show that the observations favor an SMBH surrounded by an eccentric nuclear disk (END). END formation models require the SMBH to experience a gravitational wave (GW) recoil following a binary SMBH merger. Our orbit-superposition models contain ~50% retrograde stars at the edge of the nuclear region, in striking agreement with END-formation simulations. We infer a pre-merger mass ratio q&gt;0.15 and a recoil kick of ~340 km/s. Our N-body simulations show that with such a kick, the SMBH returns to the center within ~30 Myr. Its flat central core is also consistent with earlier binary black hole scouring. We test two alternative mechanisms-buoyancy-driven oscillations and a pre-merger SMBH binary-but neither reproduces the observed offsets, favoring the GW-kick scenario. Our direct N-body simulations further show that a prograde SMBH binary in a rotating host can stall in a corotation resonance, delaying coalescence. Thus, although NGC 4486B is an old, relaxed galaxy near the Virgo cluster center, its SMBH appears to have merged only recently, making its nucleus a rare nearby laboratory for studying post-merger SMBH dynamics.</summary>
    <category term="astro-ph.GA" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-16T18:59:37Z</published>
    <arxiv:comment>Comments: Submitted to ApJL. Comments are welcome</arxiv:comment>
    <arxiv:primary_category term="astro-ph.GA"/>
    <author>
      <name>Behzad Tahmasebzadeh</name>
    </author>
    <author>
      <name>Monica Valluri</name>
    </author>
    <author>
      <name>Shashank Dattathri</name>
    </author>
    <author>
      <name>Tatsuya Akiba</name>
    </author>
    <author>
      <name>Fazeel Mahmood Khan</name>
    </author>
    <author>
      <name>Matthew A. Taylor</name>
    </author>
    <author>
      <name>Haruka Yoshino</name>
    </author>
    <author>
      <name>Solveig Thompson</name>
    </author>
    <author>
      <name>Ann-Marie Madigan</name>
    </author>
    <author>
      <name>Frank C. van den Bosch</name>
    </author>
    <author>
      <name>Kelly holley-bockelmann</name>
    </author>
    <author>
      <name>Patrick Côté</name>
    </author>
    <author>
      <name>Laura Ferrarese</name>
    </author>
    <author>
      <name>Michael J. Drinkwater</name>
    </author>
    <author>
      <name>Holger Baumgardt</name>
    </author>
    <author>
      <name>Misty C. Bentz</name>
    </author>
    <author>
      <name>Kristen Dage</name>
    </author>
    <author>
      <name>Eric W. Peng</name>
    </author>
    <author>
      <name>Somya Jha</name>
    </author>
    <author>
      <name>Andrea V. Macciò</name>
    </author>
    <author>
      <name>Chengze Liu</name>
    </author>
    <author>
      <name>Tyrone E. Woods</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.14692v1</id>
    <title>Native and Compact Structured Latents for 3D Generation</title>
    <updated>2025-12-16T18:58:28Z</updated>
    <link href="https://arxiv.org/abs/2512.14692v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.14692v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Recent advancements in 3D generative modeling have significantly improved the generation realism, yet the field is still hampered by existing representations, which struggle to capture assets with complex topologies and detailed appearance. This paper present an approach for learning a structured latent representation from native 3D data to address this challenge. At its core is a new sparse voxel structure called O-Voxel, an omni-voxel representation that encodes both geometry and appearance. O-Voxel can robustly model arbitrary topology, including open, non-manifold, and fully-enclosed surfaces, while capturing comprehensive surface attributes beyond texture color, such as physically-based rendering parameters. Based on O-Voxel, we design a Sparse Compression VAE which provides a high spatial compression rate and a compact latent space. We train large-scale flow-matching models comprising 4B parameters for 3D generation using diverse public 3D asset datasets. Despite their scale, inference remains highly efficient. Meanwhile, the geometry and material quality of our generated assets far exceed those of existing models. We believe our approach offers a significant advancement in 3D generative modeling.</summary>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-16T18:58:28Z</published>
    <arxiv:comment>Project Page: https://microsoft.github.io/TRELLIS.2/</arxiv:comment>
    <arxiv:primary_category term="cs.CV"/>
    <author>
      <name>Jianfeng Xiang</name>
    </author>
    <author>
      <name>Xiaoxue Chen</name>
    </author>
    <author>
      <name>Sicheng Xu</name>
    </author>
    <author>
      <name>Ruicheng Wang</name>
    </author>
    <author>
      <name>Zelong Lv</name>
    </author>
    <author>
      <name>Yu Deng</name>
    </author>
    <author>
      <name>Hongyuan Zhu</name>
    </author>
    <author>
      <name>Yue Dong</name>
    </author>
    <author>
      <name>Hao Zhao</name>
    </author>
    <author>
      <name>Nicholas Jing Yuan</name>
    </author>
    <author>
      <name>Jiaolong Yang</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.14691v1</id>
    <title>MMGR: Multi-Modal Generative Reasoning</title>
    <updated>2025-12-16T18:58:04Z</updated>
    <link href="https://arxiv.org/abs/2512.14691v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.14691v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Video foundation models generate visually realistic and temporally coherent content, but their reliability as world simulators depends on whether they capture physical, logical, and spatial constraints. Existing metrics such as Frechet Video Distance (FVD) emphasize perceptual quality and overlook reasoning failures, including violations of causality, physics, and global consistency. We introduce MMGR (Multi-Modal Generative Reasoning Evaluation and Benchmark), a principled evaluation framework based on five reasoning abilities: Physical, Logical, 3D Spatial, 2D Spatial, and Temporal. MMGR evaluates generative reasoning across three domains: Abstract Reasoning (ARC-AGI, Sudoku), Embodied Navigation (real-world 3D navigation and localization), and Physical Commonsense (sports and compositional interactions). MMGR applies fine-grained metrics that require holistic correctness across both video and image generation. We benchmark leading video models (Veo-3, Sora-2, Wan-2.2) and image models (Nano-banana, Nano-banana Pro, GPT-4o-image, Qwen-image), revealing strong performance gaps across domains. Models show moderate success on Physical Commonsense tasks but perform poorly on Abstract Reasoning (below 10 percent accuracy on ARC-AGI) and struggle with long-horizon spatial planning in embodied settings. Our analysis highlights key limitations in current models, including overreliance on perceptual data, weak global state consistency, and objectives that reward visual plausibility over causal correctness. MMGR offers a unified diagnostic benchmark and a path toward reasoning-aware generative world models.</summary>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-16T18:58:04Z</published>
    <arxiv:comment>work in progress</arxiv:comment>
    <arxiv:primary_category term="cs.CL"/>
    <author>
      <name>Zefan Cai</name>
    </author>
    <author>
      <name>Haoyi Qiu</name>
    </author>
    <author>
      <name>Tianyi Ma</name>
    </author>
    <author>
      <name>Haozhe Zhao</name>
    </author>
    <author>
      <name>Gengze Zhou</name>
    </author>
    <author>
      <name>Kung-Hsiang Huang</name>
    </author>
    <author>
      <name>Parisa Kordjamshidi</name>
    </author>
    <author>
      <name>Minjia Zhang</name>
    </author>
    <author>
      <name>Xiao Wen</name>
    </author>
    <author>
      <name>Jiuxiang Gu</name>
    </author>
    <author>
      <name>Nanyun Peng</name>
    </author>
    <author>
      <name>Junjie Hu</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.14681v1</id>
    <title>Fast and Accurate Causal Parallel Decoding using Jacobi Forcing</title>
    <updated>2025-12-16T18:45:18Z</updated>
    <link href="https://arxiv.org/abs/2512.14681v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.14681v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Multi-token generation has emerged as a promising paradigm for accelerating transformer-based large model inference. Recent efforts primarily explore diffusion Large Language Models (dLLMs) for parallel decoding to reduce inference latency. To achieve AR-level generation quality, many techniques adapt AR models into dLLMs to enable parallel decoding. However, they suffer from limited speedup compared to AR models due to a pretrain-to-posttrain mismatch. Specifically, the masked data distribution in post-training deviates significantly from the real-world data distribution seen during pretraining, and dLLMs rely on bidirectional attention, which conflicts with the causal prior learned during pretraining and hinders the integration of exact KV cache reuse. To address this, we introduce Jacobi Forcing, a progressive distillation paradigm where models are trained on their own generated parallel decoding trajectories, smoothly shifting AR models into efficient parallel decoders while preserving their pretrained causal inference property. The models trained under this paradigm, Jacobi Forcing Model, achieves 3.8x wall-clock speedup on coding and math benchmarks with minimal loss in performance. Based on Jacobi Forcing Models' trajectory characteristics, we introduce multi-block decoding with rejection recycling, which enables up to 4.5x higher token acceptance count per iteration and nearly 4.0x wall-clock speedup, effectively trading additional compute for lower inference latency. Our code is available at https://github.com/hao-ai-lab/JacobiForcing.</summary>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-16T18:45:18Z</published>
    <arxiv:primary_category term="cs.CL"/>
    <author>
      <name>Lanxiang Hu</name>
    </author>
    <author>
      <name>Siqi Kou</name>
    </author>
    <author>
      <name>Yichao Fu</name>
    </author>
    <author>
      <name>Samyam Rajbhandari</name>
    </author>
    <author>
      <name>Tajana Rosing</name>
    </author>
    <author>
      <name>Yuxiong He</name>
    </author>
    <author>
      <name>Zhijie Deng</name>
    </author>
    <author>
      <name>Hao Zhang</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.14676v1</id>
    <title>Cherenkov radiation in isotropic chiral matter: unlocking threshold-free emission</title>
    <updated>2025-12-16T18:43:47Z</updated>
    <link href="https://arxiv.org/abs/2512.14676v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.14676v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>We investigate Cherenkov radiation in isotropic chiral matter using Carroll-Field-Jackiw electrodynamics, with an axion angle linear in time, to describe a charge moving at constant velocity. By solving the modified Maxwell's equations in cylindrical coordinates and in the space-frequency domain, we derive closed expressions for the circularly polarized electromagnetic fields contributing independently to the radiation. The dispersion relations are obtained by imposing causality at a cylindrical surface at infinity, ensuring outgoing waves. Contrary to initial suppositions, each spectral energy distribution is gauge-invariant and positive, describing radiation at a characteristic angle. We characterize the angles and identify frequency ranges that allow for zero, one, or two Cherenkov cones. Notably, one sector of the model enables threshold-free Cherenkov radiation from slowly moving charges. Our results agree with partial findings in the nonrelativistic limit of earlier iterative analysis and clarify the regimes in which Cherenkov radiation arises in isotropic chiral matter.</summary>
    <category term="hep-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-th" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-16T18:43:47Z</published>
    <arxiv:comment>Accepted for publication in Physical Review D</arxiv:comment>
    <arxiv:primary_category term="hep-ph"/>
    <author>
      <name>Ricardo Martínez von Dossow</name>
    </author>
    <author>
      <name>Eduardo Barredo-Alamilla</name>
    </author>
    <author>
      <name>Maxim A. Gorlach</name>
    </author>
    <author>
      <name>Luis Fernando Urrutia</name>
    </author>
    <arxiv:doi>10.1103/dngn-zh7f</arxiv:doi>
    <link rel="related" href="https://doi.org/10.1103/dngn-zh7f" title="doi"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.14673v1</id>
    <title>Reconsidering Conversational Norms in LLM Chatbots for Sustainable AI</title>
    <updated>2025-12-16T18:38:11Z</updated>
    <link href="https://arxiv.org/abs/2512.14673v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.14673v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>LLM based chatbots have become central interfaces in technical, educational, and analytical domains, supporting tasks such as code reasoning, problem solving, and information exploration. As these systems scale, sustainability concerns have intensified, with most assessments focusing on model architecture, hardware efficiency, and deployment infrastructure. However, existing mitigation efforts largely overlook how user interaction practices themselves shape the energy profile of LLM based systems. In this vision paper, we argue that interaction level behavior appears to be an underexamined factor shaping the environmental impact of LLM based systems, and we present this issue across four dimensions. First, extended conversational patterns increase token production and raise the computational cost of inference. Second, expectations of instant responses limit opportunities for energy aware scheduling and workload consolidation. Third, everyday user habits contribute to cumulative operational demand in ways that are rarely quantified. Fourth, the accumulation of context affects memory requirements and reduces the efficiency of long running dialogues. Addressing these challenges requires rethinking how chatbot interactions are designed and conceptualized, and adopting perspectives that recognize sustainability as partly dependent on the conversational norms through which users engage with LLM based systems.</summary>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-16T18:38:11Z</published>
    <arxiv:primary_category term="cs.SE"/>
    <author>
      <name>Ronnie de Souza Santos</name>
    </author>
    <author>
      <name>Cleyton Magalhães</name>
    </author>
    <author>
      <name>Italo Santos</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.14661v1</id>
    <title>Focus: A Streaming Concentration Architecture for Efficient Vision-Language Models</title>
    <updated>2025-12-16T18:21:18Z</updated>
    <link href="https://arxiv.org/abs/2512.14661v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.14661v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Vision-Language Models (VLMs) have demonstrated strong performance on tasks such as video captioning and visual question answering. However, their growing scale and video-level inputs lead to significant computational and memory overhead, posing challenges for real-time deployment on hardware accelerators. While prior work attempts to reduce redundancy via token pruning or merging, these methods typically operate at coarse granularity and incur high runtime overhead due to global token-level operations. In this study, we propose Focus, a Streaming Concentration Architecture that efficiently accelerates VLM inference through progressive, fine-grained redundancy elimination. Focus introduces a multilevel concentration paradigm that hierarchically compresses vision-language inputs at three levels: (1) semantic-guided token pruning based on textual prompts, (2) spatial-temporal block-level concentration using localized comparisons, and (3) vector-level redundancy removal via motion-aware matching. All concentration steps are tightly co-designed with the architecture to support streaming-friendly, on-chip execution. Focus leverages GEMM tiling, convolution-style layout, and cross-modal attention to minimize off-chip access while enabling high throughput. Implemented as a modular unit within a systolic-array accelerator, Focus achieves a 2.4x speedup and 3.3x reduction in energy, significantly outperforming state-of-the-art accelerators in both performance and energy efficiency. Full-stack implementation of Focus is open-sourced at https://github.com/dubcyfor3/Focus.</summary>
    <category term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-16T18:21:18Z</published>
    <arxiv:comment>HPCA 2026</arxiv:comment>
    <arxiv:primary_category term="cs.AR"/>
    <author>
      <name>Chiyue Wei</name>
    </author>
    <author>
      <name>Cong Guo</name>
    </author>
    <author>
      <name>Junyao Zhang</name>
    </author>
    <author>
      <name>Haoxuan Shan</name>
    </author>
    <author>
      <name>Yifan Xu</name>
    </author>
    <author>
      <name>Ziyue Zhang</name>
    </author>
    <author>
      <name>Yudong Liu</name>
    </author>
    <author>
      <name>Qinsi Wang</name>
    </author>
    <author>
      <name>Changchun Zhou</name>
    </author>
    <author>
      <name>Hai "Helen" Li</name>
    </author>
    <author>
      <name>Yiran Chen</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.14659v1</id>
    <title>Analysis and Uncertainty Quantification of Thermal Transport Measurements through Bayesian Parameter Estimation</title>
    <updated>2025-12-16T18:20:51Z</updated>
    <link href="https://arxiv.org/abs/2512.14659v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.14659v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>The thermal transport community is increasingly interested in rigorous uncertainty quantification (UQ) of their measurements. In this work, we argue that Bayesian parameter estimation (BPE) represents a powerful framework for both analysis/fitting and UQ. We provide a detailed walkthrough of the technique (including code to duplicate our results) and example analysis based on measuring the thermal conductance of a gold/sapphire interface with FDTR. Comparisons are made against traditional analysis/UQ techniques adopted by the thermal transport community. Notable advantages of BPE include the interpretability of its results, including the capacity to indicate incorrect input assumptions, as well as a way to balance overall goodness of fit against prior knowledge of feasible parameter values. In some cases, incorporating this additional information can affect not only the magnitude of error bars but the inferred values themselves.</summary>
    <category term="cond-mat.mtrl-sci" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-16T18:20:51Z</published>
    <arxiv:primary_category term="cond-mat.mtrl-sci"/>
    <author>
      <name>Jeremy Drew</name>
    </author>
    <author>
      <name>Shravan Godse</name>
    </author>
    <author>
      <name>Yuxing Liang</name>
    </author>
    <author>
      <name>Abhishek Pathak</name>
    </author>
    <author>
      <name>Jonathan A. Malen</name>
    </author>
    <author>
      <name>Rachel C. Kurchin</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.14622v1</id>
    <title>Beyond Text-to-SQL: Autonomous Research-Driven Database Exploration with DAR</title>
    <updated>2025-12-16T17:36:09Z</updated>
    <link href="https://arxiv.org/abs/2512.14622v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.14622v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Large language models can already query databases, yet most existing systems remain reactive: they rely on explicit user prompts and do not actively explore data. We introduce DAR (Data Agnostic Researcher), a multi-agent system that performs end-to-end database research without human-initiated queries. DAR orchestrates specialized AI agents across three layers: initialization (intent inference and metadata extraction), execution (SQL and AI-based query synthesis with iterative validation), and synthesis (report generation with built-in quality control). All reasoning is executed directly inside BigQuery using native generative AI functions, eliminating data movement and preserving data governance. On a realistic asset-incident dataset, DAR completes the full analytical task in 16 minutes, compared to 8.5 hours for a professional analyst (approximately 32x times faster), while producing useful pattern-based insights and evidence-grounded recommendations. Although human experts continue to offer deeper contextual interpretation, DAR excels at rapid exploratory analysis. Overall, this work shifts database interaction from query-driven assistance toward autonomous, research-driven exploration within cloud data warehouses.</summary>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-16T17:36:09Z</published>
    <arxiv:primary_category term="cs.DB"/>
    <author>
      <name>Ostap Vykhopen</name>
    </author>
    <author>
      <name>Viktoria Skorik</name>
    </author>
    <author>
      <name>Maxim Tereschenko</name>
    </author>
    <author>
      <name>Veronika Solopova</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.14609v1</id>
    <title>Asymptotic Inference for Rank Correlations</title>
    <updated>2025-12-16T17:19:56Z</updated>
    <link href="https://arxiv.org/abs/2512.14609v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.14609v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Kendall's tau and Spearman's rho are widely used tools for measuring dependence. Surprisingly, when it comes to asymptotic inference for these rank correlations, some fundamental results and methods have not yet been developed, in particular for discrete random variables and in the time series case, and concerning variance estimation in general. Consequently, asymptotic confidence intervals are not available. We provide a comprehensive treatment of asymptotic inference for classical rank correlations, including Kendall's tau, Spearman's rho, Goodman-Kruskal's gamma, Kendall's tau-b, and grade correlation. We derive asymptotic distributions for both iid and time series data, resorting to asymptotic results for U-statistics, and introduce consistent variance estimators. This enables the construction of confidence intervals and tests, generalizes classical results for continuous random variables and leads to corrected versions of widely used tests of independence. We analyze the finite-sample performance of our variance estimators, confidence intervals, and tests in simulations and illustrate their use in case studies.</summary>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-16T17:19:56Z</published>
    <arxiv:primary_category term="stat.ME"/>
    <author>
      <name>Marc-Oliver Pohle</name>
    </author>
    <author>
      <name>Jan-Lukas Wermuth</name>
    </author>
    <author>
      <name>Christian H. Weiß</name>
    </author>
  </entry>
</feed>
