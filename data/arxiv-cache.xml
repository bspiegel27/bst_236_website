<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-11-13T00:57:33Z -->
<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/" xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns="http://www.w3.org/2005/Atom">
  <id>https://arxiv.org/api/p6EyKyP4fMY/66n9Ev8E79F7KlI</id>
  <title>arXiv Query: search_query=all:causal OR all:inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <updated>2025-11-13T00:57:33Z</updated>
  <link href="https://arxiv.org/api/query?search_query=all:causal+OR+all:inference&amp;start=0&amp;max_results=10&amp;id_list=" type="application/atom+xml"/>
  <opensearch:itemsPerPage>10</opensearch:itemsPerPage>
  <opensearch:totalResults>125933</opensearch:totalResults>
  <opensearch:startIndex>0</opensearch:startIndex>
  <entry>
    <id>http://arxiv.org/abs/1506.03880v2</id>
    <title>Causal inference via algebraic geometry: feasibility tests for functional causal structures with two binary observed variables</title>
    <updated>2017-10-18T00:08:46Z</updated>
    <link href="https://arxiv.org/abs/1506.03880v2"/>
    <link href="https://arxiv.org/pdf/1506.03880v2"/>
    <summary>We provide a scheme for inferring causal relations from uncontrolled statistical data based on tools from computational algebraic geometry, in particular, the computation of Groebner bases. We focus on causal structures containing just two observed variables, each of which is binary. We consider the consequences of imposing different restrictions on the number and cardinality of latent variables and of assuming different functional dependences of the observed variables on the latent ones (in particular, the noise need not be additive). We provide an inductive scheme for classifying functional causal structures into distinct observational equivalence classes. For each observational equivalence class, we provide a procedure for deriving constraints on the joint distribution that are necessary and sufficient conditions for it to arise from a model in that class. We also demonstrate how this sort of approach provides a means of determining which causal parameters are identifiable and how to solve for these. Prospects for expanding the scope of our scheme, in particular to the problem of quantum causal inference, are also discussed.</summary>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <published>2015-06-12T00:51:44Z</published>
    <arxiv:comment>Accepted for publication in Journal of Causal Inference. Revised and updated in response to referee feedback. 16+5 pages, 26+2 figures. Comments welcome</arxiv:comment>
    <arxiv:primary_category term="stat.ML"/>
    <arxiv:journal_ref>Journal of Causal Inference, Volume 5, Issue 2, 2017</arxiv:journal_ref>
    <author>
      <name>Ciarán M. Lee</name>
    </author>
    <author>
      <name>Robert W. Spekkens</name>
    </author>
    <arxiv:doi>10.1515/jci-2016-0013</arxiv:doi>
    <link rel="related" href="https://doi.org/10.1515/jci-2016-0013"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2209.03013v1</id>
    <title>Quantitative probing: Validating causal models using quantitative domain knowledge</title>
    <updated>2023-08-22T00:38:24Z</updated>
    <link href="https://arxiv.org/abs/2209.03013v1"/>
    <link href="https://arxiv.org/pdf/2209.03013v1"/>
    <summary>We present quantitative probing as a model-agnostic framework for validating causal models in the presence of quantitative domain knowledge. The method is constructed as an analogue of the train/test split in correlation-based machine learning and as an enhancement of current causal validation strategies that are consistent with the logic of scientific discovery. The effectiveness of the method is illustrated using Pearl's sprinkler example, before a thorough simulation-based investigation is conducted. Limits of the technique are identified by studying exemplary failing scenarios, which are furthermore used to propose a list of topics for future research and improvements of the presented version of quantitative probing. The code for integrating quantitative probing into causal analysis, as well as the code for the presented simulation-based studies of the effectiveness of quantitative probing is provided in two separate open-source Python packages.</summary>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <published>2022-09-07T09:19:11Z</published>
    <arxiv:comment>submitted to the Journal of Causal Inference</arxiv:comment>
    <arxiv:primary_category term="cs.LG"/>
    <arxiv:journal_ref>Journal of Causal Inference, vol. 11, no. 1, 2023</arxiv:journal_ref>
    <author>
      <name>Daniel Grünbaum</name>
    </author>
    <author>
      <name>Maike L. Stern</name>
    </author>
    <author>
      <name>Elmar W. Lang</name>
    </author>
    <arxiv:doi>10.1515/jci-2022-0060</arxiv:doi>
    <link rel="related" href="https://doi.org/10.1515/jci-2022-0060"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1905.11374v5</id>
    <title>A Unifying Causal Framework for Analyzing Dataset Shift-stable Learning Algorithms</title>
    <updated>2022-07-20T00:05:05Z</updated>
    <link href="https://arxiv.org/abs/1905.11374v5"/>
    <link href="https://arxiv.org/pdf/1905.11374v5"/>
    <summary>Recent interest in the external validity of prediction models (i.e., the problem of different train and test distributions, known as dataset shift) has produced many methods for finding predictive distributions that are invariant to dataset shifts and can be used for prediction in new, unseen environments. However, these methods consider different types of shifts and have been developed under disparate frameworks, making it difficult to theoretically analyze how solutions differ with respect to stability and accuracy. Taking a causal graphical view, we use a flexible graphical representation to express various types of dataset shifts. Given a known graph of the data generating process, we show that all invariant distributions correspond to a causal hierarchy of graphical operators which disable the edges in the graph that are responsible for the shifts. The hierarchy provides a common theoretical underpinning for understanding when and how stability to shifts can be achieved, and in what ways stable distributions can differ. We use it to establish conditions for minimax optimal performance across environments, and derive new algorithms that find optimal stable distributions. Using this new perspective, we empirically demonstrate that that there is a tradeoff between minimax and average performance.</summary>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <published>2019-05-27T17:56:39Z</published>
    <arxiv:comment>Published in the Journal of Causal Inference</arxiv:comment>
    <arxiv:primary_category term="stat.ML"/>
    <arxiv:journal_ref>Journal of Causal Inference, 10(1), 64-89</arxiv:journal_ref>
    <author>
      <name>Adarsh Subbaswamy</name>
    </author>
    <author>
      <name>Bryant Chen</name>
    </author>
    <author>
      <name>Suchi Saria</name>
    </author>
    <arxiv:doi>10.1515/jci-2021-0042</arxiv:doi>
    <link rel="related" href="https://doi.org/10.1515/jci-2021-0042"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2309.13103v1</id>
    <title>OpportunityFinder: A Framework for Automated Causal Inference</title>
    <updated>2023-09-26T00:01:51Z</updated>
    <link href="https://arxiv.org/abs/2309.13103v1"/>
    <link href="https://arxiv.org/pdf/2309.13103v1"/>
    <summary>We introduce OpportunityFinder, a code-less framework for performing a variety of causal inference studies with panel data for non-expert users. In its current state, OpportunityFinder only requires users to provide raw observational data and a configuration file. A pipeline is then triggered that inspects/processes data, chooses the suitable algorithm(s) to execute the causal study. It returns the causal impact of the treatment on the configured outcome, together with sensitivity and robustness results. Causal inference is widely studied and used to estimate the downstream impact of individual's interactions with products and features. It is common that these causal studies are performed by scientists and/or economists periodically. Business stakeholders are often bottle-necked on scientist or economist bandwidth to conduct causal studies. We offer OpportunityFinder as a solution for commonly performed causal studies with four key features: (1) easy to use for both Business Analysts and Scientists, (2) abstraction of multiple algorithms under a single I/O interface, (3) support for causal impact analysis under binary treatment with panel data and (4) dynamic selection of algorithm based on scale of data.</summary>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <published>2023-09-22T17:35:03Z</published>
    <arxiv:comment>KDD 2023 Workshop - Causal Inference and Machine Learning in Practice</arxiv:comment>
    <arxiv:primary_category term="cs.LG"/>
    <author>
      <name>Huy Nguyen</name>
    </author>
    <author>
      <name>Prince Grover</name>
    </author>
    <author>
      <name>Devashish Khatwani</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2109.07542v1</id>
    <title>Text as Causal Mediators: Research Design for Causal Estimates of Differential Treatment of Social Groups via Language Aspects</title>
    <updated>2021-09-17T00:02:18Z</updated>
    <link href="https://arxiv.org/abs/2109.07542v1"/>
    <link href="https://arxiv.org/pdf/2109.07542v1"/>
    <summary>Using observed language to understand interpersonal interactions is important in high-stakes decision making. We propose a causal research design for observational (non-experimental) data to estimate the natural direct and indirect effects of social group signals (e.g. race or gender) on speakers' responses with separate aspects of language as causal mediators. We illustrate the promises and challenges of this framework via a theoretical case study of the effect of an advocate's gender on interruptions from justices during U.S. Supreme Court oral arguments. We also discuss challenges conceptualizing and operationalizing causal variables such as gender and language that comprise of many components, and we articulate technical open challenges such as temporal dependence between language mediators in conversational settings.</summary>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <published>2021-09-15T19:15:35Z</published>
    <arxiv:comment>Accepted to Causal Inference and NLP (CI+NLP) Workshop at EMNLP 2021</arxiv:comment>
    <arxiv:primary_category term="cs.CL"/>
    <arxiv:journal_ref>Causal Inference and NLP (CI+NLP) Workshop at EMNLP 2021</arxiv:journal_ref>
    <author>
      <name>Katherine A. Keith</name>
    </author>
    <author>
      <name>Douglas Rice</name>
    </author>
    <author>
      <name>Brendan O'Connor</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2202.02891v1</id>
    <title>Causal Inference Using Tractable Circuits</title>
    <updated>2022-02-08T01:25:56Z</updated>
    <link href="https://arxiv.org/abs/2202.02891v1"/>
    <link href="https://arxiv.org/pdf/2202.02891v1"/>
    <summary>The aim of this paper is to discuss a recent result which shows that probabilistic inference in the presence of (unknown) causal mechanisms can be tractable for models that have traditionally been viewed as intractable. This result was reported recently to facilitate model-based supervised learning but it can be interpreted in a causality context as follows. One can compile a non-parametric causal graph into an arithmetic circuit that supports inference in time linear in the circuit size. The circuit is also non-parametric so it can be used to estimate parameters from data and to further reason (in linear time) about the causal graph parametrized by these estimates. Moreover, the circuit size can sometimes be bounded even when the treewidth of the causal graph is not, leading to tractable inference on models that have been deemed intractable previously. This has been enabled by a new technique that can exploit causal mechanisms computationally but without needing to know their identities (the classical setup in causal inference). Our goal is to provide a causality-oriented exposure to these new results and to speculate on how they may potentially contribute to more scalable and versatile causal inference.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <published>2022-02-07T00:09:39Z</published>
    <arxiv:comment>Appeared in Why-21 workshop of NeurIPS 2021 (Causal Inference &amp; Machine Learning: Why now?)</arxiv:comment>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Adnan Darwiche</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.08615v1</id>
    <title>Bridging Finite and Super Population Causal Inference</title>
    <updated>2017-03-01T01:03:11Z</updated>
    <link href="https://arxiv.org/abs/1702.08615v1"/>
    <link href="https://arxiv.org/pdf/1702.08615v1"/>
    <summary>There are two general views in causal analysis of experimental data: the super population view that the units are an independent sample from some hypothetical infinite populations, and the finite population view that the potential outcomes of the experimental units are fixed and the randomness comes solely from the physical randomization of the treatment assignment. These two views differs conceptually and mathematically, resulting in different sampling variances of the usual difference-in-means estimator of the average causal effect. Practically, however, these two views result in identical variance estimators. By recalling a variance decomposition and exploiting a completeness-type argument, we establish a connection between these two views in completely randomized experiments. This alternative formulation could serve as a template for bridging finite and super population causal inference in other scenarios.</summary>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <published>2017-02-28T02:54:56Z</published>
    <arxiv:primary_category term="math.ST"/>
    <arxiv:journal_ref>Journal of Causal Inference, 2017</arxiv:journal_ref>
    <author>
      <name>Peng Ding</name>
    </author>
    <author>
      <name>Xinran Li</name>
    </author>
    <author>
      <name>Luke W. Miratrix</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.00672v5</id>
    <title>The Inflation Technique for Causal Inference with Latent Variables</title>
    <updated>2019-07-24T00:03:00Z</updated>
    <link href="https://arxiv.org/abs/1609.00672v5"/>
    <link href="https://arxiv.org/pdf/1609.00672v5"/>
    <summary>The problem of causal inference is to determine if a given probability distribution on observed variables is compatible with some causal structure. The difficult case is when the causal structure includes latent variables. We here introduce the $\textit{inflation technique}$ for tackling this problem. An inflation of a causal structure is a new causal structure that can contain multiple copies of each of the original variables, but where the ancestry of each copy mirrors that of the original. To every distribution of the observed variables that is compatible with the original causal structure, we assign a family of marginal distributions on certain subsets of the copies that are compatible with the inflated causal structure. It follows that compatibility constraints for the inflation can be translated into compatibility constraints for the original causal structure. Even if the constraints at the level of inflation are weak, such as observable statistical independences implied by disjoint causal ancestry, the translated constraints can be strong. We apply this method to derive new inequalities whose violation by a distribution witnesses that distribution's incompatibility with the causal structure (of which Bell inequalities and Pearl's instrumental inequality are prominent examples). We describe an algorithm for deriving all such inequalities for the original causal structure that follow from ancestral independences in the inflation. For three observed binary variables with pairwise common causes, it yields inequalities that are stronger in at least some aspects than those obtainable by existing methods. We also describe an algorithm that derives a weaker set of inequalities but is more efficient. Finally, we discuss which inflations are such that the inequalities one obtains from them remain valid even for quantum (and post-quantum) generalizations of the notion of a causal model.</summary>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <published>2016-09-02T17:21:25Z</published>
    <arxiv:comment>Minor final corrections, updated to match the published version as closely as possible</arxiv:comment>
    <arxiv:primary_category term="quant-ph"/>
    <arxiv:journal_ref>J. Causal Inference 7(2), 2019</arxiv:journal_ref>
    <author>
      <name>Elie Wolfe</name>
    </author>
    <author>
      <name>Robert W. Spekkens</name>
    </author>
    <author>
      <name>Tobias Fritz</name>
    </author>
    <arxiv:doi>10.1515/jci-2017-0020</arxiv:doi>
    <link rel="related" href="https://doi.org/10.1515/jci-2017-0020"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2507.14528v1</id>
    <title>Positive-Unlabeled Learning for Control Group Construction in Observational Causal Inference</title>
    <updated>2025-07-22T00:20:07Z</updated>
    <link href="https://arxiv.org/abs/2507.14528v1"/>
    <link href="https://arxiv.org/pdf/2507.14528v1"/>
    <summary>In causal inference, whether through randomized controlled trials or observational studies, access to both treated and control units is essential for estimating the effect of a treatment on an outcome of interest. When treatment assignment is random, the average treatment effect (ATE) can be estimated directly by comparing outcomes between groups. In non-randomized settings, various techniques are employed to adjust for confounding and approximate the counterfactual scenario to recover an unbiased ATE. A common challenge, especially in observational studies, is the absence of units clearly labeled as controls-that is, units known not to have received the treatment. To address this, we propose positive-unlabeled (PU) learning as a framework for identifying, with high confidence, control units from a pool of unlabeled ones, using only the available treated (positive) units. We evaluate this approach using both simulated and real-world data. We construct a causal graph with diverse relationships and use it to generate synthetic data under various scenarios, assessing how reliably the method recovers control groups that allow estimates of true ATE. We also apply our approach to real-world data on optimal sowing and fertilizer treatments in sustainable agriculture. Our findings show that PU learning can successfully identify control (negative) units from unlabeled data based only on treated units and, through the resulting control group, estimate an ATE that closely approximates the true value. This work has important implications for observational causal inference, especially in fields where randomized experiments are difficult or costly. In domains such as earth, environmental, and agricultural sciences, it enables a plethora of quasi-experiments by leveraging available earth observation and climate data, particularly when treated units are available but control units are lacking.</summary>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-07-19T08:06:08Z</published>
    <arxiv:comment>Accepted at KDD 2025 Workshop on Causal Inference and Machine Learning in Practice</arxiv:comment>
    <arxiv:primary_category term="cs.LG"/>
    <author>
      <name>Ilias Tsoumas</name>
    </author>
    <author>
      <name>Dimitrios Bormpoudakis</name>
    </author>
    <author>
      <name>Vasileios Sitokonstantinou</name>
    </author>
    <author>
      <name>Athanasios Askitopoulos</name>
    </author>
    <author>
      <name>Andreas Kalogeras</name>
    </author>
    <author>
      <name>Charalampos Kontoes</name>
    </author>
    <author>
      <name>Ioannis Athanasiadis</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2309.04298v1</id>
    <title>Confidence in Causal Inference under Structure Uncertainty in Linear Causal Models with Equal Variances</title>
    <updated>2024-02-14T01:24:38Z</updated>
    <link href="https://arxiv.org/abs/2309.04298v1"/>
    <link href="https://arxiv.org/pdf/2309.04298v1"/>
    <summary>Inferring the effect of interventions within complex systems is a fundamental problem of statistics. A widely studied approach employs structural causal models that postulate noisy functional relations among a set of interacting variables. The underlying causal structure is then naturally represented by a directed graph whose edges indicate direct causal dependencies. In a recent line of work, additional assumptions on the causal models have been shown to render this causal graph identifiable from observational data alone. One example is the assumption of linear causal relations with equal error variances that we will take up in this work. When the graph structure is known, classical methods may be used for calculating estimates and confidence intervals for causal effects. However, in many applications, expert knowledge that provides an a priori valid causal structure is not available. Lacking alternatives, a commonly used two-step approach first learns a graph and then treats the graph as known in inference. This, however, yields confidence intervals that are overly optimistic and fail to account for the data-driven model choice. We argue that to draw reliable conclusions, it is necessary to incorporate the remaining uncertainty about the underlying causal structure in confidence statements about causal effects. To address this issue, we present a framework based on test inversion that allows us to give confidence regions for total causal effects that capture both sources of uncertainty: causal structure and numerical size of nonzero effects.</summary>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <published>2023-09-08T12:43:18Z</published>
    <arxiv:primary_category term="stat.ME"/>
    <arxiv:journal_ref>J. Causal Inference 11 (1) 20230030, 2023</arxiv:journal_ref>
    <author>
      <name>David Strieder</name>
    </author>
    <author>
      <name>Mathias Drton</name>
    </author>
    <arxiv:doi>10.1515/jci-2023-0030</arxiv:doi>
    <link rel="related" href="https://doi.org/10.1515/jci-2023-0030"/>
  </entry>
</feed>
