<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2026-02-05T01:12:46Z -->
<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/" xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns="http://www.w3.org/2005/Atom">
  <id>https://arxiv.org/api/p6EyKyP4fMY/66n9Ev8E79F7KlI</id>
  <title>arXiv Query: search_query=all:causal OR all:inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <updated>2026-02-05T01:12:46Z</updated>
  <link href="https://arxiv.org/api/query?search_query=all:causal+OR+all:inference&amp;start=0&amp;max_results=10&amp;id_list=" type="application/atom+xml"/>
  <opensearch:itemsPerPage>10</opensearch:itemsPerPage>
  <opensearch:totalResults>132913</opensearch:totalResults>
  <opensearch:startIndex>0</opensearch:startIndex>
  <entry>
    <id>http://arxiv.org/abs/2602.03839v1</id>
    <title>Understanding and Exploiting Weight Update Sparsity for Communication-Efficient Distributed RL</title>
    <updated>2026-02-03T18:56:48Z</updated>
    <link href="https://arxiv.org/abs/2602.03839v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.03839v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Reinforcement learning (RL) is a critical component for post-training large language models (LLMs). However, in bandwidth-constrained distributed RL, scalability is often bottlenecked by the synchronization of policy weights from trainers to inference workers, particularly over commodity networks or in decentralized settings. While recent studies suggest that RL updates modify only a small fraction of model parameters, these observations are typically based on coarse checkpoint differences. We present a systematic empirical study of weight-update sparsity at both step-level and multi-step granularities, examining its evolution across training dynamics, off-policy delay, and model scale. We find that update sparsity is consistently high, frequently exceeding 99% across practically relevant settings. Leveraging this structure, we propose PULSE (Patch Updates via Lossless Sparse Encoding), a simple yet highly efficient lossless weight synchronization method that transmits only the indices and values of modified parameters. PULSE is robust to transmission errors and avoids floating-point drift inherent in additive delta schemes. In bandwidth-constrained decentralized environments, our approach achieves over 100x (14 GB to ~108 MB) communication reduction while maintaining bit-identical training dynamics and performance compared to full weight synchronization. By exploiting this structure, PULSE enables decentralized RL training to approach centralized throughput, reducing the bandwidth required for weight synchronization from 20 Gbit/s to 0.2 Gbit/s to maintain high GPU utilization.</summary>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-03T18:56:48Z</published>
    <arxiv:comment>32 pages, 14 figures</arxiv:comment>
    <arxiv:primary_category term="cs.LG"/>
    <author>
      <name>Erfan Miahi</name>
    </author>
    <author>
      <name>Eugene Belilovsky</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.03829v1</id>
    <title>An Open Database of Lunar Regolith and Simulants Properties</title>
    <updated>2026-02-03T18:44:32Z</updated>
    <link href="https://arxiv.org/abs/2602.03829v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.03829v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Lunar regolith, the layer of unconsolidated material covering the Moon's surface, is central to the science and technology developed for the Moon, notably related to in-situ science investigations, resource utilization, surface infrastructure, and mobility systems. However, data on lunar soil properties remain fragmented across decades of mission reports, often in formats that are difficult to access or interpret. We present a newly compiled database of lunar regolith physical and geotechnical properties, including data collected by direct in-situ measurements from crewed missions, estimates inferred from surface interactions on the Moon and using remote sensing, as well as laboratory analyses of samples returned to Earth. The data collected include, among others, the angle of internal friction and cohesion (both Mohr-Coulomb model parameters), bulk density, and static bearing capacity, extracted from Luna and Apollo-era historical mission documentation all the way to contemporary Lunar programs. The dataset specifies the type and location of the tests from which each value was obtained. Our database also includes parameters for lunar regolith simulants, providing a direct link between mission data and laboratory studies. In addition to centralizing this information, we developed a user interface that facilitates data retrieval, filtering, and visualization. This interface enables users to generate customized plots for comparative analysis. Developed in an open-science perspective, it is designed to evolve in response to the community's needs. The database and its associated tools significantly enhance the accessibility and usability of lunar regolith and simulants data for scientific and engineering research.</summary>
    <category term="astro-ph.EP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.space-ph" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-03T18:44:32Z</published>
    <arxiv:primary_category term="astro-ph.EP"/>
    <author>
      <name>Léonie Gasteiner</name>
    </author>
    <author>
      <name>Naomi Murdoch</name>
    </author>
    <author>
      <name>Olfa D'Angelo</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.03826v1</id>
    <title>Continuous Control of Editing Models via Adaptive-Origin Guidance</title>
    <updated>2026-02-03T18:33:39Z</updated>
    <link href="https://arxiv.org/abs/2602.03826v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.03826v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Diffusion-based editing models have emerged as a powerful tool for semantic image and video manipulation. However, existing models lack a mechanism for smoothly controlling the intensity of text-guided edits. In standard text-conditioned generation, Classifier-Free Guidance (CFG) impacts prompt adherence, suggesting it as a potential control for edit intensity in editing models. However, we show that scaling CFG in these models does not produce a smooth transition between the input and the edited result. We attribute this behavior to the unconditional prediction, which serves as the guidance origin and dominates the generation at low guidance scales, while representing an arbitrary manipulation of the input content. To enable continuous control, we introduce Adaptive-Origin Guidance (AdaOr), a method that adjusts this standard guidance origin with an identity-conditioned adaptive origin, using an identity instruction corresponding to the identity manipulation. By interpolating this identity prediction with the standard unconditional prediction according to the edit strength, we ensure a continuous transition from the input to the edited result. We evaluate our method on image and video editing tasks, demonstrating that it provides smoother and more consistent control compared to current slider-based editing approaches. Our method incorporates an identity instruction into the standard training framework, enabling fine-grained control at inference time without per-edit procedure or reliance on specialized datasets.</summary>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-03T18:33:39Z</published>
    <arxiv:comment>Project page at https://adaor-paper.github.io/</arxiv:comment>
    <arxiv:primary_category term="cs.CV"/>
    <author>
      <name>Alon Wolf</name>
    </author>
    <author>
      <name>Chen Katzir</name>
    </author>
    <author>
      <name>Kfir Aberman</name>
    </author>
    <author>
      <name>Or Patashnik</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.03819v1</id>
    <title>Global Testing in Multivariate Regression Discontinuity Designs</title>
    <updated>2026-02-03T18:22:14Z</updated>
    <link href="https://arxiv.org/abs/2602.03819v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.03819v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Regression discontinuity (RD) designs with multiple running variables arise in a growing number of empirical applications, including geographic boundaries and multi-score assignment rules. Although recent methodological work has extended estimation and inference tools to multivariate settings, far less attention has been devoted to developing global testing methods that formally assess whether a discontinuity exists anywhere along a multivariate treatment boundary. Existing approaches perform well in large samples, but can exhibit severe size distortions in moderate or small samples due to the sparsity of observations near any particular boundary point. This paper introduces a complementary global testing procedure that mitigates the small-sample weaknesses of existing multivariate RD methods by integrating multivariate machine learning estimators with a distance-based aggregation strategy, yielding a test statistic that remains reliable with limited data. Simulations demonstrate that the proposed method maintains near-nominal size and strong power, including in settings where standard multivariate estimators break down. The procedure is applied to an empirical setting to demonstrate its implementation and to illustrate how it can complement existing multivariate RD estimators.</summary>
    <category term="econ.EM" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-03T18:22:14Z</published>
    <arxiv:primary_category term="econ.EM"/>
    <author>
      <name>Artem Samiahulin</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.03817v1</id>
    <title>Adaptive Evidence Weighting for Audio-Spatiotemporal Fusion</title>
    <updated>2026-02-03T18:21:13Z</updated>
    <link href="https://arxiv.org/abs/2602.03817v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.03817v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Many machine learning systems have access to multiple sources of evidence for the same prediction target, yet these sources often differ in reliability and informativeness across inputs. In bioacoustic classification, species identity may be inferred both from the acoustic signal and from spatiotemporal context such as location and season; while Bayesian inference motivates multiplicative evidence combination, in practice we typically only have access to discriminative predictors rather than calibrated generative models. We introduce \textbf{F}usion under \textbf{IN}dependent \textbf{C}onditional \textbf{H}ypotheses (\textbf{FINCH}), an adaptive log-linear evidence fusion framework that integrates a pre-trained audio classifier with a structured spatiotemporal predictor. FINCH learns a per-sample gating function that estimates the reliability of contextual information from uncertainty and informativeness statistics. The resulting fusion family \emph{contains} the audio-only classifier as a special case and explicitly bounds the influence of contextual evidence, yielding a risk-contained hypothesis class with an interpretable audio-only fallback. Across benchmarks, FINCH consistently outperforms fixed-weight fusion and audio-only baselines, improving robustness and error trade-offs even when contextual information is weak in isolation. We achieve state-of-the-art performance on CBI and competitive or improved performance on several subsets of BirdSet using a lightweight, interpretable, evidence-based approach. Code is available: \texttt{\href{https://anonymous.4open.science/r/birdnoise-85CD/README.md}{anonymous-repository}}</summary>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-03T18:21:13Z</published>
    <arxiv:primary_category term="cs.SD"/>
    <author>
      <name>Oscar Ovanger</name>
    </author>
    <author>
      <name>Levi Harris</name>
    </author>
    <author>
      <name>Timothy H. Keitt</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.03815v1</id>
    <title>Fast-Slow Efficient Training for Multimodal Large Language Models via Visual Token Pruning</title>
    <updated>2026-02-03T18:18:11Z</updated>
    <link href="https://arxiv.org/abs/2602.03815v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.03815v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Multimodal Large Language Models (MLLMs) suffer from severe training inefficiency issue, which is associated with their massive model sizes and visual token numbers. Existing efforts in efficient training focus on reducing model sizes or trainable parameters. Inspired by the success of Visual Token Pruning (VTP) in improving inference efficiency, we are exploring another substantial research direction for efficient training by reducing visual tokens. However, applying VTP at the training stage results in a training-inference mismatch: pruning-trained models perform poorly when inferring on non-pruned full visual token sequences. To close this gap, we propose DualSpeed, a fast-slow framework for efficient training of MLLMs. The fast-mode is the primary mode, which incorporates existing VTP methods as plugins to reduce visual tokens, along with a mode isolator to isolate the model's behaviors. The slow-mode is the auxiliary mode, where the model is trained on full visual sequences to retain training-inference consistency. To boost its training, it further leverages self-distillation to learn from the sufficiently trained fast-mode. Together, DualSpeed can achieve both training efficiency and non-degraded performance. Experiments show DualSpeed accelerates the training of LLaVA-1.5 by 2.1$\times$ and LLaVA-NeXT by 4.0$\times$, retaining over 99% performance. Code: https://github.com/dingkun-zhang/DualSpeed</summary>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-03T18:18:11Z</published>
    <arxiv:primary_category term="cs.CV"/>
    <author>
      <name>Dingkun Zhang</name>
    </author>
    <author>
      <name>Shuhan Qi</name>
    </author>
    <author>
      <name>Yulin Wu</name>
    </author>
    <author>
      <name>Xinyu Xiao</name>
    </author>
    <author>
      <name>Xuan Wang</name>
    </author>
    <author>
      <name>Long Chen</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.03801v1</id>
    <title>Digital-Twin Empowered Deep Reinforcement Learning For Site-Specific Radio Resource Management in NextG Wireless Aerial Corridor</title>
    <updated>2026-02-03T18:02:11Z</updated>
    <link href="https://arxiv.org/abs/2602.03801v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.03801v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Joint base station (BS) association and beam selection in multi-UAV aerial corridors constitutes a challenging radio resource management (RRM) problem. It is driven by high-dimensional action spaces, need for substantial overhead to acquire global channel state information (CSI), rapidly varying propagation channels, and stringent latency requirements. Conventional combinatorial optimization methods, while near-optimal, are computationally prohibitive for real-time operation in such dynamic environments. While learning-based approaches can mitigate computational complexity and CSI overhead, the need for extensive site-specific (SS) datasets for model training remains a key challenge. To address these challenges, we develop a Digital Twin (DT)-enabled two-stage optimization framework that couples physics-based beam gain modeling with DRL for scalable online decision-making. In the first stage, a channel twin (CT) is constructed using a high-fidelity ray-tracing solver with geo-spatial contexts, and network information to capture SS propagation characteristics, and dual annealing algorithm is employed to precompute optimal transmission beam directions. In the second stage, a Multi-Head Proximal Policy Optimization (MH-PPO) agent, equipped with a scalable multi-head actor-critic architecture, is trained on the DT-generated channel dataset to directly map complex channel and beam states to jointly execute UAV-BS-beam association decisions. The proposed PPO agent achieves a 44%-121% improvement over DQN and 249%-807% gain over traditional heuristic based optimization schemes in a dense UAV scenario, while reducing inference latency by several orders of magnitude. These results demonstrate that DT-driven training pipelines can deliver high-performance, low-latency RRM policies tailored to SS deployments suitable for real-time resource management in next-generation aerial corridor networks.</summary>
    <category term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-03T18:02:11Z</published>
    <arxiv:comment>Submitted for possible publication to IEEE. Paper currently under review. The contents of this paper may change at any time without notice</arxiv:comment>
    <arxiv:primary_category term="eess.SP"/>
    <author>
      <name>Pulok Tarafder</name>
    </author>
    <author>
      <name>Zoheb Hassan</name>
    </author>
    <author>
      <name>Imtiaz Ahmed</name>
    </author>
    <author>
      <name>Danda B. Rawat</name>
    </author>
    <author>
      <name>Kamrul Hasan</name>
    </author>
    <author>
      <name>Cong Pu</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.03787v1</id>
    <title>Inference-time Unlearning Using Conformal Prediction</title>
    <updated>2026-02-03T17:46:50Z</updated>
    <link href="https://arxiv.org/abs/2602.03787v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.03787v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Machine unlearning is the process of efficiently removing specific information from a trained machine learning model without retraining from scratch. Existing unlearning methods, which often provide provable guarantees, typically involve retraining a subset of model parameters based on a forget set. While these approaches show promise in certain scenarios, their underlying assumptions are often challenged in real-world applications -- particularly when applied to generative models. Furthermore, updating parameters using these unlearning procedures often degrades the general-purpose capabilities the model acquired during pre-training. Motivated by these shortcomings, this paper considers the paradigm of inference time unlearning -- wherein, the generative model is equipped with an (approximately correct) verifier that judges whether the model's response satisfies appropriate unlearning guarantees. This paper introduces a framework that iteratively refines the quality of the generated responses using feedback from the verifier without updating the model parameters. The proposed framework leverages conformal prediction to reduce computational overhead and provide distribution-free unlearning guarantees. This paper's approach significantly outperforms existing state-of-the-art methods, reducing unlearning error by up to 93% across challenging unlearning benchmarks.</summary>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-03T17:46:50Z</published>
    <arxiv:primary_category term="cs.LG"/>
    <author>
      <name>Somnath Basu Roy Chowdhury</name>
    </author>
    <author>
      <name>Rahul Kidambi</name>
    </author>
    <author>
      <name>Avinava Dubey</name>
    </author>
    <author>
      <name>David Wang</name>
    </author>
    <author>
      <name>Gokhan Mergen</name>
    </author>
    <author>
      <name>Amr Ahmed</name>
    </author>
    <author>
      <name>Aranyak Mehta</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.03784v1</id>
    <title>Context Compression via Explicit Information Transmission</title>
    <updated>2026-02-03T17:44:12Z</updated>
    <link href="https://arxiv.org/abs/2602.03784v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.03784v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Long-context inference with Large Language Models (LLMs) is costly due to quadratic attention and growing key-value caches, motivating context compression. In this work, we study soft context compression, where a long context is condensed into a small set of continuous representations. Existing methods typically re-purpose the LLM itself as a trainable compressor, relying on layer-by-layer self-attention to iteratively aggregate information. We argue that this paradigm suffers from two structural limitations: (i) progressive representation overwriting across layers (ii) uncoordinated allocation of compression capacity across tokens. We propose ComprExIT (Context Compression via Explicit Information Transmission), a lightweight framework that formulates soft compression into a new paradigm: explicit information transmission over frozen LLM hidden states. This decouples compression from the model's internal self-attention dynamics. ComprExIT performs (i) depth-wise transmission to selectively transmit multi-layer information into token anchors, mitigating progressive overwriting, and (ii) width-wise transmission to aggregate anchors into a small number of slots via a globally optimized transmission plan, ensuring coordinated allocation of information. Across six question-answering benchmarks, ComprExIT consistently outperforms state-of-the-art context compression methods while introducing only ~1% additional parameters, demonstrating that explicit and coordinated information transmission enables more effective and robust long-context compression.</summary>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-03T17:44:12Z</published>
    <arxiv:primary_category term="cs.CL"/>
    <author>
      <name>Jiangnan Ye</name>
    </author>
    <author>
      <name>Hanqi Yan</name>
    </author>
    <author>
      <name>Zhenyi Shen</name>
    </author>
    <author>
      <name>Heng Chang</name>
    </author>
    <author>
      <name>Ye Mao</name>
    </author>
    <author>
      <name>Yulan He</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.03781v1</id>
    <title>A Scene Graph Backed Approach to Open Set Semantic Mapping</title>
    <updated>2026-02-03T17:41:51Z</updated>
    <link href="https://arxiv.org/abs/2602.03781v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.03781v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>While Open Set Semantic Mapping and 3D Semantic Scene Graphs (3DSSGs) are established paradigms in robotic perception, deploying them effectively to support high-level reasoning in large-scale, real-world environments remains a significant challenge. Most existing approaches decouple perception from representation, treating the scene graph as a derivative layer generated post hoc. This limits both consistency and scalability. In contrast, we propose a mapping architecture where the 3DSSG serves as the foundational backend, acting as the primary knowledge representation for the entire mapping process.
  Our approach leverages prior work on incremental scene graph prediction to infer and update the graph structure in real-time as the environment is explored. This ensures that the map remains topologically consistent and computationally efficient, even during extended operations in large-scale settings. By maintaining an explicit, spatially grounded representation that supports both flat and hierarchical topologies, we bridge the gap between sub-symbolic raw sensor data and high-level symbolic reasoning. Consequently, this provides a stable, verifiable structure that knowledge-driven frameworks, ranging from knowledge graphs and ontologies to Large Language Models (LLMs), can directly exploit, enabling agents to operate with enhanced interpretability, trustworthiness, and alignment to human concepts.</summary>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-03T17:41:51Z</published>
    <arxiv:primary_category term="cs.RO"/>
    <author>
      <name>Martin Günther</name>
    </author>
    <author>
      <name>Felix Igelbrink</name>
    </author>
    <author>
      <name>Oscar Lima</name>
    </author>
    <author>
      <name>Lennart Niecksch</name>
    </author>
    <author>
      <name>Marian Renz</name>
    </author>
    <author>
      <name>Martin Atzmueller</name>
    </author>
  </entry>
</feed>
