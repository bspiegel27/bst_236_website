<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-10-21T00:55:16Z -->
<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acausal%20inference%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:causal inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/SsRksLzRb0LuVhSmQ+N8WbAs+f8</id>
  <updated>2025-10-20T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">123981</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">10</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2510.15862v1</id>
    <updated>2025-10-17T17:53:06Z</updated>
    <published>2025-10-17T17:53:06Z</published>
    <title>PokeeResearch: Effective Deep Research via Reinforcement Learning from
  AI Feedback and Robust Reasoning Scaffold</title>
    <summary>  Tool-augmented large language models (LLMs) are emerging as deep research
agents, systems that decompose complex queries, retrieve external evidence, and
synthesize grounded responses. Yet current agents remain limited by shallow
retrieval, weak alignment metrics, and brittle tool-use behavior. We introduce
PokeeResearch-7B, a 7B-parameter deep research agent built under a unified
reinforcement learning framework for robustness, alignment, and scalability.
PokeeResearch-7B is trained by an annotation-free Reinforcement Learning from
AI Feedback (RLAIF) framework to optimize policies using LLM-based reward
signals that capture factual accuracy, citation faithfulness, and instruction
adherence. A chain-of-thought-driven multi-call reasoning scaffold further
enhances robustness through self-verification and adaptive recovery from tool
failures. Among 10 popular deep research benchmarks, PokeeResearch-7B achieves
state-of-the-art performance among 7B-scale deep research agents. This
highlights that careful reinforcement learning and reasoning design can produce
efficient, resilient, and research-grade AI agents. The model and inference
code is open-sourced under MIT license at
https://github.com/Pokee-AI/PokeeResearchOSS.
</summary>
    <author>
      <name>Yi Wan</name>
    </author>
    <author>
      <name>Jiuqi Wang</name>
    </author>
    <author>
      <name>Liam Li</name>
    </author>
    <author>
      <name>Jinsong Liu</name>
    </author>
    <author>
      <name>Ruihao Zhu</name>
    </author>
    <author>
      <name>Zheqing Zhu</name>
    </author>
    <link href="http://arxiv.org/abs/2510.15862v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.15862v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.15860v1</id>
    <updated>2025-10-17T17:52:07Z</updated>
    <published>2025-10-17T17:52:07Z</published>
    <title>Quantum Monte Carlo Calculations of Light Nuclei with Fully Propagated
  Theoretical Uncertainties</title>
    <summary>  We report on the first quantum Monte Carlo calculations of helium isotopes
with fully propagated theoretical uncertainties from the interaction to the
many-body observables. To achieve this, we build emulators for solutions to the
Faddeev equations for the binding energy and Gamow-Teller matrix element of
$^3\text{H}$, as well as for auxiliary-field diffusion Monte Carlo calculations
of the $^4\text{He}$ charge radius, employing local two- and three-body
interactions up to next-to-next-to-leading order in chiral effective field
theory. We use these emulators to determine the posterior distributions for all
low-energy couplings that appear in the interaction up to this order using
Bayesian inference while accounting for theoretical uncertainties. We then
build emulators for auxiliary-field diffusion Monte Carlo for helium isotopes
and propagate the full posterior distributions to these systems. Our approach
serves as a framework for $\textit{ab initio}$ studies of atomic nuclei with
consistently treated and correlated theoretical uncertainties.
</summary>
    <author>
      <name>Ryan Curry</name>
    </author>
    <author>
      <name>Kai Hebeler</name>
    </author>
    <author>
      <name>Stefano Gandolfi</name>
    </author>
    <author>
      <name>Alexandros Gezerlis</name>
    </author>
    <author>
      <name>Achim Schwenk</name>
    </author>
    <author>
      <name>Rahul Somasundaram</name>
    </author>
    <author>
      <name>Ingo Tews</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2510.15860v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.15860v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="nucl-th" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nucl-th" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.15857v1</id>
    <updated>2025-10-17T17:50:58Z</updated>
    <published>2025-10-17T17:50:58Z</published>
    <title>BLIP3o-NEXT: Next Frontier of Native Image Generation</title>
    <summary>  We present BLIP3o-NEXT, a fully open-source foundation model in the BLIP3
series that advances the next frontier of native image generation. BLIP3o-NEXT
unifies text-to-image generation and image editing within a single
architecture, demonstrating strong image generation and image editing
capabilities. In developing the state-of-the-art native image generation model,
we identify four key insights: (1) Most architectural choices yield comparable
performance; an architecture can be deemed effective provided it scales
efficiently and supports fast inference; (2) The successful application of
reinforcement learning can further push the frontier of native image
generation; (3) Image editing still remains a challenging task, yet instruction
following and the consistency between generated and reference images can be
significantly enhanced through post-training and data engine; (4) Data quality
and scale continue to be decisive factors that determine the upper bound of
model performance. Building upon these insights, BLIP3o-NEXT leverages an
Autoregressive + Diffusion architecture in which an autoregressive model first
generates discrete image tokens conditioned on multimodal inputs, whose hidden
states are then used as conditioning signals for a diffusion model to generate
high-fidelity images. This architecture integrates the reasoning strength and
instruction following of autoregressive models with the fine-detail rendering
ability of diffusion models, achieving a new level of coherence and realism.
Extensive evaluations of various text-to-image and image-editing benchmarks
show that BLIP3o-NEXT achieves superior performance over existing models.
</summary>
    <author>
      <name>Jiuhai Chen</name>
    </author>
    <author>
      <name>Le Xue</name>
    </author>
    <author>
      <name>Zhiyang Xu</name>
    </author>
    <author>
      <name>Xichen Pan</name>
    </author>
    <author>
      <name>Shusheng Yang</name>
    </author>
    <author>
      <name>Can Qin</name>
    </author>
    <author>
      <name>An Yan</name>
    </author>
    <author>
      <name>Honglu Zhou</name>
    </author>
    <author>
      <name>Zeyuan Chen</name>
    </author>
    <author>
      <name>Lifu Huang</name>
    </author>
    <author>
      <name>Tianyi Zhou</name>
    </author>
    <author>
      <name>Junnan Li</name>
    </author>
    <author>
      <name>Silvio Savarese</name>
    </author>
    <author>
      <name>Caiming Xiong</name>
    </author>
    <author>
      <name>Ran Xu</name>
    </author>
    <link href="http://arxiv.org/abs/2510.15857v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.15857v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.15843v1</id>
    <updated>2025-10-17T17:36:05Z</updated>
    <published>2025-10-17T17:36:05Z</published>
    <title>Enhanced Sentiment Interpretation via a Lexicon-Fuzzy-Transformer
  Framework</title>
    <summary>  Accurately detecting sentiment polarity and intensity in product reviews and
social media posts remains challenging due to informal and domain-specific
language. To address this, we propose a novel hybrid lexicon-fuzzy-transformer
framework that combines rule-based heuristics, contextual deep learning, and
fuzzy logic to generate continuous sentiment scores reflecting both polarity
and strength. The pipeline begins with VADER-based initial sentiment
estimations, which are refined through a two-stage adjustment process. This
involves leveraging confidence scores from DistilBERT, a lightweight
transformer and applying fuzzy logic principles to mitigate excessive
neutrality bias and enhance granularity. A custom fuzzy inference system then
maps the refined scores onto a 0 to 1 continuum, producing expert)like
judgments. The framework is rigorously evaluated on four domain-specific
datasets. food delivery, e-commerce, tourism, and fashion. Results show
improved alignment with user ratings, better identification of sentiment
extremes, and reduced misclassifications. Both quantitative metrics
(distributional alignment, confusion matrices) and qualitative insights (case
studies, runtime analysis) affirm the models robustness and efficiency. This
work demonstrates the value of integrating symbolic reasoning with neural
models for interpretable, finegrained sentiment analysis in linguistically
dynamic domains.
</summary>
    <author>
      <name>Shayan Rokhva</name>
    </author>
    <author>
      <name>Mousa Alizadeh</name>
    </author>
    <author>
      <name>Maryam Abdollahi Shamami</name>
    </author>
    <link href="http://arxiv.org/abs/2510.15843v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.15843v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.15824v1</id>
    <updated>2025-10-17T17:06:47Z</updated>
    <published>2025-10-17T17:06:47Z</published>
    <title>Blackwell's Approachability for Sequential Conformal Inference</title>
    <summary>  We study conformal inference in non-exchangeable environments through the
lens of Blackwell's theory of approachability. We first recast adaptive
conformal inference (ACI, Gibbs and Cand\`es, 2021) as a repeated two-player
vector-valued finite game and characterize attainable coverage--efficiency
tradeoffs. We then construct coverage and efficiency objectives under potential
restrictions on the adversary's play, and design a calibration-based
approachability strategy to achieve these goals. The resulting algorithm enjoys
strong theoretical guarantees and provides practical insights, though its
computational burden may limit deployment in practice.
</summary>
    <author>
      <name>Guillaume Principato</name>
    </author>
    <author>
      <name>Gilles Stoltz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages, 0 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2510.15824v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.15824v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91A26 62G08" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.15821v1</id>
    <updated>2025-10-17T17:00:53Z</updated>
    <published>2025-10-17T17:00:53Z</published>
    <title>Chronos-2: From Univariate to Universal Forecasting</title>
    <summary>  Pretrained time series models have enabled inference-only forecasting systems
that produce accurate predictions without task-specific training. However,
existing approaches largely focus on univariate forecasting, limiting their
applicability in real-world scenarios where multivariate data and covariates
play a crucial role. We present Chronos-2, a pretrained model capable of
handling univariate, multivariate, and covariate-informed forecasting tasks in
a zero-shot manner. Chronos-2 employs a group attention mechanism that
facilitates in-context learning (ICL) through efficient information sharing
across multiple time series within a group, which may represent sets of related
series, variates of a multivariate series, or targets and covariates in a
forecasting task. These general capabilities are achieved through training on
synthetic datasets that impose diverse multivariate structures on univariate
series. Chronos-2 delivers state-of-the-art performance across three
comprehensive benchmarks: fev-bench, GIFT-Eval, and Chronos Benchmark II. On
fev-bench, which emphasizes multivariate and covariate-informed forecasting,
Chronos-2's universal ICL capabilities lead to substantial improvements over
existing models. On tasks involving covariates, it consistently outperforms
baselines by a wide margin. Case studies in the energy and retail domains
further highlight its practical advantages. The in-context learning
capabilities of Chronos-2 establish it as a general-purpose forecasting model
that can be used "as is" in real-world forecasting pipelines.
</summary>
    <author>
      <name>Abdul Fatir Ansari</name>
    </author>
    <author>
      <name>Oleksandr Shchur</name>
    </author>
    <author>
      <name>Jaris KÃ¼ken</name>
    </author>
    <author>
      <name>Andreas Auer</name>
    </author>
    <author>
      <name>Boran Han</name>
    </author>
    <author>
      <name>Pedro Mercado</name>
    </author>
    <author>
      <name>Syama Sundar Rangapuram</name>
    </author>
    <author>
      <name>Huibin Shen</name>
    </author>
    <author>
      <name>Lorenzo Stella</name>
    </author>
    <author>
      <name>Xiyuan Zhang</name>
    </author>
    <author>
      <name>Mononito Goswami</name>
    </author>
    <author>
      <name>Shubham Kapoor</name>
    </author>
    <author>
      <name>Danielle C. Maddix</name>
    </author>
    <author>
      <name>Pablo Guerron</name>
    </author>
    <author>
      <name>Tony Hu</name>
    </author>
    <author>
      <name>Junming Yin</name>
    </author>
    <author>
      <name>Nick Erickson</name>
    </author>
    <author>
      <name>Prateek Mutalik Desai</name>
    </author>
    <author>
      <name>Hao Wang</name>
    </author>
    <author>
      <name>Huzefa Rangwala</name>
    </author>
    <author>
      <name>George Karypis</name>
    </author>
    <author>
      <name>Yuyang Wang</name>
    </author>
    <author>
      <name>Michael Bohlke-Schneider</name>
    </author>
    <link href="http://arxiv.org/abs/2510.15821v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.15821v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.15817v1</id>
    <updated>2025-10-17T16:56:25Z</updated>
    <published>2025-10-17T16:56:25Z</published>
    <title>Error analysis of a compositional score-based algorithm for
  simulation-based inference</title>
    <summary>  Simulation-based inference (SBI) has become a widely used framework in
applied sciences for estimating the parameters of stochastic models that best
explain experimental observations. A central question in this setting is how to
effectively combine multiple observations in order to improve parameter
inference and obtain sharper posterior distributions. Recent advances in
score-based diffusion methods address this problem by constructing a
compositional score, obtained by aggregating individual posterior scores within
the diffusion process. While it is natural to suspect that the accumulation of
individual errors may significantly degrade sampling quality as the number of
observations grows, this important theoretical issue has so far remained
unexplored. In this paper, we study the compositional score produced by the
GAUSS algorithm of Linhart et al. (2024) and establish an upper bound on its
mean squared error in terms of both the individual score errors and the number
of observations. We illustrate our theoretical findings on a Gaussian example,
where all analytical expressions can be derived in a closed form.
</summary>
    <author>
      <name>Camille Touron</name>
    </author>
    <author>
      <name>Gabriel V. Cardoso</name>
    </author>
    <author>
      <name>Julyan Arbel</name>
    </author>
    <author>
      <name>Pedro L. C. Rodrigues</name>
    </author>
    <link href="http://arxiv.org/abs/2510.15817v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.15817v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.15803v1</id>
    <updated>2025-10-17T16:29:02Z</updated>
    <published>2025-10-17T16:29:02Z</published>
    <title>Dynamic Recalibration in LiDAR SLAM: Integrating AI and Geometric
  Methods with Real-Time Feedback Using INAF Fusion</title>
    <summary>  This paper presents a novel fusion technique for LiDAR Simultaneous
Localization and Mapping (SLAM), aimed at improving localization and 3D mapping
using LiDAR sensor. Our approach centers on the Inferred Attention Fusion
(INAF) module, which integrates AI with geometric odometry. Utilizing the KITTI
dataset's LiDAR data, INAF dynamically adjusts attention weights based on
environmental feedback, enhancing the system's adaptability and measurement
accuracy. This method advances the precision of both localization and 3D
mapping, demonstrating the potential of our fusion technique to enhance
autonomous navigation systems in complex scenarios.
</summary>
    <author>
      <name>Zahra Arjmandi</name>
    </author>
    <author>
      <name>Gunho Sohn</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2510.15803v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.15803v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.15798v1</id>
    <updated>2025-10-17T16:21:24Z</updated>
    <published>2025-10-17T16:21:24Z</published>
    <title>Ambusher: Exploring the Security of Distributed SDN Controllers Through
  Protocol State Fuzzing</title>
    <summary>  Distributed SDN (Software-Defined Networking) controllers have rapidly become
an integral element of Wide Area Networks (WAN), particularly within SD-WAN,
providing scalability and fault-tolerance for expansive network
infrastructures. However, the architecture of these controllers introduces new
potential attack surfaces that have thus far received inadequate attention. In
response to these concerns, we introduce Ambusher, a testing tool designed to
discover vulnerabilities within protocols used in distributed SDN controllers.
Ambusher achieves this by leveraging protocol state fuzzing, which
systematically finds attack scenarios based on an inferred state machine. Since
learning states from a cluster is complicated, Ambusher proposes a novel
methodology that extracts a single and relatively simple state machine,
achieving efficient state-based fuzzing. Our evaluation of Ambusher, conducted
on a real SD-WAN deployment spanning two campus networks and one enterprise
network, illustrates its ability to uncover 6 potential vulnerabilities in the
widely used distributed controller platform.
</summary>
    <author>
      <name>Jinwoo Kim</name>
    </author>
    <author>
      <name>Minjae Seo</name>
    </author>
    <author>
      <name>Eduard Marin</name>
    </author>
    <author>
      <name>Seungsoo Lee</name>
    </author>
    <author>
      <name>Jaehyun Nam</name>
    </author>
    <author>
      <name>Seungwon Shin</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TIFS.2024.3402967</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TIFS.2024.3402967" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 16 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Transactions on Information Forensics and Security, Vol. 19,
  pp. 6264-6279, May 2024</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2510.15798v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.15798v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.15787v1</id>
    <updated>2025-10-17T16:09:53Z</updated>
    <published>2025-10-17T16:09:53Z</published>
    <title>Information-theoretic constraints in quantum gravity and cosmology</title>
    <summary>  In this dissertation, we review results on quantum information constraints in
gravity that are relevant to cosmological models and demonstrate how this
approach sheds light on cosmological holography. Using Jackiw-Teitelboim
gravity as a toy model, we establish the validity of the quantum Bousso bound
and prove the restricted quantum focusing conjecture (rQFC), which is a central
assumption in semiclassical gravity and holography. Interestingly, we find
violations of the original QFC in this model. Building on these results, we
introduce a covariant prescription for computing holographic entanglement
entropy in the static patch holography description of de Sitter space and
explore a generalization to closed FLRW spacetimes. This leads us to a
formulation of subregion-subregion duality, where entanglement between
complementary holographic theories gives rise to bulk connectivity. Causality
considerations imply that entanglement wedges are bounded by surfaces that are
not extremal in the usual sense, but instead satisfy an extremization with
constraint. Finally, we discuss the connected wedge theorem, which establishes
a relation between the causal structure of spacetime and information-theoretic
constraints in the holographic dual. We argue that maintaining the consistency
of static patch holography with this theorem leads to constraints on the causal
structure of the dual theory. Our results suggest a novel relationship between
static patch holography and the dS/CFT correspondence.
</summary>
    <author>
      <name>Victor Franken</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">PhD thesis defended in June 2025. Reviews previously published papers
  and additional work. 213 pages. Published version:
  https://theses.hal.science/tel-05283576</arxiv:comment>
    <link href="http://arxiv.org/abs/2510.15787v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.15787v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="hep-th" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-th" scheme="http://arxiv.org/schemas/atom"/>
    <category term="gr-qc" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
