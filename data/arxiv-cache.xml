<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-10-25T00:53:16Z -->
<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acausal%20inference%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:causal inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/SsRksLzRb0LuVhSmQ+N8WbAs+f8</id>
  <updated>2025-10-24T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">124487</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">10</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2510.20815v1</id>
    <updated>2025-10-23T17:59:31Z</updated>
    <published>2025-10-23T17:59:31Z</published>
    <title>Generative Reasoning Recommendation via LLMs</title>
    <summary>  Despite their remarkable reasoning capabilities across diverse domains, large
language models (LLMs) face fundamental challenges in natively functioning as
generative reasoning recommendation models (GRRMs), where the intrinsic
modeling gap between textual semantics and collaborative filtering signals,
combined with the sparsity and stochasticity of user feedback, presents
significant obstacles. This work explores how to build GRRMs by adapting
pre-trained LLMs, which achieves a unified understanding-reasoning-prediction
manner for recommendation tasks. We propose GREAM, an end-to-end framework that
integrates three components: (i) Collaborative-Semantic Alignment, which fuses
heterogeneous textual evidence to construct semantically consistent, discrete
item indices and auxiliary alignment tasks that ground linguistic
representations in interaction semantics; (ii) Reasoning Curriculum Activation,
which builds a synthetic dataset with explicit Chain-of-Thought supervision and
a curriculum that progresses through behavioral evidence extraction, latent
preference modeling, intent inference, recommendation formulation, and denoised
sequence rewriting; and (iii) Sparse-Regularized Group Policy Optimization
(SRPO), which stabilizes post-training via Residual-Sensitive Verifiable Reward
and Bonus-Calibrated Group Advantage Estimation, enabling end-to-end
optimization under verifiable signals despite sparse successes. GREAM natively
supports two complementary inference modes: Direct Sequence Recommendation for
high-throughput, low-latency deployment, and Sequential Reasoning
Recommendation that first emits an interpretable reasoning chain for causal
transparency. Experiments on three datasets demonstrate consistent gains over
strong baselines, providing a practical path toward verifiable-RL-driven LLM
recommenders.
</summary>
    <author>
      <name>Minjie Hong</name>
    </author>
    <author>
      <name>Zetong Zhou</name>
    </author>
    <author>
      <name>Zirun Guo</name>
    </author>
    <author>
      <name>Ziang Zhang</name>
    </author>
    <author>
      <name>Ruofan Hu</name>
    </author>
    <author>
      <name>Weinan Gan</name>
    </author>
    <author>
      <name>Jieming Zhu</name>
    </author>
    <author>
      <name>Zhou Zhao</name>
    </author>
    <link href="http://arxiv.org/abs/2510.20815v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.20815v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.20811v1</id>
    <updated>2025-10-23T17:59:09Z</updated>
    <published>2025-10-23T17:59:09Z</published>
    <title>Simulation-calibrated Bayesian inference for progenitor properties of
  the microquasar SS 433</title>
    <summary>  SS\,433 is one of the most extreme Galactic X-ray binaries, exhibiting
semi-relativistic jets and super-critical accretion, and harboring a compact
object, likely a black hole. Despite decades of observation and modeling, the
precise nature of its progenitor binary remains uncertain. To estimate the
zero-age main sequence (ZAMS) properties of binaries that evolve into
SS\,433-like systems, we apply simulation-based calibration to Bayesian
inference and convolve a multivariate Gaussian likelihood constructed from six
measured binary parameters of SS\,433 with the isolated binary evolution model
\textsc{COSMIC}. Employing the dynamic nested sampler of \texttt{dynesty}, we
perform posterior inference over a ten-dimensional progenitor parameter space
defined by the masses, orbital parameters, mass transfer possibilities, and
natal kick velocity. We find that SS\,433-like systems arise from specific
regions of binary evolution parameter space depending on key assumptions, such
as the mass transfer rate and uncertainty taken from observations. Our
simulation-based calibration framework, implemented with a suite of machine
learning algorithms and scored by a heuristic reliability metric, allows us to
iteratively build posterior distributions of the progenitors of SS\,433-like
systems. This analysis reveals 90\% confidence intervals for the ZAMS primary
mass $(8, 11)$ M$_\odot$, secondary mass $(32, 40)$ M$_\odot $, orbital period
$(136, 2259)$ days, eccentricity $(0.26, 0.6)$, common envelope evolution
efficiency $(0.44, 0.76)$, accreted fraction in stable mass transfer $(0.22,
0.6)$, and black hole natal kick velocity magnitude $(5, 68)$ km/s. These
results demonstrate the feasibility of direct probabilistic inference of X-ray
binary progenitors to offer new insights into the evolution of
high-accretion-rate systems such as SS\,433.
</summary>
    <author>
      <name>Nathan Steinle</name>
    </author>
    <author>
      <name>Matthew Mould</name>
    </author>
    <author>
      <name>Sarah Al-Humaikani</name>
    </author>
    <author>
      <name>Austin MacMaster</name>
    </author>
    <author>
      <name>Brydyn Mac Intyre</name>
    </author>
    <author>
      <name>Samar Safi-Harb</name>
    </author>
    <link href="http://arxiv.org/abs/2510.20811v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.20811v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.HE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.HE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.GA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.SR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.20807v1</id>
    <updated>2025-10-23T17:58:45Z</updated>
    <published>2025-10-23T17:58:45Z</published>
    <title>Video Prediction of Dynamic Physical Simulations With Pixel-Space
  Spatiotemporal Transformers</title>
    <summary>  Inspired by the performance and scalability of autoregressive large language
models (LLMs), transformer-based models have seen recent success in the visual
domain. This study investigates a transformer adaptation for video prediction
with a simple end-to-end approach, comparing various spatiotemporal
self-attention layouts. Focusing on causal modeling of physical simulations
over time; a common shortcoming of existing video-generative approaches, we
attempt to isolate spatiotemporal reasoning via physical object tracking
metrics and unsupervised training on physical simulation datasets. We introduce
a simple yet effective pure transformer model for autoregressive video
prediction, utilizing continuous pixel-space representations for video
prediction. Without the need for complex training strategies or latent
feature-learning components, our approach significantly extends the time
horizon for physically accurate predictions by up to 50% when compared with
existing latent-space approaches, while maintaining comparable performance on
common video quality metrics. In addition, we conduct interpretability
experiments to identify network regions that encode information useful to
perform accurate estimations of PDE simulation parameters via probing models,
and find that this generalizes to the estimation of out-of-distribution
simulation parameters. This work serves as a platform for further
attention-based spatiotemporal modeling of videos via a simple, parameter
efficient, and interpretable approach.
</summary>
    <author>
      <name>Dean L Slack</name>
    </author>
    <author>
      <name>G Thomas Hudson</name>
    </author>
    <author>
      <name>Thomas Winterbottom</name>
    </author>
    <author>
      <name>Noura Al Moubayed</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TNNLS.2025.3585949</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TNNLS.2025.3585949" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 14 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Transactions on Neural Networks and Learning Systems, 36,
  19106-19118, 2025</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2510.20807v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.20807v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.20803v1</id>
    <updated>2025-10-23T17:58:26Z</updated>
    <published>2025-10-23T17:58:26Z</published>
    <title>ARGenSeg: Image Segmentation with Autoregressive Image Generation Model</title>
    <summary>  We propose a novel AutoRegressive Generation-based paradigm for image
Segmentation (ARGenSeg), achieving multimodal understanding and pixel-level
perception within a unified framework. Prior works integrating image
segmentation into multimodal large language models (MLLMs) typically employ
either boundary points representation or dedicated segmentation heads. These
methods rely on discrete representations or semantic prompts fed into
task-specific decoders, which limits the ability of the MLLM to capture
fine-grained visual details. To address these challenges, we introduce a
segmentation framework for MLLM based on image generation, which naturally
produces dense masks for target objects. We leverage MLLM to output visual
tokens and detokenize them into images using an universal VQ-VAE, making the
segmentation fully dependent on the pixel-level understanding of the MLLM. To
reduce inference latency, we employ a next-scale-prediction strategy to
generate required visual tokens in parallel. Extensive experiments demonstrate
that our method surpasses prior state-of-the-art approaches on multiple
segmentation datasets with a remarkable boost in inference speed, while
maintaining strong understanding capabilities.
</summary>
    <author>
      <name>Xiaolong Wang</name>
    </author>
    <author>
      <name>Lixiang Ru</name>
    </author>
    <author>
      <name>Ziyuan Huang</name>
    </author>
    <author>
      <name>Kaixiang Ji</name>
    </author>
    <author>
      <name>Dandan Zheng</name>
    </author>
    <author>
      <name>Jingdong Chen</name>
    </author>
    <author>
      <name>Jun Zhou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to NeurIPS 2025, 18 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2510.20803v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.20803v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.20795v1</id>
    <updated>2025-10-23T17:56:04Z</updated>
    <published>2025-10-23T17:56:04Z</published>
    <title>Bayesian Inference of Primordial Magnetic Field Parameters from CMB with
  Spherical Graph Neural Networks</title>
    <summary>  Deep learning has emerged as a transformative methodology in modern
cosmology, providing powerful tools to extract meaningful physical information
from complex astronomical datasets. This paper implements a novel Bayesian
graph deep learning framework for estimating key cosmological parameters in a
primordial magnetic field (PMF) cosmology directly from simulated Cosmic
Microwave Background (CMB) maps. Our methodology utilizes DeepSphere, a
spherical convolutional neural network architecture specifically designed to
respect the spherical geometry of CMB data through HEALPix pixelization. To
advance beyond deterministic point estimates and enable robust uncertainty
quantification, we integrate Bayesian Neural Networks (BNNs) into the
framework, capturing aleatoric and epistemic uncertainties that reflect the
model confidence in its predictions. The proposed approach demonstrates
exceptional performance, achieving $R^{2}$ scores exceeding 0.89 for the
magnetic parameter estimation. We further obtain well-calibrated uncertainty
estimates through post-hoc training techniques including Variance Scaling and
GPNormal. This integrated DeepSphere-BNNs framework not only delivers accurate
parameter estimation from CMB maps with PMF contributions but also provides
reliable uncertainty quantification, providing the necessary tools for robust
cosmological inference in the era of precision cosmology.
</summary>
    <author>
      <name>Juan Alejandro Pinto Castro</name>
    </author>
    <author>
      <name>Héctor J. Hortúa</name>
    </author>
    <author>
      <name>Jorge Enrique García-Farieta</name>
    </author>
    <author>
      <name>Roger Anderson Hurtado</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 6 figures, 4 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2510.20795v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.20795v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.20792v1</id>
    <updated>2025-10-23T17:54:17Z</updated>
    <published>2025-10-23T17:54:17Z</published>
    <title>BadGraph: A Backdoor Attack Against Latent Diffusion Model for
  Text-Guided Graph Generation</title>
    <summary>  The rapid progress of graph generation has raised new security concerns,
particularly regarding backdoor vulnerabilities. While prior work has explored
backdoor attacks in image diffusion and unconditional graph generation,
conditional, especially text-guided graph generation remains largely
unexamined. This paper proposes BadGraph, a backdoor attack method targeting
latent diffusion models for text-guided graph generation. BadGraph leverages
textual triggers to poison training data, covertly implanting backdoors that
induce attacker-specified subgraphs during inference when triggers appear,
while preserving normal performance on clean inputs. Extensive experiments on
four benchmark datasets (PubChem, ChEBI-20, PCDes, MoMu) demonstrate the
effectiveness and stealth of the attack: less than 10% poisoning rate can
achieves 50% attack success rate, while 24% suffices for over 80% success rate,
with negligible performance degradation on benign samples. Ablation studies
further reveal that the backdoor is implanted during VAE and diffusion training
rather than pretraining. These findings reveal the security vulnerabilities in
latent diffusion models of text-guided graph generation, highlight the serious
risks in models' applications such as drug discovery and underscore the need
for robust defenses against the backdoor attack in such diffusion models.
</summary>
    <author>
      <name>Liang Ye</name>
    </author>
    <author>
      <name>Shengqin Chen</name>
    </author>
    <author>
      <name>Jiazhu Dai</name>
    </author>
    <link href="http://arxiv.org/abs/2510.20792v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.20792v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.BM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.20785v1</id>
    <updated>2025-10-23T17:52:40Z</updated>
    <published>2025-10-23T17:52:40Z</published>
    <title>Debiasing cosmological parameters from large-scale foreground
  contamination in Cosmic Microwave Background data</title>
    <summary>  Current and future Cosmic Microwave Background (CMB) experiments aim to
achieve high-precision reconstruction of the CMB polarization signal, with the
most ambitious objective being the detection of primordial $B$ modes sourced by
cosmic inflation. Given the expected low amplitude of the signal, its estimate,
parametrized by the tensor-to-scalar ratio $r$, is highly susceptible to
contamination from Galactic foreground residuals that remain after component
separation. In this work, we introduce an agnostic, model-independent procedure
to construct a spectral template of residual foreground contamination in the
observed angular power spectrum. Specifically, a cleaned multifrequency set of
foreground-emission maps is blindly reconstructed from the observed data using
the Generalized Needlet Internal Linear Combination (GNILC) technique. These
maps are then combined with the weights adopted for CMB reconstruction,
yielding an estimate of the spatial distribution of foreground residuals after
component separation. The power spectrum of this residual map, after proper
noise debiasing, is incorporated into the spectral model of the cosmological
likelihood, thereby enabling unbiased inference of cosmological parameters. We
validate the method on realistic simulations of a LiteBIRD-like experiment,
focusing on constraints on the tensor-to-scalar ratio. We demonstrate that
including the residual template in the likelihood yields unbiased estimates of
$r$, regardless of its input value, the assumed foreground model, or the
adopted masking strategy, thus proving the robustness of the proposed
procedure. The pipeline has been made publicly available as part of the BROOM
Python package (https://github.com/alecarones/broom).
</summary>
    <author>
      <name>Alessandro Carones</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 5 figures. Comments are welcome</arxiv:comment>
    <link href="http://arxiv.org/abs/2510.20785v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.20785v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.20778v1</id>
    <updated>2025-10-23T17:48:11Z</updated>
    <published>2025-10-23T17:48:11Z</published>
    <title>Lens Model Accuracy in the Expected LSST Lensed AGN Sample</title>
    <summary>  Strong gravitational lensing of active galactic nuclei (AGN) enables
measurements of cosmological parameters through time-delay cosmography (TDC).
With data from the upcoming LSST survey, we anticipate using a sample of
O(1000) lensed AGN for TDC. To prepare for this dataset and enable this
measurement, we construct and analyze a realistic mock sample of 1300 systems
drawn from the OM10 (Oguri &amp; Marshall 2010) catalog of simulated lenses with
AGN sources at $z&lt;3.1$ in order to test a key aspect of the analysis pipeline,
that of the lens modeling. We realize the lenses as power law elliptical mass
distributions and simulate 5-year LSST i-band coadd images. From every image,
we infer the lens mass model parameters using neural posterior estimation
(NPE). Focusing on the key model parameters, $\theta_E$ (the Einstein Radius)
and $\gamma_{lens}$ (the projected mass density profile slope), with consistent
mass-light ellipticity correlations in test and training data, we recover
$\theta_E$ with less than 1% bias per lens, 6.5% precision per lens and
$\gamma_{lens}$ with less than 3% bias per lens, 8% precision per lens. We find
that lens light subtraction prior to modeling is only useful when applied to
data sampled from the training prior. If emulated deconvolution is applied to
the data prior to modeling, precision improves across all parameters by a
factor of 2. Finally, we combine the inferred lens mass models using Bayesian
Hierarchical Inference to recover the global properties of the lens sample with
less than 1% bias.
</summary>
    <author>
      <name>Padmavathi Venkatraman</name>
    </author>
    <author>
      <name>Sydney Erickson</name>
    </author>
    <author>
      <name>Phil Marshall</name>
    </author>
    <author>
      <name>Martin Millon</name>
    </author>
    <author>
      <name>Philip Holloway</name>
    </author>
    <author>
      <name>Simon Birrer</name>
    </author>
    <author>
      <name>Steven Dillmann</name>
    </author>
    <author>
      <name>Xiangyu Huang</name>
    </author>
    <author>
      <name>Sreevani Jaragula</name>
    </author>
    <author>
      <name>Ralf Kaehler</name>
    </author>
    <author>
      <name>Narayan Khadka</name>
    </author>
    <author>
      <name>Grzegorz Madejski</name>
    </author>
    <author>
      <name>Ayan Mitra</name>
    </author>
    <author>
      <name>Kevin Reil</name>
    </author>
    <author>
      <name>Aaron Roodman</name>
    </author>
    <author>
      <name>the LSST Dark Energy Science Collaboration</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">30 pages, 14 figures, submitted to AJ</arxiv:comment>
    <link href="http://arxiv.org/abs/2510.20778v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.20778v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.20776v1</id>
    <updated>2025-10-23T17:47:38Z</updated>
    <published>2025-10-23T17:47:38Z</published>
    <title>CUPID: Pose-Grounded Generative 3D Reconstruction from a Single Image</title>
    <summary>  This work proposes a new generation-based 3D reconstruction method, named
Cupid, that accurately infers the camera pose, 3D shape, and texture of an
object from a single 2D image. Cupid casts 3D reconstruction as a conditional
sampling process from a learned distribution of 3D objects, and it jointly
generates voxels and pixel-voxel correspondences, enabling robust pose and
shape estimation under a unified generative framework. By representing both
input camera poses and 3D shape as a distribution in a shared 3D latent space,
Cupid adopts a two-stage flow matching pipeline: (1) a coarse stage that
produces initial 3D geometry with associated 2D projections for pose recovery;
and (2) a refinement stage that integrates pose-aligned image features to
enhance structural fidelity and appearance details. Extensive experiments
demonstrate Cupid outperforms leading 3D reconstruction methods with an over 3
dB PSNR gain and an over 10% Chamfer Distance reduction, while matching
monocular estimators on pose accuracy and delivering superior visual fidelity
over baseline 3D generative models. For an immersive view of the 3D results
generated by Cupid, please visit cupid3d.github.io.
</summary>
    <author>
      <name>Binbin Huang</name>
    </author>
    <author>
      <name>Haobin Duan</name>
    </author>
    <author>
      <name>Yiqun Zhao</name>
    </author>
    <author>
      <name>Zibo Zhao</name>
    </author>
    <author>
      <name>Yi Ma</name>
    </author>
    <author>
      <name>Shenghua Gao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">project page at https://cupid3d.github.io</arxiv:comment>
    <link href="http://arxiv.org/abs/2510.20776v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.20776v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.20769v1</id>
    <updated>2025-10-23T17:43:38Z</updated>
    <published>2025-10-23T17:43:38Z</published>
    <title>CSU-PCAST: A Dual-Branch Transformer Framework for medium-range ensemble
  Precipitation Forecasting</title>
    <summary>  Accurate medium-range precipitation forecasting is crucial for
hydrometeorological risk management and disaster mitigation, yet remains
challenging for current numerical weather prediction (NWP) systems. Traditional
ensemble systems such as the Global Ensemble Forecast System (GEFS) struggle to
maintain high skill, especially for moderate and heavy rainfall at extended
lead times. This study develops a deep learning-based ensemble framework for
multi-step precipitation prediction through joint modeling of a comprehensive
set of atmospheric variables. The model is trained on ERA5 reanalysis data at
0.25$^{\circ}$ spatial resolution, with precipitation labels from NASA's
Integrated Multi-satellite Retrievals for Global Precipitation Measurement
(GPM) constellation (IMERG), incorporating 57 input variables, including
upper-air and surface predictors. The architecture employs a patch-based Swin
Transformer backbone with periodic convolutions to handle longitudinal
continuity and integrates time and noise embeddings through conditional layer
normalization. A dual-branch decoder predicts total precipitation and other
variables, with targeted freezing of encoder-decoder pathways for specialized
training. Training minimizes a hybrid loss combining the Continuous Ranked
Probability Score (CRPS) and weighted log1p mean squared error (log1pMSE),
balancing probabilistic accuracy and magnitude fidelity. During inference, the
model ingests real-time Global Forecast System (GFS) initial conditions to
generate 15-day forecasts autoregressively. Evaluation against GEFS using IMERG
data demonstrates higher Critical Success Index (CSI) scores at precipitation
thresholds of 0.1 mm, 1 mm, 10 mm, and 20 mm, highlighting improved performance
for moderate to heavy rainfall.
</summary>
    <author>
      <name>Tianyi Xiong</name>
    </author>
    <author>
      <name>Haonan Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 12 figures, submitted to arXiv under Atmospheric and
  Oceanic Physics (physics.ao-ph) and Machine Learning (cs.LG)</arxiv:comment>
    <link href="http://arxiv.org/abs/2510.20769v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.20769v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
