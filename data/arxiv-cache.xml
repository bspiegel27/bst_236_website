<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-08-21T00:54:10Z -->
<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acausal%20inference%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:causal inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/SsRksLzRb0LuVhSmQ+N8WbAs+f8</id>
  <updated>2025-08-20T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">119276</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">10</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2508.14023v1</id>
    <updated>2025-08-19T17:30:29Z</updated>
    <published>2025-08-19T17:30:29Z</published>
    <title>Oscillation of delay differential equations via the hyper4 convergence</title>
    <summary>  A sharp condition is provided to guarantee that the (nontrivial) solutions of
a DDE of the form $\dot{x}(t)+F(t,x)=0$ $t\geq 0,$ (where $F(t,\cdot)$ is an
odd-like causal operator) either oscillate, or converge monotonically to zero.
The method used is based on the convergence of the sequence of
hyper4-iterations to the Lambert's function.
</summary>
    <author>
      <name>George L. Karakostas</name>
    </author>
    <link href="http://arxiv.org/abs/2508.14023v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.14023v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="39A21 39A12" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.14022v1</id>
    <updated>2025-08-19T17:28:14Z</updated>
    <published>2025-08-19T17:28:14Z</published>
    <title>BLIPs: Bayesian Learned Interatomic Potentials</title>
    <summary>  Machine Learning Interatomic Potentials (MLIPs) are becoming a central tool
in simulation-based chemistry. However, like most deep learning models, MLIPs
struggle to make accurate predictions on out-of-distribution data or when
trained in a data-scarce regime, both common scenarios in simulation-based
chemistry. Moreover, MLIPs do not provide uncertainty estimates by
construction, which are fundamental to guide active learning pipelines and to
ensure the accuracy of simulation results compared to quantum calculations. To
address this shortcoming, we propose BLIPs: Bayesian Learned Interatomic
Potentials. BLIP is a scalable, architecture-agnostic variational Bayesian
framework for training or fine-tuning MLIPs, built on an adaptive version of
Variational Dropout. BLIP delivers well-calibrated uncertainty estimates and
minimal computational overhead for energy and forces prediction at inference
time, while integrating seamlessly with (equivariant) message-passing
architectures. Empirical results on simulation-based computational chemistry
tasks demonstrate improved predictive accuracy with respect to standard MLIPs,
and trustworthy uncertainty estimates, especially in data-scarse or heavy
out-of-distribution regimes. Moreover, fine-tuning pretrained MLIPs with BLIP
yields consistent performance gains and calibrated uncertainties.
</summary>
    <author>
      <name>Dario Coscia</name>
    </author>
    <author>
      <name>Pim de Haan</name>
    </author>
    <author>
      <name>Max Welling</name>
    </author>
    <link href="http://arxiv.org/abs/2508.14022v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.14022v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.14021v1</id>
    <updated>2025-08-19T17:27:47Z</updated>
    <published>2025-08-19T17:27:47Z</published>
    <title>Data Compression with Noise Suppression for Inference under Noisy
  Covariance</title>
    <summary>  In many fields including cosmology, statistical inference often relies on
Gaussian likelihoods whose covariance matrices are estimated from a finite
number of simulations. This finite-sample estimation introduces noise into the
covariance, which propagates to parameter estimates, a phenomenon known as the
Dodelson-Schneider (DS) effect, leading to inflated uncertainties. While the
Massively Optimized Parameter Estimation and Data compression (MOPED) algorithm
offers lossless Fisher information-preserving compression, it does not mitigate
the DS effect when the compression matrix itself is derived from noisy
covariances. In this paper, we propose a modified compression scheme, powered
MOPED ($p$-MOPED), which suppresses noise propagation by balancing information
retention and covariance estimate noise reduction through a tunable power-law
transformation of the sample correlation matrix. We test $p$-MOPED against
standard and diagonal MOPED on toy models and on cosmological data from the
Subaru Hyper Suprime-Cam Year 3 weak lensing survey. Our results demonstrate
that $p$-MOPED consistently outperforms other approaches, especially in regimes
with limited simulations, offering a robust compression strategy for
high-dimensional data analyses under practical constraints.
</summary>
    <author>
      <name>Sunao Sugiyama</name>
    </author>
    <author>
      <name>Minsu Park</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 5 figures, comments welcomed!</arxiv:comment>
    <link href="http://arxiv.org/abs/2508.14021v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.14021v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.13967v1</id>
    <updated>2025-08-19T15:57:55Z</updated>
    <published>2025-08-19T15:57:55Z</published>
    <title>A PC Algorithm for Max-Linear Bayesian Networks</title>
    <summary>  Max-linear Bayesian networks (MLBNs) are a relatively recent class of
structural equation models which arise when the random variables involved have
heavy-tailed distributions. Unlike most directed graphical models, MLBNs are
typically not faithful to d-separation and thus classical causal discovery
algorithms such as the PC algorithm or greedy equivalence search can not be
used to accurately recover the true graph structure. In this paper, we begin
the study of constraint-based discovery algorithms for MLBNs given an oracle
for testing conditional independence in the true, unknown graph. We show that
if the oracle is given by the $\ast$-separation criteria in the true graph,
then the PC algorithm remains consistent despite the presence of additional CI
statements implied by $\ast$-separation. We also introduce a new causal
discovery algorithm named "PCstar" which assumes faithfulness to
$C^\ast$-separation and is able to orient additional edges which cannot be
oriented with only d- or $\ast$-separation.
</summary>
    <author>
      <name>Carlos Am√©ndola</name>
    </author>
    <author>
      <name>Benjamin Hollering</name>
    </author>
    <author>
      <name>Francesco Nowell</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">24 pages, 7 figures, 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/2508.13967v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.13967v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62H22, 14T90, 05C20, 62R01" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.13946v1</id>
    <updated>2025-08-19T15:36:29Z</updated>
    <published>2025-08-19T15:36:29Z</published>
    <title>Partial Identification of Causal Effects for Endogenous Continuous
  Treatments</title>
    <summary>  No unmeasured confounding is a common assumption when reasoning about
counterfactual outcomes, but such an assumption may not be plausible in
observational studies. Sensitivity analysis is often employed to assess the
robustness of causal conclusions to unmeasured confounding, but existing
methods are predominantly designed for binary treatments. In this paper, we
provide natural extensions of two extensively used sensitivity frameworks --
the Rosenbaum and Marginal sensitivity models -- to the setting of continuous
exposures. Our generalization replaces scalar sensitivity parameters with
sensitivity functions that vary with exposure level, enabling richer modeling
and sharper identification bounds. We develop a unified pseudo-outcome
regression formulation for bounding the counterfactual dose-response curve
under both models, and propose corresponding nonparametric estimators which
have second order bias. These estimators accommodate modern machine learning
methods for obtaining nuisance parameter estimators, which are shown to achieve
$L^2$- consistency, minimax rates of convergence under suitable conditions. Our
resulting estimators of bounds for the counterfactual dose-response curve are
shown to be consistent and asymptotic normal allowing for a user-specified
bound on the degree of uncontrolled exposure endogeneity. We also offer a
geometric interpretation that relates the Rosenbaum and Marginal sensitivity
model and guides their practical usage in global versus targeted sensitivity
analysis. The methods are validated through simulations and a real-data
application on the effect of second-hand smoke exposure on blood lead levels in
children.
</summary>
    <author>
      <name>Abhinandan Dalal</name>
    </author>
    <author>
      <name>Eric J. Tchetgen Tchetgen</name>
    </author>
    <link href="http://arxiv.org/abs/2508.13946v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.13946v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="econ.EM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.13941v1</id>
    <updated>2025-08-19T15:30:57Z</updated>
    <published>2025-08-19T15:30:57Z</published>
    <title>A Catalog of M&amp;M Eclipsing Binaries with TESS</title>
    <summary>  We present a catalog of 1292 low-mass (M&amp;M) short-period eclipsing binaries
observed by the TESS mission. Eclipsing binaries are useful for many aspects of
stellar astrophysics, including calibrating stellar models. Catalogs of
eclipsing binary properties provide context for population-level inferences. In
this work, we present our selection criteria for our catalog, along with steps
taken to characterize both the orbital and physical properties of our EBs. We
further detail crucial steps in vetting our catalog to ensure that the stars in
our catalog have a high likelihood of being true M&amp;Ms. We compare distributions
of orbital and physical properties to other relevant datasets. Our sample
consists primarily of binaries with short-period, circular orbits and often
manifest as high-mass ratio "twin" M&amp;Ms. We find that M&amp;Ms do not exhibit an
overdensity of contact binaries, which is different from previous results for
solar-type binaries. Further, we find a tidal circularization period of
approximately 2.7 days, which is significantly shorter compared to the
literature value of 7 days. Finally, we explore the prospects for additional
companions to our M&amp;Ms. Future avenues include spectroscopic follow-up of
bright M&amp;Ms to better-characterize low-mass stellar properties and a deeper
assessment of the presence of tertiary companions.
</summary>
    <author>
      <name>Dominic Oddo</name>
    </author>
    <author>
      <name>Diana Dragomir</name>
    </author>
    <author>
      <name>Brian P. Powell</name>
    </author>
    <author>
      <name>Veselin B. Kostov</name>
    </author>
    <author>
      <name>Te Han</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">29 pages, 14 figures. Submitted to APJ, under review</arxiv:comment>
    <link href="http://arxiv.org/abs/2508.13941v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.13941v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.SR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.SR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.13940v1</id>
    <updated>2025-08-19T15:29:57Z</updated>
    <published>2025-08-19T15:29:57Z</published>
    <title>Convergence Rates for Realizations of Gaussian Random Variables</title>
    <summary>  This paper investigates the approximation of Gaussian random variables in
Banach spaces, focusing on the high-probability bounds for the approximation of
Gaussian random variables using finitely many observations. We derive
non-asymptotic error bounds for the approximation of a Gaussian process $ X $
by its conditional expectation, given finitely many linear functionals.
Specifically, we quantify the difference between the covariance of $ X $ and
its finite-dimensional approximation, establishing a direct relationship
between the quality of the covariance approximation and the convergence of the
process in the Banach space norm. Our approach avoids the reliance on spectral
methods or eigenfunction expansions commonly used in Hilbert space settings,
and instead uses finite, linear observations. This makes our result
particularly suitable for practical applications in nonparametric statistics,
machine learning, and Bayesian inference.
</summary>
    <author>
      <name>Daniel Winkle</name>
    </author>
    <author>
      <name>Ingo Steinwart</name>
    </author>
    <author>
      <name>Bernard Haasdonk</name>
    </author>
    <link href="http://arxiv.org/abs/2508.13940v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.13940v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
    <category term="Primary 60G15, Secondary 62F15" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.13905v1</id>
    <updated>2025-08-19T15:06:04Z</updated>
    <published>2025-08-19T15:06:04Z</published>
    <title>Automated Energy-Aware Time-Series Model Deployment on Embedded FPGAs
  for Resilient Combined Sewer Overflow Management</title>
    <summary>  Extreme weather events, intensified by climate change, increasingly challenge
aging combined sewer systems, raising the risk of untreated wastewater
overflow. Accurate forecasting of sewer overflow basin filling levels can
provide actionable insights for early intervention, helping mitigating
uncontrolled discharge. In recent years, AI-based forecasting methods have
offered scalable alternatives to traditional physics-based models, but their
reliance on cloud computing limits their reliability during communication
outages. To address this, we propose an end-to-end forecasting framework that
enables energy-efficient inference directly on edge devices. Our solution
integrates lightweight Transformer and Long Short-Term Memory (LSTM) models,
compressed via integer-only quantization for efficient on-device execution.
Moreover, an automated hardware-aware deployment pipeline is used to search for
optimal model configurations by jointly minimizing prediction error and energy
consumption on an AMD Spartan-7 XC7S15 FPGA. Evaluated on real-world sewer
data, the selected 8-bit Transformer model, trained on 24 hours of historical
measurements, achieves high accuracy (MSE 0.0376) at an energy cost of 0.370 mJ
per inference. In contrast, the optimal 8-bit LSTM model requires significantly
less energy (0.009 mJ, over 40x lower) but yields 14.89% worse accuracy (MSE
0.0432) and much longer training time. This trade-off highlights the need to
align model selection with deployment priorities, favoring LSTM for ultra-low
energy consumption or Transformer for higher predictive accuracy. In general,
our work enables local, energy-efficient forecasting, contributing to more
resilient combined sewer systems. All code can be found in the GitHub
Repository (https://github.com/tianheng-ling/EdgeOverflowForecast).
</summary>
    <author>
      <name>Tianheng Ling</name>
    </author>
    <author>
      <name>Vipin Singh</name>
    </author>
    <author>
      <name>Chao Qian</name>
    </author>
    <author>
      <name>Felix Biessmann</name>
    </author>
    <author>
      <name>Gregor Schiele</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 6 figures, 1 table, accepted by the 11th IEEE International
  Smart Cities Conference</arxiv:comment>
    <link href="http://arxiv.org/abs/2508.13905v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.13905v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.13904v1</id>
    <updated>2025-08-19T15:05:55Z</updated>
    <published>2025-08-19T15:05:55Z</published>
    <title>Revisiting Diffusion Q-Learning: From Iterative Denoising to One-Step
  Action Generation</title>
    <summary>  The generative power of diffusion models (DMs) has recently enabled
high-performing decision-making algorithms in offline reinforcement learning
(RL), achieving state-of-the-art results across standard benchmarks. Among
them, Diffusion Q-Learning (DQL) stands out as a leading method for its
consistently strong performance. Nevertheless, DQL remains limited in practice
due to its reliance on multi-step denoising for action generation during both
training and inference. Although one-step denoising is desirable, simply
applying it to DQL leads to a drastic performance drop. In this work, we
revisit DQL and identify its core limitations. We then propose One-Step Flow
Q-Learning (OFQL), a novel framework that enables efficient one-step action
generation during both training and inference, without requiring auxiliary
models, distillation, or multi-phase training. Specifically, OFQL reformulates
DQL within the sample-efficient Flow Matching (FM) framework. While
conventional FM induces curved generative trajectories that impede one-step
generation, OFQL instead learns an average velocity field that facilitates
direct, accurate action generation. Collectively, OFQL eliminates the need for
multi-step sampling and recursive gradient updates in DQL, resulting in faster
and more robust training and inference. Extensive experiments on the D4RL
benchmark demonstrate that OFQL outperforms DQL and other diffusion-based
baselines, while substantially reducing both training and inference time
compared to DQL.
</summary>
    <author>
      <name>Thanh Nguyen</name>
    </author>
    <author>
      <name>Chang D. Yoo</name>
    </author>
    <link href="http://arxiv.org/abs/2508.13904v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.13904v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.13890v1</id>
    <updated>2025-08-19T14:54:20Z</updated>
    <published>2025-08-19T14:54:20Z</published>
    <title>Diffusion-Driven High-Dimensional Variable Selection</title>
    <summary>  Variable selection for high-dimensional, highly correlated data has long been
a challenging problem, often yielding unstable and unreliable models. We
propose a resample-aggregate framework that exploits diffusion models' ability
to generate high-fidelity synthetic data. Specifically, we draw multiple
pseudo-data sets from a diffusion model fitted to the original data, apply any
off-the-shelf selector (e.g., lasso or SCAD), and store the resulting inclusion
indicators and coefficients. Aggregating across replicas produces a stable
subset of predictors with calibrated stability scores for variable selection.
Theoretically, we show that the proposed method is selection consistent under
mild assumptions. Because the generative model imports knowledge from large
pre-trained weights, the procedure naturally benefits from transfer learning,
boosting power when the observed sample is small or noisy. We also extend the
framework of aggregating synthetic data to other model selection problems,
including graphical model selection, and statistical inference that supports
valid confidence intervals and hypothesis tests. Extensive simulations show
consistent gains over the lasso, stability selection, and knockoff baselines,
especially when predictors are strongly correlated, achieving higher
true-positive rates and lower false-discovery proportions. By coupling
diffusion-based data augmentation with principled aggregation, our method
advances variable selection methodology and broadens the toolkit for
interpretable, statistically rigorous analysis in complex scientific
applications.
</summary>
    <author>
      <name>Minjie Wang</name>
    </author>
    <author>
      <name>Xiaotong Shen</name>
    </author>
    <author>
      <name>Wei Pan</name>
    </author>
    <link href="http://arxiv.org/abs/2508.13890v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.13890v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
