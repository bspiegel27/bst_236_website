<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-12-11T01:00:48Z -->
<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/" xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns="http://www.w3.org/2005/Atom">
  <id>https://arxiv.org/api/p6EyKyP4fMY/66n9Ev8E79F7KlI</id>
  <title>arXiv Query: search_query=all:causal OR all:inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <updated>2025-12-11T01:00:50Z</updated>
  <link href="https://arxiv.org/api/query?search_query=all:causal+OR+all:inference&amp;start=0&amp;max_results=10&amp;id_list=" type="application/atom+xml"/>
  <opensearch:itemsPerPage>10</opensearch:itemsPerPage>
  <opensearch:totalResults>128251</opensearch:totalResults>
  <opensearch:startIndex>0</opensearch:startIndex>
  <entry>
    <id>http://arxiv.org/abs/2512.08932v1</id>
    <title>Hot Jupiters are Inflated Primarily by Shallow Heating</title>
    <updated>2025-12-09T18:59:59Z</updated>
    <link href="https://arxiv.org/abs/2512.08932v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.08932v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>The unexpectedly large radii of transiting hot Jupiters have led to many proposals for the physical mechanisms responsible for heating their interiors. While it has been shown that hot Jupiters reinflate as their host stars brighten due to heating deep in planetary interiors, young hot Jupiters also exhibit signs of delayed cooling possibly related to heating closer to their surfaces. To investigate this tension, we enhance our previously published hot Jupiter thermal evolution model by adding a parameter that allows for both deep heating and delayed cooling. We fit our thermal evolution models to a homogeneous, physically self-consistent catalog of accurate and precise hot Jupiter system properties in a hierarchical Bayesian framework. We find that hot Jupiters' interior cooling rates are reduced on average by 95\%--98\% compared to simpler anomalous heating models. The most plausible explanation for this inference is substantial shallow heating just below their radiative--convective boundaries that enables reinflation with much less deep heating. Shallow heating by Ohmic dissipation and/or temperature advection are therefore important components of accurate models of hot Jupiter atmospheres, especially in circulation models. If hot Jupiters are inflated primarily by shallow heating as we propose, then we predict that their observed phase curve offsets should increase with temperature in the range $T_{\text{eq}}~\lesssim1500~\text{K}$, peak in the range $1500~\text{K}~\lesssim~T_{\text{eq}}~\lesssim~1800~\text{K}$, and decrease in the range $T_{\text{eq}}~\gtrsim~1800~\text{K}$.</summary>
    <category term="astro-ph.EP" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-09T18:59:59Z</published>
    <arxiv:comment>17 Pages, 4 figures, 2 tables. Submitted to AAS Journals - comments welcome!</arxiv:comment>
    <arxiv:primary_category term="astro-ph.EP"/>
    <author>
      <name>Stephen P. Schmidt</name>
    </author>
    <author>
      <name>Daniel P. Thorngren</name>
    </author>
    <author>
      <name>Kevin C. Schlaufman</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.08931v1</id>
    <title>Astra: General Interactive World Model with Autoregressive Denoising</title>
    <updated>2025-12-09T18:59:57Z</updated>
    <link href="https://arxiv.org/abs/2512.08931v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.08931v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Recent advances in diffusion transformers have empowered video generation models to generate high-quality video clips from texts or images. However, world models with the ability to predict long-horizon futures from past observations and actions remain underexplored, especially for general-purpose scenarios and various forms of actions. To bridge this gap, we introduce Astra, an interactive general world model that generates real-world futures for diverse scenarios (e.g., autonomous driving, robot grasping) with precise action interactions (e.g., camera motion, robot action). We propose an autoregressive denoising architecture and use temporal causal attention to aggregate past observations and support streaming outputs. We use a noise-augmented history memory to avoid over-reliance on past frames to balance responsiveness with temporal coherence. For precise action control, we introduce an action-aware adapter that directly injects action signals into the denoising process. We further develop a mixture of action experts that dynamically route heterogeneous action modalities, enhancing versatility across diverse real-world tasks such as exploration, manipulation, and camera control. Astra achieves interactive, consistent, and general long-term video prediction and supports various forms of interactions. Experiments across multiple datasets demonstrate the improvements of Astra in fidelity, long-range prediction, and action alignment over existing state-of-the-art world models.</summary>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-09T18:59:57Z</published>
    <arxiv:comment>Code is available at: https://github.com/EternalEvan/Astra</arxiv:comment>
    <arxiv:primary_category term="cs.CV"/>
    <author>
      <name>Yixuan Zhu</name>
    </author>
    <author>
      <name>Jiaqi Feng</name>
    </author>
    <author>
      <name>Wenzhao Zheng</name>
    </author>
    <author>
      <name>Yuan Gao</name>
    </author>
    <author>
      <name>Xin Tao</name>
    </author>
    <author>
      <name>Pengfei Wan</name>
    </author>
    <author>
      <name>Jie Zhou</name>
    </author>
    <author>
      <name>Jiwen Lu</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.08924v1</id>
    <title>Efficiently Reconstructing Dynamic Scenes One D4RT at a Time</title>
    <updated>2025-12-09T18:57:21Z</updated>
    <link href="https://arxiv.org/abs/2512.08924v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.08924v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Understanding and reconstructing the complex geometry and motion of dynamic scenes from video remains a formidable challenge in computer vision. This paper introduces D4RT, a simple yet powerful feedforward model designed to efficiently solve this task. D4RT utilizes a unified transformer architecture to jointly infer depth, spatio-temporal correspondence, and full camera parameters from a single video. Its core innovation is a novel querying mechanism that sidesteps the heavy computation of dense, per-frame decoding and the complexity of managing multiple, task-specific decoders. Our decoding interface allows the model to independently and flexibly probe the 3D position of any point in space and time. The result is a lightweight and highly scalable method that enables remarkably efficient training and inference. We demonstrate that our approach sets a new state of the art, outperforming previous methods across a wide spectrum of 4D reconstruction tasks. We refer to the project webpage for animated results: https://d4rt-paper.github.io/.</summary>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-09T18:57:21Z</published>
    <arxiv:comment>Project Page: https://d4rt-paper.github.io/</arxiv:comment>
    <arxiv:primary_category term="cs.CV"/>
    <author>
      <name>Chuhan Zhang</name>
    </author>
    <author>
      <name>Guillaume Le Moing</name>
    </author>
    <author>
      <name>Skanda Koppula</name>
    </author>
    <author>
      <name>Ignacio Rocco</name>
    </author>
    <author>
      <name>Liliane Momeni</name>
    </author>
    <author>
      <name>Junyu Xie</name>
    </author>
    <author>
      <name>Shuyang Sun</name>
    </author>
    <author>
      <name>Rahul Sukthankar</name>
    </author>
    <author>
      <name>Joëlle K Barral</name>
    </author>
    <author>
      <name>Raia Hadsell</name>
    </author>
    <author>
      <name>Zoubin Ghahramani</name>
    </author>
    <author>
      <name>Andrew Zisserman</name>
    </author>
    <author>
      <name>Junlin Zhang</name>
    </author>
    <author>
      <name>Mehdi SM Sajjadi</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.08920v1</id>
    <title>OSMO: Open-Source Tactile Glove for Human-to-Robot Skill Transfer</title>
    <updated>2025-12-09T18:56:30Z</updated>
    <link href="https://arxiv.org/abs/2512.08920v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.08920v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Human video demonstrations provide abundant training data for learning robot policies, but video alone cannot capture the rich contact signals critical for mastering manipulation. We introduce OSMO, an open-source wearable tactile glove designed for human-to-robot skill transfer. The glove features 12 three-axis tactile sensors across the fingertips and palm and is designed to be compatible with state-of-the-art hand-tracking methods for in-the-wild data collection. We demonstrate that a robot policy trained exclusively on human demonstrations collected with OSMO, without any real robot data, is capable of executing a challenging contact-rich manipulation task. By equipping both the human and the robot with the same glove, OSMO minimizes the visual and tactile embodiment gap, enabling the transfer of continuous shear and normal force feedback while avoiding the need for image inpainting or other vision-based force inference. On a real-world wiping task requiring sustained contact pressure, our tactile-aware policy achieves a 72% success rate, outperforming vision-only baselines by eliminating contact-related failure modes. We release complete hardware designs, firmware, and assembly instructions to support community adoption.</summary>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-09T18:56:30Z</published>
    <arxiv:comment>Project website: https://jessicayin.github.io/osmo_tactile_glove/</arxiv:comment>
    <arxiv:primary_category term="cs.RO"/>
    <author>
      <name>Jessica Yin</name>
    </author>
    <author>
      <name>Haozhi Qi</name>
    </author>
    <author>
      <name>Youngsun Wi</name>
    </author>
    <author>
      <name>Sayantan Kundu</name>
    </author>
    <author>
      <name>Mike Lambeta</name>
    </author>
    <author>
      <name>William Yang</name>
    </author>
    <author>
      <name>Changhao Wang</name>
    </author>
    <author>
      <name>Tingfan Wu</name>
    </author>
    <author>
      <name>Jitendra Malik</name>
    </author>
    <author>
      <name>Tess Hellebrekers</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.08911v1</id>
    <title>A Bayesian Approach Study of Hybrid Neutron Stars</title>
    <updated>2025-12-09T18:47:02Z</updated>
    <link href="https://arxiv.org/abs/2512.08911v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.08911v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>In this work, we explore how astronomical observations (specifically measurements of masses, radii, and tidal deformabilities) can constrain the presence of quark matter inside neutron stars, namely the phase transition from nuclear matter to deconfined quark matter. Our approach employs Bayesian analysis to study this phenomenon. Hadronic matter is modeled using the relativistic mean-field (RMF) approximation, for which we have selected two parameter sets: \(NL3^{*}ωρ\), representing hadronic matter with nucleons only, and $EL3ωρ$ with nucleons only and $EL3ωρY$, which includes hyperons. On the other hand deconfined quark matter is modeled using the vector-MIT bag model. For our purpose, the phase transition is implemented using the Maxwell construction. Bayesian inference is performed by tuning three parameters: the bag constant (i.e. $B^{1/4}$), the vector coupling constant \(\left(G_{v}\right)\), and the Dirac sea contribution ($b_{4}$). We found that a phase transition could exist at densities below \(2.0\,n_{0}\) for both the $EL3ωρ- EL3ωρY $ and $NL3^{*}ωρ$ parametrizations. As a consequence, our results also indicate that a hybrid neutron star could have a large quark core that comprises more than \(80\%\) of its size.</summary>
    <category term="nucl-th" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.HE" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-09T18:47:02Z</published>
    <arxiv:comment>19 pages and 24 figures</arxiv:comment>
    <arxiv:primary_category term="nucl-th"/>
    <author>
      <name>Fábio Köpp</name>
    </author>
    <author>
      <name>César H. Lenzi</name>
    </author>
    <author>
      <name>César V. Flores</name>
    </author>
    <author>
      <name>and Débora P. Menezes</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.08898v1</id>
    <title>Self-lensing of moving gravitational-wave sources can break the microlensing crossing timescale degeneracy</title>
    <updated>2025-12-09T18:38:47Z</updated>
    <link href="https://arxiv.org/abs/2512.08898v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.08898v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>When a moving gravitational-wave (GW) source travels behind a massive astrophysical object, its signal is gravitationally lensed, showing a waveform distortion similar to a Paczyński curve. We present a first study of the lensing signature of a massive black hole (MBH) on a frequency-dependent GW signal from a moving binary merger. For both light and GW sources in a Keplerian circular orbit around a MBH lens, the self-lensing geometry breaks the microlensing degeneracy in the Einstein radius crossing timescale $t_{\rm E}$. The duration of the curve ($2 t_{\rm E}$) becomes independent on the MBH mass $M_{\rm MBH}$, and provides a direct measure of the distance $d_{\rm LS}$ to the MBH. However, $M_{\rm MBH}$ remains unknown. We show that, in GW signals, the redshifted mass $M_{{\rm MBH},z}$ can additionally be obtained from the interference pattern, by measuring the modulation period $T$, the GW frequency $f$, and $t_{\rm E}$: $M_{{\rm MBH},z}\simeq 2.5\times 10^6\,M_\odot\,(t_{\rm E}/[100\,{\rm s}])\,(f\,T)^{-1}$. If this lensing signature is not considered, it may be confused with other waveform distortions, especially in the modeling of overlapping signals in next generation ground-based GW detectors. The observation of one of these curves and its associated parameters may help (1) constrain the orbital distance $d_{\rm LS}$ of sources, especially around low mass MBHs at the centers of star clusters and galaxies, (2) additionally estimate the mass $M_{{\rm MBH},z}$ of these MBHs, and (3) infer the orbital inclination of the binary. Simultaneously obtaining $d_{\rm LS}$ and $M_{{\rm MBH},z}$ through self-lensing can help constrain the astrophysical environments where GW signals come from.</summary>
    <category term="astro-ph.HE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.GA" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-09T18:38:47Z</published>
    <arxiv:comment>9 pages, 6 figures. Comments welcome</arxiv:comment>
    <arxiv:primary_category term="astro-ph.HE"/>
    <author>
      <name>Helena Ubach</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.08895v1</id>
    <title>Unsupervised Learning of Density Estimates with Topological Optimization</title>
    <updated>2025-12-09T18:35:51Z</updated>
    <link href="https://arxiv.org/abs/2512.08895v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.08895v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Kernel density estimation is a key component of a wide variety of algorithms in machine learning, Bayesian inference, stochastic dynamics and signal processing. However, the unsupervised density estimation technique requires tuning a crucial hyperparameter: the kernel bandwidth. The choice of bandwidth is critical as it controls the bias-variance trade-off by over- or under-smoothing the topological features. Topological data analysis provides methods to mathematically quantify topological characteristics, such as connected components, loops, voids et cetera, even in high dimensions where visualization of density estimates is impossible. In this paper, we propose an unsupervised learning approach using a topology-based loss function for the automated and unsupervised selection of the optimal bandwidth and benchmark it against classical techniques -- demonstrating its potential across different dimensions.</summary>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-09T18:35:51Z</published>
    <arxiv:primary_category term="cs.LG"/>
    <author>
      <name>Suina Tanweer</name>
    </author>
    <author>
      <name>Firas A. Khasawneh</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.08894v1</id>
    <title>Revisiting the Scaling Properties of Downstream Metrics in Large Language Model Training</title>
    <updated>2025-12-09T18:33:48Z</updated>
    <link href="https://arxiv.org/abs/2512.08894v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.08894v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>While scaling laws for Large Language Models (LLMs) traditionally focus on proxy metrics like pretraining loss, predicting downstream task performance has been considered unreliable. This paper challenges that view by proposing a direct framework to model the scaling of benchmark performance from the training budget. We find that for a fixed token-to-parameter ratio, a simple power law can accurately describe the scaling behavior of log accuracy on multiple popular downstream tasks. Our results show that the direct approach extrapolates better than the previously proposed two-stage procedure, which is prone to compounding errors. Furthermore, we introduce functional forms that predict accuracy across token-to-parameter ratios and account for inference compute under repeated sampling. We validate our findings on models with up to 17B parameters trained on up to 350B tokens across two dataset mixtures. To support reproducibility and encourage future research, we release the complete set of pretraining losses and downstream evaluation results.</summary>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-09T18:33:48Z</published>
    <arxiv:primary_category term="cs.LG"/>
    <author>
      <name>Jakub Krajewski</name>
    </author>
    <author>
      <name>Amitis Shidani</name>
    </author>
    <author>
      <name>Dan Busbridge</name>
    </author>
    <author>
      <name>Sam Wiseman</name>
    </author>
    <author>
      <name>Jason Ramapuram</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.08892v1</id>
    <title>Toward Faithful Retrieval-Augmented Generation with Sparse Autoencoders</title>
    <updated>2025-12-09T18:33:22Z</updated>
    <link href="https://arxiv.org/abs/2512.08892v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.08892v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Retrieval-Augmented Generation (RAG) improves the factuality of large language models (LLMs) by grounding outputs in retrieved evidence, but faithfulness failures, where generations contradict or extend beyond the provided sources, remain a critical challenge. Existing hallucination detection methods for RAG often rely either on large-scale detector training, which requires substantial annotated data, or on querying external LLM judges, which leads to high inference costs. Although some approaches attempt to leverage internal representations of LLMs for hallucination detection, their accuracy remains limited. Motivated by recent advances in mechanistic interpretability, we employ sparse autoencoders (SAEs) to disentangle internal activations, successfully identifying features that are specifically triggered during RAG hallucinations. Building on a systematic pipeline of information-based feature selection and additive feature modeling, we introduce RAGLens, a lightweight hallucination detector that accurately flags unfaithful RAG outputs using LLM internal representations. RAGLens not only achieves superior detection performance compared to existing methods, but also provides interpretable rationales for its decisions, enabling effective post-hoc mitigation of unfaithful RAG. Finally, we justify our design choices and reveal new insights into the distribution of hallucination-related signals within LLMs. The code is available at https://github.com/Teddy-XiongGZ/RAGLens.</summary>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-09T18:33:22Z</published>
    <arxiv:primary_category term="cs.CL"/>
    <author>
      <name>Guangzhi Xiong</name>
    </author>
    <author>
      <name>Zhenghao He</name>
    </author>
    <author>
      <name>Bohan Liu</name>
    </author>
    <author>
      <name>Sanchit Sinha</name>
    </author>
    <author>
      <name>Aidong Zhang</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.08875v1</id>
    <title>When Tables Leak: Attacking String Memorization in LLM-Based Tabular Data Generation</title>
    <updated>2025-12-09T18:06:31Z</updated>
    <link href="https://arxiv.org/abs/2512.08875v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.08875v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Large Language Models (LLMs) have recently demonstrated remarkable performance in generating high-quality tabular synthetic data. In practice, two primary approaches have emerged for adapting LLMs to tabular data generation: (i) fine-tuning smaller models directly on tabular datasets, and (ii) prompting larger models with examples provided in context. In this work, we show that popular implementations from both regimes exhibit a tendency to compromise privacy by reproducing memorized patterns of numeric digits from their training data. To systematically analyze this risk, we introduce a simple No-box Membership Inference Attack (MIA) called LevAtt that assumes adversarial access to only the generated synthetic data and targets the string sequences of numeric digits in synthetic observations. Using this approach, our attack exposes substantial privacy leakage across a wide range of models and datasets, and in some cases, is even a perfect membership classifier on state-of-the-art models. Our findings highlight a unique privacy vulnerability of LLM-based synthetic data generation and the need for effective defenses. To this end, we propose two methods, including a novel sampling strategy that strategically perturbs digits during generation. Our evaluation demonstrates that this approach can defeat these attacks with minimal loss of fidelity and utility of the synthetic data.</summary>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-09T18:06:31Z</published>
    <arxiv:primary_category term="cs.LG"/>
    <author>
      <name>Joshua Ward</name>
    </author>
    <author>
      <name>Bochao Gu</name>
    </author>
    <author>
      <name>Chi-Hua Wang</name>
    </author>
    <author>
      <name>Guang Cheng</name>
    </author>
  </entry>
</feed>
