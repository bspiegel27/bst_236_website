<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-06-29T01:05:07Z -->
<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acausal%20inference%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:causal inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/SsRksLzRb0LuVhSmQ+N8WbAs+f8</id>
  <updated>2025-06-28T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">115857</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">10</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2506.21527v1</id>
    <updated>2025-06-26T17:48:18Z</updated>
    <published>2025-06-26T17:48:18Z</published>
    <title>Asymptotic Inference for Exchangeable Gibbs Partition</title>
    <summary>  We study the asymptotic properties of parameter estimation and predictive
inference under the exchangeable Gibbs partition, characterized by a discount
parameter $\alpha\in(0,1)$ and a triangular array $v_{n,k}$ satisfying a
backward recursion. Assuming that $v_{n,k}$ admits a mixture representation
over the Ewens--Pitman family $(\alpha, \theta)$, with $\theta$ integrated by
an unknown mixing distribution, we show that the (quasi) maximum likelihood
estimator $\hat\alpha_n$ (QMLE) for $\alpha$ is asymptotically mixed normal.
This generalizes earlier results for the Ewens--Pitman model to a more general
class. We further study the predictive task of estimating the probability
simplex $\mathsf{p}_n$, which governs the allocation of the $(n+1)$-th item,
conditional on the current partition of $[n]$. Based on the asymptotics of the
QMLE $\hat{\alpha}_n$, we construct an estimator $\hat{\mathsf{p}}_n$ and
derive the limit distributions of the $f$-divergence
$\mathsf{D}_f(\hat{\mathsf{p}}_n||\mathsf{p}_n)$ for general convex functions
$f$, including explicit results for the TV distance and KL divergence. These
results lead to asymptotically valid confidence intervals for both parameter
estimation and prediction.
</summary>
    <author>
      <name>Takuya Koriyama</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">35 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2506.21527v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.21527v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.21521v1</id>
    <updated>2025-06-26T17:41:35Z</updated>
    <published>2025-06-26T17:41:35Z</published>
    <title>Potemkin Understanding in Large Language Models</title>
    <summary>  Large language models (LLMs) are regularly evaluated using benchmark
datasets. But what justifies making inferences about an LLM's capabilities
based on its answers to a curated set of questions? This paper first introduces
a formal framework to address this question. The key is to note that the
benchmarks used to test LLMs -- such as AP exams -- are also those used to test
people. However, this raises an implication: these benchmarks are only valid
tests if LLMs misunderstand concepts in ways that mirror human
misunderstandings. Otherwise, success on benchmarks only demonstrates potemkin
understanding: the illusion of understanding driven by answers irreconcilable
with how any human would interpret a concept. We present two procedures for
quantifying the existence of potemkins: one using a specially designed
benchmark in three domains, the other using a general procedure that provides a
lower-bound on their prevalence. We find that potemkins are ubiquitous across
models, tasks, and domains. We also find that these failures reflect not just
incorrect understanding, but deeper internal incoherence in concept
representations.
</summary>
    <author>
      <name>Marina Mancoridis</name>
    </author>
    <author>
      <name>Bec Weeks</name>
    </author>
    <author>
      <name>Keyon Vafa</name>
    </author>
    <author>
      <name>Sendhil Mullainathan</name>
    </author>
    <link href="http://arxiv.org/abs/2506.21521v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.21521v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.21517v1</id>
    <updated>2025-06-26T17:39:30Z</updated>
    <published>2025-06-26T17:39:30Z</published>
    <title>The Relation between Solar Spicules and Magnetohydrodynamic Shocks</title>
    <summary>  Spicules are thin, elongated jet-like features seen in observations of the
solar atmosphere, at the interface between the solar photosphere and the
corona. These features exhibit highly complex dynamics and are a necessary
connecting link between the cooler, denser solar chromosphere and the extremely
hot, tenuous corona. In this work, we explore the spatial and temporal relation
between solar spicules and magneto-hydrodynamic (MHD) shocks using data from a
2D radiative MHD (rMHD) simulation of the solar atmosphere driven by solar
convection. Here, we demonstrate, through direct identification, that slow MHD
shocks, which propagate along magnetic field lines, are regions of strong
positive vertical acceleration of the plasma that forms the tip of the spicule
material during its rise phase. We quantify the effect of pressure and Lorentz
forces on the acceleration of the plasma inside the shocks during the rise of
spicules. The causality between spicule and shock propagation in the atmosphere
of the model is also investigated. It is further shown that the strength of
these shocks may play a vital role in determining the height of the spicules,
supporting the idea that shocks act as drivers of some spicules. In addition,
we also find the presence of structures similar to propagating coronal
disturbances (PCDs) in the simulation, linked with the spicules. Here, PCDs
appear to be associated with the shock waves driving the spicules that
subsequently propagate into the corona and have similar speeds to those
reported in observations.
</summary>
    <author>
      <name>Sankalp Srivastava</name>
    </author>
    <author>
      <name>Piyali Chatterjee</name>
    </author>
    <author>
      <name>Sahel Dey</name>
    </author>
    <author>
      <name>Robertus Erd√©lyi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 11 figures. Accepted for publication in ApJ. The animation
  is available as an ancillary file</arxiv:comment>
    <link href="http://arxiv.org/abs/2506.21517v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.21517v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.SR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.SR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.21509v1</id>
    <updated>2025-06-26T17:35:40Z</updated>
    <published>2025-06-26T17:35:40Z</published>
    <title>Mitigating Hallucination of Large Vision-Language Models via Dynamic
  Logits Calibration</title>
    <summary>  Large Vision-Language Models (LVLMs) have demonstrated significant
advancements in multimodal understanding, yet they are frequently hampered by
hallucination-the generation of text that contradicts visual input. Existing
training-free decoding strategies exhibit critical limitations, including the
use of static constraints that do not adapt to semantic drift during
generation, inefficiency stemming from the need for multiple forward passes,
and degradation of detail due to overly rigid intervention rules. To overcome
these challenges, this paper introduces Dynamic Logits Calibration (DLC), a
novel training-free decoding framework designed to dynamically align text
generation with visual evidence at inference time. At the decoding phase, DLC
step-wise employs CLIP to assess the semantic alignment between the input image
and the generated text sequence. Then, the Relative Visual Advantage (RVA) of
candidate tokens is evaluated against a dynamically updated contextual
baseline, adaptively adjusting output logits to favor tokens that are visually
grounded. Furthermore, an adaptive weighting mechanism, informed by a real-time
context alignment score, carefully balances the visual guidance while ensuring
the overall quality of the textual output. Extensive experiments conducted
across diverse benchmarks and various LVLM architectures (such as LLaVA,
InstructBLIP, and MiniGPT-4) demonstrate that DLC significantly reduces
hallucinations, outperforming current methods while maintaining high inference
efficiency by avoiding multiple forward passes. Overall, we present an
effective and efficient decoding-time solution to mitigate hallucinations,
thereby enhancing the reliability of LVLMs for more practices. Code will be
released on Github.
</summary>
    <author>
      <name>Jiahe Chen</name>
    </author>
    <author>
      <name>Jiaying He</name>
    </author>
    <author>
      <name>Qian Shao</name>
    </author>
    <author>
      <name>Qiyuan Chen</name>
    </author>
    <author>
      <name>Jiahe Ying</name>
    </author>
    <author>
      <name>Hongxia Xu</name>
    </author>
    <author>
      <name>Jintai Chen</name>
    </author>
    <author>
      <name>Jianwei Zheng</name>
    </author>
    <author>
      <name>Jian Wu</name>
    </author>
    <link href="http://arxiv.org/abs/2506.21509v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.21509v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.21501v1</id>
    <updated>2025-06-26T17:29:36Z</updated>
    <published>2025-06-26T17:29:36Z</published>
    <title>Causal inference via implied interventions</title>
    <summary>  In the context of having an instrumental variable, the standard practice in
causal inference begins by targeting an effect of interest and proceeds by
formulating assumptions enabling identification of this effect. We turn this
around by simply not making assumptions anymore and just adhere to the
interventions we can identify, rather than starting with a desired causal
estimand and imposing untestable hypotheses. The randomization of an instrument
and its exclusion restriction define a class of auxiliary stochastic
interventions on the treatment that are implied by stochastic interventions on
the instrument. This mapping effectively characterizes the identifiable causal
effects of the treatment on the outcome given the observable probability
distribution, leading to an explicit transparent G-computation formula under
hidden confounding. Alternatively, searching for an intervention on the
instrument whose implied one best approximates a desired target -- whose causal
effect the user aims to estimate -- naturally leads to a projection on a
function space representing the closest identifiable treatment effect. The
generality of this projection allows to select different norms and indexing
sets for the function class that turn optimization into different estimation
procedures with the Highly Adaptive Lasso. This shift from identification under
assumptions to identification under observation redefines how the problem of
causal inference is approached.
</summary>
    <author>
      <name>Carlos Garc√≠a Meixide</name>
    </author>
    <author>
      <name>Mark J. van der Laan</name>
    </author>
    <link href="http://arxiv.org/abs/2506.21501v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.21501v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.21467v1</id>
    <updated>2025-06-26T16:54:39Z</updated>
    <published>2025-06-26T16:54:39Z</published>
    <title>Efficient and Reuseable Cloud Configuration Search Using Discovery
  Spaces</title>
    <summary>  Finding the optimal set of cloud resources to deploy a given workload at
minimal cost while meeting a defined service level agreement is an active area
of research. Combining tens of parameters applicable across a large selection
of compute, storage, and services offered by cloud providers with similar
numbers of application-specific parameters leads to configuration spaces with
millions of deployment options.
  In this paper, we propose Discovery Space, an abstraction that formalizes the
description of workload configuration problems, and exhibits a set of
characteristics required for structured, robust and distributed investigations
of large search spaces. We describe a concrete implementation of the Discovery
Space abstraction and show that it is generalizable across a diverse set of
workloads such as Large Language Model inference and Big Data Analytics.
  We demonstrate that our approach enables safe, transparent sharing of data
between executions of best-of-breed optimizers increasing the efficiency of
optimal configuration detection in large search spaces. We also demonstrate how
Discovery Spaces enable transfer and reuse of knowledge across similar search
spaces, enabling configuration search speed-ups of over 90%.
</summary>
    <author>
      <name>Michael Johnston</name>
    </author>
    <author>
      <name>Burkhard Ringlein</name>
    </author>
    <author>
      <name>Christoph Hagleitner</name>
    </author>
    <author>
      <name>Alessandro Pomponio</name>
    </author>
    <author>
      <name>Vassilis Vassiliadis</name>
    </author>
    <author>
      <name>Christian Pinto</name>
    </author>
    <author>
      <name>Srikumar Venugopal</name>
    </author>
    <link href="http://arxiv.org/abs/2506.21467v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.21467v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.21428v1</id>
    <updated>2025-06-26T16:11:05Z</updated>
    <published>2025-06-26T16:11:05Z</published>
    <title>Imaginary Time Formalism for Causal Nonlinear Response Functions</title>
    <summary>  It is well established that causal linear response functions can be found by
computing the much simpler imaginary time-ordered Matsubara functions and
performing an analytic continuation. This principle is the basis for much of
our understanding of linear response for interacting and disordered systems,
via diagrammatic perturbation theory. Similar imaginary-time approaches have
recently been introduced for computing nonlinear response functions as well,
although the rigorous connection between Matsubara and causal nonlinear
response functions has not been clearly elucidated. In this work, we provide a
proof of this connection to all orders in perturbation theory. Using an
equations of motion approach, we show by induction that casual nonlinear
response functions at every order can be obtained from an analytic continuation
of an appropriate time-ordered Matsubara function. We demonstrate this
connection explicitly for second order response functions in the Lehmann
representation. As a byproduct of our approach, we derive an explicit
expression for the Lehmann representation of $n$-th order response functions by
solving the equations of motion. We also use our result to find an analytic
spectral density representation for both causal response functions and
Matsubara functions. Finally, we show how our results lead to a family of
generalized sum rules, focusing explicitly on the asymptotic expression for
$n$-th harmonic generation rate.
</summary>
    <author>
      <name>Sounak Sinha</name>
    </author>
    <author>
      <name>Barry Bradlyn</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7+15pgs</arxiv:comment>
    <link href="http://arxiv.org/abs/2506.21428v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.21428v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.mes-hall" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.mes-hall" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.21427v1</id>
    <updated>2025-06-26T16:09:53Z</updated>
    <published>2025-06-26T16:09:53Z</published>
    <title>Flow-Based Single-Step Completion for Efficient and Expressive Policy
  Learning</title>
    <summary>  Generative models such as diffusion and flow-matching offer expressive
policies for offline reinforcement learning (RL) by capturing rich, multimodal
action distributions, but their iterative sampling introduces high inference
costs and training instability due to gradient propagation across sampling
steps. We propose the \textit{Single-Step Completion Policy} (SSCP), a
generative policy trained with an augmented flow-matching objective to predict
direct completion vectors from intermediate flow samples, enabling accurate,
one-shot action generation. In an off-policy actor-critic framework, SSCP
combines the expressiveness of generative models with the training and
inference efficiency of unimodal policies, without requiring long
backpropagation chains. Our method scales effectively to offline,
offline-to-online, and online RL settings, offering substantial gains in speed
and adaptability over diffusion-based baselines. We further extend SSCP to
goal-conditioned RL, enabling flat policies to exploit subgoal structures
without explicit hierarchical inference. SSCP achieves strong results across
standard offline RL and behavior cloning benchmarks, positioning it as a
versatile, expressive, and efficient framework for deep RL and sequential
decision-making.
</summary>
    <author>
      <name>Prajwal Koirala</name>
    </author>
    <author>
      <name>Cody Fleming</name>
    </author>
    <link href="http://arxiv.org/abs/2506.21427v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.21427v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.21408v1</id>
    <updated>2025-06-26T15:54:45Z</updated>
    <published>2025-06-26T15:54:45Z</published>
    <title>Scalable Bayesian Low-Rank Adaptation of Large Language Models via
  Stochastic Variational Subspace Inference</title>
    <summary>  Despite their widespread use, large language models (LLMs) are known to
hallucinate incorrect information and be poorly calibrated. This makes the
uncertainty quantification of these models of critical importance, especially
in high-stakes domains, such as autonomy and healthcare. Prior work has made
Bayesian deep learning-based approaches to this problem more tractable by
performing inference over the low-rank adaptation (LoRA) parameters of a
fine-tuned model. While effective, these approaches struggle to scale to larger
LLMs due to requiring further additional parameters compared to LoRA. In this
work we present $\textbf{Scala}$ble $\textbf{B}$ayesian $\textbf{L}$ow-Rank
Adaptation via Stochastic Variational Subspace Inference (ScalaBL). We perform
Bayesian inference in an $r$-dimensional subspace, for LoRA rank $r$. By
repurposing the LoRA parameters as projection matrices, we are able to map
samples from this subspace into the full weight space of the LLM. This allows
us to learn all the parameters of our approach using stochastic variational
inference. Despite the low dimensionality of our subspace, we are able to
achieve competitive performance with state-of-the-art approaches while only
requiring ${\sim}1000$ additional parameters. Furthermore, it allows us to
scale up to the largest Bayesian LLM to date, with four times as a many base
parameters as prior work.
</summary>
    <author>
      <name>Colin Samplawski</name>
    </author>
    <author>
      <name>Adam D. Cobb</name>
    </author>
    <author>
      <name>Manoj Acharya</name>
    </author>
    <author>
      <name>Ramneet Kaur</name>
    </author>
    <author>
      <name>Susmit Jha</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at UAI 2025</arxiv:comment>
    <link href="http://arxiv.org/abs/2506.21408v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.21408v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.21387v1</id>
    <updated>2025-06-26T15:36:37Z</updated>
    <published>2025-06-26T15:36:37Z</published>
    <title>Early Stopping Tabular In-Context Learning</title>
    <summary>  Tabular foundation models have shown strong performance across various
tabular learning tasks via in-context learning, offering robust generalization
without any downstream finetuning. However, their inference-time costs remain
high, particularly for larger datasets. To address this, we propose
early-stopping the in-context learning process. We achieve this by dynamically
evaluating whether to stop in-context learning after each Transformer encoder
layer. Once stopped, we decode the embedding using a pre-trained layer-wise
decoder. Experiments across 34 small classification tasks size show that early
stopping in-context learning accelerates inference by up to x1.3 with
negligible degradation in predictive performance. To assess scalability, we
further evaluate our method on five larger classification tasks, achieving
speedups of up to x2.2. Our results demonstrate the potential of early exiting
as an effective and practical strategy for improving the efficiency of tabular
in-context learning.
</summary>
    <author>
      <name>Jaris K√ºken</name>
    </author>
    <author>
      <name>Lennart Purucker</name>
    </author>
    <author>
      <name>Frank Hutter</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICML Workshop Paper</arxiv:comment>
    <link href="http://arxiv.org/abs/2506.21387v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.21387v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
