<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-06-24T00:58:37Z -->
<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acausal%20inference%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:causal inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/SsRksLzRb0LuVhSmQ+N8WbAs+f8</id>
  <updated>2025-06-23T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">115461</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">10</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2506.17201v1</id>
    <updated>2025-06-20T17:50:37Z</updated>
    <published>2025-06-20T17:50:37Z</published>
    <title>Hunyuan-GameCraft: High-dynamic Interactive Game Video Generation with
  Hybrid History Condition</title>
    <summary>  Recent advances in diffusion-based and controllable video generation have
enabled high-quality and temporally coherent video synthesis, laying the
groundwork for immersive interactive gaming experiences. However, current
methods face limitations in dynamics, generality, long-term consistency, and
efficiency, which limit the ability to create various gameplay videos. To
address these gaps, we introduce Hunyuan-GameCraft, a novel framework for
high-dynamic interactive video generation in game environments. To achieve
fine-grained action control, we unify standard keyboard and mouse inputs into a
shared camera representation space, facilitating smooth interpolation between
various camera and movement operations. Then we propose a hybrid
history-conditioned training strategy that extends video sequences
autoregressively while preserving game scene information. Additionally, to
enhance inference efficiency and playability, we achieve model distillation to
reduce computational overhead while maintaining consistency across long
temporal sequences, making it suitable for real-time deployment in complex
interactive environments. The model is trained on a large-scale dataset
comprising over one million gameplay recordings across over 100 AAA games,
ensuring broad coverage and diversity, then fine-tuned on a carefully annotated
synthetic dataset to enhance precision and control. The curated game scene data
significantly improves the visual fidelity, realism and action controllability.
Extensive experiments demonstrate that Hunyuan-GameCraft significantly
outperforms existing models, advancing the realism and playability of
interactive game video generation.
</summary>
    <author>
      <name>Jiaqi Li</name>
    </author>
    <author>
      <name>Junshu Tang</name>
    </author>
    <author>
      <name>Zhiyong Xu</name>
    </author>
    <author>
      <name>Longhuang Wu</name>
    </author>
    <author>
      <name>Yuan Zhou</name>
    </author>
    <author>
      <name>Shuai Shao</name>
    </author>
    <author>
      <name>Tianbao Yu</name>
    </author>
    <author>
      <name>Zhiguo Cao</name>
    </author>
    <author>
      <name>Qinglin Lu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Project page: https://hunyuan-gamecraft.github.io/</arxiv:comment>
    <link href="http://arxiv.org/abs/2506.17201v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.17201v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.17193v1</id>
    <updated>2025-06-20T17:46:15Z</updated>
    <published>2025-06-20T17:46:15Z</published>
    <title>Any nonincreasing convergence curves are simultaneously possible for
  GMRES and weighted GMRES, as well as for left and right preconditioned GMRES</title>
    <summary>  The convergence of the GMRES linear solver is notoriously hard to predict. A
particularly enlightening result by [Greenbaum, Pt\'ak, Strako\v{s}, 1996] is
that, given any convergence curve, one can build a linear system for which
GMRES realizes that convergence curve. What is even more extraordinary is that
the eigenvalues of the problem matrix can be chosen arbitrarily. We build upon
this idea to derive novel results about weighted GMRES. We prove that for any
linear system and any prescribed convergence curve, there exists a weight
matrix M for which weighted GMRES (i.e., GMRES in the inner product induced by
M) realizes that convergence curve, and we characterize the form of M.
Additionally, we exhibit a necessary and sufficient condition on M for the
simultaneous prescription of two convergence curves, one realized by GMRES in
the Euclidean inner product, and the other in the inner product induced by M.
These results are then applied to infer some properties of preconditioned GMRES
when the preconditioner is applied either on the left or on the right. For
instance, we show that any two convergence curves are simultaneously possible
for left and right preconditioned GMRES.
</summary>
    <author>
      <name>Pierre Matalon</name>
    </author>
    <author>
      <name>Nicole Spillane</name>
    </author>
    <link href="http://arxiv.org/abs/2506.17193v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.17193v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65F10, 65Y05, 68W40" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.17188v1</id>
    <updated>2025-06-20T17:42:13Z</updated>
    <published>2025-06-20T17:42:13Z</published>
    <title>Towards AI Search Paradigm</title>
    <summary>  In this paper, we introduce the AI Search Paradigm, a comprehensive blueprint
for next-generation search systems capable of emulating human information
processing and decision-making. The paradigm employs a modular architecture of
four LLM-powered agents (Master, Planner, Executor and Writer) that dynamically
adapt to the full spectrum of information needs, from simple factual queries to
complex multi-stage reasoning tasks. These agents collaborate dynamically
through coordinated workflows to evaluate query complexity, decompose problems
into executable plans, and orchestrate tool usage, task execution, and content
synthesis. We systematically present key methodologies for realizing this
paradigm, including task planning and tool integration, execution strategies,
aligned and robust retrieval-augmented generation, and efficient LLM inference,
spanning both algorithmic techniques and infrastructure-level optimizations. By
providing an in-depth guide to these foundational components, this work aims to
inform the development of trustworthy, adaptive, and scalable AI search
systems.
</summary>
    <author>
      <name>Yuchen Li</name>
    </author>
    <author>
      <name>Hengyi Cai</name>
    </author>
    <author>
      <name>Rui Kong</name>
    </author>
    <author>
      <name>Xinran Chen</name>
    </author>
    <author>
      <name>Jiamin Chen</name>
    </author>
    <author>
      <name>Jun Yang</name>
    </author>
    <author>
      <name>Haojie Zhang</name>
    </author>
    <author>
      <name>Jiayi Li</name>
    </author>
    <author>
      <name>Jiayi Wu</name>
    </author>
    <author>
      <name>Yiqun Chen</name>
    </author>
    <author>
      <name>Changle Qu</name>
    </author>
    <author>
      <name>Keyi Kong</name>
    </author>
    <author>
      <name>Wenwen Ye</name>
    </author>
    <author>
      <name>Lixin Su</name>
    </author>
    <author>
      <name>Xinyu Ma</name>
    </author>
    <author>
      <name>Long Xia</name>
    </author>
    <author>
      <name>Daiting Shi</name>
    </author>
    <author>
      <name>Jiashu Zhao</name>
    </author>
    <author>
      <name>Haoyi Xiong</name>
    </author>
    <author>
      <name>Shuaiqiang Wang</name>
    </author>
    <author>
      <name>Dawei Yin</name>
    </author>
    <link href="http://arxiv.org/abs/2506.17188v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.17188v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.17180v1</id>
    <updated>2025-06-20T17:35:36Z</updated>
    <published>2025-06-20T17:35:36Z</published>
    <title>CLEAR-3K: Assessing Causal Explanatory Capabilities in Language Models</title>
    <summary>  We introduce CLEAR-3K, a dataset of 3,000 assertion-reasoning questions
designed to evaluate whether language models can determine if one statement
causally explains another. Each question present an assertion-reason pair and
challenge language models to distinguish between semantic relatedness and
genuine causal explanatory relationships. Through comprehensive evaluation of
21 state-of-the-art language models (ranging from 0.5B to 72B parameters), we
identify two fundamental findings. First, language models frequently confuse
semantic similarity with causality, relying on lexical and semantic overlap
instead of inferring actual causal explanatory relationships. Second, as
parameter size increases, models tend to shift from being overly skeptical
about causal relationships to being excessively permissive in accepting them.
Despite this shift, performance measured by the Matthews Correlation
Coefficient plateaus at just 0.55, even for the best-performing models.Hence,
CLEAR-3K provides a crucial benchmark for developing and evaluating genuine
causal reasoning in language models, which is an essential capability for
applications that require accurate assessment of causal relationships.
</summary>
    <author>
      <name>Naiming Liu</name>
    </author>
    <author>
      <name>Richard Baraniuk</name>
    </author>
    <author>
      <name>Shashank Sonkar</name>
    </author>
    <link href="http://arxiv.org/abs/2506.17180v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.17180v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.17174v1</id>
    <updated>2025-06-20T17:24:58Z</updated>
    <published>2025-06-20T17:24:58Z</published>
    <title>High-accuracy inference using HfO$_x$S$_y$/HfS$_2$ Memristors</title>
    <summary>  We demonstrate high accuracy classification for handwritten digits from the
MNIST dataset ($\sim$98.00$\%$) and RGB images from the CIFAR-10 dataset
($\sim$86.80$\%$) by using resistive memories based on a 2D van-der-Waals
semiconductor: hafnium disulfide (HfS$_2$). These memories are fabricated via
dry thermal oxidation, forming vertical crossbar HfO$_x$S$_y$/HfS$_2$ devices
with a highly-ordered oxide-semiconductor structure. Our devices operate
without electroforming or current compliance and exhibit multi-state,
non-volatile resistive switching, allowing resistance to be tuned using voltage
pulse trains. Using low-energy potentiation and depression pulses (0.7V-0.995V,
160ns-350ns), we achieve 31 ($\sim$5 bits) stable conductance states with high
linearity, symmetry, and low variation over 100 cycles. Key performance
metrics-such as weight update, quantisation, and retention-are extracted from
these experimental devices. These characteristics are used to simulate neural
networks with our resistive memories as weights. Neural networks are trained on
state-of-the-art (SOTA) digital hardware (CUDA cores) and a baseline inference
accuracy is extracted. IBM's Analog Hardware Acceleration Kit (AIHWKIT) is used
to modify and remap digital weights in the pretrained network, based on the
characteristics of our devices. Simulations account for factors like
conductance linearity, device variation, and converter resolution. In both
image recognition tasks, we demonstrate excellent performance, similar to SOTA,
with only $&lt;$0.07$\%$ and $&lt;$1.00$\%$ difference in inference accuracy for the
MNIST and CIFAR-10 datasets respectively. The forming-free, compliance-free
operation, fast switching, low energy consumption, and high accuracy
classification demonstrate the potential of HfO$_x$S$_y$/HfS$_2$-based
resistive memories for energy-efficient neural network acceleration and
neuromorphic computing.
</summary>
    <author>
      <name>Aferdita Xhameni</name>
    </author>
    <author>
      <name>Antonio Lombardo</name>
    </author>
    <link href="http://arxiv.org/abs/2506.17174v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.17174v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.app-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.app-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.mes-hall" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.17139v1</id>
    <updated>2025-06-20T16:38:29Z</updated>
    <published>2025-06-20T16:38:29Z</published>
    <title>Consistent Sampling and Simulation: Molecular Dynamics with Energy-Based
  Diffusion Models</title>
    <summary>  Diffusion models have recently gained significant attention due to their
effectiveness in various scientific domains, including biochemistry. When
trained on equilibrium molecular distributions, diffusion models provide both:
a generative procedure to sample equilibrium conformations and associated
forces derived from the model's scores. However, using the forces for
coarse-grained molecular dynamics simulations uncovers inconsistencies in the
samples generated via classical diffusion inference and simulation, despite
both originating from the same model. Particularly at the small diffusion
timesteps required for simulations, diffusion models fail to satisfy the
Fokker-Planck equation, which governs how the score should evolve over time. We
interpret this deviation as an indication of the observed inconsistencies and
propose an energy-based diffusion model with a Fokker-Planck-derived
regularization term enforcing consistency. We demonstrate the effectiveness of
our approach on toy systems, alanine dipeptide, and introduce a
state-of-the-art transferable Boltzmann emulator for dipeptides that supports
simulation and demonstrates enhanced consistency and efficient sampling.
</summary>
    <author>
      <name>Michael Plainer</name>
    </author>
    <author>
      <name>Hao Wu</name>
    </author>
    <author>
      <name>Leon Klein</name>
    </author>
    <author>
      <name>Stephan Günnemann</name>
    </author>
    <author>
      <name>Frank Noé</name>
    </author>
    <link href="http://arxiv.org/abs/2506.17139v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.17139v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.chem-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.17121v1</id>
    <updated>2025-06-20T16:21:12Z</updated>
    <published>2025-06-20T16:21:12Z</published>
    <title>Cache Me If You Can: How Many KVs Do You Need for Effective Long-Context
  LMs?</title>
    <summary>  Language models handle increasingly long contexts for tasks such as book
summarization, but this leads to growing memory costs for the key-value (KV)
cache. Many prior works have proposed ways of discarding KVs from memory, but
their approaches are tailored to favorable settings, obscuring caveats like
high peak memory and performance degradation, and a fair comparison between
methods is difficult. In this paper, we propose the *KV footprint* as a unified
metric, which accounts for both the amount of KV entries stored and their
lifespan in memory. We evaluate methods based on the smallest footprint they
attain while preserving performance in both long-context understanding and
generation, with context lengths of up to 128K tokens. This metric reveals the
high peak memory of prior KV eviction methods. One class of methods --
*post-fill eviction* -- has a high footprint due to being incompatible with
eviction during pre-filling. We adapt these methods to be able to evict KVs
during pre-filling, achieving substantially lower KV footprints. We then turn
to *recency eviction* methods, wherein we propose PruLong, an end-to-end
optimization method for learning which attention heads need to retain the full
KV cache and which do not. PruLong saves memory while preserving long-context
performance, achieving 12% smaller KV footprint than prior methods while
retaining performance in challenging recall tasks. Our paper clarifies the
complex tangle of long-context inference methods and paves the way for future
development to minimize the KV footprint.
</summary>
    <author>
      <name>Adithya Bhaskar</name>
    </author>
    <author>
      <name>Alexander Wettig</name>
    </author>
    <author>
      <name>Tianyu Gao</name>
    </author>
    <author>
      <name>Yihe Dong</name>
    </author>
    <author>
      <name>Danqi Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">We release our code publicly at
  https://github.com/princeton-pli/PruLong</arxiv:comment>
    <link href="http://arxiv.org/abs/2506.17121v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.17121v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.17119v1</id>
    <updated>2025-06-20T16:19:28Z</updated>
    <published>2025-06-20T16:19:28Z</published>
    <title>RGBTrack: Fast, Robust Depth-Free 6D Pose Estimation and Tracking</title>
    <summary>  We introduce a robust framework, RGBTrack, for real-time 6D pose estimation
and tracking that operates solely on RGB data, thereby eliminating the need for
depth input for such dynamic and precise object pose tracking tasks. Building
on the FoundationPose architecture, we devise a novel binary search strategy
combined with a render-and-compare mechanism to efficiently infer depth and
generate robust pose hypotheses from true-scale CAD models. To maintain stable
tracking in dynamic scenarios, including rapid movements and occlusions,
RGBTrack integrates state-of-the-art 2D object tracking (XMem) with a Kalman
filter and a state machine for proactive object pose recovery. In addition,
RGBTrack's scale recovery module dynamically adapts CAD models of unknown scale
using an initial depth estimate, enabling seamless integration with modern
generative reconstruction techniques. Extensive evaluations on benchmark
datasets demonstrate that RGBTrack's novel depth-free approach achieves
competitive accuracy and real-time performance, making it a promising practical
solution candidate for application areas including robotics, augmented reality,
and computer vision.
  The source code for our implementation will be made publicly available at
https://github.com/GreatenAnoymous/RGBTrack.git.
</summary>
    <author>
      <name>Teng Guo</name>
    </author>
    <author>
      <name>Jingjin Yu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to IROS 2025</arxiv:comment>
    <link href="http://arxiv.org/abs/2506.17119v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.17119v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.17104v1</id>
    <updated>2025-06-20T16:09:56Z</updated>
    <published>2025-06-20T16:09:56Z</published>
    <title>Towards Advanced Mathematical Reasoning for LLMs via First-Order Logic
  Theorem Proving</title>
    <summary>  Large language models (LLMs) have shown promising first-order logic (FOL)
reasoning capabilities with applications in various areas. However, their
effectiveness in complex mathematical reasoning involving multi-step FOL
deductions is still under-researched. While LLMs perform competitively on
established mathematical reasoning benchmarks, they struggle with multi-step
FOL tasks, as demonstrated by Deepseek-Prover-V2-7B's low accuracy (4.2%) on
our proposed theorem proving dataset. This issue arises from the limited
exploration of diverse proof strategies and the potential for early reasoning
mistakes to undermine entire proofs. To address these issues, we propose DREAM,
a self-adaptive solution that enhances the Diversity and REAsonability of LLMs'
generation strategies. DREAM incorporates an Axiom-Driven Strategy
Diversification mechanism to promote varied strategic outcomes and a
Sub-Proposition Error Feedback to help LLMs reflect on and correct their
proofs. Our contributions include pioneering advancements in LLMs' mathematical
reasoning through FOL theorem proving, introducing a novel inference stage
solution that improves performance by 0.6% to 6.4%, and providing a curated
dataset of 447 mathematical theorems in Lean 4 format for evaluation.
</summary>
    <author>
      <name>Chuxue Cao</name>
    </author>
    <author>
      <name>Mengze Li</name>
    </author>
    <author>
      <name>Juntao Dai</name>
    </author>
    <author>
      <name>Jinluan Yang</name>
    </author>
    <author>
      <name>Zijian Zhao</name>
    </author>
    <author>
      <name>Shengyu Zhang</name>
    </author>
    <author>
      <name>Weijie Shi</name>
    </author>
    <author>
      <name>Chengzhong Liu</name>
    </author>
    <author>
      <name>Sirui Han</name>
    </author>
    <author>
      <name>Yike Guo</name>
    </author>
    <link href="http://arxiv.org/abs/2506.17104v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.17104v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.17065v1</id>
    <updated>2025-06-20T15:12:43Z</updated>
    <published>2025-06-20T15:12:43Z</published>
    <title>Flow-Based Non-stationary Temporal Regime Causal Structure Learning</title>
    <summary>  Understanding causal relationships in multivariate time series is crucial in
many scenarios, such as those dealing with financial or neurological data. Many
such time series exhibit multiple regimes, i.e., consecutive temporal segments
with a priori unknown boundaries, with each regime having its own causal
structure. Inferring causal dependencies and regime shifts is critical for
analyzing the underlying processes. However, causal structure learning in this
setting is challenging due to (1) non stationarity, i.e., each regime can have
its own causal graph and mixing function, and (2) complex noise distributions,
which may be non Gaussian or heteroscedastic. Existing causal discovery
approaches cannot address these challenges, since generally assume stationarity
or Gaussian noise with constant variance. Hence, we introduce FANTOM, a unified
framework for causal discovery that handles non stationary processes along with
non Gaussian and heteroscedastic noises. FANTOM simultaneously infers the
number of regimes and their corresponding indices and learns each regime's
Directed Acyclic Graph. It uses a Bayesian Expectation Maximization algorithm
that maximizes the evidence lower bound of the data log likelihood. On the
theoretical side, we prove, under mild assumptions, that temporal
heteroscedastic causal models, introduced in FANTOM's formulation, are
identifiable in both stationary and non stationary settings. In addition,
extensive experiments on synthetic and real data show that FANTOM outperforms
existing methods.
</summary>
    <author>
      <name>Abdellah Rahmani</name>
    </author>
    <author>
      <name>Pascal Frossard</name>
    </author>
    <link href="http://arxiv.org/abs/2506.17065v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.17065v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
