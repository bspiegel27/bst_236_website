<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-05-15T00:54:47Z -->
<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acausal%20inference%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:causal inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/SsRksLzRb0LuVhSmQ+N8WbAs+f8</id>
  <updated>2025-05-14T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">112162</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">10</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2505.08785v1</id>
    <updated>2025-05-13T17:58:56Z</updated>
    <published>2025-05-13T17:58:56Z</published>
    <title>Divisible and indivisible Stochastic-Quantum dynamics</title>
    <summary>  This work presents a complete geometrical characterisation of divisible and
indivisible time-evolution at the level of probabilities for systems with two
configurations, open or closed. Our new geometrical construction in the space
of stochastic matrices shows the existence of conical bounds separating
divisible and indivisible dynamics, bearing analogy with the relativistic
causal structure, with an emerging time pointing towards information erasure
when the dynamics are divisible. Indivisible dynamics, which include quantum
dynamics, are characterised by a time-flow against the information-erasure time
coordinate or by being tachyonic with respect to the cones in the stochastic
matrix space. This provides a geometric counterpart of other results in the
literature, such as the equivalence between information-decreasing and
divisible processes. The results apply under minimal assumptions: (i) the
system has two configurations, (ii) one can freely ascribe initial
probabilities to both and (iii) probabilities at other times are linearly
related to the initial ones through conditional probabilities. The optional
assumption of (iv) continuity places further constraints on the system,
removing one of the past cones. Discontinuous stochastic dynamics in continuous
time include cases with divisible blocks of evolution which are not themselves
divisible. We show that the connection between continuity and multiplicity of
divisors holds for any dimension. We extend methods of coarse graining and
dilations by incorporating dynamics and uncertainty, connecting them with
divisibility criteria. This is a first step towards a full geometric
characterisation of indivisible stochastic dynamics for any number of
configurations which, as they cannot at the level of probabilities be reduced
to a composition of evolution operators, constitute fundamental elements of
probabilistic time-evolution.
</summary>
    <author>
      <name>Leandro Silva Pimenta</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages, 29 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2505.08785v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2505.08785v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2505.08784v1</id>
    <updated>2025-05-13T17:58:16Z</updated>
    <published>2025-05-13T17:58:16Z</published>
    <title>PCS-UQ: Uncertainty Quantification via the
  Predictability-Computability-Stability Framework</title>
    <summary>  As machine learning (ML) models are increasingly deployed in high-stakes
domains, trustworthy uncertainty quantification (UQ) is critical for ensuring
the safety and reliability of these models. Traditional UQ methods rely on
specifying a true generative model and are not robust to misspecification. On
the other hand, conformal inference allows for arbitrary ML models but does not
consider model selection, which leads to large interval sizes. We tackle these
drawbacks by proposing a UQ method based on the predictability, computability,
and stability (PCS) framework for veridical data science proposed by Yu and
Kumbier. Specifically, PCS-UQ addresses model selection by using a prediction
check to screen out unsuitable models. PCS-UQ then fits these screened
algorithms across multiple bootstraps to assess inter-sample variability and
algorithmic instability, enabling more reliable uncertainty estimates. Further,
we propose a novel calibration scheme that improves local adaptivity of our
prediction sets. Experiments across $17$ regression and $6$ classification
datasets show that PCS-UQ achieves the desired coverage and reduces width over
conformal approaches by $\approx 20\%$. Further, our local analysis shows
PCS-UQ often achieves target coverage across subgroups while conformal methods
fail to do so. For large deep-learning models, we propose computationally
efficient approximation schemes that avoid the expensive multiple bootstrap
trainings of PCS-UQ. Across three computer vision benchmarks, PCS-UQ reduces
prediction set size over conformal methods by $20\%$. Theoretically, we show a
modified PCS-UQ algorithm is a form of split conformal inference and achieves
the desired coverage with exchangeable data.
</summary>
    <author>
      <name>Abhineet Agarwal</name>
    </author>
    <author>
      <name>Michael Xiao</name>
    </author>
    <author>
      <name>Rebecca Barter</name>
    </author>
    <author>
      <name>Omer Ronen</name>
    </author>
    <author>
      <name>Boyu Fan</name>
    </author>
    <author>
      <name>Bin Yu</name>
    </author>
    <link href="http://arxiv.org/abs/2505.08784v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2505.08784v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2505.08783v1</id>
    <updated>2025-05-13T17:58:08Z</updated>
    <published>2025-05-13T17:58:08Z</published>
    <title>CodePDE: An Inference Framework for LLM-driven PDE Solver Generation</title>
    <summary>  Partial differential equations (PDEs) are fundamental to modeling physical
systems, yet solving them remains a complex challenge. Traditional numerical
solvers rely on expert knowledge to implement and are computationally
expensive, while neural-network-based solvers require large training datasets
and often lack interpretability. In this work, we frame PDE solving as a code
generation task and introduce CodePDE, the first inference framework for
generating PDE solvers using large language models (LLMs). Leveraging advanced
inference-time algorithms and scaling strategies, CodePDE unlocks critical
capacities of LLM for PDE solving: reasoning, debugging, selfrefinement, and
test-time scaling -- all without task-specific tuning. CodePDE achieves
superhuman performance across a range of representative PDE problems. We also
present a systematic empirical analysis of LLM generated solvers, analyzing
their accuracy, efficiency, and numerical scheme choices. Our findings
highlight the promise and the current limitations of LLMs in PDE solving,
offering a new perspective on solver design and opportunities for future model
development. Our code is available at https://github.com/LithiumDA/CodePDE.
</summary>
    <author>
      <name>Shanda Li</name>
    </author>
    <author>
      <name>Tanya Marwah</name>
    </author>
    <author>
      <name>Junhong Shen</name>
    </author>
    <author>
      <name>Weiwei Sun</name>
    </author>
    <author>
      <name>Andrej Risteski</name>
    </author>
    <author>
      <name>Yiming Yang</name>
    </author>
    <author>
      <name>Ameet Talwalkar</name>
    </author>
    <link href="http://arxiv.org/abs/2505.08783v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2505.08783v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2505.08780v1</id>
    <updated>2025-05-13T17:56:02Z</updated>
    <published>2025-05-13T17:56:02Z</published>
    <title>Polar motion of Venus</title>
    <summary>  Five Venus missions are under development to study the planet in the next
decade, with both NASA's VERITAS and ESA's EnVision featuring a geophysical
investigation among their objectives. Their radar and gravity experiments will
determine Venus's orientation, enabling spin dynamics analyses to infer
geophysical and atmospheric properties. This work aims to characterize Venus's
polar motion -- the motion of its spin axis in a body-fixed frame-focusing on
signatures from its interior and atmosphere to support its potential detection
by future orbiters. We develop a polar motion model for a triaxial planet
accounting for solar torque, centrifugal and tidal deformations of a
viscoelastic mantle, and atmospheric dynamics. Core-mantle coupling effects are
analyzed separately considering a simplified spherical core. We compute the
period and damping time of the free motion -- called the Chandler wobble -- and
determine the frequencies and amplitudes of the forced motion. We revisit the
Chandler frequency expression. Solar torque is the dominant phenomenon
affecting Venus's Chandler frequency, increasing it by a factor of 2.75. Our
model predicts a Chandler period in the range [12900 ; 18900] years. The
Chandler wobble appears as a linear polar drift of about 90 meters on Venus's
surface during EnVision's 4-year primary mission, at the limit of its
resolution. We also predict forced polar motion oscillations with an amplitude
of about 20 meters, driven by the atmosphere and the solar torque. Compared to
the 240-meter spin axis precession occurring in inertial space over this
duration, these results suggest that Venus's polar motion could also be
detectable by future orbiters. It should be incorporated into rotation models
when anticipating these missions, providing additional constraints on Venus's
interior structure.
</summary>
    <author>
      <name>PL. Phan</name>
    </author>
    <author>
      <name>N. Rambaux</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 7 figures, 6 tables, accepted for publication in A&amp;A</arxiv:comment>
    <link href="http://arxiv.org/abs/2505.08780v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2505.08780v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.EP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.EP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2505.08768v1</id>
    <updated>2025-05-13T17:39:31Z</updated>
    <published>2025-05-13T17:39:31Z</published>
    <title>SPAT: Sensitivity-based Multihead-attention Pruning on Time Series
  Forecasting Models</title>
    <summary>  Attention-based architectures have achieved superior performance in
multivariate time series forecasting but are computationally expensive.
Techniques such as patching and adaptive masking have been developed to reduce
their sizes and latencies. In this work, we propose a structured pruning
method, SPAT ($\textbf{S}$ensitivity $\textbf{P}$runer for
$\textbf{At}$tention), which selectively removes redundant attention mechanisms
and yields highly effective models. Different from previous approaches, SPAT
aims to remove the entire attention module, which reduces the risk of
overfitting and enables speed-up without demanding specialized hardware. We
propose a dynamic sensitivity metric, $\textbf{S}$ensitivity
$\textbf{E}$nhanced $\textbf{N}$ormalized $\textbf{D}$ispersion (SEND) that
measures the importance of each attention module during the pre-training phase.
Experiments on multivariate datasets demonstrate that SPAT-pruned models
achieve reductions of 2.842% in MSE, 1.996% in MAE, and 35.274% in FLOPs.
Furthermore, SPAT-pruned models outperform existing lightweight, Mamba-based
and LLM-based SOTA methods in both standard and zero-shot inference,
highlighting the importance of retaining only the most effective attention
mechanisms. We have made our code publicly available
https://anonymous.4open.science/r/SPAT-6042.
</summary>
    <author>
      <name>Suhan Guo</name>
    </author>
    <author>
      <name>Jiahong Deng</name>
    </author>
    <author>
      <name>Mengjun Yi</name>
    </author>
    <author>
      <name>Furao Shen</name>
    </author>
    <author>
      <name>Jian Zhao</name>
    </author>
    <link href="http://arxiv.org/abs/2505.08768v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2505.08768v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2505.08750v1</id>
    <updated>2025-05-13T17:02:33Z</updated>
    <published>2025-05-13T17:02:33Z</published>
    <title>AC-Reason: Towards Theory-Guided Actual Causality Reasoning with Large
  Language Models</title>
    <summary>  Actual causality (AC), a fundamental aspect of causal reasoning (CR), is
responsible for attribution and responsibility assignment in real-world
scenarios. However, existing LLM-based methods lack grounding in formal AC
theory, resulting in limited interpretability. Therefore, we propose AC-Reason,
a semi-formal reasoning framework that identifies causally relevant events
within an AC scenario, infers the values of their formal causal factors (e.g.,
sufficiency, necessity, and normality), and answers AC queries via a
theory-guided algorithm with explanations. While AC-Reason does not explicitly
construct a causal graph, it operates over variables in the underlying causal
structure to support principled reasoning. To enable comprehensive evaluation,
we introduce AC-Bench, a new benchmark built upon and substantially extending
Big-Bench Hard Causal Judgment (BBH-CJ). AC-Bench comprises ~1K carefully
annotated samples, each with detailed reasoning steps and focuses solely on
actual causation. The case study shows that synthesized samples in AC-Bench
present greater challenges for LLMs. Extensive experiments on BBH-CJ and
AC-Bench show that AC-Reason consistently improves LLM performance over
baselines. On BBH-CJ, all tested LLMs surpass the average human rater accuracy
of 69.60%, with GPT-4 + AC-Reason achieving 75.04%. On AC-Bench, GPT-4 +
AC-Reason again achieves the highest accuracy of 71.82%. AC-Bench further
enables fine-grained analysis of reasoning faithfulness, revealing that only
Qwen-2.5-72B-Instruct, Claude-3.5-Sonnet, and GPT-4o exhibit faithful
reasoning, whereas GPT-4 tends to exploit shortcuts. Finally, our ablation
study proves that integrating AC theory into LLMs is highly effective, with the
proposed algorithm contributing the most significant performance gains.
</summary>
    <author>
      <name>Yanxi Zhang</name>
    </author>
    <author>
      <name>Xin Cong</name>
    </author>
    <author>
      <name>Zhong Zhang</name>
    </author>
    <author>
      <name>Xiao Liu</name>
    </author>
    <author>
      <name>Dongyan Zhao</name>
    </author>
    <author>
      <name>Yesai Wu</name>
    </author>
    <link href="http://arxiv.org/abs/2505.08750v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2505.08750v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2505.08736v1</id>
    <updated>2025-05-13T16:49:45Z</updated>
    <published>2025-05-13T16:49:45Z</published>
    <title>Towards Foundation Models for Experimental Readout Systems Combining
  Discrete and Continuous Data</title>
    <summary>  We present a (proto) Foundation Model for Nuclear Physics, capable of
operating on low-level detector inputs from Imaging Cherenkov Detectors at the
future Electron Ion Collider. To address limitations in existing next-token
prediction approaches-namely resolution loss from VQ-VAE tokenization and lack
of conditional generation-we propose three key innovations: (i) separate
vocabularies for discrete spatial features and continuous variates, combined
via Causal Multi-Head Cross-Attention (CMHCA), (ii) continuous kinematic
conditioning through prepended context embeddings, and (iii) scalable and
simple, high-resolution continuous variate tokenization without joint
vocabulary inflation. Our model enables fast, high-fidelity generation of pixel
and time sequences for Cherenkov photons, validated through closure tests in
the High Performance DIRC. We also show our model generalizes to reconstruction
tasks such as pion and kaon identification, in which we show its ability to
leverage fine-tuning.
</summary>
    <author>
      <name>James Giroux</name>
    </author>
    <author>
      <name>Cristiano Fanelli</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages; 14 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2505.08736v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2505.08736v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-ex" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nucl-ex" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ins-det" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2505.08733v1</id>
    <updated>2025-05-13T16:46:15Z</updated>
    <published>2025-05-13T16:46:15Z</published>
    <title>Absolute measurement of the exchange interaction in an InSb quantum well
  using Landau-level tunnelling spectroscopy</title>
    <summary>  We studied InSb quantum well devices using Landau level tunneling
spectroscopy through a three-terminal differential conductance technique. This
method is similar to filled state scanning tunneling microscopy but uses a
stationary contact instead of a mobile tip to analyze the two-dimensional
electron system. Applying magnetic fields up to 15~T, we identified clear peaks
in the differential current-voltage profiles, indicative of Landau level
formation. By examining deviations from the expected Landau fan diagram, we
extract an absolute value for the exchange-induced energy shift. Through an
empirical analysis, we derive a formula describing the exchange shift as a
function of both magnetic field strength and electron filling. Our findings
indicate that the emptying of the $\nu=2$ and $\nu=3$ Landau levels causes an
exchange interaction energy shift in the $\nu=1$ level. Unlike prior studies
that infer level energies relative to one another and report oscillatory
g-factor behavior, our method references the energy of the Landau levels above
the filled states of the contact under a bias voltage, revealing that only the
ground state Landau level experiences a measurable exchange shift.
</summary>
    <author>
      <name>S. K. Clowes</name>
    </author>
    <author>
      <name>C. P. Allford</name>
    </author>
    <author>
      <name>D. Shearer</name>
    </author>
    <author>
      <name>G. V. Smith</name>
    </author>
    <author>
      <name>R. Simmons</name>
    </author>
    <author>
      <name>B. N. Murdin</name>
    </author>
    <author>
      <name>U. Zeitler</name>
    </author>
    <author>
      <name>P. D. Buckle</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2505.08733v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2505.08733v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.mes-hall" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.mes-hall" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2505.08729v1</id>
    <updated>2025-05-13T16:39:19Z</updated>
    <published>2025-05-13T16:39:19Z</published>
    <title>Assumption-robust Causal Inference</title>
    <summary>  In observational causal inference, it is common to encounter multiple
adjustment sets that appear equally plausible. It is often untestable which of
these adjustment sets are valid to adjust for (i.e., satisfies ignorability).
This discrepancy can pose practical challenges as it is typically unclear how
to reconcile multiple, possibly conflicting estimates of the average treatment
effect (ATE). A naive approach is to report the whole range (convex hull of the
union) of the resulting confidence intervals. However, the width of this
interval might not shrink to zero in large samples and can be unnecessarily
wide in real applications. To address this issue, we propose a summary
procedure that generates a single estimate, one confidence interval, and
identifies a set of units for which the causal effect estimate remains valid,
provided at least one adjustment set is valid. The width of our proposed
confidence interval shrinks to zero with sample size at $n^{-1/2}$ rate, unlike
the original range which is of constant order. Thus, our assumption-robust
approach enables reliable causal inference on the ATE even in scenarios where
most of the adjustment sets are invalid. Admittedly, this robustness comes at a
cost: our inferential guarantees apply to a target population close to, but
different from, the one originally intended. We use synthetic and real-data
examples to demonstrate that our proposed procedure provides substantially
tighter confidence intervals for the ATE as compared to the whole range. In
particular, for a real-world dataset on 401(k) retirement plans our method
produces a confidence interval 50\% shorter than the whole range of confidence
intervals based on multiple adjustment sets.
</summary>
    <author>
      <name>Aditya Ghosh</name>
    </author>
    <author>
      <name>Dominik Rothenh√§usler</name>
    </author>
    <link href="http://arxiv.org/abs/2505.08729v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2505.08729v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="econ.EM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2505.08695v1</id>
    <updated>2025-05-13T15:54:36Z</updated>
    <published>2025-05-13T15:54:36Z</published>
    <title>SPAST: Arbitrary Style Transfer with Style Priors via Pre-trained
  Large-scale Model</title>
    <summary>  Given an arbitrary content and style image, arbitrary style transfer aims to
render a new stylized
  image which preserves the content image's structure and possesses the style
image's style. Existing
  arbitrary style transfer methods are based on either small models or
pre-trained large-scale models.
  The small model-based methods fail to generate high-quality stylized images,
bringing artifacts and
  disharmonious patterns. The pre-trained large-scale model-based methods can
generate high-quality
  stylized images but struggle to preserve the content structure and cost long
inference time. To this
  end, we propose a new framework, called SPAST, to generate high-quality
stylized images with
  less inference time. Specifically, we design a novel Local-global Window Size
Stylization Module
  (LGWSSM)tofuse style features into content features. Besides, we introduce a
novel style prior loss,
  which can dig out the style priors from a pre-trained large-scale model into
the SPAST and motivate
  the SPAST to generate high-quality stylized images with short inference
time.We conduct abundant
  experiments to verify that our proposed method can generate high-quality
stylized images and less
  inference time compared with the SOTA arbitrary style transfer methods.
</summary>
    <author>
      <name>Zhanjie Zhang</name>
    </author>
    <author>
      <name>Quanwei Zhang</name>
    </author>
    <author>
      <name>Junsheng Luan</name>
    </author>
    <author>
      <name>Mengyuan Yang</name>
    </author>
    <author>
      <name>Yun Wang</name>
    </author>
    <author>
      <name>Lei Zhao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by Neural Networks</arxiv:comment>
    <link href="http://arxiv.org/abs/2505.08695v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2505.08695v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
