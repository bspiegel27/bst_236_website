<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-04-24T00:54:52Z -->
<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acausal%20inference%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:causal inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/SsRksLzRb0LuVhSmQ+N8WbAs+f8</id>
  <updated>2025-04-23T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">111096</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">10</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2504.16084v1</id>
    <updated>2025-04-22T17:59:56Z</updated>
    <published>2025-04-22T17:59:56Z</published>
    <title>TTRL: Test-Time Reinforcement Learning</title>
    <summary>  This paper investigates Reinforcement Learning (RL) on data without explicit
labels for reasoning tasks in Large Language Models (LLMs). The core challenge
of the problem is reward estimation during inference while not having access to
ground-truth information. While this setting appears elusive, we find that
common practices in Test-Time Scaling (TTS), such as majority voting, yield
surprisingly effective rewards suitable for driving RL training. In this work,
we introduce Test-Time Reinforcement Learning (TTRL), a novel method for
training LLMs using RL on unlabeled data. TTRL enables self-evolution of LLMs
by utilizing the priors in the pre-trained models. Our experiments demonstrate
that TTRL consistently improves performance across a variety of tasks and
models. Notably, TTRL boosts the pass@1 performance of Qwen-2.5-Math-7B by
approximately 159% on the AIME 2024 with only unlabeled test data. Furthermore,
although TTRL is only supervised by the Maj@N metric, TTRL has demonstrated
performance to consistently surpass the upper limit of the initial model, and
approach the performance of models trained directly on test data with
ground-truth labels. Our experimental findings validate the general
effectiveness of TTRL across various tasks, and highlight TTRL's potential for
broader tasks and domains. GitHub: https://github.com/PRIME-RL/TTRL
</summary>
    <author>
      <name>Yuxin Zuo</name>
    </author>
    <author>
      <name>Kaiyan Zhang</name>
    </author>
    <author>
      <name>Shang Qu</name>
    </author>
    <author>
      <name>Li Sheng</name>
    </author>
    <author>
      <name>Xuekai Zhu</name>
    </author>
    <author>
      <name>Biqing Qi</name>
    </author>
    <author>
      <name>Youbang Sun</name>
    </author>
    <author>
      <name>Ganqu Cui</name>
    </author>
    <author>
      <name>Ning Ding</name>
    </author>
    <author>
      <name>Bowen Zhou</name>
    </author>
    <link href="http://arxiv.org/abs/2504.16084v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.16084v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.16083v1</id>
    <updated>2025-04-22T17:59:51Z</updated>
    <published>2025-04-22T17:59:51Z</published>
    <title>MMInference: Accelerating Pre-filling for Long-Context VLMs via
  Modality-Aware Permutation Sparse Attention</title>
    <summary>  The integration of long-context capabilities with visual understanding
unlocks unprecedented potential for Vision Language Models (VLMs). However, the
quadratic attention complexity during the pre-filling phase remains a
significant obstacle to real-world deployment. To overcome this limitation, we
introduce MMInference (Multimodality Million tokens Inference), a dynamic
sparse attention method that accelerates the prefilling stage for long-context
multi-modal inputs. First, our analysis reveals that the temporal and spatial
locality of video input leads to a unique sparse pattern, the Grid pattern.
Simultaneously, VLMs exhibit markedly different sparse distributions across
different modalities. We introduce a permutation-based method to leverage the
unique Grid pattern and handle modality boundary issues. By offline search the
optimal sparse patterns for each head, MMInference constructs the sparse
distribution dynamically based on the input. We also provide optimized GPU
kernels for efficient sparse computations. Notably, MMInference integrates
seamlessly into existing VLM pipelines without any model modifications or
fine-tuning. Experiments on multi-modal benchmarks-including Video QA,
Captioning, VisionNIAH, and Mixed-Modality NIAH-with state-of-the-art
long-context VLMs (LongVila, LlavaVideo, VideoChat-Flash, Qwen2.5-VL) show that
MMInference accelerates the pre-filling stage by up to 8.3x at 1M tokens while
maintaining accuracy. Our code is available at https://aka.ms/MMInference.
</summary>
    <author>
      <name>Yucheng Li</name>
    </author>
    <author>
      <name>Huiqiang Jiang</name>
    </author>
    <author>
      <name>Chengruidong Zhang</name>
    </author>
    <author>
      <name>Qianhui Wu</name>
    </author>
    <author>
      <name>Xufang Luo</name>
    </author>
    <author>
      <name>Surin Ahn</name>
    </author>
    <author>
      <name>Amir H. Abdi</name>
    </author>
    <author>
      <name>Dongsheng Li</name>
    </author>
    <author>
      <name>Jianfeng Gao</name>
    </author>
    <author>
      <name>Yuqing Yang</name>
    </author>
    <author>
      <name>Lili Qiu</name>
    </author>
    <link href="http://arxiv.org/abs/2504.16083v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.16083v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.16080v1</id>
    <updated>2025-04-22T17:58:07Z</updated>
    <published>2025-04-22T17:58:07Z</published>
    <title>From Reflection to Perfection: Scaling Inference-Time Optimization for
  Text-to-Image Diffusion Models via Reflection Tuning</title>
    <summary>  Recent text-to-image diffusion models achieve impressive visual quality
through extensive scaling of training data and model parameters, yet they often
struggle with complex scenes and fine-grained details. Inspired by the
self-reflection capabilities emergent in large language models, we propose
ReflectionFlow, an inference-time framework enabling diffusion models to
iteratively reflect upon and refine their outputs. ReflectionFlow introduces
three complementary inference-time scaling axes: (1) noise-level scaling to
optimize latent initialization; (2) prompt-level scaling for precise semantic
guidance; and most notably, (3) reflection-level scaling, which explicitly
provides actionable reflections to iteratively assess and correct previous
generations. To facilitate reflection-level scaling, we construct GenRef, a
large-scale dataset comprising 1 million triplets, each containing a
reflection, a flawed image, and an enhanced image. Leveraging this dataset, we
efficiently perform reflection tuning on state-of-the-art diffusion
transformer, FLUX.1-dev, by jointly modeling multimodal inputs within a unified
framework. Experimental results show that ReflectionFlow significantly
outperforms naive noise-level scaling methods, offering a scalable and
compute-efficient solution toward higher-quality image synthesis on challenging
tasks.
</summary>
    <author>
      <name>Le Zhuo</name>
    </author>
    <author>
      <name>Liangbing Zhao</name>
    </author>
    <author>
      <name>Sayak Paul</name>
    </author>
    <author>
      <name>Yue Liao</name>
    </author>
    <author>
      <name>Renrui Zhang</name>
    </author>
    <author>
      <name>Yi Xin</name>
    </author>
    <author>
      <name>Peng Gao</name>
    </author>
    <author>
      <name>Mohamed Elhoseiny</name>
    </author>
    <author>
      <name>Hongsheng Li</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">All code, checkpoints, and datasets are available at
  \url{https://diffusion-cot.github.io/reflection2perfection}</arxiv:comment>
    <link href="http://arxiv.org/abs/2504.16080v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.16080v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.16073v1</id>
    <updated>2025-04-22T17:52:42Z</updated>
    <published>2025-04-22T17:52:42Z</published>
    <title>Guiding VLM Agents with Process Rewards at Inference Time for GUI
  Navigation</title>
    <summary>  Recent advancements in visual language models (VLMs) have notably enhanced
their capabilities in handling complex Graphical User Interface (GUI)
interaction tasks. Despite these improvements, current frameworks often
struggle to generate correct actions in challenging GUI environments.
State-of-the-art commercial VLMs are black-boxes, and fine-tuning open-source
VLMs for GUI tasks requires significant resources. Additionally, existing
trajectory-level evaluation and refinement techniques frequently fall short due
to delayed feedback and local optimization issues. To address these challenges,
we propose an approach that guides VLM agents with process supervision by a
reward model during GUI navigation and control at inference time. This guidance
allows the VLM agent to optimize actions at each inference step, thereby
improving performance in both static and dynamic environments. In particular,
our method demonstrates significant performance gains in three GUI navigation
tasks, achieving a 3.4% improvement in single step action accuracy for static
environments, along with a around 33% increase in task success rate in one
dynamic environment. With further integration of trajectory reflection and
retry mechanisms, we also demonstrate even greater enhancement in task success.
</summary>
    <author>
      <name>Zhiyuan Hu</name>
    </author>
    <author>
      <name>Shiyun Xiong</name>
    </author>
    <author>
      <name>Yifan Zhang</name>
    </author>
    <author>
      <name>See-Kiong Ng</name>
    </author>
    <author>
      <name>Anh Tuan Luu</name>
    </author>
    <author>
      <name>Bo An</name>
    </author>
    <author>
      <name>Shuicheng Yan</name>
    </author>
    <author>
      <name>Bryan Hooi</name>
    </author>
    <link href="http://arxiv.org/abs/2504.16073v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.16073v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.16068v1</id>
    <updated>2025-04-22T17:47:01Z</updated>
    <published>2025-04-22T17:47:01Z</published>
    <title>High-performance training and inference for deep equivariant interatomic
  potentials</title>
    <summary>  Machine learning interatomic potentials, particularly those based on deep
equivariant neural networks, have demonstrated state-of-the-art accuracy and
computational efficiency in atomistic modeling tasks like molecular dynamics
and high-throughput screening. The size of datasets and demands of downstream
workflows are growing rapidly, making robust and scalable software essential.
This work presents a major overhaul of the NequIP framework focusing on
multi-node parallelism, computational performance, and extensibility. The
redesigned framework supports distributed training on large datasets and
removes barriers preventing full utilization of the PyTorch 2.0 compiler at
train time. We demonstrate this acceleration in a case study by training
Allegro models on the SPICE 2 dataset of organic molecular systems. For
inference, we introduce the first end-to-end infrastructure that uses the
PyTorch Ahead-of-Time Inductor compiler for machine learning interatomic
potentials. Additionally, we implement a custom kernel for the Allegro model's
most expensive operation, the tensor product. Together, these advancements
speed up molecular dynamics calculations on system sizes of practical relevance
by up to a factor of 18.
</summary>
    <author>
      <name>Chuin Wei Tan</name>
    </author>
    <author>
      <name>Marc L. Descoteaux</name>
    </author>
    <author>
      <name>Mit Kotak</name>
    </author>
    <author>
      <name>Gabriel de Miranda Nascimento</name>
    </author>
    <author>
      <name>Seán R. Kavanagh</name>
    </author>
    <author>
      <name>Laura Zichi</name>
    </author>
    <author>
      <name>Menghang Wang</name>
    </author>
    <author>
      <name>Aadit Saluja</name>
    </author>
    <author>
      <name>Yizhong R. Hu</name>
    </author>
    <author>
      <name>Tess Smidt</name>
    </author>
    <author>
      <name>Anders Johansson</name>
    </author>
    <author>
      <name>William C. Witt</name>
    </author>
    <author>
      <name>Boris Kozinsky</name>
    </author>
    <author>
      <name>Albert Musaelian</name>
    </author>
    <link href="http://arxiv.org/abs/2504.16068v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.16068v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.chem-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.16064v1</id>
    <updated>2025-04-22T17:41:42Z</updated>
    <published>2025-04-22T17:41:42Z</published>
    <title>Boosting Generative Image Modeling via Joint Image-Feature Synthesis</title>
    <summary>  Latent diffusion models (LDMs) dominate high-quality image generation, yet
integrating representation learning with generative modeling remains a
challenge. We introduce a novel generative image modeling framework that
seamlessly bridges this gap by leveraging a diffusion model to jointly model
low-level image latents (from a variational autoencoder) and high-level
semantic features (from a pretrained self-supervised encoder like DINO). Our
latent-semantic diffusion approach learns to generate coherent image-feature
pairs from pure noise, significantly enhancing both generative quality and
training efficiency, all while requiring only minimal modifications to standard
Diffusion Transformer architectures. By eliminating the need for complex
distillation objectives, our unified design simplifies training and unlocks a
powerful new inference strategy: Representation Guidance, which leverages
learned semantics to steer and refine image generation. Evaluated in both
conditional and unconditional settings, our method delivers substantial
improvements in image quality and training convergence speed, establishing a
new direction for representation-aware generative modeling.
</summary>
    <author>
      <name>Theodoros Kouzelis</name>
    </author>
    <author>
      <name>Efstathios Karypidis</name>
    </author>
    <author>
      <name>Ioannis Kakogeorgiou</name>
    </author>
    <author>
      <name>Spyros Gidaris</name>
    </author>
    <author>
      <name>Nikos Komodakis</name>
    </author>
    <link href="http://arxiv.org/abs/2504.16064v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.16064v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.16046v1</id>
    <updated>2025-04-22T17:16:53Z</updated>
    <published>2025-04-22T17:16:53Z</published>
    <title>Certified Mitigation of Worst-Case LLM Copyright Infringement</title>
    <summary>  The exposure of large language models (LLMs) to copyrighted material during
pre-training raises concerns about unintentional copyright infringement post
deployment. This has driven the development of "copyright takedown" methods,
post-training approaches aimed at preventing models from generating content
substantially similar to copyrighted ones. While current mitigation approaches
are somewhat effective for average-case risks, we demonstrate that they
overlook worst-case copyright risks exhibits by the existence of long, verbatim
quotes from copyrighted sources. We propose BloomScrub, a remarkably simple yet
highly effective inference-time approach that provides certified copyright
takedown. Our method repeatedly interleaves quote detection with rewriting
techniques to transform potentially infringing segments. By leveraging
efficient data sketches (Bloom filters), our approach enables scalable
copyright screening even for large-scale real-world corpora. When quotes beyond
a length threshold cannot be removed, the system can abstain from responding,
offering certified risk reduction. Experimental results show that BloomScrub
reduces infringement risk, preserves utility, and accommodates different levels
of enforcement stringency with adaptive abstention. Our results suggest that
lightweight, inference-time methods can be surprisingly effective for copyright
prevention.
</summary>
    <author>
      <name>Jingyu Zhang</name>
    </author>
    <author>
      <name>Jiacan Yu</name>
    </author>
    <author>
      <name>Marc Marone</name>
    </author>
    <author>
      <name>Benjamin Van Durme</name>
    </author>
    <author>
      <name>Daniel Khashabi</name>
    </author>
    <link href="http://arxiv.org/abs/2504.16046v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.16046v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.16015v1</id>
    <updated>2025-04-22T16:26:29Z</updated>
    <published>2025-04-22T16:26:29Z</published>
    <title>From observed transitions to hidden paths in Markov networks</title>
    <summary>  The number of observable degrees of freedom is typically limited in
experiments. Here, we consider discrete Markov networks in which an observer
has access to a few visible transitions and the waiting times between these
transitions. Focusing on the underlying structure of a discrete network, we
present methods to infer local and global properties of the network from
observed data. First, we derive bounds on the microscopic entropy production
along the hidden paths between two visible transitions, which complement extant
bounds on mean entropy production and affinities of hidden cycles. Second, we
demonstrate how the operationally accessible data encodes information about the
topology of shortest hidden paths, which can be used to identify potential
clusters of states or exclude their existence. Finally, we outline a systematic
way to combine the inferred data, resulting in an algorithm that finds the
candidates for a minimal graph of the underlying network, i.e., a graph that is
part of the original one and compatible with the observations. Our results
highlight the interplay between thermodynamic methods, waiting-time
distributions and topological aspects like network structure, which can be
expected to provide novel insights in other set-ups of coarse graining as well.
</summary>
    <author>
      <name>Alexander M. Maier</name>
    </author>
    <author>
      <name>Udo Seifert</name>
    </author>
    <author>
      <name>Jann van der Meer</name>
    </author>
    <link href="http://arxiv.org/abs/2504.16015v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.16015v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.16000v1</id>
    <updated>2025-04-22T16:05:26Z</updated>
    <published>2025-04-22T16:05:26Z</published>
    <title>How Private is Your Attention? Bridging Privacy with In-Context Learning</title>
    <summary>  In-context learning (ICL)-the ability of transformer-based models to perform
new tasks from examples provided at inference time-has emerged as a hallmark of
modern language models. While recent works have investigated the mechanisms
underlying ICL, its feasibility under formal privacy constraints remains
largely unexplored. In this paper, we propose a differentially private
pretraining algorithm for linear attention heads and present the first
theoretical analysis of the privacy-accuracy trade-off for ICL in linear
regression. Our results characterize the fundamental tension between
optimization and privacy-induced noise, formally capturing behaviors observed
in private training via iterative methods. Additionally, we show that our
method is robust to adversarial perturbations of training prompts, unlike
standard ridge regression. All theoretical findings are supported by extensive
simulations across diverse settings.
</summary>
    <author>
      <name>Soham Bonnerjee</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Kingsley</arxiv:affiliation>
    </author>
    <author>
      <name>Zhen Wei</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Kingsley</arxiv:affiliation>
    </author>
    <author>
      <name> Yeon</name>
    </author>
    <author>
      <name>Anna Asch</name>
    </author>
    <author>
      <name>Sagnik Nandy</name>
    </author>
    <author>
      <name>Promit Ghosal</name>
    </author>
    <link href="http://arxiv.org/abs/2504.16000v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.16000v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.15995v1</id>
    <updated>2025-04-22T16:00:11Z</updated>
    <published>2025-04-22T16:00:11Z</published>
    <title>OPUS-VFL: Incentivizing Optimal Privacy-Utility Tradeoffs in Vertical
  Federated Learning</title>
    <summary>  Vertical Federated Learning (VFL) enables organizations with disjoint feature
spaces but shared user bases to collaboratively train models without sharing
raw data. However, existing VFL systems face critical limitations: they often
lack effective incentive mechanisms, struggle to balance privacy-utility
tradeoffs, and fail to accommodate clients with heterogeneous resource
capabilities. These challenges hinder meaningful participation, degrade model
performance, and limit practical deployment. To address these issues, we
propose OPUS-VFL, an Optimal Privacy-Utility tradeoff Strategy for VFL.
OPUS-VFL introduces a novel, privacy-aware incentive mechanism that rewards
clients based on a principled combination of model contribution, privacy
preservation, and resource investment. It employs a lightweight leave-one-out
(LOO) strategy to quantify feature importance per client, and integrates an
adaptive differential privacy mechanism that enables clients to dynamically
calibrate noise levels to optimize their individual utility. Our framework is
designed to be scalable, budget-balanced, and robust to inference and poisoning
attacks. Extensive experiments on benchmark datasets (MNIST, CIFAR-10, and
CIFAR-100) demonstrate that OPUS-VFL significantly outperforms state-of-the-art
VFL baselines in both efficiency and robustness. It reduces label inference
attack success rates by up to 20%, increases feature inference reconstruction
error (MSE) by over 30%, and achieves up to 25% higher incentives for clients
that contribute meaningfully while respecting privacy and cost constraints.
These results highlight the practicality and innovation of OPUS-VFL as a
secure, fair, and performance-driven solution for real-world VFL.
</summary>
    <author>
      <name>Sindhuja Madabushi</name>
    </author>
    <author>
      <name>Ahmad Faraz Khan</name>
    </author>
    <author>
      <name>Haider Ali</name>
    </author>
    <author>
      <name>Jin-Hee Cho</name>
    </author>
    <link href="http://arxiv.org/abs/2504.15995v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.15995v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
