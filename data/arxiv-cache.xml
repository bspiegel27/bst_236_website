<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2026-02-14T01:13:09Z -->
<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/" xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns="http://www.w3.org/2005/Atom">
  <id>https://arxiv.org/api/p6EyKyP4fMY/66n9Ev8E79F7KlI</id>
  <title>arXiv Query: search_query=all:causal OR all:inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <updated>2026-02-14T01:13:10Z</updated>
  <link href="https://arxiv.org/api/query?search_query=all:causal+OR+all:inference&amp;start=0&amp;max_results=10&amp;id_list=" type="application/atom+xml"/>
  <opensearch:itemsPerPage>10</opensearch:itemsPerPage>
  <opensearch:totalResults>133973</opensearch:totalResults>
  <opensearch:startIndex>0</opensearch:startIndex>
  <entry>
    <id>http://arxiv.org/abs/2602.12281v1</id>
    <title>Scaling Verification Can Be More Effective than Scaling Policy Learning for Vision-Language-Action Alignment</title>
    <updated>2026-02-12T18:59:59Z</updated>
    <link href="https://arxiv.org/abs/2602.12281v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.12281v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>The long-standing vision of general-purpose robots hinges on their ability to understand and act upon natural language instructions. Vision-Language-Action (VLA) models have made remarkable progress toward this goal, yet their generated actions can still misalign with the given instructions. In this paper, we investigate test-time verification as a means to shrink the "intention-action gap.'' We first characterize the test-time scaling law for embodied instruction following and demonstrate that jointly scaling the number of rephrased instructions and generated actions greatly increases test-time sample diversity, often recovering correct actions more efficiently than scaling each dimension independently. To capitalize on these scaling laws, we present CoVer, a contrastive verifier for vision-language-action alignment, and show that our architecture scales gracefully with additional computational resources and data. We then introduce "boot-time compute" and a hierarchical verification inference pipeline for VLAs. At deployment, our framework precomputes a diverse set of rephrased instructions from a Vision-Language-Model (VLM), repeatedly generates action candidates for each instruction, and then uses a verifier to select the optimal high-level prompt and low-level action chunks. Compared to scaling policy pre-training on the same data, our verification approach yields 22% gains in-distribution and 13% out-of-distribution on the SIMPLER benchmark, with a further 45% improvement in real-world experiments. On the PolaRiS benchmark, CoVer achieves 14% gains in task progress and 9% in success rate.</summary>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SY" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-12T18:59:59Z</published>
    <arxiv:primary_category term="cs.RO"/>
    <author>
      <name>Jacky Kwok</name>
    </author>
    <author>
      <name>Xilun Zhang</name>
    </author>
    <author>
      <name>Mengdi Xu</name>
    </author>
    <author>
      <name>Yuejiang Liu</name>
    </author>
    <author>
      <name>Azalia Mirhoseini</name>
    </author>
    <author>
      <name>Chelsea Finn</name>
    </author>
    <author>
      <name>Marco Pavone</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.12279v1</id>
    <title>UniT: Unified Multimodal Chain-of-Thought Test-time Scaling</title>
    <updated>2026-02-12T18:59:49Z</updated>
    <link href="https://arxiv.org/abs/2602.12279v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.12279v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Unified models can handle both multimodal understanding and generation within a single architecture, yet they typically operate in a single pass without iteratively refining their outputs. Many multimodal tasks, especially those involving complex spatial compositions, multiple interacting objects, or evolving instructions, require decomposing instructions, verifying intermediate results, and making iterative corrections. While test-time scaling (TTS) has demonstrated that allocating additional inference compute for iterative reasoning substantially improves language model performance, extending this paradigm to unified multimodal models remains an open challenge. We introduce UniT, a framework for multimodal chain-of-thought test-time scaling that enables a single unified model to reason, verify, and refine across multiple rounds. UniT combines agentic data synthesis, unified model training, and flexible test-time inference to elicit cognitive behaviors including verification, subgoal decomposition, and content memory. Our key findings are: (1) unified models trained on short reasoning trajectories generalize to longer inference chains at test time; (2) sequential chain-of-thought reasoning provides a more scalable and compute-efficient TTS strategy than parallel sampling; (3) training on generation and editing trajectories improves out-of-distribution visual reasoning. These results establish multimodal test-time scaling as an effective paradigm for advancing both generation and understanding in unified models.</summary>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-12T18:59:49Z</published>
    <arxiv:primary_category term="cs.CV"/>
    <author>
      <name>Leon Liangyu Chen</name>
    </author>
    <author>
      <name>Haoyu Ma</name>
    </author>
    <author>
      <name>Zhipeng Fan</name>
    </author>
    <author>
      <name>Ziqi Huang</name>
    </author>
    <author>
      <name>Animesh Sinha</name>
    </author>
    <author>
      <name>Xiaoliang Dai</name>
    </author>
    <author>
      <name>Jialiang Wang</name>
    </author>
    <author>
      <name>Zecheng He</name>
    </author>
    <author>
      <name>Jianwei Yang</name>
    </author>
    <author>
      <name>Chunyuan Li</name>
    </author>
    <author>
      <name>Junzhe Sun</name>
    </author>
    <author>
      <name>Chu Wang</name>
    </author>
    <author>
      <name>Serena Yeung-Levy</name>
    </author>
    <author>
      <name>Felix Juefei-Xu</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.12278v1</id>
    <title>AttentionRetriever: Attention Layers are Secretly Long Document Retrievers</title>
    <updated>2026-02-12T18:59:35Z</updated>
    <link href="https://arxiv.org/abs/2602.12278v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.12278v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Retrieval augmented generation (RAG) has been widely adopted to help Large Language Models (LLMs) to process tasks involving long documents. However, existing retrieval models are not designed for long document retrieval and fail to address several key challenges of long document retrieval, including context-awareness, causal dependence, and scope of retrieval. In this paper, we proposed AttentionRetriever, a novel long document retrieval model that leverages attention mechanism and entity-based retrieval to build context-aware embeddings for long document and determine the scope of retrieval. With extensive experiments, we found AttentionRetriever is able to outperform existing retrieval models on long document retrieval datasets by a large margin while remaining as efficient as dense retrieval models.</summary>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-12T18:59:35Z</published>
    <arxiv:primary_category term="cs.IR"/>
    <author>
      <name>David Jiahao Fu</name>
    </author>
    <author>
      <name>Lam Thanh Do</name>
    </author>
    <author>
      <name>Jiayu Li</name>
    </author>
    <author>
      <name>Kevin Chen-Chuan Chang</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.12276v1</id>
    <title>Agentic Test-Time Scaling for WebAgents</title>
    <updated>2026-02-12T18:58:30Z</updated>
    <link href="https://arxiv.org/abs/2602.12276v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.12276v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Test-time scaling has become a standard way to improve performance and boost reliability of neural network models. However, its behavior on agentic, multi-step tasks remains less well-understood: small per-step errors can compound over long horizons; and we find that naive policies that uniformly increase sampling show diminishing returns. In this work, we present CATTS, a simple technique for dynamically allocating compute for multi-step agents. We first conduct an empirical study of inference-time scaling for web agents. We find that uniformly increasing per-step compute quickly saturates in long-horizon environments. We then investigate stronger aggregation strategies, including an LLM-based Arbiter that can outperform naive voting, but that can overrule high-consensus decisions. We show that uncertainty statistics derived from the agent's own vote distribution (entropy and top-1/top-2 margin) correlate with downstream success and provide a practical signal for dynamic compute allocation. Based on these findings, we introduce Confidence-Aware Test-Time Scaling (CATTS), which uses vote-derived uncertainty to allocate compute only when decisions are genuinely contentious. CATTS improves performance on WebArena-Lite and GoBrowse by up to 9.1% over React while using up to 2.3x fewer tokens than uniform scaling, providing both efficiency gains and an interpretable decision rule.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-12T18:58:30Z</published>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Nicholas Lee</name>
    </author>
    <author>
      <name>Lutfi Eren Erdogan</name>
    </author>
    <author>
      <name>Chris Joseph John</name>
    </author>
    <author>
      <name>Surya Krishnapillai</name>
    </author>
    <author>
      <name>Michael W. Mahoney</name>
    </author>
    <author>
      <name>Kurt Keutzer</name>
    </author>
    <author>
      <name>Amir Gholami</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.12272v1</id>
    <title>The Wandering Supermassive Black Hole Powering the off-nuclear TDE AT2024tvd</title>
    <updated>2026-02-12T18:57:35Z</updated>
    <link href="https://arxiv.org/abs/2602.12272v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.12272v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>We present an analysis of the spectral energy distribution (SED) of the off-nuclear tidal disruption event (TDE) AT2024tvd during its late-time plateau phase, combining X-ray spectra and UV/optical photometry. Using a fully relativistic, compact accretion disk model with self-consistent inner-disk Comptonization, we reproduce the observed SED without significant residuals. The inferred black hole mass ${\rm log}{10}(M{\bullet}/M_\odot) \approx 6.0 \pm 0.2$, and the inferred disk parameters place AT2024tvd within known TDE-disk scaling relations ($L_{\rm bol}^{\rm disk}/L_{\rm Edd} \propto T_{\rm p}^4 \propto M_{\bullet}^{-1}$, $L_{\rm plat} \propto M_{\bullet}^{2/3}$, $R_{\rm out}/r_{\rm g} \propto M_{\bullet}^{-2/3}$). Our results show that: (i) there is no \textit{detected} star cluster or dwarf galaxy associated with the source, down to a mass limit of $\log_{10}(M_{\rm gal}/M_{\odot}) \leq 7.6$; (ii) the black hole is a wandering supermassive, rather than intermediate-mass, black hole; and (iii) the source represents an extreme case of black hole-to-host mass ratio, with $M_{\bullet}/M_{\rm gal} &gt; 3\%$, consistent with a heavily tidally stripped nucleus. The latter aligns with cosmological simulations predicting that surviving host remnants of most wandering black holes should not retain a detectable stellar overdensity when located at small halo-centric distances. We discuss differences with previous analyses of this source and highlight why our modeling approach provides a more physically consistent solution with more reliable parameter inference.</summary>
    <category term="astro-ph.HE" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-12T18:57:35Z</published>
    <arxiv:comment>Submitted to ApJ Letters</arxiv:comment>
    <arxiv:primary_category term="astro-ph.HE"/>
    <author>
      <name>M. Guolo</name>
    </author>
    <author>
      <name>A. Mummery</name>
    </author>
    <author>
      <name>S. van Velzen</name>
    </author>
    <author>
      <name>M. Nicholl</name>
    </author>
    <author>
      <name>S. Gezari</name>
    </author>
    <author>
      <name>Y. Yao</name>
    </author>
    <author>
      <name>K. C. Chambers</name>
    </author>
    <author>
      <name>T. de Boer</name>
    </author>
    <author>
      <name>M. E. Huber</name>
    </author>
    <author>
      <name>C. -C. Lin</name>
    </author>
    <author>
      <name>T. B. Lowe</name>
    </author>
    <author>
      <name>E. A. Magnier</name>
    </author>
    <author>
      <name>G. Paek</name>
    </author>
    <author>
      <name>R. Wainscoat</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.12267v1</id>
    <title>Self-Supervised Learning via Flow-Guided Neural Operator on Time-Series Data</title>
    <updated>2026-02-12T18:54:57Z</updated>
    <link href="https://arxiv.org/abs/2602.12267v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.12267v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Self-supervised learning (SSL) is a powerful paradigm for learning from unlabeled time-series data. However, popular methods such as masked autoencoders (MAEs) rely on reconstructing inputs from a fixed, predetermined masking ratio. Instead of this static design, we propose treating the corruption level as a new degree of freedom for representation learning, enhancing flexibility and performance. To achieve this, we introduce the Flow-Guided Neural Operator (FGNO), a novel framework combining operator learning with flow matching for SSL training. FGNO learns mappings in functional spaces by using Short-Time Fourier Transform to unify different time resolutions. We extract a rich hierarchy of features by tapping into different network layers and flow times that apply varying strengths of noise to the input data. This enables the extraction of versatile representations, from low-level patterns to high-level global features, using a single model adaptable to specific tasks. Unlike prior generative SSL methods that use noisy inputs during inference, we propose using clean inputs for representation extraction while learning representations with noise; this eliminates randomness and boosts accuracy. We evaluate FGNO across three biomedical domains, where it consistently outperforms established baselines. Our method yields up to 35% AUROC gains in neural signal decoding (BrainTreeBank), 16% RMSE reductions in skin temperature prediction (DREAMT), and over 20% improvement in accuracy and macro-F1 on SleepEDF under low-data regimes. These results highlight FGNO's robustness to data scarcity and its superior capacity to learn expressive representations for diverse time series.</summary>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-12T18:54:57Z</published>
    <arxiv:primary_category term="cs.LG"/>
    <author>
      <name>Duy Nguyen</name>
    </author>
    <author>
      <name>Jiachen Yao</name>
    </author>
    <author>
      <name>Jiayun Wang</name>
    </author>
    <author>
      <name>Julius Berner</name>
    </author>
    <author>
      <name>Animashree Anandkumar</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.12262v1</id>
    <title>T3D: Few-Step Diffusion Language Models via Trajectory Self-Distillation with Direct Discriminative Optimization</title>
    <updated>2026-02-12T18:52:35Z</updated>
    <link href="https://arxiv.org/abs/2602.12262v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.12262v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Diffusion large language models (DLLMs) have the potential to enable fast text generation by decoding multiple tokens in parallel. However, in practice, their inference efficiency is constrained by the need for many refinement steps, while aggressively reducing the number of steps leads to a substantial degradation in generation quality. To alleviate this, we propose a trajectory self-distillation framework that improves few-step decoding by distilling the model's own generative trajectories. We incorporate Direct Discriminative Optimization (DDO), a reverse-KL objective that promotes mode-seeking distillation and encourages the student to concentrate on high-probability teacher modes. Across benchmarks, our approach consistently outperforms strong few-step baselines and standard training under tight step budgets. Although full-step decoding remains superior, we substantially narrow the gap, establishing a strong foundation towards practical few-step DLLMs. The source code is available at https://github.com/Tyrion58/T3D.</summary>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-12T18:52:35Z</published>
    <arxiv:primary_category term="cs.CL"/>
    <author>
      <name>Tunyu Zhang</name>
    </author>
    <author>
      <name>Xinxi Zhang</name>
    </author>
    <author>
      <name>Ligong Han</name>
    </author>
    <author>
      <name>Haizhou Shi</name>
    </author>
    <author>
      <name>Xiaoxiao He</name>
    </author>
    <author>
      <name>Zhuowei Li</name>
    </author>
    <author>
      <name>Hao Wang</name>
    </author>
    <author>
      <name>Kai Xu</name>
    </author>
    <author>
      <name>Akash Srivastava</name>
    </author>
    <author>
      <name>Hao Wang</name>
    </author>
    <author>
      <name>Vladimir Pavlovic</name>
    </author>
    <author>
      <name>Dimitris N. Metaxas</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.12259v1</id>
    <title>Think like a Scientist: Physics-guided LLM Agent for Equation Discovery</title>
    <updated>2026-02-12T18:49:27Z</updated>
    <link href="https://arxiv.org/abs/2602.12259v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.12259v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Explaining observed phenomena through symbolic, interpretable formulas is a fundamental goal of science. Recently, large language models (LLMs) have emerged as promising tools for symbolic equation discovery, owing to their broad domain knowledge and strong reasoning capabilities. However, most existing LLM-based systems try to guess equations directly from data, without modeling the multi-step reasoning process that scientists often follow: first inferring physical properties such as symmetries, then using these as priors to restrict the space of candidate equations. We introduce KeplerAgent, an agentic framework that explicitly follows this scientific reasoning process. The agent coordinates physics-based tools to extract intermediate structure and uses these results to configure symbolic regression engines such as PySINDy and PySR, including their function libraries and structural constraints. Across a suite of physical equation benchmarks, KeplerAgent achieves substantially higher symbolic accuracy and greater robustness to noisy data than both LLM and traditional baselines.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-12T18:49:27Z</published>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Jianke Yang</name>
    </author>
    <author>
      <name>Ohm Venkatachalam</name>
    </author>
    <author>
      <name>Mohammad Kianezhad</name>
    </author>
    <author>
      <name>Sharvaree Vadgama</name>
    </author>
    <author>
      <name>Rose Yu</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.12250v1</id>
    <title>Community Concealment from Unsupervised Graph Learning-Based Clustering</title>
    <updated>2026-02-12T18:36:19Z</updated>
    <link href="https://arxiv.org/abs/2602.12250v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.12250v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Graph neural networks (GNNs) are designed to use attributed graphs to learn representations. Such representations are beneficial in the unsupervised learning of clusters and community detection. Nonetheless, such inference may reveal sensitive groups, clustered systems, or collective behaviors, raising concerns regarding group-level privacy. Community attribution in social and critical infrastructure networks, for example, can expose coordinated asset groups, operational hierarchies, and system dependencies that could be used for profiling or intelligence gathering. We study a defensive setting in which a data publisher (defender) seeks to conceal a community of interest while making limited, utility-aware changes in the network. Our analysis indicates that community concealment is strongly influenced by two quantifiable factors: connectivity at the community boundary and feature similarity between the protected community and adjacent communities. Informed by these findings, we present a perturbation strategy that rewires a set of selected edges and modifies node features to reduce the distinctiveness leveraged by GNN message passing. The proposed method outperforms DICE in our experiments on synthetic benchmarks and real network graphs under identical perturbation budgets. Overall, it achieves median relative concealment improvements of approximately 20-45% across the evaluated settings. These findings demonstrate a mitigation strategy against GNN-based community learning and highlight group-level privacy risks intrinsic to graph learning.</summary>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-12T18:36:19Z</published>
    <arxiv:primary_category term="cs.LG"/>
    <author>
      <name>Dalyapraz Manatova</name>
    </author>
    <author>
      <name>Pablo Moriano</name>
    </author>
    <author>
      <name>L. Jean Camp</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.12243v1</id>
    <title>Federated Gaussian Process Learning via Pseudo-Representations for Large-Scale Multi-Robot Systems</title>
    <updated>2026-02-12T18:28:27Z</updated>
    <link href="https://arxiv.org/abs/2602.12243v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.12243v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Multi-robot systems require scalable and federated methods to model complex environments under computational and communication constraints. Gaussian Processes (GPs) offer robust probabilistic modeling, but suffer from cubic computational complexity, limiting their applicability in large-scale deployments. To address this challenge, we introduce the pxpGP, a novel distributed GP framework tailored for both centralized and decentralized large-scale multi-robot networks. Our approach leverages sparse variational inference to generate a local compact pseudo-representation. We introduce a sparse variational optimization scheme that bounds local pseudo-datasets and formulate a global scaled proximal-inexact consensus alternating direction method of multipliers (ADMM) with adaptive parameter updates and warm-start initialization. Experiments on synthetic and real-world datasets demonstrate that pxpGP and its decentralized variant, dec-pxpGP, outperform existing distributed GP methods in hyperparameter estimation and prediction accuracy, particularly in large-scale networks.</summary>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-12T18:28:27Z</published>
    <arxiv:comment>Accepted at 25th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2026)</arxiv:comment>
    <arxiv:primary_category term="cs.MA"/>
    <arxiv:journal_ref>25th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2026)</arxiv:journal_ref>
    <author>
      <name>Sanket A. Salunkhe</name>
    </author>
    <author>
      <name>George P. Kontoudis</name>
    </author>
    <arxiv:doi>10.65109/YQEA8075</arxiv:doi>
    <link rel="related" href="https://doi.org/10.65109/YQEA8075" title="doi"/>
  </entry>
</feed>
