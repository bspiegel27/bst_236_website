<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-12-16T01:00:43Z -->
<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/" xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns="http://www.w3.org/2005/Atom">
  <id>https://arxiv.org/api/p6EyKyP4fMY/66n9Ev8E79F7KlI</id>
  <title>arXiv Query: search_query=all:causal OR all:inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <updated>2025-12-16T01:00:44Z</updated>
  <link href="https://arxiv.org/api/query?search_query=all:causal+OR+all:inference&amp;start=0&amp;max_results=10&amp;id_list=" type="application/atom+xml"/>
  <opensearch:itemsPerPage>10</opensearch:itemsPerPage>
  <opensearch:totalResults>128549</opensearch:totalResults>
  <opensearch:startIndex>0</opensearch:startIndex>
  <entry>
    <id>http://arxiv.org/abs/2512.11798v1</id>
    <title>Particulate: Feed-Forward 3D Object Articulation</title>
    <updated>2025-12-12T18:59:51Z</updated>
    <link href="https://arxiv.org/abs/2512.11798v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.11798v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>We present Particulate, a feed-forward approach that, given a single static 3D mesh of an everyday object, directly infers all attributes of the underlying articulated structure, including its 3D parts, kinematic structure, and motion constraints. At its core is a transformer network, Part Articulation Transformer, which processes a point cloud of the input mesh using a flexible and scalable architecture to predict all the aforementioned attributes with native multi-joint support. We train the network end-to-end on a diverse collection of articulated 3D assets from public datasets. During inference, Particulate lifts the network's feed-forward prediction to the input mesh, yielding a fully articulated 3D model in seconds, much faster than prior approaches that require per-object optimization. Particulate can also accurately infer the articulated structure of AI-generated 3D assets, enabling full-fledged extraction of articulated 3D objects from a single (real or synthetic) image when combined with an off-the-shelf image-to-3D generator. We further introduce a new challenging benchmark for 3D articulation estimation curated from high-quality public 3D assets, and redesign the evaluation protocol to be more consistent with human preferences. Quantitative and qualitative results show that Particulate significantly outperforms state-of-the-art approaches.</summary>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-12T18:59:51Z</published>
    <arxiv:comment>Project page: https://ruiningli.com/particulate</arxiv:comment>
    <arxiv:primary_category term="cs.CV"/>
    <author>
      <name>Ruining Li</name>
    </author>
    <author>
      <name>Yuxin Yao</name>
    </author>
    <author>
      <name>Chuanxia Zheng</name>
    </author>
    <author>
      <name>Christian Rupprecht</name>
    </author>
    <author>
      <name>Joan Lasenby</name>
    </author>
    <author>
      <name>Shangzhe Wu</name>
    </author>
    <author>
      <name>Andrea Vedaldi</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.11769v1</id>
    <title>BLURR: A Boosted Low-Resource Inference for Vision-Language-Action Models</title>
    <updated>2025-12-12T18:30:45Z</updated>
    <link href="https://arxiv.org/abs/2512.11769v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.11769v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Vision-language-action (VLA) models enable impressive zero shot manipulation, but their inference stacks are often too heavy for responsive web demos or high frequency robot control on commodity GPUs. We present BLURR, a lightweight inference wrapper that can be plugged into existing VLA controllers without retraining or changing model checkpoints. Instantiated on the pi-zero VLA controller, BLURR keeps the original observation interfaces and accelerates control by combining an instruction prefix key value cache, mixed precision execution, and a single step rollout schedule that reduces per step computation. In our SimplerEnv based evaluation, BLURR maintains task success rates comparable to the original controller while significantly lowering effective FLOPs and wall clock latency. We also build an interactive web demo that allows users to switch between controllers and toggle inference options in real time while watching manipulation episodes. This highlights BLURR as a practical approach for deploying modern VLA policies under tight compute budgets.</summary>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-12T18:30:45Z</published>
    <arxiv:comment>10 pages, 3 figures. Code and integration scripts will be released at this http URL: https://github.com/JijiKing-Sam/BLURR-A-Boosted-Low-Resource-Inference-for-Vision-Language-Action-Model</arxiv:comment>
    <arxiv:primary_category term="cs.RO"/>
    <author>
      <name>Xiaoyu Ma</name>
    </author>
    <author>
      <name>Zhengqing Yuan</name>
    </author>
    <author>
      <name>Zheyuan Zhang</name>
    </author>
    <author>
      <name>Kaiwen Shi</name>
    </author>
    <author>
      <name>Lichao Sun</name>
    </author>
    <author>
      <name>Yanfang Ye</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.11761v1</id>
    <title>Covariate-assisted graph matching</title>
    <updated>2025-12-12T18:12:56Z</updated>
    <link href="https://arxiv.org/abs/2512.11761v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.11761v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Data integration is essential across diverse domains, from historical records to biomedical research, facilitating joint statistical inference. A crucial initial step in this process involves merging multiple data sources based on matching individual records, often in the absence of unique identifiers. When the datasets are networks, this problem is typically addressed through graph matching methodologies. For such cases, auxiliary features or covariates associated with nodes or edges can be instrumental in achieving improved accuracy. However, most existing graph matching techniques do not incorporate this information, limiting their performance against non-identifiable and erroneous matches. To overcome these limitations, we propose two novel covariate-assisted seeded graph matching methods, where a partial alignment for a set of nodes, called seeds, is known. The first one solves a quadratic assignment problem (QAP) over the whole graph, while the second one only leverages the local neighborhood structure of seed nodes for computational scalability. Both methods are grounded in a conditional modeling framework, where elements of one graph's adjacency matrix are modeled using a generalized linear model (GLM), given the other graph and the available covariates. We establish theoretical guarantees for model estimation error and exact recovery of the solution of the QAP. The effectiveness of our methods is demonstrated through numerical experiments and in an application to matching the statistics academic genealogy and the collaboration networks. By leveraging additional covariates, we achieve improved alignment accuracy. Our work highlights the power of integrating covariate information in the classical graph matching setup, offering a practical and improved framework for combining network data with wide-ranging applications.</summary>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-12T18:12:56Z</published>
    <arxiv:primary_category term="stat.ME"/>
    <author>
      <name>Trisha Dawn</name>
    </author>
    <author>
      <name>Jes√∫s Arroyo</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.11758v1</id>
    <title>The Effect of a Non-universal Extinction Curve on the Wesenheit Function and Cepheid Distances</title>
    <updated>2025-12-12T18:08:36Z</updated>
    <link href="https://arxiv.org/abs/2512.11758v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.11758v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>The Wesenheit function is widely used to reduce the effects of interstellar reddening in distance measurements. Its construction, however, relies on the assumption of a universal extinction curve and on fixed values of the total-to-selective extinction ratio, Rv. Recent studies have shown that Rv varies significantly across the Milky Way and between different galaxies, raising concerns about systematic biases in Wesenheit magnitudes and period-Wesenheit relations. In this work, we discuss the impact of non-universal extinction on Wesenheit indices by combining the Rv-dependent extinction curve with a grid of stellar atmosphere models. We compute the integrated extinction in optical and near-infrared passbands, derive Rv-dependent R coefficients for multiple Wesenheit indices, and examine how changes in Rv propagate into Wesenheit magnitudes and Cepheid distances in our Galaxy. We find that the R coefficients in the Wesenheit functions vary strongly with Rv. For classical Cepheids in the Milky Way disk, variations of Rv within the typical observed range (2.6-3.6) can lead to substantial differences in the Wesenheit function, reaching +-0.7 mag from the mean for the Gaia-based Wesenheit index W_G and resulting in distance errors of almost 40%. Near-infrared Wesenheit indices are much less sensitive to Rv changes. Our results clearly show that accounting for variable Rv is essential when applying period-Wesenheit relations, particularly in the optical regime, or that near or mid infrared based distances should be used. While we present this effect for classical Cepheids, it applies to all pulsating stars for which period-Wesenheit relations are used to infer distances.</summary>
    <category term="astro-ph.GA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.SR" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-12T18:08:36Z</published>
    <arxiv:comment>8 pages, 5 figures, 1 table, submitted to AAS Journals</arxiv:comment>
    <arxiv:primary_category term="astro-ph.GA"/>
    <author>
      <name>D. M. Skowron</name>
    </author>
    <author>
      <name>M. L. Fouesneau</name>
    </author>
    <author>
      <name>R. Drimmel</name>
    </author>
    <author>
      <name>S. Khanna</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.11751v1</id>
    <title>Forest Kernel Balancing Weights: Outcome-Guided Features for Causal Inference</title>
    <updated>2025-12-12T17:52:03Z</updated>
    <link href="https://arxiv.org/abs/2512.11751v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.11751v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>While balancing covariates between groups is central for observational causal inference, selecting which features to balance remains a challenging problem. Kernel balancing is a promising approach that first estimates a kernel that captures similarity across units and then balances a (possibly low-dimensional) summary of that kernel, indirectly learning important features to balance. In this paper, we propose forest kernel balancing, which leverages the underappreciated fact that tree-based machine learning models, namely random forests and Bayesian additive regression trees (BART), implicitly estimate a kernel based on the co-occurrence of observations in the same terminal leaf node. Thus, even though the resulting kernel is solely a function of baseline features, the selected nonlinearities and other interactions are important for predicting the outcome -- and therefore are important for addressing confounding. Through simulations and applied illustrations, we show that forest kernel balancing leads to meaningful computational and statistical improvement relative to standard kernel methods, which do not incorporate outcome information when learning features.</summary>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-12T17:52:03Z</published>
    <arxiv:primary_category term="stat.ME"/>
    <author>
      <name>Andy A. Shen</name>
    </author>
    <author>
      <name>Eli Ben-Michael</name>
    </author>
    <author>
      <name>Avi Feller</name>
    </author>
    <author>
      <name>Luke Keele</name>
    </author>
    <author>
      <name>Jared Murray</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.11749v1</id>
    <title>SVG-T2I: Scaling Up Text-to-Image Latent Diffusion Model Without Variational Autoencoder</title>
    <updated>2025-12-12T17:45:03Z</updated>
    <link href="https://arxiv.org/abs/2512.11749v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.11749v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Visual generation grounded in Visual Foundation Model (VFM) representations offers a highly promising unified pathway for integrating visual understanding, perception, and generation. Despite this potential, training large-scale text-to-image diffusion models entirely within the VFM representation space remains largely unexplored. To bridge this gap, we scale the SVG (Self-supervised representations for Visual Generation) framework, proposing SVG-T2I to support high-quality text-to-image synthesis directly in the VFM feature domain. By leveraging a standard text-to-image diffusion pipeline, SVG-T2I achieves competitive performance, reaching 0.75 on GenEval and 85.78 on DPG-Bench. This performance validates the intrinsic representational power of VFMs for generative tasks. We fully open-source the project, including the autoencoder and generation model, together with their training, inference, evaluation pipelines, and pre-trained weights, to facilitate further research in representation-driven visual generation.</summary>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-12T17:45:03Z</published>
    <arxiv:comment>Code Repository: https://github.com/KlingTeam/SVG-T2I; Model Weights: https://huggingface.co/KlingTeam/SVG-T2I</arxiv:comment>
    <arxiv:primary_category term="cs.CV"/>
    <author>
      <name>Minglei Shi</name>
    </author>
    <author>
      <name>Haolin Wang</name>
    </author>
    <author>
      <name>Borui Zhang</name>
    </author>
    <author>
      <name>Wenzhao Zheng</name>
    </author>
    <author>
      <name>Bohan Zeng</name>
    </author>
    <author>
      <name>Ziyang Yuan</name>
    </author>
    <author>
      <name>Xiaoshi Wu</name>
    </author>
    <author>
      <name>Yuanxing Zhang</name>
    </author>
    <author>
      <name>Huan Yang</name>
    </author>
    <author>
      <name>Xintao Wang</name>
    </author>
    <author>
      <name>Pengfei Wan</name>
    </author>
    <author>
      <name>Kun Gai</name>
    </author>
    <author>
      <name>Jie Zhou</name>
    </author>
    <author>
      <name>Jiwen Lu</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.11744v1</id>
    <title>The low-mass and structured stellar halo of M83 argues against a merger origin for its starburst and extended neutral hydrogen disk</title>
    <updated>2025-12-12T17:38:46Z</updated>
    <link href="https://arxiv.org/abs/2512.11744v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.11744v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>A merger origin has been suggested for M83's massive, metal-rich extended HI disk and nuclear starburst. We observe M83's stellar halo to test this idea. We train nearest-neighbor star-galaxy separation on wide-area Subaru imaging with Hubble Space Telescope data to map M83's halo in resolved stars. We find that M83 has an extended, very low density smooth stellar halo of old and metal-poor [M/H]$\sim -1.15$ RGB stars with a mass between 15 and 40 kpc of $\log_{10}M_{*,15-40,maj}/M_{\odot}=8.02\pm0.10$. In addition to M83's well-known Northern Stream, our ground-based Subaru imaging reveals a new stream to M83's south, which modeling suggests could be its trailing arm. The combined stream masses are $\log_{10}M_{stream}/M_{\odot}=7.93\pm0.10$, with metallicity [M/H]$= -1.0\pm0.2$. The stream progenitor was only recently accreted, as its stellar populations suggest that it formed stars until $2.1\pm1.3$ Gyr ago. M83 lies on the stellar halo mass-metallicity correlation seen for other Milky Way mass galaxies, albeit with low stellar halo mass. We infer a total accreted mass of $\log_{10}M_{*,accreted}/M_{\odot}=8.78^{+0.22}_{-0.28}$, with the most massive past merger having $\log_{10}M_{*,dom}/M_{\odot}=8.5\pm0.3$. We identify plausible M83 analogs in TNG-50 with similar stellar halos, finding that while a recent accretion can create a prominent stellar stream, such accretions do not trigger starburst activity, nor do they deliver enough gas to form M83's extended Hi disk. We conclude that other non-merger mechanisms, such as secular evolution or accretion of gas from the IGM, are likely to be responsible for M83's remarkable properties.</summary>
    <category term="astro-ph.GA" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-12T17:38:46Z</published>
    <arxiv:comment>31 pages, 15 figures. Accepted to AAS Journals December 10, 2025. The Subaru and HST photometric catalogs are available at https://doi.org/10.5281/zenodo.17398573</arxiv:comment>
    <arxiv:primary_category term="astro-ph.GA"/>
    <author>
      <name>Eric F. Bell</name>
    </author>
    <author>
      <name>Benjamin Harmsen</name>
    </author>
    <author>
      <name>Matthew Cosby</name>
    </author>
    <author>
      <name>Paul A. Price</name>
    </author>
    <author>
      <name>Sarah Pearson</name>
    </author>
    <author>
      <name>Antonela Monachesi</name>
    </author>
    <author>
      <name>Roelof S. de Jong</name>
    </author>
    <author>
      <name>Richard D'Souza</name>
    </author>
    <author>
      <name>Katya Gozman</name>
    </author>
    <author>
      <name>Jacob Nibauer</name>
    </author>
    <author>
      <name>Michael P. Busch</name>
    </author>
    <author>
      <name>Jeremy Bailin</name>
    </author>
    <author>
      <name>Benne W. Holwerda</name>
    </author>
    <author>
      <name>In Sung Jang</name>
    </author>
    <author>
      <name>Adam Smercina</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.11738v1</id>
    <title>Multiscale Causal Geometric Deep Learning for Modeling Brain Structure</title>
    <updated>2025-12-12T17:29:32Z</updated>
    <link href="https://arxiv.org/abs/2512.11738v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.11738v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Multimodal MRI offers complementary multi-scale information to characterize the brain structure. However, it remains challenging to effectively integrate multimodal MRI while achieving neuroscience interpretability. Here we propose to use Laplacian harmonics and spectral graph theory for multimodal alignment and multiscale integration. Based on the cortical mesh and connectome matrix that offer multi-scale representations, we devise Laplacian operators and spectral graph attentions to construct a shared latent space for model alignment. Next, we employ a disentangled learning combined with Graph Variational Autoencoder architectures to separate scale-specific and shared features. Lastly, we design a mutual information-informed bilevel regularizer to separate causal and non-causal factors based on the disentangled features, achieving robust model performance with enhanced interpretability. Our model outperforms baselines and other state-of-the-art models. The ablation studies confirmed the effectiveness of the proposed modules. Our model promises to offer a robust and interpretable framework for multi-scale brain structure analysis.</summary>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-12T17:29:32Z</published>
    <arxiv:primary_category term="q-bio.NC"/>
    <author>
      <name>Chengzhi Xia</name>
    </author>
    <author>
      <name>Jianwei Chen</name>
    </author>
    <author>
      <name>Yixuan Jiang</name>
    </author>
    <author>
      <name>Qi Yan</name>
    </author>
    <author>
      <name>Chao Li</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.11734v1</id>
    <title>Model Error Resonance: The Geometric Nature of Error Dynamics</title>
    <updated>2025-12-12T17:21:58Z</updated>
    <link href="https://arxiv.org/abs/2512.11734v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.11734v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>This paper introduces a geometric theory of model error, treating true and model dynamics as geodesic flows generated by distinct affine connections on a smooth manifold. When these connections differ, the resulting trajectory discrepancy--termed the Latent Error Dynamic Response (LEDR)--acquires an intrinsic dynamical structure governed by curvature. We show that the LEDR satisfies a Jacobi-type equation, where curvature mismatch acts as an explicit forcing term. In the important case of a flat model connection, the LEDR reduces to a classical Jacobi field on the true manifold, causing Model Error Resonance (MER) to emerge under positive sectional curvature. The theory is extended to a discrete-time analogue, establishing that this geometric structure and its resonant behavior persist in sampled systems. A closed-form analysis of a sphere--plane example demonstrates that curvature can be inferred directly from the LEDR evolution. This framework provides a unified geometric interpretation of structured error dynamics and offers foundational tools for curvature-informed model validation.</summary>
    <category term="eess.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-12T17:21:58Z</published>
    <arxiv:primary_category term="eess.SY"/>
    <author>
      <name>Yuntao Dai</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.11732v1</id>
    <title>Spatially Varying Gene Regulatory Networks via Bayesian Nonparametric Covariate-Dependent Directed Cyclic Graphical Models</title>
    <updated>2025-12-12T17:16:58Z</updated>
    <link href="https://arxiv.org/abs/2512.11732v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.11732v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Spatial transcriptomics technologies enable the measurement of gene expression with spatial context, providing opportunities to understand how gene regulatory networks vary across tissue regions. However, existing graphical models focus primarily on undirected graphs or directed acyclic graphs, limiting their ability to capture feedback loops that are prevalent in gene regulation. Moreover, ensuring the so-called stability condition of cyclic graphs, while allowing graph structures to vary continuously with spatial covariates, presents significant statistical and computational challenges. We propose BNP-DCGx, a Bayesian nonparametric approach for learning spatially varying gene regulatory networks via covariate-dependent directed cyclic graphical models. Our method introduces a covariate-dependent random partition as an intermediary layer in a hierarchical model, which discretizes the covariate space into clusters with cluster-specific stable directed cyclic graphs. Through partition averaging, we obtain smoothly varying graph structures over space while maintaining theoretical guarantees of stability. We develop an efficient parallel tempered Markov chain Monte Carlo algorithm for posterior inference and demonstrate through simulations that our method accurately recovers both piecewise constant and continuously varying graph structures. Application to spatial transcriptomics data from human dorsolateral prefrontal cortex reveals spatially varying regulatory networks with feedback loops, identifies potential cell subtypes within established cell types based on distinct regulatory mechanisms, and provides new insights into spatial organization of gene regulation in brain tissue.</summary>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-12T17:16:58Z</published>
    <arxiv:primary_category term="stat.ME"/>
    <author>
      <name>Trisha Dawn</name>
    </author>
    <author>
      <name>Yang Ni</name>
    </author>
  </entry>
</feed>
