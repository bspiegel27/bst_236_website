<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-10-04T00:49:40Z -->
<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acausal%20inference%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:causal inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/SsRksLzRb0LuVhSmQ+N8WbAs+f8</id>
  <updated>2025-10-03T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">122619</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">10</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2510.02312v1</id>
    <updated>2025-10-02T17:59:51Z</updated>
    <published>2025-10-02T17:59:51Z</published>
    <title>KaVa: Latent Reasoning via Compressed KV-Cache Distillation</title>
    <summary>  Large Language Models (LLMs) excel at multi-step reasoning problems with
explicit chain-of-thought (CoT), but verbose traces incur significant
computational costs and memory overhead, and often carry redundant, stylistic
artifacts. Latent reasoning has emerged as an efficient alternative that
internalizes the thought process, but it suffers from a critical lack of
supervision, limiting its effectiveness on complex, natural-language reasoning
traces. In this work, we propose KaVa, the first framework that bridges this
gap by distilling knowledge directly from a compressed KV-cache of the teacher
into a latent-reasoning student via self-distillation, leveraging the
representational flexibility of continuous latent tokens to align stepwise KV
trajectories. We show that the abstract, unstructured knowledge within
compressed KV-cache, which lacks direct token correspondence, can serve as a
rich supervisory signal for a latent reasoning student. Empirically, the
approach consistently outperforms strong latent baselines, exhibits markedly
smaller degradation from equation-only to natural-language traces, and scales
to larger backbones while preserving efficiency. These results establish
compressed KV-cache distillation as a scalable supervision signal for latent
reasoning, combining the accuracy of CoT-trained teachers with the efficiency
and deployability of latent inference.
</summary>
    <author>
      <name>Anna Kuzina</name>
    </author>
    <author>
      <name>Maciej Pioro</name>
    </author>
    <author>
      <name>Paul N. Whatmough</name>
    </author>
    <author>
      <name>Babak Ehteshami Bejnordi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Preprint. Under Review</arxiv:comment>
    <link href="http://arxiv.org/abs/2510.02312v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.02312v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.02311v1</id>
    <updated>2025-10-02T17:59:50Z</updated>
    <published>2025-10-02T17:59:50Z</published>
    <title>Inferring Dynamic Physical Properties from Video Foundation Models</title>
    <summary>  We study the task of predicting dynamic physical properties from videos. More
specifically, we consider physical properties that require temporal information
to be inferred: elasticity of a bouncing object, viscosity of a flowing liquid,
and dynamic friction of an object sliding on a surface. To this end, we make
the following contributions: (i) We collect a new video dataset for each
physical property, consisting of synthetic training and testing splits, as well
as a real split for real world evaluation. (ii) We explore three ways to infer
the physical property from videos: (a) an oracle method where we supply the
visual cues that intrinsically reflect the property using classical computer
vision techniques; (b) a simple read out mechanism using a visual prompt and
trainable prompt vector for cross-attention on pre-trained video generative and
self-supervised models; and (c) prompt strategies for Multi-modal Large
Language Models (MLLMs). (iii) We show that video foundation models trained in
a generative or self-supervised manner achieve a similar performance, though
behind that of the oracle, and MLLMs are currently inferior to the other
models, though their performance can be improved through suitable prompting.
</summary>
    <author>
      <name>Guanqi Zhan</name>
    </author>
    <author>
      <name>Xianzheng Ma</name>
    </author>
    <author>
      <name>Weidi Xie</name>
    </author>
    <author>
      <name>Andrew Zisserman</name>
    </author>
    <link href="http://arxiv.org/abs/2510.02311v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.02311v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.02300v1</id>
    <updated>2025-10-02T17:59:06Z</updated>
    <published>2025-10-02T17:59:06Z</published>
    <title>Equilibrium Matching: Generative Modeling with Implicit Energy-Based
  Models</title>
    <summary>  We introduce Equilibrium Matching (EqM), a generative modeling framework
built from an equilibrium dynamics perspective. EqM discards the
non-equilibrium, time-conditional dynamics in traditional diffusion and
flow-based generative models and instead learns the equilibrium gradient of an
implicit energy landscape. Through this approach, we can adopt an
optimization-based sampling process at inference time, where samples are
obtained by gradient descent on the learned landscape with adjustable step
sizes, adaptive optimizers, and adaptive compute. EqM surpasses the generation
performance of diffusion/flow models empirically, achieving an FID of 1.90 on
ImageNet 256$\times$256. EqM is also theoretically justified to learn and
sample from the data manifold. Beyond generation, EqM is a flexible framework
that naturally handles tasks including partially noised image denoising, OOD
detection, and image composition. By replacing time-conditional velocities with
a unified equilibrium landscape, EqM offers a tighter bridge between flow and
energy-based models and a simple route to optimization-driven inference.
</summary>
    <author>
      <name>Runqian Wang</name>
    </author>
    <author>
      <name>Yilun Du</name>
    </author>
    <link href="http://arxiv.org/abs/2510.02300v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.02300v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.02291v1</id>
    <updated>2025-10-02T17:58:37Z</updated>
    <published>2025-10-02T17:58:37Z</published>
    <title>Test-Time Anchoring for Discrete Diffusion Posterior Sampling</title>
    <summary>  We study the problem of posterior sampling using pretrained discrete
diffusion foundation models, aiming to recover images from noisy measurements
without retraining task-specific models. While diffusion models have achieved
remarkable success in generative modeling, most advances rely on continuous
Gaussian diffusion. In contrast, discrete diffusion offers a unified framework
for jointly modeling categorical data such as text and images. Beyond
unification, discrete diffusion provides faster inference, finer control, and
principled training-free Bayesian inference, making it particularly well-suited
for posterior sampling. However, existing approaches to discrete diffusion
posterior sampling face severe challenges: derivative-free guidance yields
sparse signals, continuous relaxations limit applicability, and split Gibbs
samplers suffer from the curse of dimensionality. To overcome these
limitations, we introduce Anchored Posterior Sampling (APS) for masked
diffusion foundation models, built on two key innovations -- quantized
expectation for gradient-like guidance in discrete embedding space, and
anchored remasking for adaptive decoding. Our approach achieves
state-of-the-art performance among discrete diffusion samplers across linear
and nonlinear inverse problems on the standard benchmarks. We further
demonstrate the benefits of our approach in training-free stylization and
text-guided editing.
</summary>
    <author>
      <name>Litu Rout</name>
    </author>
    <author>
      <name>Andreas Lugmayr</name>
    </author>
    <author>
      <name>Yasamin Jafarian</name>
    </author>
    <author>
      <name>Srivatsan Varadharajan</name>
    </author>
    <author>
      <name>Constantine Caramanis</name>
    </author>
    <author>
      <name>Sanjay Shakkottai</name>
    </author>
    <author>
      <name>Ira Kemelmacher-Shlizerman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Preprint</arxiv:comment>
    <link href="http://arxiv.org/abs/2510.02291v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.02291v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.02287v1</id>
    <updated>2025-10-02T17:57:06Z</updated>
    <published>2025-10-02T17:57:06Z</published>
    <title>MultiModal Action Conditioned Video Generation</title>
    <summary>  Current video models fail as world model as they lack fine-graiend control.
General-purpose household robots require real-time fine motor control to handle
delicate tasks and urgent situations. In this work, we introduce fine-grained
multimodal actions to capture such precise control. We consider senses of
proprioception, kinesthesia, force haptics, and muscle activation. Such
multimodal senses naturally enables fine-grained interactions that are
difficult to simulate with text-conditioned generative models. To effectively
simulate fine-grained multisensory actions, we develop a feature learning
paradigm that aligns these modalities while preserving the unique information
each modality provides. We further propose a regularization scheme to enhance
causality of the action trajectory features in representing intricate
interaction dynamics. Experiments show that incorporating multimodal senses
improves simulation accuracy and reduces temporal drift. Extensive ablation
studies and downstream applications demonstrate the effectiveness and
practicality of our work.
</summary>
    <author>
      <name>Yichen Li</name>
    </author>
    <author>
      <name>Antonio Torralba</name>
    </author>
    <link href="http://arxiv.org/abs/2510.02287v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.02287v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.02284v1</id>
    <updated>2025-10-02T17:56:46Z</updated>
    <published>2025-10-02T17:56:46Z</published>
    <title>Learning to Generate Object Interactions with Physics-Guided Video
  Diffusion</title>
    <summary>  Recent models for video generation have achieved remarkable progress and are
now deployed in film, social media production, and advertising. Beyond their
creative potential, such models also hold promise as world simulators for
robotics and embodied decision making. Despite strong advances, however,
current approaches still struggle to generate physically plausible object
interactions and lack physics-grounded control mechanisms. To address this
limitation, we introduce KineMask, an approach for physics-guided video
generation that enables realistic rigid body control, interactions, and
effects. Given a single image and a specified object velocity, our method
generates videos with inferred motions and future object interactions. We
propose a two-stage training strategy that gradually removes future motion
supervision via object masks. Using this strategy we train video diffusion
models (VDMs) on synthetic scenes of simple interactions and demonstrate
significant improvements of object interactions in real scenes. Furthermore,
KineMask integrates low-level motion control with high-level textual
conditioning via predictive scene descriptions, leading to effective support
for synthesis of complex dynamical phenomena. Extensive experiments show that
KineMask achieves strong improvements over recent models of comparable size.
Ablation studies further highlight the complementary roles of low- and
high-level conditioning in VDMs. Our code, model, and data will be made
publicly available.
</summary>
    <author>
      <name>David Romero</name>
    </author>
    <author>
      <name>Ariana Bermudez</name>
    </author>
    <author>
      <name>Hao Li</name>
    </author>
    <author>
      <name>Fabio Pizzati</name>
    </author>
    <author>
      <name>Ivan Laptev</name>
    </author>
    <link href="http://arxiv.org/abs/2510.02284v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.02284v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.02268v1</id>
    <updated>2025-10-02T17:47:06Z</updated>
    <published>2025-10-02T17:47:06Z</published>
    <title>Do You Know Where Your Camera Is? View-Invariant Policy Learning with
  Camera Conditioning</title>
    <summary>  We study view-invariant imitation learning by explicitly conditioning
policies on camera extrinsics. Using Plucker embeddings of per-pixel rays, we
show that conditioning on extrinsics significantly improves generalization
across viewpoints for standard behavior cloning policies, including ACT,
Diffusion Policy, and SmolVLA. To evaluate policy robustness under realistic
viewpoint shifts, we introduce six manipulation tasks in RoboSuite and
ManiSkill that pair "fixed" and "randomized" scene variants, decoupling
background cues from camera pose. Our analysis reveals that policies without
extrinsics often infer camera pose using visual cues from static backgrounds in
fixed scenes; this shortcut collapses when workspace geometry or camera
placement shifts. Conditioning on extrinsics restores performance and yields
robust RGB-only control without depth. We release the tasks, demonstrations,
and code at https://ripl.github.io/know_your_camera/ .
</summary>
    <author>
      <name>Tianchong Jiang</name>
    </author>
    <author>
      <name>Jingtian Ji</name>
    </author>
    <author>
      <name>Xiangshan Tan</name>
    </author>
    <author>
      <name>Jiading Fang</name>
    </author>
    <author>
      <name>Anand Bhattad</name>
    </author>
    <author>
      <name>Vitor Guizilini</name>
    </author>
    <author>
      <name>Matthew R. Walter</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Code and project materials are available at
  ripl.github.io/know_your_camera</arxiv:comment>
    <link href="http://arxiv.org/abs/2510.02268v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.02268v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.02260v1</id>
    <updated>2025-10-02T17:42:26Z</updated>
    <published>2025-10-02T17:42:26Z</published>
    <title>Mapping the Cloud-Driven Atmospheric Dynamics &amp; Chemistry of an Isolated
  Exoplanet Analog with Harmonic Signatures</title>
    <summary>  Young planetary-mass objects and brown dwarfs near the L/T spectral
transition exhibit enhanced spectrophotometric variability over field brown
dwarfs. Patchy clouds, auroral processes, stratospheric hot spots, and complex
carbon chemistry have all been proposed as potential sources of this
variability. Using time-resolved, low-to-mid-resolution spectroscopy collected
with the JWST/NIRISS and NIRSpec instruments, we apply harmonic analysis to
SIMP J0136, a highly variable, young, isolated planetary-mass object. Odd
harmonics (k=3) at pressure levels (&gt; 1 bar) corresponding to iron and
forsterite cloud formation suggest North/South hemispheric asymmetry in the
cloudy, and likely equatorial, regions. We use the inferred harmonics, along
with 1-D substellar atmospheric models, to map the flux variability by
atmospheric pressure level. These vertical maps demonstrate robust interaction
between deep convective weather layers and the overlying stratified and
radiative atmosphere. We identify distinct time-varying structures in the
near-infrared that we interpret as planetary-scale wave (e.g., Rossby or
Kelvin)-associated cloud modulation. We detect variability in water (S/N =
14.0), carbon monoxide (S/N = 13.0), and methane (S/N = 14.9) molecular
signatures. Forsterite cloud modulation is anti-correlated with overlying
carbon monoxide and water abundances and correlated with deep methane
absorption, suggesting complex interaction between cloud formation, atmospheric
chemistry, and temperature structure. Furthermore, we identify distinct
harmonic behavior between methane and carbon monoxide absorption bands,
providing evidence for time-resolved disequilibrium carbon chemistry. At the
lowest pressures (&lt; 100 mbar), we find that the mapped methane lines transition
from absorption to emission, supporting evidence of high-altitude auroral
heating via electron precipitation.
</summary>
    <author>
      <name>Michael K. Plummer</name>
    </author>
    <author>
      <name>Francis P. Cocchini</name>
    </author>
    <author>
      <name>Peter A. Kearns</name>
    </author>
    <author>
      <name>Allison McCarthy</name>
    </author>
    <author>
      <name>Étienne Artigau</name>
    </author>
    <author>
      <name>Nicolas B. Cowan</name>
    </author>
    <author>
      <name>Roman Akhmetshyn</name>
    </author>
    <author>
      <name>Johanna Vos</name>
    </author>
    <author>
      <name>Evert Nasedkin</name>
    </author>
    <author>
      <name>Channon Visscher</name>
    </author>
    <author>
      <name>Björn Benneke</name>
    </author>
    <author>
      <name>René Doyon</name>
    </author>
    <author>
      <name>Stanimir A. Metchev</name>
    </author>
    <author>
      <name>Jason F. Rowe</name>
    </author>
    <author>
      <name>Genaro Suárez</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 6 figures, submitted</arxiv:comment>
    <link href="http://arxiv.org/abs/2510.02260v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.02260v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.EP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.EP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.SR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.02259v1</id>
    <updated>2025-10-02T17:42:10Z</updated>
    <published>2025-10-02T17:42:10Z</published>
    <title>Transformers Discover Molecular Structure Without Graph Priors</title>
    <summary>  Graph Neural Networks (GNNs) are the dominant architecture for molecular
machine learning, particularly for molecular property prediction and machine
learning interatomic potentials (MLIPs). GNNs perform message passing on
predefined graphs often induced by a fixed radius cutoff or k-nearest neighbor
scheme. While this design aligns with the locality present in many molecular
tasks, a hard-coded graph can limit expressivity due to the fixed receptive
field and slows down inference with sparse graph operations. In this work, we
investigate whether pure, unmodified Transformers trained directly on Cartesian
coordinates$\unicode{x2013}$without predefined graphs or physical
priors$\unicode{x2013}$can approximate molecular energies and forces. As a
starting point for our analysis, we demonstrate how to train a Transformer to
competitive energy and force mean absolute errors under a matched training
compute budget, relative to a state-of-the-art equivariant GNN on the OMol25
dataset. We discover that the Transformer learns physically consistent
patterns$\unicode{x2013}$such as attention weights that decay inversely with
interatomic distance$\unicode{x2013}$and flexibly adapts them across different
molecular environments due to the absence of hard-coded biases. The use of a
standard Transformer also unlocks predictable improvements with respect to
scaling training resources, consistent with empirical scaling laws observed in
other domains. Our results demonstrate that many favorable properties of GNNs
can emerge adaptively in Transformers, challenging the necessity of hard-coded
graph inductive biases and pointing toward standardized, scalable architectures
for molecular modeling.
</summary>
    <author>
      <name>Tobias Kreiman</name>
    </author>
    <author>
      <name>Yutong Bai</name>
    </author>
    <author>
      <name>Fadi Atieh</name>
    </author>
    <author>
      <name>Elizabeth Weaver</name>
    </author>
    <author>
      <name>Eric Qu</name>
    </author>
    <author>
      <name>Aditi S. Krishnapriyan</name>
    </author>
    <link href="http://arxiv.org/abs/2510.02259v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.02259v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.mtrl-sci" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.chem-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.BM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2510.02242v1</id>
    <updated>2025-10-02T17:29:53Z</updated>
    <published>2025-10-02T17:29:53Z</published>
    <title>Transfer of Stability from the Classical to the Fractional Anisotropic
  Calderón Problem</title>
    <summary>  We discuss two spectral fractional anisotropic Calder\'on problems with
source-to-solution measurements and their quantitative relation to the
classical Calder\'on problem. Firstly, we consider the anistropic fractional
Calder\'on problem from [FGKU25]. In this setting, we quantify the relation
between the local and nonlocal Calder\'on problems which had been deduced in
[R25] and provide an associated stability estimate. As a consequence, any
stability result which holds on the level of the local problem with
source-to-solution data has a direct nonlocal analogue (up to a logarithmic
loss). Secondly, we introduce and discuss the fractional Calder\'on problem
with source-to-solution measurements for the spectral fractional Dirichlet
Laplacian on open, bounded, connected, Lipschitz sets on $\mathbb{R}^n$. Also
in this context, we provide a qualitative and quantitative transfer of
uniqueness from the local to the nonlocal setting. As a consequence, we infer
the first stability results for the principal part for a fractional Calder\'on
type problem for which no reduction of Liouville type is known. Our arguments
rely on quantitative unique continuation arguments. As a result of independent
interest, we also prove a quantitative relation between source-to-solution and
Dirichlet-to-Neumann measurements for the classical Calder\'on problem.
</summary>
    <author>
      <name>Hendrik Baers</name>
    </author>
    <author>
      <name>Angkana Rüland</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">54 pages, 4 figures, comments welcome</arxiv:comment>
    <link href="http://arxiv.org/abs/2510.02242v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2510.02242v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
