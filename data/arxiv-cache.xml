<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-08-05T01:04:30Z -->
<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acausal%20inference%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:causal inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/SsRksLzRb0LuVhSmQ+N8WbAs+f8</id>
  <updated>2025-08-04T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">118055</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">10</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2508.00819v1</id>
    <updated>2025-08-01T17:56:07Z</updated>
    <published>2025-08-01T17:56:07Z</published>
    <title>Beyond Fixed: Variable-Length Denoising for Diffusion Large Language
  Models</title>
    <summary>  Diffusion Large Language Models (DLLMs) are emerging as a powerful
alternative to the dominant Autoregressive Large Language Models, offering
efficient parallel generation and capable global context modeling. However, the
practical application of DLLMs is hindered by a critical architectural
constraint: the need for a statically predefined generation length. This static
length allocation leads to a problematic trade-off: insufficient lengths
cripple performance on complex tasks, while excessive lengths incur significant
computational overhead and sometimes result in performance degradation. While
the inference framework is rigid, we observe that the model itself possesses
internal signals that correlate with the optimal response length for a given
task. To bridge this gap, we leverage these latent signals and introduce
DAEDAL, a novel training-free denoising strategy that enables Dynamic Adaptive
Length Expansion for Diffusion Large Language Models. DAEDAL operates in two
phases: 1) Before the denoising process, DAEDAL starts from a short initial
length and iteratively expands it to a coarse task-appropriate length, guided
by a sequence completion metric. 2) During the denoising process, DAEDAL
dynamically intervenes by pinpointing and expanding insufficient generation
regions through mask token insertion, ensuring the final output is fully
developed. Extensive experiments on DLLMs demonstrate that DAEDAL achieves
performance comparable, and in some cases superior, to meticulously tuned
fixed-length baselines, while simultaneously enhancing computational efficiency
by achieving a higher effective token ratio. By resolving the static length
constraint, DAEDAL unlocks new potential for DLLMs, bridging a critical gap
with their Autoregressive counterparts and paving the way for more efficient
and capable generation.
</summary>
    <author>
      <name>Jinsong Li</name>
    </author>
    <author>
      <name>Xiaoyi Dong</name>
    </author>
    <author>
      <name>Yuhang Zang</name>
    </author>
    <author>
      <name>Yuhang Cao</name>
    </author>
    <author>
      <name>Jiaqi Wang</name>
    </author>
    <author>
      <name>Dahua Lin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Code is available at https://github.com/Li-Jinsong/DAEDAL</arxiv:comment>
    <link href="http://arxiv.org/abs/2508.00819v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.00819v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.00804v1</id>
    <updated>2025-08-01T17:37:19Z</updated>
    <published>2025-08-01T17:37:19Z</published>
    <title>Online Fine-Tuning of Carbon Emission Predictions using Real-Time
  Recurrent Learning for State Space Models</title>
    <summary>  This paper introduces a new approach for fine-tuning the predictions of
structured state space models (SSMs) at inference time using real-time
recurrent learning. While SSMs are known for their efficiency and long-range
modeling capabilities, they are typically trained offline and remain static
during deployment. Our method enables online adaptation by continuously
updating model parameters in response to incoming data. We evaluate our
approach for linear-recurrent-unit SSMs using a small carbon emission dataset
collected from embedded automotive hardware. Experimental results show that our
method consistently reduces prediction error online during inference,
demonstrating its potential for dynamic, resource-constrained environments.
</summary>
    <author>
      <name>Julian Lemmel</name>
    </author>
    <author>
      <name>Manuel Kranzl</name>
    </author>
    <author>
      <name>Adam Lamine</name>
    </author>
    <author>
      <name>Philipp Neubauer</name>
    </author>
    <author>
      <name>Radu Grosu</name>
    </author>
    <author>
      <name>Sophie Neubauer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2508.00804v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.00804v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.00788v1</id>
    <updated>2025-08-01T17:11:42Z</updated>
    <published>2025-08-01T17:11:42Z</published>
    <title>Do They Understand Them? An Updated Evaluation on Nonbinary Pronoun
  Handling in Large Language Models</title>
    <summary>  Large language models (LLMs) are increasingly deployed in sensitive contexts
where fairness and inclusivity are critical. Pronoun usage, especially
concerning gender-neutral and neopronouns, remains a key challenge for
responsible AI. Prior work, such as the MISGENDERED benchmark, revealed
significant limitations in earlier LLMs' handling of inclusive pronouns, but
was constrained to outdated models and limited evaluations. In this study, we
introduce MISGENDERED+, an extended and updated benchmark for evaluating LLMs'
pronoun fidelity. We benchmark five representative LLMs, GPT-4o, Claude 4,
DeepSeek-V3, Qwen Turbo, and Qwen2.5, across zero-shot, few-shot, and gender
identity inference. Our results show notable improvements compared with
previous studies, especially in binary and gender-neutral pronoun accuracy.
However, accuracy on neopronouns and reverse inference tasks remains
inconsistent, underscoring persistent gaps in identity-sensitive reasoning. We
discuss implications, model-specific observations, and avenues for future
inclusive AI research.
</summary>
    <author>
      <name>Xushuo Tang</name>
    </author>
    <author>
      <name>Yi Ding</name>
    </author>
    <author>
      <name>Zhengyi Yang</name>
    </author>
    <author>
      <name>Yin Chen</name>
    </author>
    <author>
      <name>Yongrui Gu</name>
    </author>
    <author>
      <name>Wenke Yang</name>
    </author>
    <author>
      <name>Mingchen Ju</name>
    </author>
    <author>
      <name>Xin Cao</name>
    </author>
    <author>
      <name>Yongfei Liu</name>
    </author>
    <author>
      <name>Wenjie Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/2508.00788v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.00788v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.00785v1</id>
    <updated>2025-08-01T17:09:49Z</updated>
    <published>2025-08-01T17:09:49Z</published>
    <title>Explainable AI and Machine Learning for Exam-based Student Evaluation:
  Causal and Predictive Analysis of Socio-academic and Economic Factors</title>
    <summary>  Academic performance depends on a multivariable nexus of socio-academic and
financial factors. This study investigates these influences to develop
effective strategies for optimizing students' CGPA. To achieve this, we
reviewed various literature to identify key influencing factors and constructed
an initial hypothetical causal graph based on the findings. Additionally, an
online survey was conducted, where 1,050 students participated, providing
comprehensive data for analysis. Rigorous data preprocessing techniques,
including cleaning and visualization, ensured data quality before analysis.
Causal analysis validated the relationships among variables, offering deeper
insights into their direct and indirect effects on CGPA. Regression models were
implemented for CGPA prediction, while classification models categorized
students based on performance levels. Ridge Regression demonstrated strong
predictive accuracy, achieving a Mean Absolute Error of 0.12 and a Mean Squared
Error of 0.023. Random Forest outperformed in classification, attaining an
F1-score near perfection and an accuracy of 98.68%. Explainable AI techniques
such as SHAP, LIME, and Interpret enhanced model interpretability, highlighting
critical factors such as study hours, scholarships, parental education, and
prior academic performance. The study culminated in the development of a
web-based application that provides students with personalized insights,
allowing them to predict academic performance, identify areas for improvement,
and make informed decisions to enhance their outcomes.
</summary>
    <author>
      <name>Bushra Akter</name>
    </author>
    <author>
      <name>Md Biplob Hosen</name>
    </author>
    <author>
      <name>Sabbir Ahmed</name>
    </author>
    <author>
      <name>Mehrin Anannya</name>
    </author>
    <author>
      <name>Md. Farhad Hossain</name>
    </author>
    <link href="http://arxiv.org/abs/2508.00785v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.00785v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.00768v1</id>
    <updated>2025-08-01T16:43:45Z</updated>
    <published>2025-08-01T16:43:45Z</published>
    <title>Evaluating Angle and Amplitude Encoding Strategies for Variational
  Quantum Machine Learning: their impact on model's accuracy</title>
    <summary>  Recent advancements in Quantum Computing and Machine Learning have increased
attention to Quantum Machine Learning (QML), which aims to develop machine
learning models by exploiting the quantum computing paradigm. One of the widely
used models in this area is the Variational Quantum Circuit (VQC), a hybrid
model where the quantum circuit handles data inference while classical
optimization adjusts the parameters of the circuit. The quantum circuit
consists of an encoding layer, which loads data into the circuit, and a
template circuit, known as the ansatz, responsible for processing the data.
This work involves performing an analysis by considering both Amplitude- and
Angle-encoding models, and examining how the type of rotational gate applied
affects the classification performance of the model. This comparison is carried
out by training the different models on two datasets, Wine and Diabetes, and
evaluating their performance. The study demonstrates that, under identical
model topologies, the difference in accuracy between the best and worst models
ranges from 10% to 30%, with differences reaching up to 41%. Moreover, the
results highlight how the choice of rotational gates used in encoding can
significantly impact the model's classification performance. The findings
confirm that the embedding represents a hyperparameter for VQC models.
</summary>
    <author>
      <name>Antonio Tudisco</name>
    </author>
    <author>
      <name>Andrea Marchesin</name>
    </author>
    <author>
      <name>Maurizio Zamboni</name>
    </author>
    <author>
      <name>Mariagrazia Graziano</name>
    </author>
    <author>
      <name>Giovanna Turvani</name>
    </author>
    <link href="http://arxiv.org/abs/2508.00768v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.00768v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.00756v1</id>
    <updated>2025-08-01T16:32:48Z</updated>
    <published>2025-08-01T16:32:48Z</published>
    <title>LeakyCLIP: Extracting Training Data from CLIP</title>
    <summary>  Understanding the memorization and privacy leakage risks in Contrastive
Language--Image Pretraining (CLIP) is critical for ensuring the security of
multimodal models. Recent studies have demonstrated the feasibility of
extracting sensitive training examples from diffusion models, with conditional
diffusion models exhibiting a stronger tendency to memorize and leak
information. In this work, we investigate data memorization and extraction
risks in CLIP through the lens of CLIP inversion, a process that aims to
reconstruct training images from text prompts. To this end, we introduce
\textbf{LeakyCLIP}, a novel attack framework designed to achieve high-quality,
semantically accurate image reconstruction from CLIP embeddings. We identify
three key challenges in CLIP inversion: 1) non-robust features, 2) limited
visual semantics in text embeddings, and 3) low reconstruction fidelity. To
address these challenges, LeakyCLIP employs 1) adversarial fine-tuning to
enhance optimization smoothness, 2) linear transformation-based embedding
alignment, and 3) Stable Diffusion-based refinement to improve fidelity.
Empirical results demonstrate the superiority of LeakyCLIP, achieving over 358%
improvement in Structural Similarity Index Measure (SSIM) for ViT-B-16 compared
to baseline methods on LAION-2B subset. Furthermore, we uncover a pervasive
leakage risk, showing that training data membership can even be successfully
inferred from the metrics of low-fidelity reconstructions. Our work introduces
a practical method for CLIP inversion while offering novel insights into the
nature and scope of privacy risks in multimodal models.
</summary>
    <author>
      <name>Yunhao Chen</name>
    </author>
    <author>
      <name>Shujie Wang</name>
    </author>
    <author>
      <name>Xin Wang</name>
    </author>
    <author>
      <name>Xingjun Ma</name>
    </author>
    <link href="http://arxiv.org/abs/2508.00756v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.00756v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.00751v1</id>
    <updated>2025-08-01T16:28:18Z</updated>
    <published>2025-08-01T16:28:18Z</published>
    <title>Harnessing the Power of Interleaving and Counterfactual Evaluation for
  Airbnb Search Ranking</title>
    <summary>  Evaluation plays a crucial role in the development of ranking algorithms on
search and recommender systems. It enables online platforms to create
user-friendly features that drive commercial success in a steady and effective
manner. The online environment is particularly conducive to applying causal
inference techniques, such as randomized controlled experiments (known as A/B
test), which are often more challenging to implement in fields like medicine
and public policy. However, businesses face unique challenges when it comes to
effective A/B test. Specifically, achieving sufficient statistical power for
conversion-based metrics can be time-consuming, especially for significant
purchases like booking accommodations. While offline evaluations are quicker
and more cost-effective, they often lack accuracy and are inadequate for
selecting candidates for A/B test. To address these challenges, we developed
interleaving and counterfactual evaluation methods to facilitate rapid online
assessments for identifying the most promising candidates for A/B tests. Our
approach not only increased the sensitivity of experiments by a factor of up to
100 (depending on the approach and metrics) compared to traditional A/B testing
but also streamlined the experimental process. The practical insights gained
from usage in production can also benefit organizations with similar interests.
</summary>
    <author>
      <name>Qing Zhang</name>
    </author>
    <author>
      <name>Alex Deng</name>
    </author>
    <author>
      <name>Michelle Du</name>
    </author>
    <author>
      <name>Huiji Gao</name>
    </author>
    <author>
      <name>Liwei He</name>
    </author>
    <author>
      <name>Sanjeev Katariya</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3711896.3737232</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3711896.3737232" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 31st ACM SIGKDD Conference on Knowledge
  Discovery and Data Mining V.2 (KDD 2025)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2508.00751v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.00751v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3; G.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.00746v1</id>
    <updated>2025-08-01T16:21:11Z</updated>
    <published>2025-08-01T16:21:11Z</published>
    <title>GECO: Geometrically Consistent Embedding with Lightspeed Inference</title>
    <summary>  Recent advances in feature learning have shown that self-supervised vision
foundation models can capture semantic correspondences but often lack awareness
of underlying 3D geometry. GECO addresses this gap by producing geometrically
coherent features that semantically distinguish parts based on geometry (e.g.,
left/right eyes, front/back legs). We propose a training framework based on
optimal transport, enabling supervision beyond keypoints, even under occlusions
and disocclusions. With a lightweight architecture, GECO runs at 30 fps, 98.2%
faster than prior methods, while achieving state-of-the-art performance on
PFPascal, APK, and CUB, improving PCK by 6.0%, 6.2%, and 4.1%, respectively.
Finally, we show that PCK alone is insufficient to capture geometric quality
and introduce new metrics and insights for more geometry-aware feature
learning. Link to project page:
https://reginehartwig.github.io/publications/geco/
</summary>
    <author>
      <name>Regine Hartwig</name>
    </author>
    <author>
      <name>Dominik Muhle</name>
    </author>
    <author>
      <name>Riccardo Marin</name>
    </author>
    <author>
      <name>Daniel Cremers</name>
    </author>
    <link href="http://arxiv.org/abs/2508.00746v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.00746v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.00741v1</id>
    <updated>2025-08-01T16:12:23Z</updated>
    <published>2025-08-01T16:12:23Z</published>
    <title>Out-of-Context Abduction: LLMs Make Inferences About Procedural Data
  Leveraging Declarative Facts in Earlier Training Data</title>
    <summary>  Large language models (LLMs) are trained on large corpora, yet it is unclear
whether they can reason about the information present within their training
data. We design experiments to study out-of-context abduction in LLMs, the
ability to infer the most plausible explanations for observations using
relevant facts present in training data. We train treatment LLMs on names and
behavior descriptions of fictitious chatbots, but not on examples of dialogue
with the chatbots. We find that OpenAI's GPT 4o LLM can correctly infer at
least one chatbot's name after observing example responses characteristic of
that chatbot. We also find that previously training GPT 4o on descriptions of a
chatbot's behavior allows it to display behaviors more characteristic of the
chatbot when iteratively trained to display such behaviors. Our results have
implications for situational awareness in LLMs and, therefore, for AI safety.
</summary>
    <author>
      <name>Sohaib Imran</name>
    </author>
    <author>
      <name>Rob Lamb</name>
    </author>
    <author>
      <name>Peter M. Atkinson</name>
    </author>
    <link href="http://arxiv.org/abs/2508.00741v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.00741v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.00738v1</id>
    <updated>2025-08-01T16:08:24Z</updated>
    <published>2025-08-01T16:08:24Z</published>
    <title>Tool-Assisted Conformance Checking to Reference Process Models</title>
    <summary>  Reference models convey best practices and standards. The reference
frameworks necessitate conformance checks to ensure adherence to established
guidelines and principles, which is crucial for maintaining quality and
consistency in various processes. This paper explores automated conformance
checks for concrete process models against reference models using causal
dependency analysis of tasks and events. Existing notions of conformance
checking for process models focus on verifying process execution traces and
lack the expressiveness and automation needed for semantic model comparison,
leaving this question unresolved. We integrate our approach into a broader
semantic framework for defining reference model conformance. We outline an
algorithm for reference process model conformance checking, evaluate it through
a case study, and discuss its strengths and limitations. Our research provides
a tool-assisted solution enhancing accuracy and flexibility in process model
conformance verification.
</summary>
    <author>
      <name>Bernhard Rumpe</name>
    </author>
    <author>
      <name>Max Stachon</name>
    </author>
    <author>
      <name>Sebastian St√ºber</name>
    </author>
    <author>
      <name>Valdes Voufo</name>
    </author>
    <link href="http://arxiv.org/abs/2508.00738v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.00738v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68N30" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
