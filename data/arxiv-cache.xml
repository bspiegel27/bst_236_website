<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2026-01-22T01:03:44Z -->
<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/" xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns="http://www.w3.org/2005/Atom">
  <id>https://arxiv.org/api/p6EyKyP4fMY/66n9Ev8E79F7KlI</id>
  <title>arXiv Query: search_query=all:causal OR all:inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <updated>2026-01-22T01:03:45Z</updated>
  <link href="https://arxiv.org/api/query?search_query=all:causal+OR+all:inference&amp;start=0&amp;max_results=10&amp;id_list=" type="application/atom+xml"/>
  <opensearch:itemsPerPage>10</opensearch:itemsPerPage>
  <opensearch:totalResults>131368</opensearch:totalResults>
  <opensearch:startIndex>0</opensearch:startIndex>
  <entry>
    <id>http://arxiv.org/abs/2601.14254v1</id>
    <title>Using observations of escaping H/He to constrain the atmospheric composition of sub-Neptunes</title>
    <updated>2026-01-20T18:59:55Z</updated>
    <link href="https://arxiv.org/abs/2601.14254v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.14254v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>The internal composition of sub-Neptunes remains a prominent unresolved question in exoplanetary science. We present a technique to place constraints on envelope mean molecular weight that utilises observations of escaping hydrogen or helium exospheres. This method is based on a simple timescale argument, which states that sub-Neptunes require a sufficiently large hydrogen or helium reservoir to explain on-going escape at their observed rates. This then naturally leads to an upper limit on atmospheric mean molecular weight. We apply this technique to archetypal sub-Neptunes, namely GJ-436 b, TOI-776 b and TOI-776 c, which have all been observed to be losing significant hydrogen content as well as relatively featureless transit spectra when observed with JWST. Combining constraints from atmospheric escape and transit spectroscopy in the case of TOI-776 c allows us to tentatively rule out the high mean molecular weight scenario, pointing towards a low mean molecular weight atmosphere with high-altitude aerosols muting spectral features in the infra-red. Finally, we reframe our analysis to the hycean candidate K2-18 b, which has also been shown to host a tentative escaping hydrogen exosphere. If such a detection is robust, we infer a hydrogen-rich envelope mass fraction of $\log f_\text{env} = -1.67\pm0.78$, which is inconsistent with the hycean scenario at the $\sim 4σ$ level. This latter result requires further observational follow-up to confirm.</summary>
    <category term="astro-ph.EP" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-20T18:59:55Z</published>
    <arxiv:comment>12 pages, 7 figures, submitted to MNRAS. Comments welcome</arxiv:comment>
    <arxiv:primary_category term="astro-ph.EP"/>
    <author>
      <name>James G. Rogers</name>
    </author>
    <author>
      <name>James E. Owen</name>
    </author>
    <author>
      <name>Ethan Schreyer</name>
    </author>
    <author>
      <name>James Kirk</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.14250v1</id>
    <title>OmniTransfer: All-in-one Framework for Spatio-temporal Video Transfer</title>
    <updated>2026-01-20T18:58:11Z</updated>
    <link href="https://arxiv.org/abs/2601.14250v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.14250v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Videos convey richer information than images or text, capturing both spatial and temporal dynamics. However, most existing video customization methods rely on reference images or task-specific temporal priors, failing to fully exploit the rich spatio-temporal information inherent in videos, thereby limiting flexibility and generalization in video generation. To address these limitations, we propose OmniTransfer, a unified framework for spatio-temporal video transfer. It leverages multi-view information across frames to enhance appearance consistency and exploits temporal cues to enable fine-grained temporal control. To unify various video transfer tasks, OmniTransfer incorporates three key designs: Task-aware Positional Bias that adaptively leverages reference video information to improve temporal alignment or appearance consistency; Reference-decoupled Causal Learning separating reference and target branches to enable precise reference transfer while improving efficiency; and Task-adaptive Multimodal Alignment using multimodal semantic guidance to dynamically distinguish and tackle different tasks. Extensive experiments show that OmniTransfer outperforms existing methods in appearance (ID and style) and temporal transfer (camera movement and video effects), while matching pose-guided methods in motion transfer without using pose, establishing a new paradigm for flexible, high-fidelity video generation.</summary>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-20T18:58:11Z</published>
    <arxiv:comment>Github Page: https://pangzecheung.github.io/OmniTransfer/</arxiv:comment>
    <arxiv:primary_category term="cs.CV"/>
    <author>
      <name>Pengze Zhang</name>
    </author>
    <author>
      <name>Yanze Wu</name>
    </author>
    <author>
      <name>Mengtian Li</name>
    </author>
    <author>
      <name>Xu Bai</name>
    </author>
    <author>
      <name>Songtao Zhao</name>
    </author>
    <author>
      <name>Fulong Ye</name>
    </author>
    <author>
      <name>Chong Mou</name>
    </author>
    <author>
      <name>Xinghui Li</name>
    </author>
    <author>
      <name>Zhuowei Chen</name>
    </author>
    <author>
      <name>Qian He</name>
    </author>
    <author>
      <name>Mingyuan Gao</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.14246v1</id>
    <title>Soft Tail-dropping for Adaptive Visual Tokenization</title>
    <updated>2026-01-20T18:57:19Z</updated>
    <link href="https://arxiv.org/abs/2601.14246v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.14246v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>We present Soft Tail-dropping Adaptive Tokenizer (STAT), a 1D discrete visual tokenizer that adaptively chooses the number of output tokens per image according to its structural complexity and level of detail. STAT encodes an image into a sequence of discrete codes together with per-token keep probabilities. Beyond standard autoencoder objectives, we regularize these keep probabilities to be monotonically decreasing along the sequence and explicitly align their distribution with an image-level complexity measure. As a result, STAT produces length-adaptive 1D visual tokens that are naturally compatible with causal 1D autoregressive (AR) visual generative models. On ImageNet-1k, equipping vanilla causal AR models with STAT yields competitive or superior visual generation quality compared to other probabilistic model families, while also exhibiting favorable scaling behavior that has been elusive in prior vanilla AR visual generation attempts.</summary>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-20T18:57:19Z</published>
    <arxiv:primary_category term="cs.CV"/>
    <author>
      <name>Zeyuan Chen</name>
    </author>
    <author>
      <name>Kai Zhang</name>
    </author>
    <author>
      <name>Zhuowen Tu</name>
    </author>
    <author>
      <name>Yuanjun Xiong</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.14243v1</id>
    <title>Jet-RL: Enabling On-Policy FP8 Reinforcement Learning with Unified Training and Rollout Precision Flow</title>
    <updated>2026-01-20T18:54:31Z</updated>
    <link href="https://arxiv.org/abs/2601.14243v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.14243v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Reinforcement learning (RL) is essential for enhancing the complex reasoning capabilities of large language models (LLMs). However, existing RL training pipelines are computationally inefficient and resource-intensive, with the rollout phase accounting for over 70% of total training time. Quantized RL training, particularly using FP8 precision, offers a promising approach to mitigating this bottleneck. A commonly adopted strategy applies FP8 precision during rollout while retaining BF16 precision for training. In this work, we present the first comprehensive study of FP8 RL training and demonstrate that the widely used BF16-training + FP8-rollout strategy suffers from severe training instability and catastrophic accuracy collapse under long-horizon rollouts and challenging tasks. Our analysis shows that these failures stem from the off-policy nature of the approach, which introduces substantial numerical mismatch between training and inference. Motivated by these observations, we propose Jet-RL, an FP8 RL training framework that enables robust and stable RL optimization. The key idea is to adopt a unified FP8 precision flow for both training and rollout, thereby minimizing numerical discrepancies and eliminating the need for inefficient inter-step calibration. Extensive experiments validate the effectiveness of Jet-RL: our method achieves up to 33% speedup in the rollout phase, up to 41% speedup in the training phase, and a 16% end-to-end speedup over BF16 training, while maintaining stable convergence across all settings and incurring negligible accuracy degradation.</summary>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-20T18:54:31Z</published>
    <arxiv:comment>11 pages, 6 figures, 4 tables</arxiv:comment>
    <arxiv:primary_category term="cs.LG"/>
    <author>
      <name>Haocheng Xi</name>
    </author>
    <author>
      <name>Charlie Ruan</name>
    </author>
    <author>
      <name>Peiyuan Liao</name>
    </author>
    <author>
      <name>Yujun Lin</name>
    </author>
    <author>
      <name>Han Cai</name>
    </author>
    <author>
      <name>Yilong Zhao</name>
    </author>
    <author>
      <name>Shuo Yang</name>
    </author>
    <author>
      <name>Kurt Keutzer</name>
    </author>
    <author>
      <name>Song Han</name>
    </author>
    <author>
      <name>Ligeng Zhu</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.14235v1</id>
    <title>Opportunities in AI/ML for the Rubin LSST Dark Energy Science Collaboration</title>
    <updated>2026-01-20T18:46:42Z</updated>
    <link href="https://arxiv.org/abs/2601.14235v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.14235v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>The Vera C. Rubin Observatory's Legacy Survey of Space and Time (LSST) will produce unprecedented volumes of heterogeneous astronomical data (images, catalogs, and alerts) that challenge traditional analysis pipelines. The LSST Dark Energy Science Collaboration (DESC) aims to derive robust constraints on dark energy and dark matter from these data, requiring methods that are statistically powerful, scalable, and operationally reliable. Artificial intelligence and machine learning (AI/ML) are already embedded across DESC science workflows, from photometric redshifts and transient classification to weak lensing inference and cosmological simulations. Yet their utility for precision cosmology hinges on trustworthy uncertainty quantification, robustness to covariate shift and model misspecification, and reproducible integration within scientific pipelines. This white paper surveys the current landscape of AI/ML across DESC's primary cosmological probes and cross-cutting analyses, revealing that the same core methodologies and fundamental challenges recur across disparate science cases. Since progress on these cross-cutting challenges would benefit multiple probes simultaneously, we identify key methodological research priorities, including Bayesian inference at scale, physics-informed methods, validation frameworks, and active learning for discovery. With an eye on emerging techniques, we also explore the potential of the latest foundation model methodologies and LLM-driven agentic AI systems to reshape DESC workflows, provided their deployment is coupled with rigorous evaluation and governance. Finally, we discuss critical software, computing, data infrastructure, and human capital requirements for the successful deployment of these new methodologies, and consider associated risks and opportunities for broader coordination with external actors.</summary>
    <category term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-20T18:46:42Z</published>
    <arxiv:comment>84 pages. This is v1.0 of the DESC's white paper on AI/ML, a collaboration document that is being made public but which is not planned for submission to a journal</arxiv:comment>
    <arxiv:primary_category term="astro-ph.IM"/>
    <author>
      <name> LSST Dark Energy Science Collaboration</name>
    </author>
    <author>
      <name>Eric Aubourg</name>
    </author>
    <author>
      <name>Camille Avestruz</name>
    </author>
    <author>
      <name>Matthew R. Becker</name>
    </author>
    <author>
      <name>Biswajit Biswas</name>
    </author>
    <author>
      <name>Rahul Biswas</name>
    </author>
    <author>
      <name>Boris Bolliet</name>
    </author>
    <author>
      <name>Adam S. Bolton</name>
    </author>
    <author>
      <name>Clecio R. Bom</name>
    </author>
    <author>
      <name>Raphaël Bonnet-Guerrini</name>
    </author>
    <author>
      <name>Alexandre Boucaud</name>
    </author>
    <author>
      <name>Jean-Eric Campagne</name>
    </author>
    <author>
      <name>Chihway Chang</name>
    </author>
    <author>
      <name>Aleksandra Ćiprijanović</name>
    </author>
    <author>
      <name>Johann Cohen-Tanugi</name>
    </author>
    <author>
      <name>Michael W. Coughlin</name>
    </author>
    <author>
      <name>John Franklin Crenshaw</name>
    </author>
    <author>
      <name>Juan C. Cuevas-Tello</name>
    </author>
    <author>
      <name>Juan de Vicente</name>
    </author>
    <author>
      <name>Seth W. Digel</name>
    </author>
    <author>
      <name>Steven Dillmann</name>
    </author>
    <author>
      <name>Mariano Javier de León Dominguez Romero</name>
    </author>
    <author>
      <name>Alex Drlica-Wagner</name>
    </author>
    <author>
      <name>Sydney Erickson</name>
    </author>
    <author>
      <name>Alexander T. Gagliano</name>
    </author>
    <author>
      <name>Christos Georgiou</name>
    </author>
    <author>
      <name>Aritra Ghosh</name>
    </author>
    <author>
      <name>Matthew Grayling</name>
    </author>
    <author>
      <name>Kirill A. Grishin</name>
    </author>
    <author>
      <name>Alan Heavens</name>
    </author>
    <author>
      <name>Lindsay R. House</name>
    </author>
    <author>
      <name>Mustapha Ishak</name>
    </author>
    <author>
      <name>Wassim Kabalan</name>
    </author>
    <author>
      <name>Arun Kannawadi</name>
    </author>
    <author>
      <name>François Lanusse</name>
    </author>
    <author>
      <name>C. Danielle Leonard</name>
    </author>
    <author>
      <name>Pierre-François Léget</name>
    </author>
    <author>
      <name>Michelle Lochner</name>
    </author>
    <author>
      <name>Yao-Yuan Mao</name>
    </author>
    <author>
      <name>Peter Melchior</name>
    </author>
    <author>
      <name>Grant Merz</name>
    </author>
    <author>
      <name>Martin Millon</name>
    </author>
    <author>
      <name>Anais Möller</name>
    </author>
    <author>
      <name>Gautham Narayan</name>
    </author>
    <author>
      <name>Yuuki Omori</name>
    </author>
    <author>
      <name>Hiranya Peiris</name>
    </author>
    <author>
      <name>Laurence Perreault-Levasseur</name>
    </author>
    <author>
      <name>Andrés A. Plazas Malagón</name>
    </author>
    <author>
      <name>Nesar Ramachandra</name>
    </author>
    <author>
      <name>Benjamin Remy</name>
    </author>
    <author>
      <name>Cécile Roucelle</name>
    </author>
    <author>
      <name>Jaime Ruiz-Zapatero</name>
    </author>
    <author>
      <name>Stefan Schuldt</name>
    </author>
    <author>
      <name>Ignacio Sevilla-Noarbe</name>
    </author>
    <author>
      <name>Ved G. Shah</name>
    </author>
    <author>
      <name>Tjitske Starkenburg</name>
    </author>
    <author>
      <name>Stephen Thorp</name>
    </author>
    <author>
      <name>Laura Toribio San Cipriano</name>
    </author>
    <author>
      <name>Tilman Tröster</name>
    </author>
    <author>
      <name>Roberto Trotta</name>
    </author>
    <author>
      <name>Padma Venkatraman</name>
    </author>
    <author>
      <name>Amanda Wasserman</name>
    </author>
    <author>
      <name>Tim White</name>
    </author>
    <author>
      <name>Justine Zeghal</name>
    </author>
    <author>
      <name>Tianqing Zhang</name>
    </author>
    <author>
      <name>Yuanyuan Zhang</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.14227v1</id>
    <title>Transformer Architectures for Respiratory Sound Analysis and Multimodal Diagnosis</title>
    <updated>2026-01-20T18:40:42Z</updated>
    <link href="https://arxiv.org/abs/2601.14227v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.14227v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Respiratory sound analysis is a crucial tool for screening asthma and other pulmonary pathologies, yet traditional auscultation remains subjective and experience-dependent. Our prior research established a CNN baseline using DenseNet201, which demonstrated high sensitivity in classifying respiratory sounds. In this work, we (i) adapt the Audio Spectrogram Transformer (AST) for respiratory sound analysis and (ii) evaluate a multimodal Vision-Language Model (VLM) that integrates spectrograms with structured patient metadata.
  AST is initialized from publicly available weights and fine-tuned on a medical dataset containing hundreds of recordings per diagnosis. The VLM experiment uses a compact Moondream-type model that processes spectrogram images alongside a structured text prompt (sex, age, recording site) to output a JSON-formatted diagnosis. Results indicate that AST achieves approximately 97% accuracy with an F1-score around 97% and ROC AUC of 0.98 for asthma detection, significantly outperforming both the internal CNN baseline and typical external benchmarks. The VLM reaches 86-87% accuracy, performing comparably to the CNN baseline while demonstrating the capability to integrate clinical context into the inference process. These results confirm the effectiveness of self-attention for acoustic screening and highlight the potential of multimodal architectures for holistic diagnostic tools.</summary>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-20T18:40:42Z</published>
    <arxiv:comment>7 pages, 4 figures</arxiv:comment>
    <arxiv:primary_category term="cs.SD"/>
    <author>
      <name>Theodore Aptekarev</name>
    </author>
    <author>
      <name>Vladimir Sokolovsky</name>
    </author>
    <author>
      <name>Gregory Furman</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.14218v1</id>
    <title>The [Fe XIII] Infrared 10747 Angstrom and 10798 Angstrom Lines in Novae</title>
    <updated>2026-01-20T18:27:14Z</updated>
    <link href="https://arxiv.org/abs/2601.14218v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.14218v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>The forbidden lines of [Fe XIII] at 10,747 Angstrom and 10,798 Angsrtom are among the most prominent lines in the near-infrared spectrum of the solar corona. They have been used routinely, both outside and during eclipses, as sensitive probes of the electron density and polarization in the solar corona. Many novae pass through a coronal phase, wherein the highly ionized nova ejecta have physical conditions that are remarkably similar to those of the solar corona. Many of the coronal emission lines that are seen are common to the spectra of both the Sun and novae. Yet, it appears that no robust detection of the [Fe XIII] lines has been made in a nova. Here we report the detection of these two infrared [Fe XIII]lines in the spectrum of the recurrent nova V3890 Sgr, taken 23.43 and 31.35 days after its August 2019 outburst. From their line strengths, we derive values of 10^10 per cubic cm and 10^[8.5-9] per cubic cm for the electron density on the two. The decrease in density between epochs can be explained if the density decreased with a power law n ~ r**alpha with a alpha inferred to be -3. The average temperature of the coronal gas is estimated to be T = (2.51\pm0.06) x 10^6~K. We find that recurrent novae with giant secondaries, including T CrB whose eruption is imminent, are the most suitable sources for further detections of the [Fe XIII] lines. epochs.</summary>
    <category term="astro-ph.SR" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-20T18:27:14Z</published>
    <arxiv:comment>8 Page, 5 Figures, 1 Table, To Appear in the Astrophysical J</arxiv:comment>
    <arxiv:primary_category term="astro-ph.SR"/>
    <author>
      <name>D. P. K. Banerjee</name>
    </author>
    <author>
      <name>C. E. Woodward</name>
    </author>
    <author>
      <name>A. Evans</name>
    </author>
    <author>
      <name>T. R. Geballe</name>
    </author>
    <author>
      <name>V. Joshi</name>
    </author>
    <author>
      <name>S. Starrfield</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.14210v1</id>
    <title>HALT: Hallucination Assessment via Latent Testing</title>
    <updated>2026-01-20T18:16:10Z</updated>
    <link href="https://arxiv.org/abs/2601.14210v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.14210v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Hallucination in large language models (LLMs) can be understood as a failure of faithful readout: although internal representations may encode uncertainty about a query, decoding pressures still yield a fluent answer. We propose lightweight residual probes that read hallucination risk directly from intermediate hidden states of question tokens, motivated by the hypothesis that these layers retain epistemic signals that are attenuated in the final decoding stage. The probe is a small auxiliary network whose computation is orders of magnitude cheaper than token generation and can be evaluated fully in parallel with inference, enabling near-instantaneous hallucination risk estimation with effectively zero added latency in low-risk cases. We deploy the probe as an agentic critic for fast selective generation and routing, allowing LLMs to immediately answer confident queries while delegating uncertain ones to stronger verification pipelines. Across four QA benchmarks and multiple LLM families, the method achieves strong AUROC and AURAC, generalizes under dataset shift, and reveals interpretable structure in intermediate representations, positioning fast internal uncertainty readout as a principled foundation for reliable agentic AI.</summary>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-20T18:16:10Z</published>
    <arxiv:primary_category term="cs.CL"/>
    <author>
      <name>Rohan Bhatnagar</name>
    </author>
    <author>
      <name>Youran Sun</name>
    </author>
    <author>
      <name>Chi Andrew Zhang</name>
    </author>
    <author>
      <name>Yixin Wen</name>
    </author>
    <author>
      <name>Haizhao Yang</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.14199v1</id>
    <title>Factor Analysis of Multivariate Stochastic Volatility Model</title>
    <updated>2026-01-20T18:01:57Z</updated>
    <link href="https://arxiv.org/abs/2601.14199v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.14199v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Modeling the time-varying covariance structures of high-dimensional variables is critical across diverse scientific and industrial applications; however, existing approaches exhibit notable limitations in either modeling flexibility or inferential efficiency. For instance, change-point modeling fails to account for the continuous time-varying nature of covariance structures, while GARCH and stochastic volatility models suffer from over-parameterization and the risk of overfitting. To address these challenges, we propose a Bayesian factor modeling framework designed to enable simultaneous inference of both the covariance structure of a high-dimensional time series and its time-varying dynamics. The associated Expectation-Maximization (EM) algorithm not only features an exact, closed-form update for the M-step but also is easily generalizable to more complex settings, such as spatiotemporal multivariate factor analysis. We validate our method through simulation studies and real-data experiments using climate and financial datasets.</summary>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-20T18:01:57Z</published>
    <arxiv:comment>Submitted to Journal of the American Statistical Association (JASA)</arxiv:comment>
    <arxiv:primary_category term="stat.ME"/>
    <author>
      <name>Taehee Lee</name>
    </author>
    <author>
      <name>Jun S. Liu</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.14194v1</id>
    <title>Influence of Finite-Nuclei Constraints on High-Density Transitions and Neutron Star Properties</title>
    <updated>2026-01-20T17:58:11Z</updated>
    <link href="https://arxiv.org/abs/2601.14194v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.14194v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>We construct posterior distributions of the equation of state (EoS) for matter beyond the inner crust of neutron stars by incorporating finite nuclei (FN) constraints within relativistic mean field models. These constraints are implemented in three complementary ways: (i) through theoretical bounds on the EoS, (ii) implicitly via nuclear matter parameters, and (iii) explicitly by enforcing consistency with experimental binding energies and charge radii of selected nuclei. The resulting low-density nucleonic EoSs are subsequently matched to a model-agnostic speed-of-sound parametrization, constrained by astrophysical observations, including NICER mass-radius measurements, tidal deformability limits from GW170817, and lower bounds on the maximum neutron-star mass inferred from radio pulsar observations. We find that the admissible range of the transition density is strongly sensitive to the choice of the low-density EoS. In particular, the inclusion of explicit FN constraints significantly reduces the allowed parameter space of the nucleonic EoS at low densities, narrowing the transition-density range by nearly a factor of two. Consequently, neutron-star properties inferred from EoSs with explicit FN constraints differ substantially, with especially pronounced effects for low-mass neutron stars and their correlations with nuclear matter parameters. A quantitative comparison, using metrics based on Mahalanobis distance, shows consistency of the explicit constraints with PSRs J0740+6620, J0030+0451, and J0437-4715, but suggest a possible tension with PSR J0614-3329. These findings underscore the critical importance of a consistent treatment of finite-nuclei properties for reliably inferring the behavior of high-density matter and the presence of possible phase transitions from astrophysical observations.</summary>
    <category term="nucl-th" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.HE" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-20T17:58:11Z</published>
    <arxiv:comment>16 Pages, 7 figures, 3 tables</arxiv:comment>
    <arxiv:primary_category term="nucl-th"/>
    <author>
      <name>Anagh Venneti</name>
    </author>
    <author>
      <name>Sarmistha Banik</name>
    </author>
    <author>
      <name>Bijay K Agrawal</name>
    </author>
  </entry>
</feed>
