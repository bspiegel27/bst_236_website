<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-09-22T00:57:24Z -->
<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acausal%20inference%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:causal inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/SsRksLzRb0LuVhSmQ+N8WbAs+f8</id>
  <updated>2025-09-21T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">121264</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">10</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2509.15224v1</id>
    <updated>2025-09-18T17:59:51Z</updated>
    <published>2025-09-18T17:59:51Z</published>
    <title>Depth AnyEvent: A Cross-Modal Distillation Paradigm for Event-Based
  Monocular Depth Estimation</title>
    <summary>  Event cameras capture sparse, high-temporal-resolution visual information,
making them particularly suitable for challenging environments with high-speed
motion and strongly varying lighting conditions. However, the lack of large
datasets with dense ground-truth depth annotations hinders learning-based
monocular depth estimation from event data. To address this limitation, we
propose a cross-modal distillation paradigm to generate dense proxy labels
leveraging a Vision Foundation Model (VFM). Our strategy requires an event
stream spatially aligned with RGB frames, a simple setup even available
off-the-shelf, and exploits the robustness of large-scale VFMs. Additionally,
we propose to adapt VFMs, either a vanilla one like Depth Anything v2 (DAv2),
or deriving from it a novel recurrent architecture to infer depth from
monocular event cameras. We evaluate our approach with synthetic and real-world
datasets, demonstrating that i) our cross-modal paradigm achieves competitive
performance compared to fully supervised methods without requiring expensive
depth annotations, and ii) our VFM-based models achieve state-of-the-art
performance.
</summary>
    <author>
      <name>Luca Bartolomei</name>
    </author>
    <author>
      <name>Enrico Mannocci</name>
    </author>
    <author>
      <name>Fabio Tosi</name>
    </author>
    <author>
      <name>Matteo Poggi</name>
    </author>
    <author>
      <name>Stefano Mattoccia</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICCV 2025. Code: https://github.com/bartn8/depthanyevent/ Project
  Page: https://bartn8.github.io/depthanyevent/</arxiv:comment>
    <link href="http://arxiv.org/abs/2509.15224v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.15224v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.15223v1</id>
    <updated>2025-09-18T17:59:30Z</updated>
    <published>2025-09-18T17:59:30Z</published>
    <title>Parameter sensitivity of cosmic pairwise velocities in the non-linear
  regime of structure formation</title>
    <summary>  The peculiar velocities of dark matter tracers drive the growth of cosmic
structures, providing a sensitive test of cosmological models and strengthening
constraints on the nature of dark energy. In this work, we investigate the mean
pairwise velocities, $v_{12}$, of dark matter tracers as a cosmological probe
in the non-linear regime of cosmic structure formation. Using N-body dark
matter-only simulations, we measure $v_{12}$ for pair separations up to 50
$h^{-1}$Mpc and model it by solving the pair conservation equation for a
self-gravitating particle system, along with various prescriptions of the
nonlinear matter power spectrum. We quantified the sensitivity of $v_{12}$ to
variations in key cosmological parameters such as $\Omega_{\mathrm{m}}$,
$\sigma_8$, $h$, $M_\nu$, and $w$. Our parameter inference analysis using MCMC
shows sub-11% agreement with simulation data, with notable degeneracies,
particularly between $\Omega_\mathrm{m}$ and $\sigma_8$. We further compute the
stable clustering crossing scale across redshifts $z=0$, $0.5$, and $1$,
assessing its dependence on cosmology. Among the tested power spectrum modeling
approaches, we find that the CSSTEmu emulator provides the most accurate
predictions, with deviations below 5% for $r &gt; 10$ $h^{-1}$Mpc at $z=0.5$. Our
results are validated using independent simulation suites, demonstrating that
our framework offers a robust method for extracting cosmological constraints
from upcoming peculiar velocity data.
</summary>
    <author>
      <name>Jorge Enrique García-Farieta</name>
    </author>
    <author>
      <name>Héctor J. Hortúa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 8 figures, 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2509.15223v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.15223v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.15199v1</id>
    <updated>2025-09-18T17:54:01Z</updated>
    <published>2025-09-18T17:54:01Z</published>
    <title>CausalPre: Scalable and Effective Data Pre-processing for Causal
  Fairness</title>
    <summary>  Causal fairness in databases is crucial to preventing biased and inaccurate
outcomes in downstream tasks. While most prior work assumes a known causal
model, recent efforts relax this assumption by enforcing additional
constraints. However, these approaches often fail to capture broader attribute
relationships that are critical to maintaining utility. This raises a
fundamental question: Can we harness the benefits of causal reasoning to design
efficient and effective fairness solutions without relying on strong
assumptions about the underlying causal model? In this paper, we seek to answer
this question by introducing CausalPre, a scalable and effective
causality-guided data pre-processing framework that guarantees justifiable
fairness, a strong causal notion of fairness. CausalPre extracts causally fair
relationships by reformulating the originally complex and computationally
infeasible extraction task into a tailored distribution estimation problem. To
ensure scalability, CausalPre adopts a carefully crafted variant of
low-dimensional marginal factorization to approximate the joint distribution,
complemented by a heuristic algorithm that efficiently tackles the associated
computational challenge. Extensive experiments on benchmark datasets
demonstrate that CausalPre is both effective and scalable, challenging the
conventional belief that achieving causal fairness requires trading off
relationship coverage for relaxed model assumptions.
</summary>
    <author>
      <name>Ying Zheng</name>
    </author>
    <author>
      <name>Yangfan Jiang</name>
    </author>
    <author>
      <name>Kian-Lee Tan</name>
    </author>
    <link href="http://arxiv.org/abs/2509.15199v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.15199v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.15197v1</id>
    <updated>2025-09-18T17:52:26Z</updated>
    <published>2025-09-18T17:52:26Z</published>
    <title>Consistent causal discovery with equal error variances: a least-squares
  perspective</title>
    <summary>  We consider the problem of recovering the true causal structure among a set
of variables, generated by a linear acyclic structural equation model (SEM)
with the error terms being independent and having equal variances. It is
well-known that the true underlying directed acyclic graph (DAG) encoding the
causal structure is uniquely identifiable under this assumption. In this work,
we establish that the sum of minimum expected squared errors for every
variable, while predicted by the best linear combination of its parent
variables, is minimised if and only if the causal structure is represented by
any supergraph of the true DAG. This property is further utilised to design a
Bayesian DAG selection method that recovers the true graph consistently.
</summary>
    <author>
      <name>Anamitra Chaudhuri</name>
    </author>
    <author>
      <name>Yang Ni</name>
    </author>
    <author>
      <name>Anirban Bhattacharya</name>
    </author>
    <link href="http://arxiv.org/abs/2509.15197v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.15197v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62H22, 62F15 (Primary) 62C10, 62E10 (Secondary)" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.15196v1</id>
    <updated>2025-09-18T17:52:23Z</updated>
    <published>2025-09-18T17:52:23Z</published>
    <title>Measuring the Two-Dimensional Thermal Structures of Protoplanetary Disks</title>
    <summary>  We present a flexible, annulus-by-annulus method to constrain the 2-D thermal
structure of a protoplanetary disk from optically thick spectral line emission.
Using synthetic disk models with a known temperature and density structure, we
extracted the vertical emission surfaces and brightness temperatures in radial
annuli for multiple CO isotopologue transitions and used them to infer the
vertical temperature profiles. This approach reliably recovers the injected
temperature structure despite noise and finite resolution. We demonstrated that
even a modest set of emission lines can constrain the temperature across a wide
range of radii and elevations. Nevertheless, biases in the extracted emission
surfaces constitute a major source of systematic error. Finally, we applied
this method to archival ALMA observations of the HD 163296 disk, revealing that
simple parametric radial temperature models may obscure the complexity of real
disks and that additional observations are necessary to distinguish between
different models of the vertical structure. This flexible framework can be
readily applied to other systems, helping to characterize the thermal
environments that shape planet formation.
</summary>
    <author>
      <name>Anna J. Fehr</name>
    </author>
    <author>
      <name>Sean M. Andrews</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 15 figures, accepted by ApJ</arxiv:comment>
    <link href="http://arxiv.org/abs/2509.15196v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.15196v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.EP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.EP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.15188v1</id>
    <updated>2025-09-18T17:48:21Z</updated>
    <published>2025-09-18T17:48:21Z</published>
    <title>Fast and Fluent Diffusion Language Models via Convolutional Decoding and
  Rejective Fine-tuning</title>
    <summary>  Autoregressive (AR) language models generate text one token at a time, which
limits their inference speed. Diffusion-based language models offer a promising
alternative, as they can decode multiple tokens in parallel. However, we
identify a key bottleneck in current diffusion LMs: the long decoding-window
problem, where tokens generated far from the input context often become
irrelevant or repetitive. Previous solutions like semi-autoregressive address
this issue by splitting windows into blocks, but this sacrifices speed and
bidirectionality, eliminating the main advantage of diffusion models. To
overcome this, we propose Convolutional decoding (Conv), a normalization-based
method that narrows the decoding window without hard segmentation, leading to
better fluency and flexibility. Additionally, we introduce Rejecting Rule-based
Fine-Tuning (R2FT), a post-hoc training scheme that better aligns tokens at
positions far from context. Our methods achieve state-of-the-art results on
open-ended generation benchmarks (e.g., AlpacaEval) among diffusion LM
baselines, with significantly lower step size than previous works,
demonstrating both speed and quality improvements.
</summary>
    <author>
      <name>Yeongbin Seo</name>
    </author>
    <author>
      <name>Dongha Lee</name>
    </author>
    <author>
      <name>Jaehyung Kim</name>
    </author>
    <author>
      <name>Jinyoung Yeo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NeurIPS 2025 spotlight</arxiv:comment>
    <link href="http://arxiv.org/abs/2509.15188v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.15188v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T50" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.15187v1</id>
    <updated>2025-09-18T17:48:20Z</updated>
    <published>2025-09-18T17:48:20Z</published>
    <title>MaRVIn: A Cross-Layer Mixed-Precision RISC-V Framework for DNN
  Inference, from ISA Extension to Hardware Acceleration</title>
    <summary>  The evolution of quantization and mixed-precision techniques has unlocked new
possibilities for enhancing the speed and energy efficiency of NNs. Several
recent studies indicate that adapting precision levels across different
parameters can maintain accuracy comparable to full-precision models while
significantly reducing computational demands. However, existing embedded
microprocessors lack sufficient architectural support for efficiently executing
mixed-precision NNs, both in terms of ISA extensions and hardware design,
resulting in inefficiencies such as excessive data packing/unpacking and
underutilized arithmetic units. In this work, we propose novel ISA extensions
and a micro-architecture implementation specifically designed to optimize
mixed-precision execution, enabling energy-efficient deep learning inference on
RISC-V architectures. We introduce MaRVIn, a cross-layer hardware-software
co-design framework that enhances power efficiency and performance through a
combination of hardware improvements, mixed-precision quantization, ISA-level
optimizations, and cycle-accurate emulation. At the hardware level, we enhance
the ALU with configurable mixed-precision arithmetic (2, 4, 8 bits) for
weights/activations and employ multi-pumping to reduce execution latency while
implementing soft SIMD for efficient 2-bit ops. At the software level, we
integrate a pruning-aware fine-tuning method to optimize model compression and
a greedy-based DSE approach to efficiently search for Pareto-optimal
mixed-quantized models. Additionally, we incorporate voltage scaling to boost
the power efficiency of our system. Our experimental evaluation over widely
used DNNs and datasets, such as CIFAR10 and ImageNet, demonstrates that our
framework can achieve, on average, 17.6x speedup for less than 1% accuracy loss
and outperforms the ISA-agnostic state-of-the-art RISC-V cores, delivering up
to 1.8 TOPs/W.
</summary>
    <author>
      <name>Giorgos Armeniakos</name>
    </author>
    <author>
      <name>Alexis Maras</name>
    </author>
    <author>
      <name>Sotirios Xydis</name>
    </author>
    <author>
      <name>Dimitrios Soudris</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication by IEEE Transactions on Computer-Aided
  Design of Integrated Circuits and Systems, March 2025</arxiv:comment>
    <link href="http://arxiv.org/abs/2509.15187v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.15187v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.15182v1</id>
    <updated>2025-09-18T17:43:20Z</updated>
    <published>2025-09-18T17:43:20Z</published>
    <title>Conditional Prior-based Non-stationary Channel Estimation Using
  Accelerated Diffusion Models</title>
    <summary>  Wireless channels in motion-rich urban microcell (UMi) settings are
non-stationary; mobility and scatterer dynamics shift the distribution over
time, degrading classical and deep estimators. This work proposes conditional
prior diffusion for channel estimation, which learns a history-conditioned
score to denoise noisy channel snapshots. A temporal encoder with cross-time
attention compresses a short observation window into a context vector, which
captures the channel's instantaneous coherence and steers the denoiser via
feature-wise modulation. In inference, an SNR-matched initialization selects
the diffusion step whose marginal aligns with the measured input SNR, and the
process follows a shortened, geometrically spaced schedule, preserving the
signal-to-noise trajectory with far fewer iterations. Temporal
self-conditioning with the previous channel estimate and a training-only
smoothness penalty further stabilizes evolution without biasing the test-time
estimator. Evaluations on a 3GPP benchmark show lower NMSE across all SNRs than
LMMSE, GMM, LSTM, and LDAMP baselines, demonstrating stable performance and
strong high SNR fidelity.
</summary>
    <author>
      <name>Muhammad Ahmed Mohsin</name>
    </author>
    <author>
      <name>Ahsan Bilal</name>
    </author>
    <author>
      <name>Muhammad Umer</name>
    </author>
    <author>
      <name>Asad Aali</name>
    </author>
    <author>
      <name>Muhammad Ali Jamshed</name>
    </author>
    <author>
      <name>Dean F. Hougen</name>
    </author>
    <author>
      <name>John M. Cioffi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICASSP 2026</arxiv:comment>
    <link href="http://arxiv.org/abs/2509.15182v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.15182v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.15181v1</id>
    <updated>2025-09-18T17:41:59Z</updated>
    <published>2025-09-18T17:41:59Z</published>
    <title>Maize Seedling Detection Dataset (MSDD): A Curated High-Resolution RGB
  Dataset for Seedling Maize Detection and Benchmarking with YOLOv9, YOLO11,
  YOLOv12 and Faster-RCNN</title>
    <summary>  Accurate maize seedling detection is crucial for precision agriculture, yet
curated datasets remain scarce. We introduce MSDD, a high-quality aerial image
dataset for maize seedling stand counting, with applications in early-season
crop monitoring, yield prediction, and in-field management. Stand counting
determines how many plants germinated, guiding timely decisions such as
replanting or adjusting inputs. Traditional methods are labor-intensive and
error-prone, while computer vision enables efficient, accurate detection. MSDD
contains three classes-single, double, and triple plants-capturing diverse
growth stages, planting setups, soil types, lighting conditions, camera angles,
and densities, ensuring robustness for real-world use. Benchmarking shows
detection is most reliable during V4-V6 stages and under nadir views. Among
tested models, YOLO11 is fastest, while YOLOv9 yields the highest accuracy for
single plants. Single plant detection achieves precision up to 0.984 and recall
up to 0.873, but detecting doubles and triples remains difficult due to rarity
and irregular appearance, often from planting errors. Class imbalance further
reduces accuracy in multi-plant detection. Despite these challenges, YOLO11
maintains efficient inference at 35 ms per image, with an additional 120 ms for
saving outputs. MSDD establishes a strong foundation for developing models that
enhance stand counting, optimize resource allocation, and support real-time
decision-making. This dataset marks a step toward automating agricultural
monitoring and advancing precision agriculture.
</summary>
    <author>
      <name>Dewi Endah Kharismawati</name>
    </author>
    <author>
      <name>Toni Kazic</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 10 figures, 8 tables. Submitted to IEEE Journal of Selected
  Topics in Signal Processing (JSTSP) Special Series on Artificial Intelligence
  for Smart Agriculture</arxiv:comment>
    <link href="http://arxiv.org/abs/2509.15181v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.15181v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.15178v1</id>
    <updated>2025-09-18T17:35:50Z</updated>
    <published>2025-09-18T17:35:50Z</published>
    <title>Unleashing the Potential of Multimodal LLMs for Zero-Shot
  Spatio-Temporal Video Grounding</title>
    <summary>  Spatio-temporal video grounding (STVG) aims at localizing the spatio-temporal
tube of a video, as specified by the input text query. In this paper, we
utilize multimodal large language models (MLLMs) to explore a zero-shot
solution in STVG. We reveal two key insights about MLLMs: (1) MLLMs tend to
dynamically assign special tokens, referred to as \textit{grounding tokens},
for grounding the text query; and (2) MLLMs often suffer from suboptimal
grounding due to the inability to fully integrate the cues in the text query
(\textit{e.g.}, attributes, actions) for inference. Based on these insights, we
propose a MLLM-based zero-shot framework for STVG, which includes novel
decomposed spatio-temporal highlighting (DSTH) and temporal-augmented
assembling (TAS) strategies to unleash the reasoning ability of MLLMs. The DSTH
strategy first decouples the original query into attribute and action
sub-queries for inquiring the existence of the target both spatially and
temporally. It then uses a novel logit-guided re-attention (LRA) module to
learn latent variables as spatial and temporal prompts, by regularizing token
predictions for each sub-query. These prompts highlight attribute and action
cues, respectively, directing the model's attention to reliable spatial and
temporal related visual regions. In addition, as the spatial grounding by the
attribute sub-query should be temporally consistent, we introduce the TAS
strategy to assemble the predictions using the original video frames and the
temporal-augmented frames as inputs to help improve temporal consistency. We
evaluate our method on various MLLMs, and show that it outperforms SOTA methods
on three common STVG benchmarks.
  The code will be available at https://github.com/zaiquanyang/LLaVA_Next_STVG.
</summary>
    <author>
      <name>Zaiquan Yang</name>
    </author>
    <author>
      <name>Yuhao Liu</name>
    </author>
    <author>
      <name>Gerhard Hancke</name>
    </author>
    <author>
      <name>Rynson W. H. Lau</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">NeurIPS2025</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2509.15178v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.15178v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
