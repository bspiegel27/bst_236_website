<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-09-10T00:52:07Z -->
<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acausal%20inference%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:causal inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/SsRksLzRb0LuVhSmQ+N8WbAs+f8</id>
  <updated>2025-09-09T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">120540</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">10</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2509.06956v1</id>
    <updated>2025-09-08T17:59:59Z</updated>
    <published>2025-09-08T17:59:59Z</published>
    <title>H$_{2}$OT: Hierarchical Hourglass Tokenizer for Efficient Video Pose
  Transformers</title>
    <summary>  Transformers have been successfully applied in the field of video-based 3D
human pose estimation. However, the high computational costs of these video
pose transformers (VPTs) make them impractical on resource-constrained devices.
In this paper, we present a hierarchical plug-and-play pruning-and-recovering
framework, called Hierarchical Hourglass Tokenizer (H$_{2}$OT), for efficient
transformer-based 3D human pose estimation from videos. H$_{2}$OT begins with
progressively pruning pose tokens of redundant frames and ends with recovering
full-length sequences, resulting in a few pose tokens in the intermediate
transformer blocks and thus improving the model efficiency. It works with two
key modules, namely, a Token Pruning Module (TPM) and a Token Recovering Module
(TRM). TPM dynamically selects a few representative tokens to eliminate the
redundancy of video frames, while TRM restores the detailed spatio-temporal
information based on the selected tokens, thereby expanding the network output
to the original full-length temporal resolution for fast inference. Our method
is general-purpose: it can be easily incorporated into common VPT models on
both seq2seq and seq2frame pipelines while effectively accommodating different
token pruning and recovery strategies. In addition, our H$_{2}$OT reveals that
maintaining the full pose sequence is unnecessary, and a few pose tokens of
representative frames can achieve both high efficiency and estimation accuracy.
Extensive experiments on multiple benchmark datasets demonstrate both the
effectiveness and efficiency of the proposed method. Code and models are
available at https://github.com/NationalGAILab/HoT.
</summary>
    <author>
      <name>Wenhao Li</name>
    </author>
    <author>
      <name>Mengyuan Liu</name>
    </author>
    <author>
      <name>Hong Liu</name>
    </author>
    <author>
      <name>Pichao Wang</name>
    </author>
    <author>
      <name>Shijian Lu</name>
    </author>
    <author>
      <name>Nicu Sebe</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by TPAMI 2025, Open Sourced. arXiv admin note: substantial
  text overlap with arXiv:2311.12028</arxiv:comment>
    <link href="http://arxiv.org/abs/2509.06956v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.06956v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.06953v1</id>
    <updated>2025-09-08T17:59:35Z</updated>
    <published>2025-09-08T17:59:35Z</published>
    <title>Deep Reactive Policy: Learning Reactive Manipulator Motion Planning for
  Dynamic Environments</title>
    <summary>  Generating collision-free motion in dynamic, partially observable
environments is a fundamental challenge for robotic manipulators. Classical
motion planners can compute globally optimal trajectories but require full
environment knowledge and are typically too slow for dynamic scenes. Neural
motion policies offer a promising alternative by operating in closed-loop
directly on raw sensory inputs but often struggle to generalize in complex or
dynamic settings. We propose Deep Reactive Policy (DRP), a visuo-motor neural
motion policy designed for reactive motion generation in diverse dynamic
environments, operating directly on point cloud sensory input. At its core is
IMPACT, a transformer-based neural motion policy pretrained on 10 million
generated expert trajectories across diverse simulation scenarios. We further
improve IMPACT's static obstacle avoidance through iterative student-teacher
finetuning. We additionally enhance the policy's dynamic obstacle avoidance at
inference time using DCP-RMP, a locally reactive goal-proposal module. We
evaluate DRP on challenging tasks featuring cluttered scenes, dynamic moving
obstacles, and goal obstructions. DRP achieves strong generalization,
outperforming prior classical and neural methods in success rate across both
simulated and real-world settings. Video results and code available at
https://deep-reactive-policy.com
</summary>
    <author>
      <name>Jiahui Yang</name>
    </author>
    <author>
      <name>Jason Jingzhou Liu</name>
    </author>
    <author>
      <name>Yulong Li</name>
    </author>
    <author>
      <name>Youssef Khaky</name>
    </author>
    <author>
      <name>Kenneth Shaw</name>
    </author>
    <author>
      <name>Deepak Pathak</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Website at \url{deep-reactive-policy.com}</arxiv:comment>
    <link href="http://arxiv.org/abs/2509.06953v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.06953v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.06952v1</id>
    <updated>2025-09-08T17:59:32Z</updated>
    <published>2025-09-08T17:59:32Z</published>
    <title>On the Same Wavelength? Evaluating Pragmatic Reasoning in Language
  Models across Broad Concepts</title>
    <summary>  Language use is shaped by pragmatics -- i.e., reasoning about communicative
goals and norms in context. As language models (LMs) are increasingly used as
conversational agents, it becomes ever more important to understand their
pragmatic reasoning abilities. We propose an evaluation framework derived from
Wavelength, a popular communication game where a speaker and a listener
communicate about a broad range of concepts in a granular manner. We study a
range of LMs on both language comprehension and language production using
direct and Chain-of-Thought (CoT) prompting, and further explore a Rational
Speech Act (RSA) approach to incorporating Bayesian pragmatic reasoning into LM
inference. We find that state-of-the-art LMs, but not smaller ones, achieve
strong performance on language comprehension, obtaining similar-to-human
accuracy and exhibiting high correlations with human judgments even without CoT
prompting or RSA. On language production, CoT can outperform direct prompting,
and using RSA provides significant improvements over both approaches. Our study
helps identify the strengths and limitations in LMs' pragmatic reasoning
abilities and demonstrates the potential for improving them with RSA, opening
up future avenues for understanding conceptual representation, language
understanding, and social reasoning in LMs and humans.
</summary>
    <author>
      <name>Linlu Qiu</name>
    </author>
    <author>
      <name>Cedegao E. Zhang</name>
    </author>
    <author>
      <name>Joshua B. Tenenbaum</name>
    </author>
    <author>
      <name>Yoon Kim</name>
    </author>
    <author>
      <name>Roger P. Levy</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP 2025 (Main)</arxiv:comment>
    <link href="http://arxiv.org/abs/2509.06952v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.06952v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.06949v1</id>
    <updated>2025-09-08T17:58:06Z</updated>
    <published>2025-09-08T17:58:06Z</published>
    <title>Revolutionizing Reinforcement Learning Framework for Diffusion Large
  Language Models</title>
    <summary>  We propose TraceRL, a trajectory-aware reinforcement learning framework for
diffusion language models (DLMs) that incorporates preferred inference
trajectory into post-training, and is applicable across different
architectures. Equipped with a diffusion-based value model that enhances
training stability, we demonstrate improved reasoning performance on complex
math and coding tasks. Besides, it can also be applied to adapt block-specific
models to larger blocks, which improves sampling flexibility. Employing
TraceRL, we derive a series of state-of-the-art diffusion language models,
namely TraDo. Although smaller than 7B-scale AR models, TraDo-4B-Instruct still
consistently outperforms them across complex math reasoning tasks.
TraDo-8B-Instruct achieves relative accuracy improvements of 6.1% over
Qwen2.5-7B-Instruct and 51.3% over Llama3.1-8B-Instruct on mathematical
reasoning benchmarks. Through curriculum learning, we also derive the first
long-CoT DLM, outperforming Qwen2.5-7B-Instruct on MATH500 with an 18.1%
relative accuracy gain. To facilitate reproducible research and practical
applications, we release a comprehensive open-source framework for building,
training, and deploying diffusion LLMs across diverse architectures. The
framework integrates accelerated KV-cache techniques and inference engines for
both inference and reinforcement learning, and includes implementations of
various supervised fine-tuning and RL methods for mathematics, coding, and
general tasks. Code and Models: https://github.com/Gen-Verse/dLLM-RL
</summary>
    <author>
      <name>Yinjie Wang</name>
    </author>
    <author>
      <name>Ling Yang</name>
    </author>
    <author>
      <name>Bowen Li</name>
    </author>
    <author>
      <name>Ye Tian</name>
    </author>
    <author>
      <name>Ke Shen</name>
    </author>
    <author>
      <name>Mengdi Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Code and Models: https://github.com/Gen-Verse/dLLM-RL</arxiv:comment>
    <link href="http://arxiv.org/abs/2509.06949v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.06949v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.06924v1</id>
    <updated>2025-09-08T17:38:01Z</updated>
    <published>2025-09-08T17:38:01Z</published>
    <title>Neutron Reflectometry by Gradient Descent</title>
    <summary>  Neutron reflectometry (NR) is a powerful technique to probe surfaces and
interfaces. NR is inherently an indirect measurement technique, access to the
physical quantities of interest (layer thickness, scattering length density,
roughness), necessitate the solution of an inverse modelling problem, that is
inefficient for large amounts of data or complex multiplayer structures (e.g.
lithium batteries / electrodes). Recently, surrogate machine learning models
have been proposed as an alternative to existing optimisation routines.
Although such approaches have been successful, physical intuition is lost when
replacing governing equations with fast neural networks. Instead, we propose a
novel and efficient approach; to optimise reflectivity data analysis by
performing gradient descent on the forward reflection model itself. Herein,
automatic differentiation techniques are used to evaluate exact gradients of
the error function with respect to the parameters of interest. Access to these
quantities enables users of neutron reflectometry to harness a host of powerful
modern optimisation and inference techniques that remain thus far unexploited
in the context of neutron reflectometry. This paper presents two benchmark case
studies; demonstrating state-of-the-art performance on a thick oxide quartz
film, and robust co-fitting performance in the high complexity regime of
organic LED multilayer devices. Additionally, we provide an open-source library
of differentiable reflectometry kernels in the python programming language so
that gradient based approaches can readily be applied to other NR datasets.
</summary>
    <author>
      <name>Max D. ~Champneys</name>
    </author>
    <author>
      <name>Andrew J. ~Parnell</name>
    </author>
    <author>
      <name>Philipp Gutfreund</name>
    </author>
    <author>
      <name>Maximilian W. A. Skoda</name>
    </author>
    <author>
      <name>. Patrick A. Fairclough</name>
    </author>
    <author>
      <name>Timothy J. ~Rogers</name>
    </author>
    <author>
      <name>Stephanie L. ~Burg</name>
    </author>
    <link href="http://arxiv.org/abs/2509.06924v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.06924v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.mtrl-sci" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.06921v1</id>
    <updated>2025-09-08T17:33:59Z</updated>
    <published>2025-09-08T17:33:59Z</published>
    <title>Neuro-Symbolic AI for Cybersecurity: State of the Art, Challenges, and
  Opportunities</title>
    <summary>  Traditional Artificial Intelligence (AI) approaches in cybersecurity exhibit
fundamental limitations: inadequate conceptual grounding leading to
non-robustness against novel attacks; limited instructibility impeding
analyst-guided adaptation; and misalignment with cybersecurity objectives.
Neuro-Symbolic (NeSy) AI has emerged with the potential to revolutionize
cybersecurity AI. However, there is no systematic understanding of this
emerging approach. These hybrid systems address critical cybersecurity
challenges by combining neural pattern recognition with symbolic reasoning,
enabling enhanced threat understanding while introducing concerning autonomous
offensive capabilities that reshape threat landscapes. In this survey, we
systematically characterize this field by analyzing 127 publications spanning
2019-July 2025. We introduce a Grounding-Instructibility-Alignment (G-I-A)
framework to evaluate these systems, focusing on both cyber defense and cyber
offense across network security, malware analysis, and cyber operations. Our
analysis shows advantages of multi-agent NeSy architectures and identifies
critical implementation challenges including standardization gaps,
computational complexity, and human-AI collaboration requirements that
constrain deployment. We show that causal reasoning integration is the most
transformative advancement, enabling proactive defense beyond correlation-based
approaches. Our findings highlight dual-use implications where autonomous
systems demonstrate substantial capabilities in zero-day exploitation while
achieving significant cost reductions, altering threat dynamics. We provide
insights and future research directions, emphasizing the urgent need for
community-driven standardization frameworks and responsible development
practices that ensure advancement serves defensive cybersecurity objectives
while maintaining societal alignment.
</summary>
    <author>
      <name>Safayat Bin Hakim</name>
    </author>
    <author>
      <name>Muhammad Adil</name>
    </author>
    <author>
      <name>Alvaro Velasquez</name>
    </author>
    <author>
      <name>Shouhuai Xu</name>
    </author>
    <author>
      <name>Houbing Herbert Song</name>
    </author>
    <link href="http://arxiv.org/abs/2509.06921v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.06921v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.06911v1</id>
    <updated>2025-09-08T17:25:23Z</updated>
    <published>2025-09-08T17:25:23Z</published>
    <title>Hypergraph-Guided Regex Filter Synthesis for Event-Based Anomaly
  Detection</title>
    <summary>  We propose HyGLAD, a novel algorithm that automatically builds a set of
interpretable patterns that model event data. These patterns can then be used
to detect event-based anomalies in a stationary system, where any deviation
from past behavior may indicate malicious activity. The algorithm infers
equivalence classes of entities with similar behavior observed from the events,
and then builds regular expressions that capture the values of those entities.
As opposed to deep-learning approaches, the regular expressions are directly
interpretable, which also translates to interpretable anomalies. We evaluate
HyGLAD against all 7 unsupervised anomaly detection methods from DeepOD on five
datasets from real-world systems. The experimental results show that on average
HyGLAD outperforms existing deep-learning methods while being an order of
magnitude more efficient in training and inference (single CPU vs GPU).
Precision improved by 1.2x and recall by 1.3x compared to the second-best
baseline.
</summary>
    <author>
      <name>Margarida Ferreira</name>
    </author>
    <author>
      <name>Victor Nicolet</name>
    </author>
    <author>
      <name>Luan Pham</name>
    </author>
    <author>
      <name>Joey Dodds</name>
    </author>
    <author>
      <name>Daniel Kroening</name>
    </author>
    <author>
      <name>Ines Lynce</name>
    </author>
    <author>
      <name>Ruben Martins</name>
    </author>
    <link href="http://arxiv.org/abs/2509.06911v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.06911v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.06894v1</id>
    <updated>2025-09-08T17:13:28Z</updated>
    <published>2025-09-08T17:13:28Z</published>
    <title>Learning from one graph: transductive learning guarantees via the
  geometry of small random worlds</title>
    <summary>  Since their introduction by Kipf and Welling in $2017$, a primary use of
graph convolutional networks is transductive node classification, where missing
labels are inferred within a single observed graph and its feature matrix.
Despite the widespread use of the network model, the statistical foundations of
transductive learning remain limited, as standard inference frameworks
typically rely on multiple independent samples rather than a single graph. In
this work, we address these gaps by developing new concentration-of-measure
tools that leverage the geometric regularities of large graphs via
low-dimensional metric embeddings. The emergent regularities are captured using
a random graph model; however, the methods remain applicable to deterministic
graphs once observed. We establish two principal learning results. The first
concerns arbitrary deterministic $k$-vertex graphs, and the second addresses
random graphs that share key geometric properties with an Erd\H{o}s-R\'{e}nyi
graph $\mathbf{G}=\mathbf{G}(k,p)$ in the regime $p \in \mathcal{O}((\log
(k)/k)^{1/2})$. The first result serves as the basis for and illuminates the
second. We then extend these results to the graph convolutional network
setting, where additional challenges arise. Lastly, our learning guarantees
remain informative even with a few labelled nodes $N$ and achieve the optimal
nonparametric rate $\mathcal{O}(N^{-1/2})$ as $N$ grows.
</summary>
    <author>
      <name>Nils Detering</name>
    </author>
    <author>
      <name>Luca Galimberti</name>
    </author>
    <author>
      <name>Anastasis Kratsios</name>
    </author>
    <author>
      <name>Giulia Livieri</name>
    </author>
    <author>
      <name>A. Martina Neuman</name>
    </author>
    <link href="http://arxiv.org/abs/2509.06894v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.06894v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.MG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.06891v1</id>
    <updated>2025-09-08T17:11:12Z</updated>
    <published>2025-09-08T17:11:12Z</published>
    <title>Tensor Network based Gene Regulatory Network Inference for Single-Cell
  Transcriptomic Data</title>
    <summary>  Deciphering complex gene-gene interactions remains challenging in
transcriptomics as traditional methods often miss higher-order and nonlinear
dependencies. This study introduces a quantum-inspired framework leveraging
tensor networks (TNs) to optimally map expression data into a lower dimensional
representation preserving biological locality. Using Quantum Mutual Information
(QMI), a nonparametric measure natural for tensor networks, we quantify gene
dependencies and establish statistical significance via permutation testing.
This constructs robust interaction networks where the edges reflect
biologically meaningful relationships that are resilient to random chance. The
approach effectively distinguishes true regulatory patterns from experimental
noise and biological stochasticity. To test the proposed method, we recover a
gene regulatory network consisted of six pathway genes from single-cell RNA
sequencing data comprising over $28.000$ lymphoblastoid cells. Furthermore, we
unveil several triadic regulatory mechanisms. By merging quantum physics
inspired techniques with computational biology, our method provides novel
insights into gene regulation, with applications in disease mechanisms and
precision medicine.
</summary>
    <author>
      <name>Olatz Sanz Larrarte</name>
    </author>
    <author>
      <name>Borja Aizpurua</name>
    </author>
    <author>
      <name>Reza Dastbasteh</name>
    </author>
    <author>
      <name>Ruben M. Otxoa</name>
    </author>
    <author>
      <name>Josu Etxezarreta Martinez</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2509.06891v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.06891v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.MN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.MN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.06890v1</id>
    <updated>2025-09-08T17:10:43Z</updated>
    <published>2025-09-08T17:10:43Z</published>
    <title>Intraoperative 2D/3D Registration via Spherical Similarity Learning and
  Inference-Time Differentiable Levenberg-Marquardt Optimization</title>
    <summary>  Intraoperative 2D/3D registration aligns preoperative 3D volumes with
real-time 2D radiographs, enabling accurate localization of instruments and
implants. A recent fully differentiable similarity learning framework
approximates geodesic distances on SE(3), expanding the capture range of
registration and mitigating the effects of substantial disturbances, but
existing Euclidean approximations distort manifold structure and slow
convergence. To address these limitations, we explore similarity learning in
non-Euclidean spherical feature spaces to better capture and fit complex
manifold structure. We extract feature embeddings using a CNN-Transformer
encoder, project them into spherical space, and approximate their geodesic
distances with Riemannian distances in the bi-invariant SO(4) space. This
enables a more expressive and geometrically consistent deep similarity metric,
enhancing the ability to distinguish subtle pose differences. During inference,
we replace gradient descent with fully differentiable Levenberg-Marquardt
optimization to accelerate convergence. Experiments on real and synthetic
datasets show superior accuracy in both patient-specific and patient-agnostic
scenarios.
</summary>
    <author>
      <name>Minheng Chen</name>
    </author>
    <author>
      <name>Youyong Kong</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">WACV 2026 Accepted</arxiv:comment>
    <link href="http://arxiv.org/abs/2509.06890v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.06890v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.IV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
