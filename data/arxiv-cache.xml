<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-07-03T00:58:44Z -->
<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acausal%20inference%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:causal inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/SsRksLzRb0LuVhSmQ+N8WbAs+f8</id>
  <updated>2025-07-02T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">116074</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">10</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2506.24062v1</id>
    <updated>2025-06-30T17:13:00Z</updated>
    <published>2025-06-30T17:13:00Z</published>
    <title>Scout-Dose-TCM: Direct and Prospective Scout-Based Estimation of
  Personalized Organ Doses from Tube Current Modulated CT Exams</title>
    <summary>  This study proposes Scout-Dose-TCM for direct, prospective estimation of
organ-level doses under tube current modulation (TCM) and compares its
performance to two established methods. We analyzed contrast-enhanced
chest-abdomen-pelvis CT scans from 130 adults (120 kVp, TCM). Reference doses
for six organs (lungs, kidneys, liver, pancreas, bladder, spleen) were
calculated using MC-GPU and TotalSegmentator. Based on these, we trained
Scout-Dose-TCM, a deep learning model that predicts organ doses corresponding
to discrete cosine transform (DCT) basis functions, enabling real-time
estimates for any TCM profile. The model combines a feature learning module
that extracts contextual information from lateral and frontal scouts and scan
range with a dose learning module that output DCT-based dose estimates. A
customized loss function incorporated the DCT formulation during training. For
comparison, we implemented size-specific dose estimation per AAPM TG 204
(Global CTDIvol) and its organ-level TCM-adapted version (Organ CTDIvol). A
5-fold cross-validation assessed generalizability by comparing mean absolute
percentage dose errors and r-squared correlations with benchmark doses. Average
absolute percentage errors were 13% (Global CTDIvol), 9% (Organ CTDIvol), and
7% (Scout-Dose-TCM), with bladder showing the largest discrepancies (15%, 13%,
and 9%). Statistical tests confirmed Scout-Dose-TCM significantly reduced
errors vs. Global CTDIvol across most organs and improved over Organ CTDIvol
for the liver, bladder, and pancreas. It also achieved higher r-squared values,
indicating stronger agreement with Monte Carlo benchmarks. Scout-Dose-TCM
outperformed Global CTDIvol and was comparable to or better than Organ CTDIvol,
without requiring organ segmentations at inference, demonstrating its promise
as a tool for prospective organ-level dose estimation in CT.
</summary>
    <author>
      <name>Maria Jose Medrano</name>
    </author>
    <author>
      <name>Sen Wang</name>
    </author>
    <author>
      <name>Liyan Sun</name>
    </author>
    <author>
      <name>Abdullah-Al-Zubaer Imran</name>
    </author>
    <author>
      <name>Jennie Cao</name>
    </author>
    <author>
      <name>Grant Stevens</name>
    </author>
    <author>
      <name>Justin Ruey Tse</name>
    </author>
    <author>
      <name>Adam S. Wang</name>
    </author>
    <link href="http://arxiv.org/abs/2506.24062v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.24062v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.med-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.med-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.24045v1</id>
    <updated>2025-06-30T16:50:48Z</updated>
    <published>2025-06-30T16:50:48Z</published>
    <title>Agent.xpu: Efficient Scheduling of Agentic LLM Workloads on
  Heterogeneous SoC</title>
    <summary>  The proliferation of agentic Large Language Models (LLMs) on personal devices
introduces a new class of workloads characterized by a dichotomy of objectives.
Reactive tasks, initiated by users, demand immediate, low-latency responses,
while proactive tasks operate invisibly and prioritize throughput. Existing
on-device LLM engines, designed for isolated inferences, fail to efficiently
manage these concurrent and conflicting requests on consumer-grade
heterogeneous SoCs with CPU, integrated GPU, and NPU. This paper introduces
Agent.xpu, an efficient serving system for agentic LLM workloads on
memory-unified heterogeneous SoCs. With dedicated offline profiling, Agent.xpu
first constructs a heterogeneous execution graph, which fuses and chunks model
kernels for affinity-guided, elastic accelerator mapping with predictive kernel
annotation. At runtime, its online scheduler enables fine-grained, kernel-level
preemption to guarantee the responsiveness of reactive tasks. To maximize SoC
utilization, it adopts slack-aware kernel backfill to opportunistically append
proactive tasks, and mitigates NPU-iGPU contention via bandwidth-aware
dispatch. Evaluation on an Intel Core Ultra SoC shows that Agent.xpu achieves
4.6$\times$ lower latency for reactive tasks and sustains
1.6$\times$-6.8$\times$ higher throughput for proactive tasks compared to
state-of-the-art inference engines.
</summary>
    <author>
      <name>Xinming Wei</name>
    </author>
    <author>
      <name>Jiahao Zhang</name>
    </author>
    <author>
      <name>Haoran Li</name>
    </author>
    <author>
      <name>Jiayu Chen</name>
    </author>
    <author>
      <name>Rui Qu</name>
    </author>
    <author>
      <name>Maoliang Li</name>
    </author>
    <author>
      <name>Xiang Chen</name>
    </author>
    <author>
      <name>Guojie Luo</name>
    </author>
    <link href="http://arxiv.org/abs/2506.24045v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.24045v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.24041v1</id>
    <updated>2025-06-30T16:48:49Z</updated>
    <published>2025-06-30T16:48:49Z</published>
    <title>Unsupervised Sparse Coding-based Spiking Neural Network for Real-time
  Spike Sorting</title>
    <summary>  Spike sorting is a crucial step in decoding multichannel extracellular neural
signals, enabling the identification of individual neuronal activity. A key
challenge in brain-machine interfaces (BMIs) is achieving real-time, low-power
spike sorting at the edge while keeping high neural decoding performance. This
study introduces the Neuromorphic Sparse Sorter (NSS), a compact two-layer
spiking neural network optimized for efficient spike sorting. NSS leverages the
Locally Competitive Algorithm (LCA) for sparse coding to extract relevant
features from noisy events with reduced computational demands. NSS learns to
sort detected spike waveforms in an online fashion and operates entirely
unsupervised. To exploit multi-bit spike coding capabilities of neuromorphic
platforms like Intel's Loihi 2, a custom neuron model was implemented, enabling
flexible power-performance trade-offs via adjustable spike bit-widths.
Evaluations on simulated and real-world tetrode signals with biological drift
showed NSS outperformed established pipelines such as WaveClus3 and PCA+KMeans.
With 2-bit graded spikes, NSS on Loihi 2 outperformed NSS implemented with
leaky integrate-and-fire neuron and achieved an F1-score of 77% (+10%
improvement) while consuming 8.6mW (+1.65mW) when tested on a drifting
recording, with a computational processing time of 0.25ms (+60 us) per
inference.
</summary>
    <author>
      <name>Alexis Melot</name>
    </author>
    <author>
      <name>Sean U. N. Wood</name>
    </author>
    <author>
      <name>Yannick Coffinier</name>
    </author>
    <author>
      <name>Pierre Yger</name>
    </author>
    <author>
      <name>Fabien Alibart</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Main article : 16 pages, 7 figures and 4 tables. Supplementary
  Material starts at page 17 with 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2506.24041v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.24041v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.24024v1</id>
    <updated>2025-06-30T16:31:26Z</updated>
    <published>2025-06-30T16:31:26Z</published>
    <title>Post-processing of EEG-based Auditory Attention Decoding Decisions via
  Hidden Markov Models</title>
    <summary>  Auditory attention decoding (AAD) algorithms exploit brain signals, such as
electroencephalography (EEG), to identify which speaker a listener is focusing
on in a multi-speaker environment. While state-of-the-art AAD algorithms can
identify the attended speaker on short time windows, their predictions are
often too inaccurate for practical use. In this work, we propose augmenting AAD
with a hidden Markov model (HMM) that models the temporal structure of
attention. More specifically, the HMM relies on the fact that a subject is much
less likely to switch attention than to keep attending the same speaker at any
moment in time. We show how a HMM can significantly improve existing AAD
algorithms in both causal (real-time) and non-causal (offline) settings. We
further demonstrate that HMMs outperform existing postprocessing approaches in
both accuracy and responsiveness, and explore how various factors such as
window length, switching frequency, and AAD accuracy influence overall
performance. The proposed method is computationally efficient, intuitive to use
and applicable in both real-time and offline settings.
</summary>
    <author>
      <name>Nicolas Heintz</name>
    </author>
    <author>
      <name>Tom Francart</name>
    </author>
    <author>
      <name>Alexander Bertrand</name>
    </author>
    <link href="http://arxiv.org/abs/2506.24024v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.24024v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.24013v1</id>
    <updated>2025-06-30T16:18:06Z</updated>
    <published>2025-06-30T16:18:06Z</published>
    <title>CoMMiT: Co-informed inference of microbiome-metabolome interactions via
  transfer learning</title>
    <summary>  Recent multi-omic microbiome studies enable integrative analysis of microbes
and metabolites, uncovering their associations with various host conditions.
Such analyses require multivariate models capable of accounting for the complex
correlation structures between microbes and metabolites. However, existing
multivariate models often suffer from low statistical power for detecting
microbiome-metabolome interactions due to small sample sizes and weak
biological signals. To address these challenges, we introduce CoMMiT,
Co-informed inference of Microbiome-Metabolome Interactions via novel Transfer
learning models. Unlike conventional transfer-learning methods that borrow
information from external datasets, CoMMiT leverages similarities across
metabolites within a single cohort, reducing the risk of negative transfer
often caused by differences in sequencing platforms and bioinformatic pipelines
across studies. CoMMiT operates under the flexible assumption that auxiliary
metabolites are collectively informative for the target metabolite, without
requiring individual auxiliary metabolites to be informative. CoMMiT uses a
novel data-driven approach to selecting the optimal set of auxiliary
metabolites. Using this optimal set, CoMMiT employs a de-biasing framework to
enable efficient calculation of p-values, facilitating the identification of
statistically significant microbiome-metabolome interactions. Applying CoMMiT
to a feeding study reveals biologically meaningful microbiome-metabolome
interactions under a low glycemic load diet, demonstrating the diet-host link
through gut metabolism.
</summary>
    <author>
      <name>Leiyue Li</name>
    </author>
    <author>
      <name>Chenglong Ye</name>
    </author>
    <author>
      <name>Tim Randolph</name>
    </author>
    <author>
      <name>Meredith Hullar</name>
    </author>
    <author>
      <name>Johanna Lampe</name>
    </author>
    <author>
      <name>Marian Neuhouser</name>
    </author>
    <author>
      <name>Daniel Raftery</name>
    </author>
    <author>
      <name>Yue Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">38 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2506.24013v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.24013v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.24010v1</id>
    <updated>2025-06-30T16:14:09Z</updated>
    <published>2025-06-30T16:14:09Z</published>
    <title>Anchoring Stellar Age Indicators: A Cross-Calibration of [C/N] and
  Gyrochronology Ages via the Age-Velocity-Dispersion Relation</title>
    <summary>  Determining stellar ages is challenging, as it depends on other stellar
parameters in a non-linear way and often relies on stellar evolution models to
infer the underlying relation between these parameters and age. This complexity
increases when comparing different age-dating methods, as they rely on distinct
indicators and are often applicable to non-overlapping regions of the
color-magnitude diagram. Moreover, many empirical calibration methods rely on
pre-determined ages, often from open clusters or asteroseismology, which only
cover a limited parameter space. Fortunately, the age-velocity-dispersion
relation (AVR), in which the velocity dispersion increases with age, is a
universal feature among stars of all evolutionary stages. In this paper, we 1)
explore the parameter space in which [C/N] and gyrochronology are applicable,
extending beyond the domains probed by asteroseismology and open clusters, and
2) assess whether the traditionally assumed [C/N] and gyrochronology relations
yield ages on a consistent physical scale, after calibrating both using the
same AVR. We find gyrochronology can be applied to all partially convective
stars after they have converged onto the slow rotating sequence and before they
experience weakened magnetic braking; [C/N] can be used to infer ages for all
giants with metallicity &gt; -0.8 dex and [C/N] &lt; -0.05 dex, and can be used as an
age-indicator down to [Fe/H] of -1 dex if only selecting the low-$\alpha$ disk.
Lastly, ages obtained from [C/N] and gyrochronology agree within uncertainty
after accounting for systematic offsets.
</summary>
    <author>
      <name>Yuxi Lu</name>
    </author>
    <author>
      <name>Marc H. Pinsonneault</name>
    </author>
    <author>
      <name>Yuan-Sen Ting</name>
    </author>
    <author>
      <name>Phil R. Van-Lane</name>
    </author>
    <author>
      <name>John D Roberts</name>
    </author>
    <author>
      <name>Jamie Tayar</name>
    </author>
    <author>
      <name>Alexander Stone-Martinez</name>
    </author>
    <link href="http://arxiv.org/abs/2506.24010v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.24010v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.SR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.SR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.GA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.24000v1</id>
    <updated>2025-06-30T16:05:55Z</updated>
    <published>2025-06-30T16:05:55Z</published>
    <title>The Illusion of Progress? A Critical Look at Test-Time Adaptation for
  Vision-Language Models</title>
    <summary>  Test-time adaptation (TTA) methods have gained significant attention for
enhancing the performance of vision-language models (VLMs) such as CLIP during
inference, without requiring additional labeled data. However, current TTA
researches generally suffer from major limitations such as duplication of
baseline results, limited evaluation metrics, inconsistent experimental
settings, and insufficient analysis. These problems hinder fair comparisons
between TTA methods and obscure their practical strengths and weaknesses. To
address these challenges, we introduce TTA-VLM, a comprehensive benchmark for
evaluating TTA methods on VLMs. Our benchmark implements 8 episodic TTA and 7
online TTA methods within a unified and reproducible framework, and evaluates
them across 15 widely used datasets. Unlike prior studies focused solely on
CLIP, we extend the evaluation to SigLIP--a model trained with a Sigmoid
loss--and include training-time tuning methods such as CoOp, MaPLe, and TeCoA
to assess generality. Beyond classification accuracy, TTA-VLM incorporates
various evaluation metrics, including robustness, calibration,
out-of-distribution detection, and stability, enabling a more holistic
assessment of TTA methods. Through extensive experiments, we find that 1)
existing TTA methods produce limited gains compared to the previous pioneering
work; 2) current TTA methods exhibit poor collaboration with training-time
fine-tuning methods; 3) accuracy gains frequently come at the cost of reduced
model trustworthiness. We release TTA-VLM to provide fair comparison and
comprehensive evaluation of TTA methods for VLMs, and we hope it encourages the
community to develop more reliable and generalizable TTA strategies.
</summary>
    <author>
      <name>Lijun Sheng</name>
    </author>
    <author>
      <name>Jian Liang</name>
    </author>
    <author>
      <name>Ran He</name>
    </author>
    <author>
      <name>Zilei Wang</name>
    </author>
    <author>
      <name>Tieniu Tan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Github link: https://github.com/TomSheng21/tta-vlm</arxiv:comment>
    <link href="http://arxiv.org/abs/2506.24000v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.24000v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.23986v2</id>
    <updated>2025-07-01T16:23:28Z</updated>
    <published>2025-06-30T15:50:08Z</published>
    <title>StreamFlow: Streaming Flow Matching with Block-wise Guided Attention
  Mask for Speech Token Decoding</title>
    <summary>  Recent advancements in discrete token-based speech generation have
highlighted the importance of token-to-waveform generation for audio quality,
particularly in real-time interactions. Traditional frameworks integrating
semantic tokens with flow matching (FM) struggle with streaming capabilities
due to their reliance on a global receptive field. Additionally, directly
implementing token-by-token streaming speech generation often results in
degraded audio quality. To address these challenges, we propose StreamFlow, a
novel neural architecture that facilitates streaming flow matching with
diffusion transformers (DiT). To mitigate the long-sequence extrapolation
issues arising from lengthy historical dependencies, we design a local
block-wise receptive field strategy. Specifically, the sequence is first
segmented into blocks, and we introduce block-wise attention masks that enable
the current block to receive information from the previous or subsequent block.
These attention masks are combined hierarchically across different DiT-blocks
to regulate the receptive field of DiTs. Both subjective and objective
experimental results demonstrate that our approach achieves performance
comparable to non-streaming methods while surpassing other streaming methods in
terms of speech quality, all the while effectively managing inference time
during long-sequence generation. Furthermore, our method achieves a notable
first-packet latency of only 180 ms.\footnote{Speech samples:
https://dukguo.github.io/StreamFlow/}
</summary>
    <author>
      <name>Dake Guo</name>
    </author>
    <author>
      <name>Jixun Yao</name>
    </author>
    <author>
      <name>Linhan Ma</name>
    </author>
    <author>
      <name>He Wang</name>
    </author>
    <author>
      <name>Lei Xie</name>
    </author>
    <link href="http://arxiv.org/abs/2506.23986v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.23986v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.23982v1</id>
    <updated>2025-06-30T15:48:38Z</updated>
    <published>2025-06-30T15:48:38Z</published>
    <title>StyleDrive: Towards Driving-Style Aware Benchmarking of End-To-End
  Autonomous Driving</title>
    <summary>  While personalization has been explored in traditional autonomous driving
systems, it remains largely overlooked in end-to-end autonomous driving
(E2EAD), despite its growing prominence. This gap is critical, as user-aligned
behavior is essential for trust, comfort, and widespread adoption of autonomous
vehicles. A core challenge is the lack of large-scale real-world datasets
annotated with diverse and fine-grained driving preferences, hindering the
development and evaluation of personalized E2EAD models. In this work, we
present the first large-scale real-world dataset enriched with annotations
capturing diverse driving preferences, establishing a foundation for
personalization in E2EAD. We extract static environmental features from
real-world road topology and infer dynamic contextual cues using a fine-tuned
visual language model (VLM), enabling consistent and fine-grained scenario
construction. Based on these scenarios, we derive objective preference
annotations through behavioral distribution analysis and rule-based heuristics.
To address the inherent subjectivity of driving style, we further employ the
VLM to generate subjective annotations by jointly modeling scene semantics and
driver behavior. Final high-quality labels are obtained through a
human-in-the-loop verification process that fuses both perspectives. Building
on this dataset, we propose the first benchmark for evaluating personalized
E2EAD models. We assess several state-of-the-art models with and without
preference conditioning, demonstrating that incorporating personalized
preferences results in behavior more aligned with human driving. Our work lays
the foundation for personalized E2EAD by providing a standardized platform to
systematically integrate human preferences into data-driven E2EAD systems,
catalyzing future research in human-centric autonomy.
</summary>
    <author>
      <name>Ruiyang Hao</name>
    </author>
    <author>
      <name>Bowen Jing</name>
    </author>
    <author>
      <name>Haibao Yu</name>
    </author>
    <author>
      <name>Zaiqing Nie</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2506.23982v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.23982v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.9" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.23964v1</id>
    <updated>2025-06-30T15:36:22Z</updated>
    <published>2025-06-30T15:36:22Z</published>
    <title>Learning Constraints Directly from Network Data</title>
    <summary>  Network data conforms to a wide range of rules that arise from protocols,
design principles, and deployment decisions (e.g., a packet's queuing delay
must be less than its end-to-end delay). Formalizing such rules as logic
constraints can (i) improve the quality of synthetic data, (ii) reduce the
brittleness of machine learning (ML) models, and (iii) improve semantic
understanding of network measurements. However, these benefits remain out of
reach if rule extraction is manual or solely reliant on ML, as both approaches
yield incomplete, unreliable, and/or inaccurate rules.
  This paper formulates rule extraction as a constraint modeling problem and
introduces NetNomos that learns propositional logic constraints directly from
raw network measurements. Constraint modeling in this domain is uniquely
challenging due to the scale of the data, the inherent learning complexity and
passive environment, and the lack of ground truth supervision. NetNomos
addresses these challenges via a lattice-based search structured by constraint
specificity and succinctness. Our approach reduces learning complexity from
superquadratic to logarithmic and enables efficient traversal in combinatorial
search space.
  Our evaluations on diverse network datasets show that NetNomos learns all
benchmark rules, including those associated with as little as 0.01% of data
points, in under three hours. In contrast, baseline methods discover less than
25% of the rules and require several days to run. Through three case studies,
we show that: NetNomos (i) finds rule violations in the outputs of all seven
synthetic traffic generators, hence can be used to assess and guide their
generation process; (ii) detects semantic differences in traffic, hence can be
used for anomaly detection; and (iii) automatically finds rules used for
telemetry imputation, hence can support monitoring through inference.
</summary>
    <author>
      <name>Hongyu Hè</name>
    </author>
    <author>
      <name>Minhao Jin</name>
    </author>
    <author>
      <name>Maria Apostolaki</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 15 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2506.23964v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.23964v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.2.3; I.2.6; I.2.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
