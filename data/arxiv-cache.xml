<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2026-02-12T01:17:14Z -->
<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/" xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns="http://www.w3.org/2005/Atom">
  <id>https://arxiv.org/api/p6EyKyP4fMY/66n9Ev8E79F7KlI</id>
  <title>arXiv Query: search_query=all:causal OR all:inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <updated>2026-02-12T01:17:14Z</updated>
  <link href="https://arxiv.org/api/query?search_query=all:causal+OR+all:inference&amp;start=0&amp;max_results=10&amp;id_list=" type="application/atom+xml"/>
  <opensearch:itemsPerPage>10</opensearch:itemsPerPage>
  <opensearch:totalResults>133722</opensearch:totalResults>
  <opensearch:startIndex>0</opensearch:startIndex>
  <entry>
    <id>http://arxiv.org/abs/2602.10101v1</id>
    <title>Robo3R: Enhancing Robotic Manipulation with Accurate Feed-Forward 3D Reconstruction</title>
    <updated>2026-02-10T18:58:15Z</updated>
    <link href="https://arxiv.org/abs/2602.10101v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.10101v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>3D spatial perception is fundamental to generalizable robotic manipulation, yet obtaining reliable, high-quality 3D geometry remains challenging. Depth sensors suffer from noise and material sensitivity, while existing reconstruction models lack the precision and metric consistency required for physical interaction. We introduce Robo3R, a feed-forward, manipulation-ready 3D reconstruction model that predicts accurate, metric-scale scene geometry directly from RGB images and robot states in real time. Robo3R jointly infers scale-invariant local geometry and relative camera poses, which are unified into the scene representation in the canonical robot frame via a learned global similarity transformation. To meet the precision demands of manipulation, Robo3R employs a masked point head for sharp, fine-grained point clouds, and a keypoint-based Perspective-n-Point (PnP) formulation to refine camera extrinsics and global alignment. Trained on Robo3R-4M, a curated large-scale synthetic dataset with four million high-fidelity annotated frames, Robo3R consistently outperforms state-of-the-art reconstruction methods and depth sensors. Across downstream tasks including imitation learning, sim-to-real transfer, grasp synthesis, and collision-free motion planning, we observe consistent gains in performance, suggesting the promise of this alternative 3D sensing module for robotic manipulation.</summary>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-10T18:58:15Z</published>
    <arxiv:primary_category term="cs.RO"/>
    <author>
      <name>Sizhe Yang</name>
    </author>
    <author>
      <name>Linning Xu</name>
    </author>
    <author>
      <name>Hao Li</name>
    </author>
    <author>
      <name>Juncheng Mu</name>
    </author>
    <author>
      <name>Jia Zeng</name>
    </author>
    <author>
      <name>Dahua Lin</name>
    </author>
    <author>
      <name>Jiangmiao Pang</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.10095v1</id>
    <title>Causality in Video Diffusers is Separable from Denoising</title>
    <updated>2026-02-10T18:57:21Z</updated>
    <link href="https://arxiv.org/abs/2602.10095v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.10095v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Causality -- referring to temporal, uni-directional cause-effect relationships between components -- underlies many complex generative processes, including videos, language, and robot trajectories. Current causal diffusion models entangle temporal reasoning with iterative denoising, applying causal attention across all layers, at every denoising step, and over the entire context. In this paper, we show that the causal reasoning in these models is separable from the multi-step denoising process. Through systematic probing of autoregressive video diffusers, we uncover two key regularities: (1) early layers produce highly similar features across denoising steps, indicating redundant computation along the diffusion trajectory; and (2) deeper layers exhibit sparse cross-frame attention and primarily perform intra-frame rendering. Motivated by these findings, we introduce Separable Causal Diffusion (SCD), a new architecture that explicitly decouples once-per-frame temporal reasoning, via a causal transformer encoder, from multi-step frame-wise rendering, via a lightweight diffusion decoder. Extensive experiments on both pretraining and post-training tasks across synthetic and real benchmarks show that SCD significantly improves throughput and per-frame latency while matching or surpassing the generation quality of strong causal diffusion baselines.</summary>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-10T18:57:21Z</published>
    <arxiv:primary_category term="cs.CV"/>
    <author>
      <name>Xingjian Bai</name>
    </author>
    <author>
      <name>Guande He</name>
    </author>
    <author>
      <name>Zhengqi Li</name>
    </author>
    <author>
      <name>Eli Shechtman</name>
    </author>
    <author>
      <name>Xun Huang</name>
    </author>
    <author>
      <name>Zongze Wu</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.10081v1</id>
    <title>Anagent For Enhancing Scientific Table &amp; Figure Analysis</title>
    <updated>2026-02-10T18:46:28Z</updated>
    <link href="https://arxiv.org/abs/2602.10081v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.10081v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>In scientific research, analysis requires accurately interpreting complex multimodal knowledge, integrating evidence from different sources, and drawing inferences grounded in domain-specific knowledge. However, current artificial intelligence (AI) systems struggle to consistently demonstrate such capabilities. The complexity and variability of scientific tables and figures, combined with heterogeneous structures and long-context requirements, pose fundamental obstacles to scientific table \&amp; figure analysis. To quantify these challenges, we introduce AnaBench, a large-scale benchmark featuring $63,178$ instances from nine scientific domains, systematically categorized along seven complexity dimensions. To tackle these challenges, we propose Anagent, a multi-agent framework for enhanced scientific table \&amp; figure analysis through four specialized agents: Planner decomposes tasks into actionable subtasks, Expert retrieves task-specific information through targeted tool execution, Solver synthesizes information to generate coherent analysis, and Critic performs iterative refinement through five-dimensional quality assessment. We further develop modular training strategies that leverage supervised finetuning and specialized reinforcement learning to optimize individual capabilities while maintaining effective collaboration. Comprehensive evaluation across 170 subdomains demonstrates that Anagent achieves substantial improvements, up to $\uparrow 13.43\%$ in training-free settings and $\uparrow 42.12\%$ with finetuning, while revealing that task-oriented reasoning and context-aware problem-solving are essential for high-quality scientific table \&amp; figure analysis. Our project page: https://xhguo7.github.io/Anagent/.</summary>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-10T18:46:28Z</published>
    <arxiv:primary_category term="cs.CL"/>
    <author>
      <name>Xuehang Guo</name>
    </author>
    <author>
      <name>Zhiyong Lu</name>
    </author>
    <author>
      <name>Tom Hope</name>
    </author>
    <author>
      <name>Qingyun Wang</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.10066v1</id>
    <title>Programmable and nonvolatile computing with composition tuning in thin film lithium niobate</title>
    <updated>2026-02-10T18:33:28Z</updated>
    <link href="https://arxiv.org/abs/2602.10066v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.10066v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Matrix-vector multiplications are fundamental operations in artificial intelligence and high-throughput computations, and are executed repeatedly during training and inference. Their high energy cost in electronic processors motivate scalable photonic computing approaches that reduce the energy required per operation. Thin film lithium niobate (TFLN) is a dominant photonic platform due to its large electro-optic effect. However, it lacks nonvolatile index tuning mechanisms, which promise to pave the way for energy-efficient photonic computing. Here, we explore electrochemical lithiation as a route to nonvolatile matrix-vector multiplications in TFLN. The LiNbO3 phase is stable at room temperature over a 2% Li composition window with an associated composition-dependent refractive index. We computationally demonstrate this as a programmable, low-loss approach to perform matrix-vector multiplications by using composition to control matrix weights. We design Mach-Zehnder interferometers to perform image processing tasks under realistic material loss constraints. We also design microring resonators for iterative weight updates, using gradient descent training to program target matrix operations with matrix-vector multiplication accuracy validated at 1.5% average relative error. These demonstrations show a facile route towards nonvolatile photonic computing in TFLN, addressing a critical requirement for energy-efficient photonic matrix operations at scale.</summary>
    <category term="physics.optics" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-10T18:33:28Z</published>
    <arxiv:comment>20 pages, 4 figures</arxiv:comment>
    <arxiv:primary_category term="physics.optics"/>
    <author>
      <name>Abhiram Devata</name>
    </author>
    <author>
      <name>Axel Maga√±a Ponce</name>
    </author>
    <author>
      <name>David Barton</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.10026v1</id>
    <title>Degrees-of-Freedom Approximations for Conditional-Mean Inference in Random-Lot Stability Analysis</title>
    <updated>2026-02-10T17:49:15Z</updated>
    <link href="https://arxiv.org/abs/2602.10026v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.10026v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Linear mixed models are widely used for pharmaceutical stability trending when sufficient lots are available. Expiry support is typically based on whether lot-specific conditional-mean confidence limits remain within specification through a proposed expiry. These limits depend on the denominator degrees-of-freedom (DDF) method used for $t$-based inference. We document an operationally important boundary-proximal phenomenon: when a fitted random-effect variance component is close to zero, Satterthwaite DDF for conditional-mean predictions can collapse, inflating $t$ critical values and producing unnecessarily wide and sometimes nonmonotone pointwise confidence limits on scheduled time grids. In contrast, containment DDF yields stable degrees of freedom and avoids sharp discontinuities as variance components approach the boundary. Using a worked example and simulation studies, we show that DDF choice can materially change pass/fail conclusions even when observed data comfortably meet specifications. Containment-based inference with the full random-effects model provides a single modeling framework that avoids the discontinuities introduced by data-dependent model reduction at arbitrary cutoffs. When containment is unavailable, a 10\% variance-contribution reduction workflow mitigates extreme Satterthwaite behavior by simplifying the random-effects structure only when fitted contributions at the proposed expiry are negligible. An AICc step-down is also evaluated but is best treated as a sensitivity analysis, as it can be liberal when the margin between the mean trend and the specification limit at the proposed expiry is small.</summary>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-10T17:49:15Z</published>
    <arxiv:primary_category term="stat.ME"/>
    <author>
      <name>Andrew T. Karl</name>
    </author>
    <author>
      <name>Heath Rushing</name>
    </author>
    <author>
      <name>Richard K. Burdick</name>
    </author>
    <author>
      <name>Jeff Hofer</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.10021v1</id>
    <title>Decoupled Reasoning with Implicit Fact Tokens (DRIFT): A Dual-Model Framework for Efficient Long-Context Inference</title>
    <updated>2026-02-10T17:42:31Z</updated>
    <link href="https://arxiv.org/abs/2602.10021v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.10021v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>The integration of extensive, dynamic knowledge into Large Language Models (LLMs) remains a significant challenge due to the inherent entanglement of factual data and reasoning patterns. Existing solutions, ranging from non-parametric Retrieval-Augmented Generation (RAG) to parametric knowledge editing, are often constrained in practice by finite context windows, retriever noise, or the risk of catastrophic forgetting. In this paper, we propose DRIFT, a novel dual-model architecture designed to explicitly decouple knowledge extraction from the reasoning process. Unlike static prompt compression, DRIFT employs a lightweight knowledge model to dynamically compress document chunks into implicit fact tokens conditioned on the query. These dense representations are projected into the reasoning model's embedding space, replacing raw, redundant text while maintaining inference accuracy. Extensive experiments show that DRIFT significantly improves performance on long-context tasks, outperforming strong baselines among comparably sized models. Our approach provides a scalable and efficient paradigm for extending the effective context window and reasoning capabilities of LLMs. Our code is available at https://github.com/Lancelot-Xie/DRIFT.</summary>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-10T17:42:31Z</published>
    <arxiv:primary_category term="cs.CL"/>
    <author>
      <name>Wenxuan Xie</name>
    </author>
    <author>
      <name>Yujia Wang</name>
    </author>
    <author>
      <name>Xin Tan</name>
    </author>
    <author>
      <name>Chaochao Lu</name>
    </author>
    <author>
      <name>Xia Hu</name>
    </author>
    <author>
      <name>Xuhong Wang</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.10018v1</id>
    <title>Online Selective Conformal Prediction with Asymmetric Rules: A Permutation Test Approach</title>
    <updated>2026-02-10T17:39:36Z</updated>
    <link href="https://arxiv.org/abs/2602.10018v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.10018v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Selective conformal prediction aims to construct prediction sets with valid coverage for a test unit conditional on it being selected by a data-driven mechanism. While existing methods in the offline setting handle any selection mechanism that is permutation invariant to the labeled data, their extension to the online setting -- where data arrives sequentially and later decisions depend on earlier ones -- is challenged by the fact that the selection mechanism is naturally asymmetric. As such, existing methods only address a limited collection of selection mechanisms.
  In this paper, we propose PErmutation-based Mondrian Conformal Inference (PEMI), a general permutation-based framework for selective conformal prediction with arbitrary asymmetric selection rules. Motivated by full and Mondrian conformal prediction, PEMI identifies all permutations of the observed data (or a Monte-Carlo subset thereof) that lead to the same selection event, and calibrates a prediction set using conformity scores over this selection-preserving reference set. Under standard exchangeability conditions, our prediction sets achieve finite-sample exact selection-conditional coverage for any asymmetric selection mechanism and any prediction model. PEMI naturally incorporates additional offline labeled data, extends to selection mechanisms with multiple test samples, and achieves FCR control with fine-grained selection taxonomies. We further work out several efficient instantiations for commonly-used online selection rules, including covariate-based rules, conformal p/e-values-based procedures, and selection based on earlier outcomes. Finally, we demonstrate the efficacy of our methods across various selection rules on a real drug discovery dataset and investigate their performance via simulations.</summary>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-10T17:39:36Z</published>
    <arxiv:primary_category term="stat.ME"/>
    <author>
      <name>Mingyi Zheng</name>
    </author>
    <author>
      <name>Ying Jin</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.10012v1</id>
    <title>Doubly Robust Estimation of Desirability of Outcome Ranking (DOOR) Probability with Application to MDRO Studies</title>
    <updated>2026-02-10T17:35:29Z</updated>
    <link href="https://arxiv.org/abs/2602.10012v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.10012v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>In observational studies, adjusting for confounders is required if a treatment comparison is planned. A crude comparison of the primary endpoint without covariate adjustment will suffer from biases, and the addition of regression models could improve precision by incorporating imbalanced covariates and thus help make correct inference. Desirability of outcome ranking (DOOR) is a patient-centric benefit-risk evaluation methodology designed for randomized clinical trials. Still, robust covariate adjustment methods could further expand the compatibility of this method in observational studies. In DOOR analysis, each participant's outcome is ranked based on pre-specified clinical criteria, where the most desirable rank represents a good outcome with no side effects and the least desirable rank is the worst possible clinical outcome. We develop a causal framework for estimating the population-level DOOR probability, via the inverse probability of treatment weighting method, G-Computation method, and a Doubly Robust method that combines both. The performance of the proposed methodologies is examined through simulations. We also perform a causal analysis of the Multi-Drug Resistant Organism (MDRO) network within the Antibacterial Resistant Leadership Group (ARLG), comparing the benefit:risk between Mono-drug therapy and Combination-drug therapy.</summary>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-10T17:35:29Z</published>
    <arxiv:primary_category term="stat.ME"/>
    <author>
      <name>Shiyu Shu</name>
    </author>
    <author>
      <name>Toshimitsu Hamasaki</name>
    </author>
    <author>
      <name>Scott Evans</name>
    </author>
    <author>
      <name>Lauren Komarow</name>
    </author>
    <author>
      <name>David van Duin</name>
    </author>
    <author>
      <name>Guoqing Diao</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.10004v1</id>
    <title>ESTAR: Early-Stopping Token-Aware Reasoning For Efficient Inference</title>
    <updated>2026-02-10T17:27:26Z</updated>
    <link href="https://arxiv.org/abs/2602.10004v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.10004v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Large reasoning models (LRMs) achieve state-of-the-art performance by generating long chains-of-thought, but often waste computation on redundant reasoning after the correct answer has already been reached. We introduce Early-Stopping for Token-Aware Reasoning (ESTAR), which detects and reduces such reasoning redundancy to improve efficiency without sacrificing accuracy. Our method combines (i) a trajectory-based classifier that identifies when reasoning can be safely stopped, (ii) supervised fine-tuning to teach LRMs to propose self-generated &lt;stop&gt; signals, and (iii) &lt;stop&gt;-aware reinforcement learning that truncates rollouts at self-generated stop points with compute-aware rewards. Experiments on four reasoning datasets show that ESTAR reduces reasoning length by about 3.7x (from 4,799 to 1,290) while preserving accuracy (74.9% vs. 74.2%), with strong cross-domain generalization. These results highlight early stopping as a simple yet powerful mechanism for improving reasoning efficiency in LRMs.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-10T17:27:26Z</published>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Junda Wang</name>
    </author>
    <author>
      <name>Zhichao Yang</name>
    </author>
    <author>
      <name>Dongxu Zhang</name>
    </author>
    <author>
      <name>Sanjit Singh Batra</name>
    </author>
    <author>
      <name>Robert E. Tillman</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2602.10001v1</id>
    <title>Human-AI Synergy Supports Collective Creative Search</title>
    <updated>2026-02-10T17:23:33Z</updated>
    <link href="https://arxiv.org/abs/2602.10001v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2602.10001v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Generative AI is increasingly transforming creativity into a hybrid human-artificial process, but its impact on the quality and diversity of creative output remains unclear. We study collective creativity using a controlled word-guessing task that balances open-endedness with an objective measure of task performance. Participants attempt to infer a hidden target word, scored based on the semantic similarity of their guesses to the target, while also observing the best guess from previous players. We compare performance and outcome diversity across human-only, AI-only, and hybrid human-AI groups. Hybrid groups achieve the highest performance while preserving high diversity of guesses. Within hybrid groups, both humans and AI agents systematically adjust their strategies relative to single-agent conditions, suggesting higher-order interaction effects, whereby agents adapt to each other's presence. Although some performance benefits can be reproduced through collaboration between heterogeneous AI systems, human-AI collaboration remains superior, underscoring complementary roles in collective creativity.</summary>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-02-10T17:23:33Z</published>
    <arxiv:primary_category term="cs.SI"/>
    <author>
      <name>Chenyi Li</name>
    </author>
    <author>
      <name>Raja Marjieh</name>
    </author>
    <author>
      <name>Haoyu Hu</name>
    </author>
    <author>
      <name>Mark Steyvers</name>
    </author>
    <author>
      <name>Katherine M. Collins</name>
    </author>
    <author>
      <name>Ilia Sucholutsky</name>
    </author>
    <author>
      <name>Nori Jacoby</name>
    </author>
  </entry>
</feed>
