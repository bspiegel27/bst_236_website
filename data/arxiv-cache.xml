<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-07-15T01:02:26Z -->
<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acausal%20inference%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:causal inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/SsRksLzRb0LuVhSmQ+N8WbAs+f8</id>
  <updated>2025-07-14T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">116755</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">10</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2507.08802v1</id>
    <updated>2025-07-11T17:59:55Z</updated>
    <published>2025-07-11T17:59:55Z</published>
    <title>The Non-Linear Representation Dilemma: Is Causal Abstraction Enough for
  Mechanistic Interpretability?</title>
    <summary>  The concept of causal abstraction got recently popularised to demystify the
opaque decision-making processes of machine learning models; in short, a neural
network can be abstracted as a higher-level algorithm if there exists a
function which allows us to map between them. Notably, most interpretability
papers implement these maps as linear functions, motivated by the linear
representation hypothesis: the idea that features are encoded linearly in a
model's representations. However, this linearity constraint is not required by
the definition of causal abstraction. In this work, we critically examine the
concept of causal abstraction by considering arbitrarily powerful alignment
maps. In particular, we prove that under reasonable assumptions, any neural
network can be mapped to any algorithm, rendering this unrestricted notion of
causal abstraction trivial and uninformative. We complement these theoretical
findings with empirical evidence, demonstrating that it is possible to
perfectly map models to algorithms even when these models are incapable of
solving the actual task; e.g., on an experiment using randomly initialised
language models, our alignment maps reach 100% interchange-intervention
accuracy on the indirect object identification task. This raises the non-linear
representation dilemma: if we lift the linearity constraint imposed to
alignment maps in causal abstraction analyses, we are left with no principled
way to balance the inherent trade-off between these maps' complexity and
accuracy. Together, these results suggest an answer to our title's question:
causal abstraction is not enough for mechanistic interpretability, as it
becomes vacuous without assumptions about how models encode information.
Studying the connection between this information-encoding assumption and causal
abstraction should lead to exciting future work.
</summary>
    <author>
      <name>Denis Sutter</name>
    </author>
    <author>
      <name>Julian Minder</name>
    </author>
    <author>
      <name>Thomas Hofmann</name>
    </author>
    <author>
      <name>Tiago Pimentel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">42 pages, 17 figures, code available in
  github.com/densutter/non-linear-representation-dilemma</arxiv:comment>
    <link href="http://arxiv.org/abs/2507.08802v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2507.08802v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2507.08801v1</id>
    <updated>2025-07-11T17:59:42Z</updated>
    <published>2025-07-11T17:59:42Z</published>
    <title>Lumos-1: On Autoregressive Video Generation from a Unified Model
  Perspective</title>
    <summary>  Autoregressive large language models (LLMs) have unified a vast range of
language tasks, inspiring preliminary efforts in autoregressive video
generation. Existing autoregressive video generators either diverge from
standard LLM architectures, depend on bulky external text encoders, or incur
prohibitive latency due to next-token decoding. In this paper, we introduce
Lumos-1, an autoregressive video generator that retains the LLM architecture
with minimal architectural modifications. To inject spatiotemporal correlations
in LLMs, we identify the efficacy of incorporating 3D RoPE and diagnose its
imbalanced frequency spectrum ranges. Therefore, we propose MM-RoPE, a RoPE
scheme that preserves the original textual RoPE while providing comprehensive
frequency spectra and scaled 3D positions for modeling multimodal
spatiotemporal data. Moreover, Lumos-1 resorts to a token dependency strategy
that obeys intra-frame bidirectionality and inter-frame temporal causality.
Based on this dependency strategy, we identify the issue of frame-wise loss
imbalance caused by spatial information redundancy and solve it by proposing
Autoregressive Discrete Diffusion Forcing (AR-DF). AR-DF introduces temporal
tube masking during training with a compatible inference-time masking policy to
avoid quality degradation. By using memory-efficient training techniques, we
pre-train Lumos-1 on only 48 GPUs, achieving performance comparable to EMU3 on
GenEval, COSMOS-Video2World on VBench-I2V, and OpenSoraPlan on VBench-T2V. Code
and models are available at https://github.com/alibaba-damo-academy/Lumos.
</summary>
    <author>
      <name>Hangjie Yuan</name>
    </author>
    <author>
      <name>Weihua Chen</name>
    </author>
    <author>
      <name>Jun Cen</name>
    </author>
    <author>
      <name>Hu Yu</name>
    </author>
    <author>
      <name>Jingyun Liang</name>
    </author>
    <author>
      <name>Shuning Chang</name>
    </author>
    <author>
      <name>Zhihui Lin</name>
    </author>
    <author>
      <name>Tao Feng</name>
    </author>
    <author>
      <name>Pengwei Liu</name>
    </author>
    <author>
      <name>Jiazheng Xing</name>
    </author>
    <author>
      <name>Hao Luo</name>
    </author>
    <author>
      <name>Jiasheng Tang</name>
    </author>
    <author>
      <name>Fan Wang</name>
    </author>
    <author>
      <name>Yi Yang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Code and Models: https://github.com/alibaba-damo-academy/Lumos</arxiv:comment>
    <link href="http://arxiv.org/abs/2507.08801v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2507.08801v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2507.08799v1</id>
    <updated>2025-07-11T17:59:36Z</updated>
    <published>2025-07-11T17:59:36Z</published>
    <title>KV Cache Steering for Inducing Reasoning in Small Language Models</title>
    <summary>  We propose cache steering, a lightweight method for implicit steering of
language models via a one-shot intervention applied directly to the key-value
cache. To validate its effectiveness, we apply cache steering to induce
chain-of-thought reasoning in small language models. Our approach leverages
GPT-4o-generated reasoning traces to construct steering vectors that shift
model behavior toward more explicit, multi-step reasoning without fine-tuning
or prompt modifications. Experimental evaluations on diverse reasoning
benchmarks demonstrate that cache steering improves both the qualitative
structure of model reasoning and quantitative task performance. Compared to
prior activation steering techniques that require continuous interventions, our
one-shot cache steering offers substantial advantages in terms of
hyperparameter stability, inference-time efficiency, and ease of integration,
making it a more robust and practical solution for controlled generation.
</summary>
    <author>
      <name>Max Belitsky</name>
    </author>
    <author>
      <name>Dawid J. Kopiczko</name>
    </author>
    <author>
      <name>Michael Dorkenwald</name>
    </author>
    <author>
      <name>M. Jehanzeb Mirza</name>
    </author>
    <author>
      <name>Cees G. M. Snoek</name>
    </author>
    <author>
      <name>Yuki M. Asano</name>
    </author>
    <link href="http://arxiv.org/abs/2507.08799v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2507.08799v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2507.08798v1</id>
    <updated>2025-07-11T17:59:01Z</updated>
    <published>2025-07-11T17:59:01Z</published>
    <title>The Atacama Cosmology Telescope: High-redshift measurement of structure
  growth from the cross-correlation of Quaia quasars and CMB lensing from ACT
  DR6 and $\textit{Planck}$ PR4</title>
    <summary>  We measure the amplitude of matter fluctuations over a wide range of
redshifts by combining CMB lensing observations from ACT DR6 and
$\textit{Planck}$ PR4 with the overdensity of quasars from Quaia, a
$\textit{Gaia}$ and $\textit{unWISE}$ quasar catalog. Our analysis includes the
CMB lensing power spectrum from ACT DR6, the auto-correlation of two Quaia
quasar samples centered at $z \simeq 1.0$ and $z \simeq 2.1$, and their
cross-correlations with CMB lensing from both ACT DR6 and $\textit{Planck}$
PR4. By performing a series of contamination and systematic null tests, we find
no evidence for contamination in the lensing maps, contrary to what was
suggested in previous Quaia cross-correlation analyses using $\textit{Planck}$
PR4 CMB lensing data. From the joint analysis of the quasar auto- and
cross-correlations with CMB lensing, and including BOSS BAO data to break the
degeneracy between $\Omega_m$ and $\sigma_8$, we obtain $\sigma_8 =
0.802^{+0.045}_{-0.057}$, consistent with $\Lambda$CDM predictions from
$\textit{Planck}$ primary CMB measurements. Combining the CMB lensing
auto-spectrum with the cross-correlation measurement improves the constraint on
$\sigma_8$ by $12\%$ relative to the lensing auto-spectrum alone, yielding
$\sigma_8 = 0.804 \pm 0.013$. This dataset combination also enables a
reconstruction of structure growth across redshifts. We infer a $12\%$
constraint on the amplitude of matter fluctuations at $z &gt; 3$, with a
measurement at the median redshift of the signal of $\sigma_8(\tilde{z}=5.1) =
0.146^{+0.021}_{-0.014}$, consistent with $\textit{Planck}$ at the $1.4\sigma$
level. These results provide one of the highest redshift constraints on the
growth of structure to date.
</summary>
    <author>
      <name>Carmen Embil Villagra</name>
    </author>
    <author>
      <name>Gerrit Farren</name>
    </author>
    <author>
      <name>Giulio Fabbian</name>
    </author>
    <author>
      <name>Boris Bolliet</name>
    </author>
    <author>
      <name>Irene Abril-Cabezas</name>
    </author>
    <author>
      <name>David Alonso</name>
    </author>
    <author>
      <name>Anthony Challinor</name>
    </author>
    <author>
      <name>Jo Dunkley</name>
    </author>
    <author>
      <name>Joshua Kim</name>
    </author>
    <author>
      <name>Niall MacCrann</name>
    </author>
    <author>
      <name>Fiona McCarthy</name>
    </author>
    <author>
      <name>Kavilan Moodley</name>
    </author>
    <author>
      <name>Frank J. Qu</name>
    </author>
    <author>
      <name>Blake Sherwin</name>
    </author>
    <author>
      <name>Cristobal Sifon</name>
    </author>
    <author>
      <name>Alexander van Engelen</name>
    </author>
    <author>
      <name>Edward J. Wollack</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">30 pages, 15 figures, to be submitted to JCAP</arxiv:comment>
    <link href="http://arxiv.org/abs/2507.08798v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2507.08798v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2507.08781v1</id>
    <updated>2025-07-11T17:43:54Z</updated>
    <published>2025-07-11T17:43:54Z</published>
    <title>Routing Quantum Control of Causal Order</title>
    <summary>  In recent years, various frameworks have been proposed for the study of
quantum processes with indefinite causal order. In particular, quantum circuits
with quantum control of causal order (QC-QCs) form a broad class of physical
supermaps obtained from a bottom-up construction and are believed to represent
all quantum processes physically realisable in a fixed spacetime.
Complementarily, the formalism of routed quantum circuits introduces quantum
operations constrained by "routes" to represent processes in terms of a more
fine-grained routed circuit decomposition. This decomposition, formalised using
a so-called routed graph, represents the information flow within the respective
process. However, the existence of routed circuit decompositions has only been
established for a small set of processes so far, including both certain
specific QC-QCs and more exotic processes as examples.
  In this work, we remedy this fact by connecting these two frameworks. We
prove that for any given $N$, one can use a single routed graph to
systematically obtain a routed circuit decomposition for any QC-QC with $N$
parties. We detail this construction explicitly and contrast it with other
routed circuit decompositions of QC-QCs, which we obtain from alternative
routed graphs. We conclude by pointing out how this connection can be useful to
tackle various open problems in the field of indefinite causal order,
particularly establishing circuit representations of subclasses of QC-QCs.
</summary>
    <author>
      <name>Maarten Grothus</name>
    </author>
    <author>
      <name>Alastair A. Abbott</name>
    </author>
    <author>
      <name>Augustin Vanrietvelde</name>
    </author>
    <author>
      <name>Cyril Branciard</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">49+14 pages, 20 figures. Comments welcome!</arxiv:comment>
    <link href="http://arxiv.org/abs/2507.08781v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2507.08781v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2507.08765v1</id>
    <updated>2025-07-11T17:21:06Z</updated>
    <published>2025-07-11T17:21:06Z</published>
    <title>Compress Any Segment Anything Model (SAM)</title>
    <summary>  Due to the excellent performance in yielding high-quality, zero-shot
segmentation, Segment Anything Model (SAM) and its variants have been widely
applied in diverse scenarios such as healthcare and intelligent manufacturing.
Therefore, effectively compressing SAMs has become an increasingly pressing
practical need. In this study, we propose Birkhoff, a novel data-free
compression algorithm for SAM and its variants. Unlike quantization, pruning,
distillation, and other compression methods, Birkhoff embodies versatility
across model types, agility in deployment, faithfulness to the original model,
and compactness in model size. Specifically, Birkhoff introduces a novel
compression algorithm: Hyper-Compression, whose core principle is to find a
dense trajectory to turn a high-dimensional parameter vector into a
low-dimensional scalar. Furthermore, Birkhoff designs a dedicated linear layer
operator, HyperLinear, to fuse decompression and matrix multiplication to
significantly accelerate inference of the compressed SAMs. Extensive
experiments on 18 SAMs in the COCO, LVIS, and SA-1B datasets show that Birkhoff
performs consistently and competitively in compression time, compression ratio,
post-compression performance, and inference speed. For example, Birkhoff can
achieve a compression ratio of 5.17x on SAM2-B, with less than 1% performance
drop without using any fine-tuning data. Moreover, the compression is finished
within 60 seconds for all models.
</summary>
    <author>
      <name>Juntong Fan</name>
    </author>
    <author>
      <name>Zhiwei Hao</name>
    </author>
    <author>
      <name>Jianqiang Shen</name>
    </author>
    <author>
      <name>Shang-Ling Jui</name>
    </author>
    <author>
      <name>Yi Zhang</name>
    </author>
    <author>
      <name>Jing-Xiao Liao</name>
    </author>
    <author>
      <name>Feng-Lei Fan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 6 tables, 8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2507.08765v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2507.08765v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2507.08764v1</id>
    <updated>2025-07-11T17:20:29Z</updated>
    <published>2025-07-11T17:20:29Z</published>
    <title>Propensity score with factor loadings: the effect of the Paris Agreement</title>
    <summary>  Factor models for longitudinal data, where policy adoption is unconfounded
with respect to a low-dimensional set of latent factor loadings, have become
increasingly popular for causal inference. Most existing approaches, however,
rely on a causal finite-sample approach or computationally intensive methods,
limiting their applicability and external validity. In this paper, we propose a
novel causal inference method for panel data based on inverse propensity score
weighting where the propensity score is a function of latent factor loadings
within a framework of causal inference from super-population. The approach
relaxes the traditional restrictive assumptions of causal panel methods, while
offering advantages in terms of causal interpretability, policy relevance, and
computational efficiency. Under standard assumptions, we outline a three-step
estimation procedure for the ATT and derive its large-sample properties using
Mestimation theory. We apply the method to assess the causal effect of the
Paris Agreement, a policy aimed at fostering the transition to a low-carbon
economy, on European stock returns. Our empirical results suggest a
statistically significant and negative short-run effect on the stock returns of
firms that issued green bonds.
</summary>
    <author>
      <name>Angelo Forino</name>
    </author>
    <author>
      <name>Andrea Mercatanti</name>
    </author>
    <author>
      <name>Giacomo Morelli</name>
    </author>
    <link href="http://arxiv.org/abs/2507.08764v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2507.08764v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="econ.EM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="econ.EM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2507.08742v1</id>
    <updated>2025-07-11T16:44:46Z</updated>
    <published>2025-07-11T16:44:46Z</published>
    <title>Influence of river incision on landslides triggered in Nepal by the
  Gorkha earthquake: Results from a pixel-based susceptibility model using
  inlabru</title>
    <summary>  This study presents a comprehensive framework for modelling
earthquake-induced landslides (EQILs) through a channel-based analysis of
landslide centroid distributions. A key innovation is the incorporation of the
normalised channel steepness index ($k_{sn}$) as a physically meaningful and
novel covariate, inferring hillslope erosion and fluvial incision processes.
Used within spatial point process models, $k_{sn}$ supports the generation of
landslide susceptibility maps with quantified uncertainty. To address spatial
data misalignment between covariates and landslide observations, we leverage
the inlabru framework, which enables coherent integration through mesh-based
disaggregation, thereby overcoming challenges associated with spatially
misaligned data integration. Our modelling strategy explicitly prioritises
prospective transferability to unseen geographical regions, provided that
explanatory variable data are available. By modelling both landslide locations
and sizes, we find that elevated $k_{sn}$ is strongly associated with increased
landslide susceptibility but not with landslide magnitude. The best-fitting
Bayesian model, validated through cross-validation, offers a scalable and
interpretable solution for predicting earthquake-induced landslides in complex
terrain.
</summary>
    <author>
      <name>Man Ho Suen</name>
    </author>
    <author>
      <name>Mark Naylor</name>
    </author>
    <author>
      <name>Simon Mudd</name>
    </author>
    <author>
      <name>Finn Lindgren</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">45 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2507.08742v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2507.08742v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2507.08734v1</id>
    <updated>2025-07-11T16:37:15Z</updated>
    <published>2025-07-11T16:37:15Z</published>
    <title>Estimating Marginal Likelihoods in Likelihood-Free Inference via Neural
  Density Estimation</title>
    <summary>  The marginal likelihood, or evidence, plays a central role in Bayesian model
selection, yet remains notoriously challenging to compute in likelihood-free
settings. While Simulation-Based Inference (SBI) techniques such as Sequential
Neural Likelihood Estimation (SNLE) offer powerful tools to approximate
posteriors using neural density estimators, they typically do not provide
estimates of the evidence. In this technical report presented at BayesComp
2025, we present a simple and general methodology to estimate the marginal
likelihood using the output of SNLE.
</summary>
    <author>
      <name>Paul Bastide</name>
    </author>
    <author>
      <name>Arnaud Estoup</name>
    </author>
    <author>
      <name>Jean-Michel Marin</name>
    </author>
    <author>
      <name>Julien Stoehr</name>
    </author>
    <link href="http://arxiv.org/abs/2507.08734v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2507.08734v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2507.08700v1</id>
    <updated>2025-07-11T15:51:50Z</updated>
    <published>2025-07-11T15:51:50Z</published>
    <title>The breakdown scale of pionless effective field theory in the
  three-nucleon sector</title>
    <summary>  We make order-by-order predictions of neutron-deuteron total cross sections
up to next-to-next-to-leading order in pionless effective field theory. Using
Bayesian methods, we infer a posterior distribution for the breakdown scale.
The result shows a mode near 100 MeV, and a combined analysis with
neutron-proton scattering further sharpens the inference, placing the mode
close to the pion mass scale, consistent with the expected range of pionless
effective field theory.
</summary>
    <author>
      <name>Andreas Ekstr√∂m</name>
    </author>
    <author>
      <name>Lucas Platter</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 5 figured</arxiv:comment>
    <link href="http://arxiv.org/abs/2507.08700v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2507.08700v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="nucl-th" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nucl-th" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
