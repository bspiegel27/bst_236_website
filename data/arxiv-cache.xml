<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-07-06T01:04:11Z -->
<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acausal%20inference%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:causal inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/SsRksLzRb0LuVhSmQ+N8WbAs+f8</id>
  <updated>2025-07-05T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">116303</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">10</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2507.02860v1</id>
    <updated>2025-07-03T17:59:54Z</updated>
    <published>2025-07-03T17:59:54Z</published>
    <title>Less is Enough: Training-Free Video Diffusion Acceleration via
  Runtime-Adaptive Caching</title>
    <summary>  Video generation models have demonstrated remarkable performance, yet their
broader adoption remains constrained by slow inference speeds and substantial
computational costs, primarily due to the iterative nature of the denoising
process. Addressing this bottleneck is essential for democratizing advanced
video synthesis technologies and enabling their integration into real-world
applications. This work proposes EasyCache, a training-free acceleration
framework for video diffusion models. EasyCache introduces a lightweight,
runtime-adaptive caching mechanism that dynamically reuses previously computed
transformation vectors, avoiding redundant computations during inference.
Unlike prior approaches, EasyCache requires no offline profiling,
pre-computation, or extensive parameter tuning. We conduct comprehensive
studies on various large-scale video generation models, including OpenSora,
Wan2.1, and HunyuanVideo. Our method achieves leading acceleration performance,
reducing inference time by up to 2.1-3.3$\times$ compared to the original
baselines while maintaining high visual fidelity with a significant up to 36%
PSNR improvement compared to the previous SOTA method. This improvement makes
our EasyCache a efficient and highly accessible solution for high-quality video
generation in both research and practical applications. The code is available
at https://github.com/H-EmbodVis/EasyCache.
</summary>
    <author>
      <name>Xin Zhou</name>
    </author>
    <author>
      <name>Dingkang Liang</name>
    </author>
    <author>
      <name>Kaijin Chen</name>
    </author>
    <author>
      <name>Tianrui Feng</name>
    </author>
    <author>
      <name>Xiwu Chen</name>
    </author>
    <author>
      <name>Hongkai Lin</name>
    </author>
    <author>
      <name>Yikang Ding</name>
    </author>
    <author>
      <name>Feiyang Tan</name>
    </author>
    <author>
      <name>Hengshuang Zhao</name>
    </author>
    <author>
      <name>Xiang Bai</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The code is made available at
  https://github.com/H-EmbodVis/EasyCache. Project page:
  https://h-embodvis.github.io/EasyCache/</arxiv:comment>
    <link href="http://arxiv.org/abs/2507.02860v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2507.02860v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2507.02843v1</id>
    <updated>2025-07-03T17:52:27Z</updated>
    <published>2025-07-03T17:52:27Z</published>
    <title>LLM-Driven Treatment Effect Estimation Under Inference Time Text
  Confounding</title>
    <summary>  Estimating treatment effects is crucial for personalized decision-making in
medicine, but this task faces unique challenges in clinical practice. At
training time, models for estimating treatment effects are typically trained on
well-structured medical datasets that contain detailed patient information.
However, at inference time, predictions are often made using textual
descriptions (e.g., descriptions with self-reported symptoms), which are
incomplete representations of the original patient information. In this work,
we make three contributions. (1) We show that the discrepancy between the data
available during training time and inference time can lead to biased estimates
of treatment effects. We formalize this issue as an inference time text
confounding problem, where confounders are fully observed during training time
but only partially available through text at inference time. (2) To address
this problem, we propose a novel framework for estimating treatment effects
that explicitly accounts for inference time text confounding. Our framework
leverages large language models together with a custom doubly robust learner to
mitigate biases caused by the inference time text confounding. (3) Through a
series of experiments, we demonstrate the effectiveness of our framework in
real-world applications.
</summary>
    <author>
      <name>Yuchen Ma</name>
    </author>
    <author>
      <name>Dennis Frauen</name>
    </author>
    <author>
      <name>Jonas Schweisthal</name>
    </author>
    <author>
      <name>Stefan Feuerriegel</name>
    </author>
    <link href="http://arxiv.org/abs/2507.02843v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2507.02843v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2507.02827v1</id>
    <updated>2025-07-03T17:38:44Z</updated>
    <published>2025-07-03T17:38:44Z</published>
    <title>USAD: An Unsupervised Data Augmentation Spatio-Temporal Attention
  Diffusion Network</title>
    <summary>  The primary objective of human activity recognition (HAR) is to infer ongoing
human actions from sensor data, a task that finds broad applications in health
monitoring, safety protection, and sports analysis. Despite proliferating
research, HAR still faces key challenges, including the scarcity of labeled
samples for rare activities, insufficient extraction of high-level features,
and suboptimal model performance on lightweight devices. To address these
issues, this paper proposes a comprehensive optimization approach centered on
multi-attention interaction mechanisms. First, an unsupervised,
statistics-guided diffusion model is employed to perform data augmentation,
thereby alleviating the problems of labeled data scarcity and severe class
imbalance. Second, a multi-branch spatio-temporal interaction network is
designed, which captures multi-scale features of sequential data through
parallel residual branches with 3*3, 5*5, and 7*7 convolutional kernels.
Simultaneously, temporal attention mechanisms are incorporated to identify
critical time points, while spatial attention enhances inter-sensor
interactions. A cross-branch feature fusion unit is further introduced to
improve the overall feature representation capability. Finally, an adaptive
multi-loss function fusion strategy is integrated, allowing for dynamic
adjustment of loss weights and overall model optimization. Experimental results
on three public datasets, WISDM, PAMAP2, and OPPORTUNITY, demonstrate that the
proposed unsupervised data augmentation spatio-temporal attention diffusion
network (USAD) achieves accuracies of 98.84%, 93.81%, and 80.92% respectively,
significantly outperforming existing approaches. Furthermore, practical
deployment on embedded devices verifies the efficiency and feasibility of the
proposed method.
</summary>
    <author>
      <name>Ying Yu</name>
    </author>
    <author>
      <name>Hang Xiao</name>
    </author>
    <author>
      <name>Siyao Li</name>
    </author>
    <author>
      <name>Jiarui Li</name>
    </author>
    <author>
      <name>Haotian Tang</name>
    </author>
    <author>
      <name>Hanyu Liu</name>
    </author>
    <author>
      <name>Chao Li</name>
    </author>
    <link href="http://arxiv.org/abs/2507.02827v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2507.02827v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2507.02822v1</id>
    <updated>2025-07-03T17:33:58Z</updated>
    <published>2025-07-03T17:33:58Z</published>
    <title>SynapseRoute: An Auto-Route Switching Framework on Dual-State Large
  Language Model</title>
    <summary>  With the widespread adoption of large language models (LLMs) in practical
applications, selecting an appropriate model requires balancing not only
performance but also operational cost. The emergence of reasoning-capable
models has further widened the cost gap between "thinking" (high reasoning) and
"non-thinking" (fast, low-cost) modes. In this work, we reveal that
approximately 58% of medical questions can be accurately answered by the
non-thinking mode alone, without requiring the high-cost reasoning process.
This highlights a clear dichotomy in problem complexity and suggests that
dynamically routing queries to the appropriate mode based on complexity could
optimize accuracy, cost-efficiency, and overall user experience. Based on this,
we further propose SynapseRoute, a machine learning-based dynamic routing
framework that intelligently assigns input queries to either thinking or
non-thinking modes. Experimental results on several medical datasets
demonstrate that SynapseRoute not only improves overall accuracy (0.8390 vs.
0.8272) compared to the thinking mode alone but also reduces inference time by
36.8% and token consumption by 39.66%. Importantly, qualitative analysis
indicates that over-reasoning on simpler queries can lead to unnecessary delays
and even decreased accuracy, a pitfall avoided by our adaptive routing.
Finally, this work further introduces the Accuracy-Inference-Token (AIT) index
to comprehensively evaluate the trade-offs among accuracy, latency, and token
cost.
</summary>
    <author>
      <name>Wencheng Zhang</name>
    </author>
    <author>
      <name>Shiqin Qiao</name>
    </author>
    <author>
      <name>Lingjie Luo</name>
    </author>
    <author>
      <name>Yinfeng Li</name>
    </author>
    <author>
      <name>Chuanyang Zheng</name>
    </author>
    <author>
      <name>Qian Xu</name>
    </author>
    <author>
      <name>Meng Li</name>
    </author>
    <author>
      <name>Yong Gui</name>
    </author>
    <author>
      <name>Yijun He</name>
    </author>
    <author>
      <name>Jianing Qiu</name>
    </author>
    <author>
      <name>Jindong Hong</name>
    </author>
    <author>
      <name>Jiankai Sun</name>
    </author>
    <link href="http://arxiv.org/abs/2507.02822v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2507.02822v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2507.02799v1</id>
    <updated>2025-07-03T17:01:53Z</updated>
    <published>2025-07-03T17:01:53Z</published>
    <title>Is Reasoning All You Need? Probing Bias in the Age of Reasoning Language
  Models</title>
    <summary>  Reasoning Language Models (RLMs) have gained traction for their ability to
perform complex, multi-step reasoning tasks through mechanisms such as
Chain-of-Thought (CoT) prompting or fine-tuned reasoning traces. While these
capabilities promise improved reliability, their impact on robustness to social
biases remains unclear. In this work, we leverage the CLEAR-Bias benchmark,
originally designed for Large Language Models (LLMs), to investigate the
adversarial robustness of RLMs to bias elicitation. We systematically evaluate
state-of-the-art RLMs across diverse sociocultural dimensions, using an
LLM-as-a-judge approach for automated safety scoring and leveraging jailbreak
techniques to assess the strength of built-in safety mechanisms. Our evaluation
addresses three key questions: (i) how the introduction of reasoning
capabilities affects model fairness and robustness; (ii) whether models
fine-tuned for reasoning exhibit greater safety than those relying on CoT
prompting at inference time; and (iii) how the success rate of jailbreak
attacks targeting bias elicitation varies with the reasoning mechanisms
employed. Our findings reveal a nuanced relationship between reasoning
capabilities and bias safety. Surprisingly, models with explicit reasoning,
whether via CoT prompting or fine-tuned reasoning traces, are generally more
vulnerable to bias elicitation than base models without such mechanisms,
suggesting reasoning may unintentionally open new pathways for stereotype
reinforcement. Reasoning-enabled models appear somewhat safer than those
relying on CoT prompting, which are particularly prone to contextual reframing
attacks through storytelling prompts, fictional personas, or reward-shaped
instructions. These results challenge the assumption that reasoning inherently
improves robustness and underscore the need for more bias-aware approaches to
reasoning design.
</summary>
    <author>
      <name>Riccardo Cantini</name>
    </author>
    <author>
      <name>Nicola Gabriele</name>
    </author>
    <author>
      <name>Alessio Orsino</name>
    </author>
    <author>
      <name>Domenico Talia</name>
    </author>
    <link href="http://arxiv.org/abs/2507.02799v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2507.02799v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2507.02791v1</id>
    <updated>2025-07-03T16:54:56Z</updated>
    <published>2025-07-03T16:54:56Z</published>
    <title>Self-Steering Deep Non-Linear Spatially Selective Filters for Efficient
  Extraction of Moving Speakers under Weak Guidance</title>
    <summary>  Recent works on deep non-linear spatially selective filters demonstrate
exceptional enhancement performance with computationally lightweight
architectures for stationary speakers of known directions. However, to maintain
this performance in dynamic scenarios, resource-intensive data-driven tracking
algorithms become necessary to provide precise spatial guidance conditioned on
the initial direction of a target speaker. As this additional computational
overhead hinders application in resource-constrained scenarios such as
real-time speech enhancement, we present a novel strategy utilizing a
low-complexity tracking algorithm in the form of a particle filter instead.
Assuming a causal, sequential processing style, we introduce temporal feedback
to leverage the enhanced speech signal of the spatially selective filter to
compensate for the limited modeling capabilities of the particle filter.
Evaluation on a synthetic dataset illustrates how the autoregressive interplay
between both algorithms drastically improves tracking accuracy and leads to
strong enhancement performance. A listening test with real-world recordings
complements these findings by indicating a clear trend towards our proposed
self-steering pipeline as preferred choice over comparable methods.
</summary>
    <author>
      <name>Jakob Kienegger</name>
    </author>
    <author>
      <name>Alina Mannanova</name>
    </author>
    <author>
      <name>Huajian Fang</name>
    </author>
    <author>
      <name>Timo Gerkmann</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at IEEE Workshop on Applications of Signal Processing to
  Audio and Acoustics (WASPAA) 2025</arxiv:comment>
    <link href="http://arxiv.org/abs/2507.02791v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2507.02791v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2507.02734v1</id>
    <updated>2025-07-03T15:45:35Z</updated>
    <published>2025-07-03T15:45:35Z</published>
    <title>Leveraging Transformer Models to Capture Multi-Scale Dynamics in
  Biomolecules by nano-GPT</title>
    <summary>  Long-term biomolecular dynamics are critical for understanding key
evolutionary transformations in molecular systems. However, capturing these
processes requires extended simulation timescales that often exceed the
practical limits of conventional models. To address this, shorter simulations,
initialized with diverse perturbations, are commonly used to sample phase space
and explore a wide range of behaviors. Recent advances have leveraged language
models to infer long-term behavior from short trajectories, but methods such as
long short-term memory (LSTM) networks are constrained to low-dimensional
reaction coordinates, limiting their applicability to complex systems. In this
work, we present nano-GPT, a novel deep learning model inspired by the GPT
architecture, specifically designed to capture long-term dynamics in molecular
systems with fine-grained conformational states and complex transitions. The
model employs a two-pass training mechanism that incrementally replaces
molecular dynamics (MD) tokens with model-generated predictions, effectively
mitigating accumulation errors inherent in the training window. We validate
nano-GPT on three distinct systems: a four-state model potential, the alanine
dipeptide, a well-studied simple molecule, and the Fip35 WW domain, a complex
biomolecular system. Our results show that nano-GPT effectively captures
long-timescale dynamics by learning high-order dependencies through attention
mechanism, offering a novel perspective for interpreting biomolecular
processes.
</summary>
    <author>
      <name>Wenqi Zeng</name>
    </author>
    <author>
      <name>Lu Zhang</name>
    </author>
    <author>
      <name>Yuan Yao</name>
    </author>
    <link href="http://arxiv.org/abs/2507.02734v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2507.02734v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2507.02731v1</id>
    <updated>2025-07-03T15:43:06Z</updated>
    <published>2025-07-03T15:43:06Z</published>
    <title>RIS-Aided Cooperative ISAC Networks for Structural Health Monitoring</title>
    <summary>  Integrated sensing and communication (ISAC) is a key feature of future
cellular systems, enabling applications such as intruder detection, monitoring,
and tracking using the same infrastructure. However, its potential for
structural health monitoring (SHM), which requires the detection of slow and
subtle structural changes, remains largely unexplored due to challenges such as
multipath interference and the need for ultra-high sensing precision. This
study introduces a novel theoretical framework for SHM via ISAC by leveraging
reconfigurable intelligent surfaces (RIS) as reference points in collaboration
with base stations and users. By dynamically adjusting RIS phases to generate
distinct radio signals that suppress background multipath interference,
measurement accuracy at these reference points is enhanced. We theoretically
analyze RIS-aided collaborative sensing in three-dimensional cellular networks
using Fisher information theory, demonstrating how increasing observation time,
incorporating additional receivers (even with self-positioning errors),
optimizing RIS phases, and refining collaborative node selection can reduce the
position error bound to meet SHM's stringent accuracy requirements.
Furthermore, we develop a Bayesian inference model to identify structural
states and validate damage detection probabilities. Both theoretical and
numerical analyses confirm ISAC's capability for millimeter-level deformation
detection, highlighting its potential for high-precision SHM applications.
</summary>
    <author>
      <name>Jie Yang</name>
    </author>
    <author>
      <name>Chao-Kai Wen</name>
    </author>
    <author>
      <name>Xiao Li</name>
    </author>
    <author>
      <name>Shi Jin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This work has been submitted to the IEEE for possible publication</arxiv:comment>
    <link href="http://arxiv.org/abs/2507.02731v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2507.02731v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2507.02724v1</id>
    <updated>2025-07-03T15:41:04Z</updated>
    <published>2025-07-03T15:41:04Z</published>
    <title>Hierarchical Multi-Label Contrastive Learning for Protein-Protein
  Interaction Prediction Across Organisms</title>
    <summary>  Recent advances in AI for science have highlighted the power of contrastive
learning in bridging heterogeneous biological data modalities. Building on this
paradigm, we propose HIPPO (HIerarchical Protein-Protein interaction prediction
across Organisms), a hierarchical contrastive framework for protein-protein
interaction(PPI) prediction, where protein sequences and their hierarchical
attributes are aligned through multi-tiered biological representation matching.
The proposed approach incorporates hierarchical contrastive loss functions that
emulate the structured relationship among functional classes of proteins. The
framework adaptively incorporates domain and family knowledge through a
data-driven penalty mechanism, enforcing consistency between the learned
embedding space and the intrinsic hierarchy of protein functions. Experiments
on benchmark datasets demonstrate that HIPPO achieves state-of-the-art
performance, outperforming existing methods and showing robustness in low-data
regimes. Notably, the model demonstrates strong zero-shot transferability to
other species without retraining, enabling reliable PPI prediction and
functional inference even in less characterized or rare organisms where
experimental data are limited. Further analysis reveals that hierarchical
feature fusion is critical for capturing conserved interaction determinants,
such as binding motifs and functional annotations. This work advances
cross-species PPI prediction and provides a unified framework for interaction
prediction in scenarios with sparse or imbalanced multi-species data.
</summary>
    <author>
      <name>Shiyi Liu</name>
    </author>
    <author>
      <name>Buwen Liang</name>
    </author>
    <author>
      <name>Yuetong Fang</name>
    </author>
    <author>
      <name>Zixuan Jiang</name>
    </author>
    <author>
      <name>Renjing Xu</name>
    </author>
    <link href="http://arxiv.org/abs/2507.02724v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2507.02724v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.BM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2507.02690v1</id>
    <updated>2025-07-03T15:01:08Z</updated>
    <published>2025-07-03T15:01:08Z</published>
    <title>RLHGNN: Reinforcement Learning-driven Heterogeneous Graph Neural Network
  for Next Activity Prediction in Business Processes</title>
    <summary>  Next activity prediction represents a fundamental challenge for optimizing
business processes in service-oriented architectures such as microservices
environments, distributed enterprise systems, and cloud-native platforms, which
enables proactive resource allocation and dynamic service composition. Despite
the prevalence of sequence-based methods, these approaches fail to capture
non-sequential relationships that arise from parallel executions and
conditional dependencies. Even though graph-based approaches address structural
preservation, they suffer from homogeneous representations and static
structures that apply uniform modeling strategies regardless of individual
process complexity characteristics. To address these limitations, we introduce
RLHGNN, a novel framework that transforms event logs into heterogeneous process
graphs with three distinct edge types grounded in established process mining
theory. Our approach creates four flexible graph structures by selectively
combining these edges to accommodate different process complexities, and
employs reinforcement learning formulated as a Markov Decision Process to
automatically determine the optimal graph structure for each specific process
instance. RLHGNN then applies heterogeneous graph convolution with
relation-specific aggregation strategies to effectively predict the next
activity. This adaptive methodology enables precise modeling of both sequential
and non-sequential relationships in service interactions. Comprehensive
evaluation on six real-world datasets demonstrates that RLHGNN consistently
outperforms state-of-the-art approaches. Furthermore, it maintains an inference
latency of approximately 1 ms per prediction, representing a highly practical
solution suitable for real-time business process monitoring applications. The
source code is available at https://github.com/Joker3993/RLHGNN.
</summary>
    <author>
      <name>Jiaxing Wang</name>
    </author>
    <author>
      <name>Yifeng Yu</name>
    </author>
    <author>
      <name>Jiahan Song</name>
    </author>
    <author>
      <name>Bin Cao</name>
    </author>
    <author>
      <name>Jing Fan</name>
    </author>
    <author>
      <name>Ji Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 7 figures. Business process prediction using reinforcement
  learning and heterogeneous graph neural networks</arxiv:comment>
    <link href="http://arxiv.org/abs/2507.02690v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2507.02690v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
