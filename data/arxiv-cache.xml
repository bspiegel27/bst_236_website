<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-09-14T00:56:25Z -->
<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acausal%20inference%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:causal inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/SsRksLzRb0LuVhSmQ+N8WbAs+f8</id>
  <updated>2025-09-13T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">120762</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">10</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2509.09678v1</id>
    <updated>2025-09-11T17:59:46Z</updated>
    <published>2025-09-11T17:59:46Z</published>
    <title>Cosmic $τ$ensions Indirectly Correlate with Reionization Optical
  Depth</title>
    <summary>  The reionization optical depth $\tau_{\rm reio}$ has interesting connections
to existing cosmological anomalies. As first studied in the context of the
Hubble tension in our previous paper, a larger $\tau_{\rm reio}$, which could
be achieved by removing the Planck low-$\ell$ polarization data, could boost
$H_0$ slightly, resulting in a mild reduction of the tension between the early-
and late-universe determinations of $H_0$. It has been shown later that a
larger $\tau_{\rm reio}$ could also relieve other anomalies including: the
tension between BAO and CMB data, the neutrino mass tension, and the latest
DESI plus supernovae data's tension with the standard cosmological constant
scenario. In this paper, we systematically analyze the correlations between
$\tau_{\rm reio}$ and relevant cosmological parameters in the existing cosmic
observation anomalies. In addition to Pearson correlation coefficients
extracted directly from the covariance matrix, we also study partial
correlation coefficients which measure intrinsic relationships between pairs of
parameters removing the influence of other parameters. We show that $\tau_{\rm
reio}$ has weak intrinsic correlations with the parameters responsible for the
tensions and anomalies discussed. The large direct Pearson correlations that
allow larger $\tau_{\rm reio}$ inferences to alleviate the cosmological
tensions each arise from complicated networks through multiple parameters. As a
result, the relationships between $\tau_{\rm reio}$ and each anomaly are not
independent of each other. We also employ our method of computing correlations
to clarify the impact of large scale polarization data, and comment also on the
effects of CMB observations from ACT and SPT.
</summary>
    <author>
      <name>Itamar J. Allali</name>
    </author>
    <author>
      <name>Lingfeng Li</name>
    </author>
    <author>
      <name>Praniti Singh</name>
    </author>
    <author>
      <name>JiJi Fan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 12 figures, 4 tables, plus appendices</arxiv:comment>
    <link href="http://arxiv.org/abs/2509.09678v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.09678v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.09673v1</id>
    <updated>2025-09-11T17:59:12Z</updated>
    <published>2025-09-11T17:59:12Z</published>
    <title>Cosmology inference with perturbative forward modeling at the field
  level: a comparison with joint power spectrum and bispectrum analyses</title>
    <summary>  We extend field-level inference to jointly constrain the cosmological
parameters $\{A,\omega_{\rm cdm},H_0\}$, in both real and redshift space. Our
analyses are based on mock data generated using a perturbative forward model,
with noise drawn from a Gaussian distribution with a constant power spectrum.
This idealized setting, where the field-level likelihood is exactly Gaussian,
allows us to precisely quantify the information content in the nonlinear field
on large scales. We find that field-level inference accurately recovers all
cosmological parameters in both real and redshift space, with uncertainties
consistent with perturbation theory expectations. We show that these error bars
are comparable to those obtained from a joint power spectrum and bispectrum
analysis using the same perturbative model. Finally, we perform several tests
using the Gaussian field-level likelihood to fit the mock data where the true
noise model is non-Gaussian, and find significant biases in the inferred
cosmological parameters. These results highlight that the success of
field-level inference critically depends on using the correct likelihood, which
may be the primary challenge for applying this method to smaller scales even in
the perturbative regime.
</summary>
    <author>
      <name>Kazuyuki Akitsu</name>
    </author>
    <author>
      <name>Marko Simonović</name>
    </author>
    <author>
      <name>Shi-Fan Chen</name>
    </author>
    <author>
      <name>Giovanni Cabass</name>
    </author>
    <author>
      <name>Matias Zaldarriaga</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">50 pages, 27 figues, the code available at
  https://github.com/kazakitsu/field-level-inference</arxiv:comment>
    <link href="http://arxiv.org/abs/2509.09673v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.09673v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.09665v1</id>
    <updated>2025-09-11T17:57:56Z</updated>
    <published>2025-09-11T17:57:56Z</published>
    <title>1.8 per cent measurement of $H_0$ from Cepheids alone</title>
    <summary>  One of the most pressing problems in current cosmology is the cause of the
Hubble tension. We revisit a two-rung distance ladder, composed only of Cepheid
periods and magnitudes, anchor distances in the Milky Way, Large Magellanic
Cloud, NGC 4258, and host galaxy redshifts. We adopt the SH0ES data for the
most up-to-date and carefully vetted measurements, where the Cepheid hosts were
selected to harbour also Type Ia supernovae. We introduce two important
improvements: a rigorous selection modelling and a state-of-the-art density and
peculiar velocity model using Manticore-Local, based on the Bayesian Origin
Reconstruction from Galaxies (BORG) algorithm. We infer $H_0 = 71.7 \pm
1.3\,\mathrm{km}\,\mathrm{s}^{-1}\,\mathrm{Mpc}^{-1}$, assuming the Cepheid
host sample was selected by estimated supernova magnitudes. Less plausible
selection criteria shift $H_0$ by about one standard deviation. The posterior
has a lower central value and a 45 per cent smaller error than a previous study
using the same data. The result is also slightly lower than the supernova-based
SH0ES inferred value of $H_0 = 73.2 \pm
0.9\,\mathrm{km}\,\mathrm{s}^{-1}\,\mathrm{Mpc}^{-1}$, and is in $3.3\sigma$
tension with the latest standard cosmological model microwave background
results. These results demonstrate that a measurement of $H_0$ of sufficient
precision to weigh in on the Hubble tension is achievable using second-rung
data alone, underscoring the importance of robust and accurate statistical
modelling.
</summary>
    <author>
      <name>Richard Stiskalek</name>
    </author>
    <author>
      <name>Harry Desmond</name>
    </author>
    <author>
      <name>Eleni Tsaprazi</name>
    </author>
    <author>
      <name>Alan Heavens</name>
    </author>
    <author>
      <name>Guilhem Lavaux</name>
    </author>
    <author>
      <name>Stuart McAlpine</name>
    </author>
    <author>
      <name>Jens Jasche</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">24 pages, 12 figures. To be submitted to MNRAS. Comments are welcome</arxiv:comment>
    <link href="http://arxiv.org/abs/2509.09665v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.09665v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.09660v1</id>
    <updated>2025-09-11T17:55:09Z</updated>
    <published>2025-09-11T17:55:09Z</published>
    <title>Steering MoE LLMs via Expert (De)Activation</title>
    <summary>  Mixture-of-Experts (MoE) in Large Language Models (LLMs) routes each token
through a subset of specialized Feed-Forward Networks (FFN), known as experts.
We present SteerMoE, a framework for steering MoE models by detecting and
controlling behavior-linked experts. Our detection method identifies experts
with distinct activation patterns across paired inputs exhibiting contrasting
behaviors. By selectively (de)activating such experts during inference, we
control behaviors like faithfulness and safety without retraining or modifying
weights. Across 11 benchmarks and 6 LLMs, our steering raises safety by up to
+20% and faithfulness by +27%. In adversarial attack mode, it drops safety by
-41% alone, and -100% when combined with existing jailbreak methods, bypassing
all safety guardrails and exposing a new dimension of alignment faking hidden
within experts.
</summary>
    <author>
      <name>Mohsen Fayyaz</name>
    </author>
    <author>
      <name>Ali Modarressi</name>
    </author>
    <author>
      <name>Hanieh Deilamsalehy</name>
    </author>
    <author>
      <name>Franck Dernoncourt</name>
    </author>
    <author>
      <name>Ryan Rossi</name>
    </author>
    <author>
      <name>Trung Bui</name>
    </author>
    <author>
      <name>Hinrich Schütze</name>
    </author>
    <author>
      <name>Nanyun Peng</name>
    </author>
    <link href="http://arxiv.org/abs/2509.09660v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.09660v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.09650v1</id>
    <updated>2025-09-11T17:41:29Z</updated>
    <published>2025-09-11T17:41:29Z</published>
    <title>All for One: LLMs Solve Mental Math at the Last Token With Information
  Transferred From Other Tokens</title>
    <summary>  Large language models (LLMs) demonstrate proficiency across numerous
computational tasks, yet their inner workings remain unclear. In theory, the
combination of causal self-attention and multilayer perceptron layers allows
every token to access and compute information based on all preceding tokens. In
practice, to what extent are such operations present? In this paper, on mental
math tasks (i.e., direct math calculation via next-token prediction without
explicit reasoning), we investigate this question in three steps: inhibiting
input-specific token computations in the initial layers, restricting the routes
of information transfer across token positions in the next few layers, and
forcing all computation to happen at the last token in the remaining layers.
With two proposed techniques, Context-Aware Mean Ablation (CAMA) and
Attention-Based Peeking (ABP), we identify an All-for-One subgraph (AF1) with
high accuracy on a wide variety of mental math tasks, where meaningful
computation occurs very late (in terms of layer depth) and only at the last
token, which receives information of other tokens in few specific middle
layers. Experiments on a variety of models and arithmetic expressions show that
this subgraph is sufficient and necessary for high model performance, transfers
across different models, and works on a variety of input styles. Ablations on
different CAMA and ABP alternatives reveal their unique advantages over other
methods, which may be of independent interest.
</summary>
    <author>
      <name>Siddarth Mamidanna</name>
    </author>
    <author>
      <name>Daking Rai</name>
    </author>
    <author>
      <name>Ziyu Yao</name>
    </author>
    <author>
      <name>Yilun Zhou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP 2025 Main Conference</arxiv:comment>
    <link href="http://arxiv.org/abs/2509.09650v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.09650v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.09647v1</id>
    <updated>2025-09-11T17:37:40Z</updated>
    <published>2025-09-11T17:37:40Z</published>
    <title>Reconstructing the origin of black hole mergers using sparse
  astrophysical models</title>
    <summary>  The astrophysical origin of binary black hole mergers discovered by LIGO and
Virgo remains uncertain. Efforts to reconstruct the processes that lead to
mergers typically rely on either astrophysical models with fixed parameters, or
continuous analytical models that can be fit to observations. Given the
complexity of astrophysical formation mechanisms, these methods typically
cannot fully take into account model uncertainties, nor can they fully capture
the underlying processes. Here, we present a merger population analysis that
can take a discrete set of simulated model distributions as its input to
interpret observations. The analysis can take into account multiple formation
scenarios as fractional contributors to the total set of observations, and can
naturally account for model uncertainties. We apply this technique to
investigate the origin of black hole mergers observed by LIGO Virgo.
Specifically, we consider a model of AGN assisted black hole merger
distributions, exploring a range of AGN parameters along with several {{SEVN}}
population synthesis models that vary in common envelope efficiency parameter
($\alpha$) and metallicity ($Z$). We estimate the posterior distributions for
AGN+SEVN models using $87$ BBH detections from the $O1--O3$ observation runs.
The inferred total merger rate is $46.2 {Gpc}^{-3} {yr}^{-1}$, with the AGN
sub-population contributing $21.2{Gpc}^{-3}{yr}^{-1}$ and the SEVN
sub-population contributing $25.0 {Gpc}^{-3} {yr}^{-1}$.
</summary>
    <author>
      <name>V. Gayathri</name>
    </author>
    <author>
      <name>Giuliano Iorio</name>
    </author>
    <author>
      <name>Hiromichi Tagawa</name>
    </author>
    <author>
      <name>Daniel Wysocki</name>
    </author>
    <author>
      <name>Jeremiah Anglin</name>
    </author>
    <author>
      <name>Imre Bartos</name>
    </author>
    <author>
      <name>Shubhagata Bhaumik</name>
    </author>
    <author>
      <name>Zolt'an Haiman</name>
    </author>
    <author>
      <name>Michela Mapelli</name>
    </author>
    <author>
      <name>R. O'Shaughnessy</name>
    </author>
    <author>
      <name>LingQin Xue</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2509.09647v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.09647v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.HE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.HE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="gr-qc" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.09645v1</id>
    <updated>2025-09-11T17:35:32Z</updated>
    <published>2025-09-11T17:35:32Z</published>
    <title>Explaining the Reputational Risks of AI-Mediated Communication: Messages
  Labeled as AI-Assisted Are Viewed as Less Diagnostic of the Sender's Moral
  Character</title>
    <summary>  When someone sends us a thoughtful message, we naturally form judgments about
their character. But what happens when that message carries a label indicating
it was written with the help of AI? This paper investigates how the appearance
of AI assistance affects our perceptions of message senders. Adding nuance to
previous research, through two studies (N=399) featuring vignette scenarios, we
find that AI-assistance labels don't necessarily make people view senders
negatively. Rather, they dampen the strength of character signals in
communication. We show that when someone sends a warmth-signalling message
(like thanking or apologizing) without AI help, people more strongly categorize
the sender as warm. At the same time, when someone sends a coldness-signalling
message (like bragging or blaming) without assistance, people more confidently
categorize them as cold. Interestingly, AI labels weaken both these
associations: An AI-assisted apology makes the sender appear less warm than if
they had written it themselves, and an AI-assisted blame makes the sender
appear less cold than if they had composed it independently. This supports our
signal diagnosticity explanation: messages labeled as AI-assisted are viewed as
less diagnostic than messages which seem unassisted. We discuss how our
findings shed light on the causal origins of previously reported observations
in AI-Mediated Communication.
</summary>
    <author>
      <name>Pranav Khadpe</name>
    </author>
    <author>
      <name>Kimi Wenzel</name>
    </author>
    <author>
      <name>George Loewenstein</name>
    </author>
    <author>
      <name>Geoff Kaufman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear at AIES 2025</arxiv:comment>
    <link href="http://arxiv.org/abs/2509.09645v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.09645v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.ET" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.09631v1</id>
    <updated>2025-09-11T17:16:52Z</updated>
    <published>2025-09-11T17:16:52Z</published>
    <title>DiFlow-TTS: Discrete Flow Matching with Factorized Speech Tokens for
  Low-Latency Zero-Shot Text-To-Speech</title>
    <summary>  Zero-shot Text-to-Speech (TTS) aims to synthesize high-quality speech that
mimics the voice of an unseen speaker using only a short reference sample,
requiring not only speaker adaptation but also accurate modeling of prosodic
attributes. Recent approaches based on language models, diffusion, and flow
matching have shown promising results in zero-shot TTS, but still suffer from
slow inference and repetition artifacts. Discrete codec representations have
been widely adopted for speech synthesis, and recent works have begun to
explore diffusion models in purely discrete settings, suggesting the potential
of discrete generative modeling for speech synthesis. However, existing
flow-matching methods typically embed these discrete tokens into a continuous
space and apply continuous flow matching, which may not fully leverage the
advantages of discrete representations. To address these challenges, we
introduce DiFlow-TTS, which, to the best of our knowledge, is the first model
to explore purely Discrete Flow Matching for speech synthesis. DiFlow-TTS
explicitly models factorized speech attributes within a compact and unified
architecture. It leverages in-context learning by conditioning on textual
content, along with prosodic and acoustic attributes extracted from a reference
speech, enabling effective attribute cloning in a zero-shot setting. In
addition, the model employs a factorized flow prediction mechanism with
distinct heads for prosody and acoustic details, allowing it to learn
aspect-specific distributions. Experimental results demonstrate that DiFlow-TTS
achieves promising performance in several key metrics, including naturalness,
prosody, preservation of speaker style, and energy control. It also maintains a
compact model size and achieves low-latency inference, generating speech up to
25.8 times faster than the latest existing baselines.
</summary>
    <author>
      <name>Ngoc-Son Nguyen</name>
    </author>
    <author>
      <name>Hieu-Nghia Huynh-Nguyen</name>
    </author>
    <author>
      <name>Thanh V. T. Tran</name>
    </author>
    <author>
      <name>Truong-Son Hy</name>
    </author>
    <author>
      <name>Van Nguyen</name>
    </author>
    <link href="http://arxiv.org/abs/2509.09631v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.09631v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.09605v1</id>
    <updated>2025-09-11T16:45:07Z</updated>
    <published>2025-09-11T16:45:07Z</published>
    <title>Multiwavelength observations of a new black-widow millisecond pulsar PSR
  J1544-2555</title>
    <summary>  We report the discovery of a new black-widow millisecond pulsar, PSR
J1544-2555, associated with the Fermi-LAT source 4FGL J1544.2-2554. Optical,
radio, and gamma-ray observations confirmed its nature as a compact spider
binary system. Optical photometry from ULTRACAM revealed a \(\sim\)2.7-hour
orbital period, guiding MeerKAT observations that detected \(\sim\)2.4-ms radio
pulsations. Subsequent timing campaigns using the Murriyang Parkes Telescope,
the Effelsberg 100-m Radio Telescope, and the Nan\c{c}ay Radio Telescope
allowed us to obtain a preliminary timing solution, which enabled us to find
gamma-ray pulsations. The final timing solution, spanning 16 years of Fermi-LAT
gamma-ray data, also displays orbital period variations typical of spider
pulsars. X-ray observations from eROSITA indicate non-thermal emission, but the
relatively low count rate prohibits the search for X-ray pulsations. Optical
light curve modelling using Icarus suggests the asymmetry is best explained by
a spot model, where uneven heating creates localised temperature variations on
the companion. While the optical spectra we obtained are compatible with the
physical properties we infer for the companion star, they were not of
sufficient signal-to-noise to allow for radial velocity measurements, thus
limiting constraints on the neutron star's mass. The observed bluer colour near
the light curve minimum suggests possible non-thermal emission from
intra-binary shocks, supported by the presence of an X-ray source. This
discovery exemplifies the proven capability of the Fermi-LAT catalogue in
identifying millisecond pulsar candidates and highlights the role of optical
surveys in detecting variable sources suitable for radio follow-up.
</summary>
    <author>
      <name>Sergio Belmonte Diaz</name>
    </author>
    <author>
      <name>Tinn Thingmeearkom</name>
    </author>
    <author>
      <name>Adipol Phosrisom</name>
    </author>
    <author>
      <name>Rene Breton</name>
    </author>
    <author>
      <name>Marta Burgay</name>
    </author>
    <author>
      <name>Colin Clark</name>
    </author>
    <author>
      <name>Lars Nieder</name>
    </author>
    <author>
      <name>Martin Mayer</name>
    </author>
    <author>
      <name>Werner Becker</name>
    </author>
    <author>
      <name>Ewann Barr</name>
    </author>
    <author>
      <name>Sarah Buchner</name>
    </author>
    <author>
      <name>Kaustav Kashyap Das</name>
    </author>
    <author>
      <name>Vik Dhillon</name>
    </author>
    <author>
      <name>Oliver Dodge</name>
    </author>
    <author>
      <name>Elizabeth Ferrara</name>
    </author>
    <author>
      <name>Jean-Mathias Griessmeier</name>
    </author>
    <author>
      <name>Ramesh Karuppusamy</name>
    </author>
    <author>
      <name>Mark Kennedy</name>
    </author>
    <author>
      <name>Michael Kramer</name>
    </author>
    <author>
      <name>Prajwal Padmanabh</name>
    </author>
    <author>
      <name>John Paice</name>
    </author>
    <author>
      <name>Antonio Rodriguez</name>
    </author>
    <author>
      <name>Ben Stappers</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication in Monthly Notices of the Royal Astronomical
  Society. 16 pages. 11 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2509.09605v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.09605v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.HE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.HE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.SR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.09585v1</id>
    <updated>2025-09-11T16:22:20Z</updated>
    <published>2025-09-11T16:22:20Z</published>
    <title>Causal PDE-Control Models: A Structural Framework for Dynamic Portfolio
  Optimization</title>
    <summary>  Classical portfolio models collapse under structural breaks, while modern
machine-learning allocators adapt flexibly but often at the cost of
transparency and interpretability. This paper introduces Causal PDE-Control
Models (CPCMs), a unifying framework that integrates causal inference,
nonlinear filtering, and forward-backward partial differential equations for
dynamic portfolio optimization. The framework delivers three theoretical
advances: (i) the existence of conditional risk-neutral measures under evolving
information sets; (ii) a projection-divergence duality that quantifies the
stability cost of departing from the causal driver manifold; and (iii) causal
completeness, establishing that a finite driver span can capture all systematic
premia. Classical methods such as Markowitz, CAPM, and Black-Litterman appear
as degenerate cases, while reinforcement learning and deep-hedging policies
emerge as unconstrained, symmetry-breaking approximations. Empirically, CPCM
solvers implemented with physics-informed neural networks achieve higher Sharpe
ratios, lower turnover, and more persistent premia than both econometric and
machine-learning benchmarks, using a global equity panel with more than 300
candidate drivers. By reframing portfolio optimization around structural
causality and PDE control, CPCMs provide a rigorous, interpretable, and
computationally tractable foundation for robust asset allocation under
nonstationary conditions.
</summary>
    <author>
      <name>Alejandro Rodriguez Dominguez</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">54 pages, 14 pages, 14 figures. Code and data available from authors
  upon request</arxiv:comment>
    <link href="http://arxiv.org/abs/2509.09585v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.09585v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.6; G.1.8; G.1.10; G.3; I.2.6; I.5.3; I.5.4; I.6.5; J.2; J.4; J.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
