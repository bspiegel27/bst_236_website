<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-05-21T00:57:04Z -->
<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acausal%20inference%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:causal inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/SsRksLzRb0LuVhSmQ+N8WbAs+f8</id>
  <updated>2025-05-20T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">112567</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">10</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2505.13436v1</id>
    <updated>2025-05-19T17:58:03Z</updated>
    <published>2025-05-19T17:58:03Z</published>
    <title>KinTwin: Imitation Learning with Torque and Muscle Driven Biomechanical
  Models Enables Precise Replication of Able-Bodied and Impaired Movement from
  Markerless Motion Capture</title>
    <summary>  Broader access to high-quality movement analysis could greatly benefit
movement science and rehabilitation, such as allowing more detailed
characterization of movement impairments and responses to interventions, or
even enabling early detection of new neurological conditions or fall risk.
While emerging technologies are making it easier to capture kinematics with
biomechanical models, or how joint angles change over time, inferring the
underlying physics that give rise to these movements, including ground reaction
forces, joint torques, or even muscle activations, is still challenging. Here
we explore whether imitation learning applied to a biomechanical model from a
large dataset of movements from able-bodied and impaired individuals can learn
to compute these inverse dynamics. Although imitation learning in human pose
estimation has seen great interest in recent years, our work differences in
several ways: we focus on using an accurate biomechanical model instead of
models adopted for computer vision, we test it on a dataset that contains
participants with impaired movements, we reported detailed tracking metrics
relevant for the clinical measurement of movement including joint angles and
ground contact events, and finally we apply imitation learning to a
muscle-driven neuromusculoskeletal model. We show that our imitation learning
policy, KinTwin, can accurately replicate the kinematics of a wide range of
movements, including those with assistive devices or therapist assistance, and
that it can infer clinically meaningful differences in joint torques and muscle
activations. Our work demonstrates the potential for using imitation learning
to enable high-quality movement analysis in clinical practice.
</summary>
    <author>
      <name>R. James Cotton</name>
    </author>
    <link href="http://arxiv.org/abs/2505.13436v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2505.13436v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2505.13432v1</id>
    <updated>2025-05-19T17:55:56Z</updated>
    <published>2025-05-19T17:55:56Z</published>
    <title>Synthetic-Powered Predictive Inference</title>
    <summary>  Conformal prediction is a framework for predictive inference with a
distribution-free, finite-sample guarantee. However, it tends to provide
uninformative prediction sets when calibration data are scarce. This paper
introduces Synthetic-powered predictive inference (SPPI), a novel framework
that incorporates synthetic data -- e.g., from a generative model -- to improve
sample efficiency. At the core of our method is a score transporter: an
empirical quantile mapping that aligns nonconformity scores from trusted, real
data with those from synthetic data. By carefully integrating the score
transporter into the calibration process, SPPI provably achieves finite-sample
coverage guarantees without making any assumptions about the real and synthetic
data distributions. When the score distributions are well aligned, SPPI yields
substantially tighter and more informative prediction sets than standard
conformal prediction. Experiments on image classification and tabular
regression demonstrate notable improvements in predictive efficiency in
data-scarce settings.
</summary>
    <author>
      <name>Meshi Bashari</name>
    </author>
    <author>
      <name>Roy Maor Lotan</name>
    </author>
    <author>
      <name>Yonghoon Lee</name>
    </author>
    <author>
      <name>Edgar Dobriban</name>
    </author>
    <author>
      <name>Yaniv Romano</name>
    </author>
    <link href="http://arxiv.org/abs/2505.13432v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2505.13432v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2505.13427v1</id>
    <updated>2025-05-19T17:55:08Z</updated>
    <published>2025-05-19T17:55:08Z</published>
    <title>MM-PRM: Enhancing Multimodal Mathematical Reasoning with Scalable
  Step-Level Supervision</title>
    <summary>  While Multimodal Large Language Models (MLLMs) have achieved impressive
progress in vision-language understanding, they still struggle with complex
multi-step reasoning, often producing logically inconsistent or partially
correct solutions. A key limitation lies in the lack of fine-grained
supervision over intermediate reasoning steps. To address this, we propose
MM-PRM, a process reward model trained within a fully automated, scalable
framework. We first build MM-Policy, a strong multimodal model trained on
diverse mathematical reasoning data. Then, we construct MM-K12, a curated
dataset of 10,000 multimodal math problems with verifiable answers, which
serves as seed data. Leveraging a Monte Carlo Tree Search (MCTS)-based
pipeline, we generate over 700k step-level annotations without human labeling.
The resulting PRM is used to score candidate reasoning paths in the Best-of-N
inference setup and achieves significant improvements across both in-domain
(MM-K12 test set) and out-of-domain (OlympiadBench, MathVista, etc.)
benchmarks. Further analysis confirms the effectiveness of soft labels, smaller
learning rates, and path diversity in optimizing PRM performance. MM-PRM
demonstrates that process supervision is a powerful tool for enhancing the
logical robustness of multimodal reasoning systems. We release all our codes
and data at https://github.com/ModalMinds/MM-PRM.
</summary>
    <author>
      <name>Lingxiao Du</name>
    </author>
    <author>
      <name>Fanqing Meng</name>
    </author>
    <author>
      <name>Zongkai Liu</name>
    </author>
    <author>
      <name>Zhixiang Zhou</name>
    </author>
    <author>
      <name>Ping Luo</name>
    </author>
    <author>
      <name>Qiaosheng Zhang</name>
    </author>
    <author>
      <name>Wenqi Shao</name>
    </author>
    <link href="http://arxiv.org/abs/2505.13427v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2505.13427v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2505.13425v1</id>
    <updated>2025-05-19T17:54:35Z</updated>
    <published>2025-05-19T17:54:35Z</published>
    <title>Learnware of Language Models: Specialized Small Language Models Can Do
  Big</title>
    <summary>  The learnware paradigm offers a novel approach to machine learning by
enabling users to reuse a set of well-trained models for tasks beyond the
models' original purposes. It eliminates the need to build models from scratch,
instead relying on specifications (representations of a model's capabilities)
to identify and leverage the most suitable models for new tasks. While
learnware has proven effective in many scenarios, its application to language
models has remained largely unexplored. At the same time, large language models
(LLMs) have demonstrated remarkable universal question-answering abilities, yet
they face challenges in specialized scenarios due to data scarcity, privacy
concerns, and high computational costs, thus more and more specialized small
language models (SLMs) are being trained for specific domains. To address these
limitations systematically, the learnware paradigm provides a promising
solution by enabling maximum utilization of specialized SLMs, and allowing
users to identify and reuse them in a collaborative and privacy-preserving
manner.
  This paper presents a preliminary attempt to apply the learnware paradigm to
language models. We simulated a learnware system comprising approximately 100
learnwares of specialized SLMs with 8B parameters, fine-tuned across finance,
healthcare, and mathematics domains. Each learnware contains an SLM and a
specification, which enables users to identify the most relevant models without
exposing their own data. Experimental results demonstrate promising
performance: by selecting one suitable learnware for each task-specific
inference, the system outperforms the base SLMs on all benchmarks. Compared to
LLMs, the system outperforms Qwen1.5-110B, Qwen2.5-72B, and
Llama3.1-70B-Instruct by at least 14% in finance domain tasks, and surpasses
Flan-PaLM-540B (ranked 7th on the Open Medical LLM Leaderboard) in medical
domain tasks.
</summary>
    <author>
      <name>Zhi-Hao Tan</name>
    </author>
    <author>
      <name>Zi-Chen Zhao</name>
    </author>
    <author>
      <name>Hao-Yu Shi</name>
    </author>
    <author>
      <name>Xin-Yu Zhang</name>
    </author>
    <author>
      <name>Peng Tan</name>
    </author>
    <author>
      <name>Yang Yu</name>
    </author>
    <author>
      <name>Zhi-Hua Zhou</name>
    </author>
    <link href="http://arxiv.org/abs/2505.13425v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2505.13425v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2505.13422v1</id>
    <updated>2025-05-19T17:53:15Z</updated>
    <published>2025-05-19T17:53:15Z</published>
    <title>Machine learning the first stage in 2SLS: Practical guidance from bias
  decomposition and simulation</title>
    <summary>  Machine learning (ML) primarily evolved to solve "prediction problems." The
first stage of two-stage least squares (2SLS) is a prediction problem,
suggesting potential gains from ML first-stage assistance. However, little
guidance exists on when ML helps 2SLS$\unicode{x2014}$or when it hurts. We
investigate the implications of inserting ML into 2SLS, decomposing the bias
into three informative components. Mechanically, ML-in-2SLS procedures face
issues common to prediction and causal-inference settings$\unicode{x2014}$and
their interaction. Through simulation, we show linear ML methods (e.g.,
post-Lasso) work well, while nonlinear methods (e.g., random forests, neural
nets) generate substantial bias in second-stage
estimates$\unicode{x2014}$potentially exceeding the bias of endogenous OLS.
</summary>
    <author>
      <name>Connor Lennon</name>
    </author>
    <author>
      <name>Edward Rubin</name>
    </author>
    <author>
      <name>Glen Waddell</name>
    </author>
    <link href="http://arxiv.org/abs/2505.13422v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2505.13422v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="econ.EM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="econ.EM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2505.13419v1</id>
    <updated>2025-05-19T17:52:15Z</updated>
    <published>2025-05-19T17:52:15Z</published>
    <title>FEALLM: Advancing Facial Emotion Analysis in Multimodal Large Language
  Models with Emotional Synergy and Reasoning</title>
    <summary>  Facial Emotion Analysis (FEA) plays a crucial role in visual affective
computing, aiming to infer a person's emotional state based on facial data.
Scientifically, facial expressions (FEs) result from the coordinated movement
of facial muscles, which can be decomposed into specific action units (AUs)
that provide detailed emotional insights. However, traditional methods often
struggle with limited interpretability, constrained generalization and
reasoning abilities. Recently, Multimodal Large Language Models (MLLMs) have
shown exceptional performance in various visual tasks, while they still face
significant challenges in FEA due to the lack of specialized datasets and their
inability to capture the intricate relationships between FEs and AUs. To
address these issues, we introduce a novel FEA Instruction Dataset that
provides accurate and aligned FE and AU descriptions and establishes causal
reasoning relationships between them, followed by constructing a new benchmark,
FEABench. Moreover, we propose FEALLM, a novel MLLM architecture designed to
capture more detailed facial information, enhancing its capability in FEA
tasks. Our model demonstrates strong performance on FEABench and impressive
generalization capability through zero-shot evaluation on various datasets,
including RAF-DB, AffectNet, BP4D, and DISFA, showcasing its robustness and
effectiveness in FEA tasks. The dataset and code will be available at
https://github.com/953206211/FEALLM.
</summary>
    <author>
      <name>Zhuozhao Hu</name>
    </author>
    <author>
      <name>Kaishen Yuan</name>
    </author>
    <author>
      <name>Xin Liu</name>
    </author>
    <author>
      <name>Zitong Yu</name>
    </author>
    <author>
      <name>Yuan Zong</name>
    </author>
    <author>
      <name>Jingang Shi</name>
    </author>
    <author>
      <name>Huanjing Yue</name>
    </author>
    <author>
      <name>Jingyu Yang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2505.13419v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2505.13419v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2505.13417v1</id>
    <updated>2025-05-19T17:50:52Z</updated>
    <published>2025-05-19T17:50:52Z</published>
    <title>AdaptThink: Reasoning Models Can Learn When to Think</title>
    <summary>  Recently, large reasoning models have achieved impressive performance on
various tasks by employing human-like deep thinking. However, the lengthy
thinking process substantially increases inference overhead, making efficiency
a critical bottleneck. In this work, we first demonstrate that NoThinking,
which prompts the reasoning model to skip thinking and directly generate the
final solution, is a better choice for relatively simple tasks in terms of both
performance and efficiency. Motivated by this, we propose AdaptThink, a novel
RL algorithm to teach reasoning models to choose the optimal thinking mode
adaptively based on problem difficulty. Specifically, AdaptThink features two
core components: (1) a constrained optimization objective that encourages the
model to choose NoThinking while maintaining the overall performance; (2) an
importance sampling strategy that balances Thinking and NoThinking samples
during on-policy training, thereby enabling cold start and allowing the model
to explore and exploit both thinking modes throughout the training process. Our
experiments indicate that AdaptThink significantly reduces the inference costs
while further enhancing performance. Notably, on three math datasets,
AdaptThink reduces the average response length of DeepSeek-R1-Distill-Qwen-1.5B
by 53% and improves its accuracy by 2.4%, highlighting the promise of adaptive
thinking-mode selection for optimizing the balance between reasoning quality
and efficiency. Our codes and models are available at
https://github.com/THU-KEG/AdaptThink.
</summary>
    <author>
      <name>Jiajie Zhang</name>
    </author>
    <author>
      <name>Nianyi Lin</name>
    </author>
    <author>
      <name>Lei Hou</name>
    </author>
    <author>
      <name>Ling Feng</name>
    </author>
    <author>
      <name>Juanzi Li</name>
    </author>
    <link href="http://arxiv.org/abs/2505.13417v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2505.13417v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2505.13408v1</id>
    <updated>2025-05-19T17:44:26Z</updated>
    <published>2025-05-19T17:44:26Z</published>
    <title>CoT-Kinetics: A Theoretical Modeling Assessing LRM Reasoning Process</title>
    <summary>  Recent Large Reasoning Models significantly improve the reasoning ability of
Large Language Models by learning to reason, exhibiting the promising
performance in solving complex tasks. LRMs solve tasks that require complex
reasoning by explicitly generating reasoning trajectories together with
answers. Nevertheless, judging the quality of such an output answer is not easy
because only considering the correctness of the answer is not enough and the
soundness of the reasoning trajectory part matters as well. Logically, if the
soundness of the reasoning part is poor, even if the answer is correct, the
confidence of the derived answer should be low. Existing methods did consider
jointly assessing the overall output answer by taking into account the
reasoning part, however, their capability is still not satisfactory as the
causal relationship of the reasoning to the concluded answer cannot properly
reflected. In this paper, inspired by classical mechanics, we present a novel
approach towards establishing a CoT-Kinetics energy equation. Specifically, our
CoT-Kinetics energy equation formulates the token state transformation process,
which is regulated by LRM internal transformer layers, as like a particle
kinetics dynamics governed in a mechanical field. Our CoT-Kinetics energy
assigns a scalar score to evaluate specifically the soundness of the reasoning
phase, telling how confident the derived answer could be given the evaluated
reasoning. As such, the LRM's overall output quality can be accurately
measured, rather than a coarse judgment (e.g., correct or incorrect) anymore.
</summary>
    <author>
      <name>Jinhe Bi</name>
    </author>
    <author>
      <name>Danqi Yan</name>
    </author>
    <author>
      <name>Yifan Wang</name>
    </author>
    <author>
      <name>Wenke Huang</name>
    </author>
    <author>
      <name>Haokun Chen</name>
    </author>
    <author>
      <name>Guancheng Wan</name>
    </author>
    <author>
      <name>Mang Ye</name>
    </author>
    <author>
      <name>Xun Xiao</name>
    </author>
    <author>
      <name>Hinrich Schuetze</name>
    </author>
    <author>
      <name>Volker Tresp</name>
    </author>
    <author>
      <name>Yunpu Ma</name>
    </author>
    <link href="http://arxiv.org/abs/2505.13408v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2505.13408v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2505.13404v1</id>
    <updated>2025-05-19T17:40:58Z</updated>
    <published>2025-05-19T17:40:58Z</published>
    <title>Granary: Speech Recognition and Translation Dataset in 25 European
  Languages</title>
    <summary>  Multi-task and multilingual approaches benefit large models, yet speech
processing for low-resource languages remains underexplored due to data
scarcity. To address this, we present Granary, a large-scale collection of
speech datasets for recognition and translation across 25 European languages.
This is the first open-source effort at this scale for both transcription and
translation. We enhance data quality using a pseudo-labeling pipeline with
segmentation, two-pass inference, hallucination filtering, and punctuation
restoration. We further generate translation pairs from pseudo-labeled
transcriptions using EuroLLM, followed by a data filtration pipeline. Designed
for efficiency, our pipeline processes vast amount of data within hours. We
assess models trained on processed data by comparing their performance on
previously curated datasets for both high- and low-resource languages. Our
findings show that these models achieve similar performance using approx. 50%
less data. Dataset will be made available at
https://hf.co/datasets/nvidia/Granary
</summary>
    <author>
      <name>Nithin Rao Koluguri</name>
    </author>
    <author>
      <name>Monica Sekoyan</name>
    </author>
    <author>
      <name>George Zelenfroynd</name>
    </author>
    <author>
      <name>Sasha Meister</name>
    </author>
    <author>
      <name>Shuoyang Ding</name>
    </author>
    <author>
      <name>Sofia Kostandian</name>
    </author>
    <author>
      <name>He Huang</name>
    </author>
    <author>
      <name>Nikolay Karpov</name>
    </author>
    <author>
      <name>Jagadeesh Balam</name>
    </author>
    <author>
      <name>Vitaly Lavrukhin</name>
    </author>
    <author>
      <name>Yifan Peng</name>
    </author>
    <author>
      <name>Sara Papi</name>
    </author>
    <author>
      <name>Marco Gaido</name>
    </author>
    <author>
      <name>Alessio Brutti</name>
    </author>
    <author>
      <name>Boris Ginsburg</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at Interspeech 2025</arxiv:comment>
    <link href="http://arxiv.org/abs/2505.13404v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2505.13404v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2505.13403v1</id>
    <updated>2025-05-19T17:37:39Z</updated>
    <published>2025-05-19T17:37:39Z</published>
    <title>MR. Judge: Multimodal Reasoner as a Judge</title>
    <summary>  The paradigm of using Large Language Models (LLMs) and Multimodal Large
Language Models (MLLMs) as evaluative judges has emerged as an effective
approach in RLHF and inference-time scaling. In this work, we propose
Multimodal Reasoner as a Judge (MR. Judge), a paradigm for empowering
general-purpose MLLMs judges with strong reasoning capabilities. Instead of
directly assigning scores for each response, we formulate the judgement process
as a reasoning-inspired multiple-choice problem. Specifically, the judge model
first conducts deliberate reasoning covering different aspects of the responses
and eventually selects the best response from them. This reasoning process not
only improves the interpretibility of the judgement, but also greatly enhances
the performance of MLLM judges. To cope with the lack of questions with scored
responses, we propose the following strategy to achieve automatic annotation:
1) Reverse Response Candidates Synthesis: starting from a supervised
fine-tuning (SFT) dataset, we treat the original response as the best candidate
and prompt the MLLM to generate plausible but flawed negative candidates. 2)
Text-based reasoning extraction: we carefully design a data synthesis pipeline
for distilling the reasoning capability from a text-based reasoning model,
which is adopted to enable the MLLM judges to regain complex reasoning ability
via warm up supervised fine-tuning. Experiments demonstrate that our MR. Judge
is effective across a wide range of tasks. Specifically, our MR. Judge-7B
surpasses GPT-4o by 9.9% on VL-RewardBench, and improves performance on MM-Vet
during inference-time scaling by up to 7.7%.
</summary>
    <author>
      <name>Renjie Pi</name>
    </author>
    <author>
      <name>Felix Bai</name>
    </author>
    <author>
      <name>Qibin Chen</name>
    </author>
    <author>
      <name>Simon Wang</name>
    </author>
    <author>
      <name>Jiulong Shan</name>
    </author>
    <author>
      <name>Kieran Liu</name>
    </author>
    <author>
      <name>Meng Cao</name>
    </author>
    <link href="http://arxiv.org/abs/2505.13403v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2505.13403v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
