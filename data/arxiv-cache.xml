<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-04-22T00:54:17Z -->
<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acausal%20inference%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:causal inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/SsRksLzRb0LuVhSmQ+N8WbAs+f8</id>
  <updated>2025-04-21T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">110896</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">10</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2504.13825v1</id>
    <updated>2025-04-18T17:54:33Z</updated>
    <published>2025-04-18T17:54:33Z</published>
    <title>Feature Alignment and Representation Transfer in Knowledge Distillation
  for Large Language Models</title>
    <summary>  Knowledge distillation (KD) is a technique for transferring knowledge from
complex teacher models to simpler student models, significantly enhancing model
efficiency and accuracy. It has demonstrated substantial advancements in
various applications including image classification, object detection, language
modeling, text classification, and sentiment analysis. Recent innovations in KD
methods, such as attention-based approaches, block-wise logit distillation, and
decoupling distillation, have notably improved student model performance. These
techniques focus on stimulus complexity, attention mechanisms, and global
information capture to optimize knowledge transfer. In addition, KD has proven
effective in compressing large language models while preserving accuracy,
reducing computational overhead, and improving inference speed. This survey
synthesizes the latest literature, highlighting key findings, contributions,
and future directions in knowledge distillation to provide insights for
researchers and practitioners on its evolving role in artificial intelligence
and machine learning.
</summary>
    <author>
      <name>Junjie Yang</name>
    </author>
    <author>
      <name>Junhao Song</name>
    </author>
    <author>
      <name>Xudong Han</name>
    </author>
    <author>
      <name>Ziqian Bi</name>
    </author>
    <author>
      <name>Tianyang Wang</name>
    </author>
    <author>
      <name>Chia Xin Liang</name>
    </author>
    <author>
      <name>Xinyuan Song</name>
    </author>
    <author>
      <name>Yichao Zhang</name>
    </author>
    <author>
      <name>Qian Niu</name>
    </author>
    <author>
      <name>Benji Peng</name>
    </author>
    <author>
      <name>Keyu Chen</name>
    </author>
    <author>
      <name>Ming Liu</name>
    </author>
    <link href="http://arxiv.org/abs/2504.13825v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.13825v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.13818v1</id>
    <updated>2025-04-18T17:49:55Z</updated>
    <published>2025-04-18T17:49:55Z</published>
    <title>Not All Rollouts are Useful: Down-Sampling Rollouts in LLM Reinforcement
  Learning</title>
    <summary>  Reinforcement learning (RL) has emerged as a powerful paradigm for enhancing
reasoning capabilities in large language models, but faces a fundamental
asymmetry in computation and memory requirements: inference is embarrassingly
parallel with a minimal memory footprint, while policy updates require
extensive synchronization and are memory-intensive. To address this asymmetry,
we introduce PODS (Policy Optimization with Down-Sampling), a framework that
strategically decouples these phases by generating numerous rollouts in
parallel but updating only on an informative subset. Within this framework, we
develop max-variance down-sampling, a theoretically motivated method that
selects rollouts with maximally diverse reward signals. We prove that this
approach has an efficient algorithmic solution, and empirically demonstrate
that GRPO with PODS using max-variance down-sampling achieves superior
performance over standard GRPO on the GSM8K benchmark.
</summary>
    <author>
      <name>Yixuan Even Xu</name>
    </author>
    <author>
      <name>Yash Savani</name>
    </author>
    <author>
      <name>Fei Fang</name>
    </author>
    <author>
      <name>Zico Kolter</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/2504.13818v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.13818v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.13803v1</id>
    <updated>2025-04-18T17:12:00Z</updated>
    <published>2025-04-18T17:12:00Z</published>
    <title>Imitation Learning with Precisely Labeled Human Demonstrations</title>
    <summary>  Within the imitation learning paradigm, training generalist robots requires
large-scale datasets obtainable only through diverse curation. Due to the
relative ease to collect, human demonstrations constitute a valuable addition
when incorporated appropriately. However, existing methods utilizing human
demonstrations face challenges in inferring precise actions, ameliorating
embodiment gaps, and fusing with frontier generalist robot training pipelines.
In this work, building on prior studies that demonstrate the viability of using
hand-held grippers for efficient data collection, we leverage the user's
control over the gripper's appearance--specifically by assigning it a unique,
easily segmentable color--to enable simple and reliable application of the
RANSAC and ICP registration method for precise end-effector pose estimation. We
show in simulation that precisely labeled human demonstrations on their own
allow policies to reach on average 88.1% of the performance of using robot
demonstrations, and boost policy performance when combined with robot
demonstrations, despite the inherent embodiment gap.
</summary>
    <author>
      <name>Yilong Song</name>
    </author>
    <link href="http://arxiv.org/abs/2504.13803v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.13803v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.13785v1</id>
    <updated>2025-04-18T16:35:12Z</updated>
    <published>2025-04-18T16:35:12Z</published>
    <title>Learning Through Retrospection: Improving Trajectory Prediction for
  Automated Driving with Error Feedback</title>
    <summary>  In automated driving, predicting trajectories of surrounding vehicles
supports reasoning about scene dynamics and enables safe planning for the ego
vehicle. However, existing models handle predictions as an instantaneous task
of forecasting future trajectories based on observed information. As time
proceeds, the next prediction is made independently of the previous one, which
means that the model cannot correct its errors during inference and will repeat
them. To alleviate this problem and better leverage temporal data, we propose a
novel retrospection technique. Through training on closed-loop rollouts the
model learns to use aggregated feedback. Given new observations it reflects on
previous predictions and analyzes its errors to improve the quality of
subsequent predictions. Thus, the model can learn to correct systematic errors
during inference. Comprehensive experiments on nuScenes and Argoverse
demonstrate a considerable decrease in minimum Average Displacement Error of up
to 31.9% compared to the state-of-the-art baseline without retrospection. We
further showcase the robustness of our technique by demonstrating a better
handling of out-of-distribution scenarios with undetected road-users.
</summary>
    <author>
      <name>Steffen Hagedorn</name>
    </author>
    <author>
      <name>Aron Distelzweig</name>
    </author>
    <author>
      <name>Marcel Hallgarten</name>
    </author>
    <author>
      <name>Alexandru P. Condurache</name>
    </author>
    <link href="http://arxiv.org/abs/2504.13785v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.13785v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.13774v1</id>
    <updated>2025-04-18T16:22:20Z</updated>
    <published>2025-04-18T16:22:20Z</published>
    <title>DP2Unlearning: An Efficient and Guaranteed Unlearning Framework for LLMs</title>
    <summary>  Large language models (LLMs) have recently revolutionized language processing
tasks but have also brought ethical and legal issues. LLMs have a tendency to
memorize potentially private or copyrighted information present in the training
data, which might then be delivered to end users at inference time. When this
happens, a naive solution is to retrain the model from scratch after excluding
the undesired data. Although this guarantees that the target data have been
forgotten, it is also prohibitively expensive for LLMs. Approximate unlearning
offers a more efficient alternative, as it consists of ex post modifications of
the trained model itself to prevent undesirable results, but it lacks
forgetting guarantees because it relies solely on empirical evidence. In this
work, we present DP2Unlearning, a novel LLM unlearning framework that offers
formal forgetting guarantees at a significantly lower cost than retraining from
scratch on the data to be retained. DP2Unlearning involves training LLMs on
textual data protected using {\epsilon}-differential privacy (DP), which later
enables efficient unlearning with the guarantees against disclosure associated
with the chosen {\epsilon}. Our experiments demonstrate that DP2Unlearning
achieves similar model performance post-unlearning, compared to an LLM
retraining from scratch on retained data -- the gold standard exact unlearning
-- but at approximately half the unlearning cost. In addition, with a
reasonable computational cost, it outperforms approximate unlearning methods at
both preserving the utility of the model post-unlearning and effectively
forgetting the targeted information.
</summary>
    <author>
      <name>Tamim Al Mahmud</name>
    </author>
    <author>
      <name>Najeeb Jebreel</name>
    </author>
    <author>
      <name>Josep Domingo-Ferrer</name>
    </author>
    <author>
      <name>David Sanchez</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.2139/ssrn.5217160</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.2139/ssrn.5217160" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">49 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2504.13774v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.13774v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.13765v1</id>
    <updated>2025-04-18T16:04:22Z</updated>
    <published>2025-04-18T16:04:22Z</published>
    <title>Modeling L1 Influence on L2 Pronunciation: An MFCC-Based Framework for
  Explainable Machine Learning and Pedagogical Feedback</title>
    <summary>  This study investigates the extent to which Mel-Frequency Cepstral
Coefficients (MFCCs) capture first language (L1) transfer in extended second
language (L2) English speech. Speech samples from Mandarin and American English
L1 speakers were extracted from the GMU Speech Accent Archive, converted to WAV
format, and processed to obtain thirteen MFCCs per speaker. A multi-method
analytic framework combining inferential statistics (t-tests, MANOVA, Canonical
Discriminant Analysis) and machine learning (Random Forest classification)
identified MFCC-1 (broadband energy), MFCC-2 (first formant region), and MFCC-5
(voicing and fricative energy) as the most discriminative features for
distinguishing L1 backgrounds. A reduced-feature model using these MFCCs
significantly outperformed the full-feature model, as confirmed by McNemar's
test and non-overlapping confidence intervals. The findings empirically support
the Perceptual Assimilation Model for L2 (PAM-L2) and the Speech Learning Model
(SLM), demonstrating that L1-conditioned variation in L2 speech is both
perceptually grounded and acoustically quantifiable. Methodologically, the
study contributes to applied linguistics and explainable AI by proposing a
transparent, data-efficient pipeline for L2 pronunciation modeling. The results
also offer pedagogical implications for ESL/EFL instruction by highlighting
L1-specific features that can inform intelligibility-oriented instruction,
curriculum design, and speech assessment tools.
</summary>
    <author>
      <name>Peyman Jahanbin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">27 pages (including references), 4 figures, 1 table. Combines
  statistical inference and explainable machine learning to model L1 influence
  in L2 pronunciation using MFCC features. Methodology and code are openly
  available via Zenodo and OSF: Zenodo: https://doi.org/10.5281/zenodo.15186197
  OSF: https://doi.org/10.17605/OSF.IO/4UXGM</arxiv:comment>
    <link href="http://arxiv.org/abs/2504.13765v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.13765v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.5.4; I.2.6; H.3.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.13756v1</id>
    <updated>2025-04-18T15:45:30Z</updated>
    <published>2025-04-18T15:45:30Z</published>
    <title>Scaling sparse feature circuit finding for in-context learning</title>
    <summary>  Sparse autoencoders (SAEs) are a popular tool for interpreting large language
model activations, but their utility in addressing open questions in
interpretability remains unclear. In this work, we demonstrate their
effectiveness by using SAEs to deepen our understanding of the mechanism behind
in-context learning (ICL). We identify abstract SAE features that (i) encode
the model's knowledge of which task to execute and (ii) whose latent vectors
causally induce the task zero-shot. This aligns with prior work showing that
ICL is mediated by task vectors. We further demonstrate that these task vectors
are well approximated by a sparse sum of SAE latents, including these
task-execution features. To explore the ICL mechanism, we adapt the sparse
feature circuits methodology of Marks et al. (2024) to work for the much larger
Gemma-1 2B model, with 30 times as many parameters, and to the more complex
task of ICL. Through circuit finding, we discover task-detecting features with
corresponding SAE latents that activate earlier in the prompt, that detect when
tasks have been performed. They are causally linked with task-execution
features through the attention and MLP sublayers.
</summary>
    <author>
      <name>Dmitrii Kharlapenko</name>
    </author>
    <author>
      <name>Stepan Shabalin</name>
    </author>
    <author>
      <name>Fazl Barez</name>
    </author>
    <author>
      <name>Arthur Conmy</name>
    </author>
    <author>
      <name>Neel Nanda</name>
    </author>
    <link href="http://arxiv.org/abs/2504.13756v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.13756v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.13744v1</id>
    <updated>2025-04-18T15:18:08Z</updated>
    <published>2025-04-18T15:18:08Z</published>
    <title>Observation of gyroscopic coupling in a non-spinning levitated
  ferromagnet</title>
    <summary>  A non-spinning permanent ferromagnet is predicted to behave as a gyroscope at
sufficiently low frequencies, which can be seen as a manifestation of the
Einstein-de Haas effect. This yet unexplored regime has been recently proposed
for ultrasensitive precession-based magnetometry and for atomic-like quantum
stabilization of a levitated nanomagnet in a static field. Here, we observe
signatures of gyroscopic effects in the rotational dynamics of a non-spinning
permanent ferromagnet levitated in a superconducting trap. Specifically, we
detect spin-rotation coupling between different librational modes, in good
agreement with theoretical predictions. From our measurements, we can infer
both the intrinsic angular momentum of the levitated magnet and its
gyromagnetic $g$-factor.
</summary>
    <author>
      <name>F. Ahrens</name>
    </author>
    <author>
      <name>A. Vinante</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2504.13744v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.13744v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.13739v1</id>
    <updated>2025-04-18T15:08:45Z</updated>
    <published>2025-04-18T15:08:45Z</published>
    <title>Modular Hamiltonian of holographic time band states</title>
    <summary>  A holographic time band is a causal incomplete boundary spacetime subregion
whose causal wedge is a causal complete bulk spacetime subregion. In an AdS$_3$
spacetime with a specifically modified IR geometry, its causal wedge coincides
with its entanglement wedge, which suggests the existence of a local modular
Hamiltonian for the holographic time band state. In this work, we construct the
local modular Hamiltonian for holographic time bands using two independent
methods: from the quantum information properties of the time band state and
from the construction of consistent geometric modular flows. Both methods lead
to the same unique result of the local modular Hamiltonian, reflecting the
intrinsic property of the time band state. The entanglement first law has also
been checked to hold for the simplest time band state. This is a substantial
addition to the known holographic subsystems with a local modular Hamiltonian,
beyond the few cases previously identified.
</summary>
    <author>
      <name>Xin-Xiang Ju</name>
    </author>
    <author>
      <name>Bo-Hao Liu</name>
    </author>
    <author>
      <name>Ya-Wen Sun</name>
    </author>
    <author>
      <name>Yang Zhao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2504.13739v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.13739v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="hep-th" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-th" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.13736v1</id>
    <updated>2025-04-18T15:04:53Z</updated>
    <published>2025-04-18T15:04:53Z</published>
    <title>LimitNet: Progressive, Content-Aware Image Offloading for Extremely Weak
  Devices &amp; Networks</title>
    <summary>  IoT devices have limited hardware capabilities and are often deployed in
remote areas. Consequently, advanced vision models surpass such devices'
processing and storage capabilities, requiring offloading of such tasks to the
cloud. However, remote areas often rely on LPWANs technology with limited
bandwidth, high packet loss rates, and extremely low duty cycles, which makes
fast offloading for time-sensitive inference challenging. Today's approaches,
which are deployable on weak devices, generate a non-progressive bit stream,
and therefore, their decoding quality suffers strongly when data is only
partially available on the cloud at a deadline due to limited bandwidth or
packet losses.
  In this paper, we introduce LimitNet, a progressive, content-aware image
compression model designed for extremely weak devices and networks. LimitNet's
lightweight progressive encoder prioritizes critical data during transmission
based on the content of the image, which gives the cloud the opportunity to run
inference even with partial data availability.
  Experimental results demonstrate that LimitNet, on average, compared to SOTA,
achieves 14.01 p.p. (percentage point) higher accuracy on ImageNet1000, 18.01
pp on CIFAR100, and 0.1 higher mAP@0.5 on COCO. Also, on average, LimitNet
saves 61.24% bandwidth on ImageNet1000, 83.68% on CIFAR100, and 42.25% on the
COCO dataset compared to SOTA, while it only has 4% more encoding time compared
to JPEG (with a fixed quality) on STM32F7 (Cortex-M7).
</summary>
    <author>
      <name>Ali Hojjat</name>
    </author>
    <author>
      <name>Janek Haberer</name>
    </author>
    <author>
      <name>Tayyaba Zainab</name>
    </author>
    <author>
      <name>Olaf Landsiedel</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3643832.3661856</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3643832.3661856" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This is the author's accepted manuscript. The Version of Record is
  available at: https://doi.org/10.1145/3643832.3661856</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings of the 22nd ACM International Conference on Mobile
  Systems, Applications, and Services (MobiSys '24), June 3-7, 2024, Minato-ku,
  Tokyo, Japan. ACM, New York, NY, USA</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2504.13736v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.13736v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.IV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
