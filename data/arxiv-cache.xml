<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2026-01-02T01:02:03Z -->
<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/" xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns="http://www.w3.org/2005/Atom">
  <id>https://arxiv.org/api/p6EyKyP4fMY/66n9Ev8E79F7KlI</id>
  <title>arXiv Query: search_query=all:causal OR all:inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <updated>2026-01-02T01:02:04Z</updated>
  <link href="https://arxiv.org/api/query?search_query=all:causal+OR+all:inference&amp;start=0&amp;max_results=10&amp;id_list=" type="application/atom+xml"/>
  <opensearch:itemsPerPage>10</opensearch:itemsPerPage>
  <opensearch:totalResults>129868</opensearch:totalResults>
  <opensearch:startIndex>0</opensearch:startIndex>
  <entry>
    <id>http://arxiv.org/abs/2512.25071v1</id>
    <title>Edit3r: Instant 3D Scene Editing from Sparse Unposed Images</title>
    <updated>2025-12-31T18:59:53Z</updated>
    <link href="https://arxiv.org/abs/2512.25071v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.25071v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>We present Edit3r, a feed-forward framework that reconstructs and edits 3D scenes in a single pass from unposed, view-inconsistent, instruction-edited images. Unlike prior methods requiring per-scene optimization, Edit3r directly predicts instruction-aligned 3D edits, enabling fast and photorealistic rendering without optimization or pose estimation. A key challenge in training such a model lies in the absence of multi-view consistent edited images for supervision. We address this with (i) a SAM2-based recoloring strategy that generates reliable, cross-view-consistent supervision, and (ii) an asymmetric input strategy that pairs a recolored reference view with raw auxiliary views, encouraging the network to fuse and align disparate observations. At inference, our model effectively handles images edited by 2D methods such as InstructPix2Pix, despite not being exposed to such edits during training. For large-scale quantitative evaluation, we introduce DL3DV-Edit-Bench, a benchmark built on the DL3DV test split, featuring 20 diverse scenes, 4 edit types and 100 edits in total. Comprehensive quantitative and qualitative results show that Edit3r achieves superior semantic alignment and enhanced 3D consistency compared to recent baselines, while operating at significantly higher inference speed, making it promising for real-time 3D editing applications.</summary>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-31T18:59:53Z</published>
    <arxiv:comment>Project page: https://edit3r.github.io/edit3r/</arxiv:comment>
    <arxiv:primary_category term="cs.CV"/>
    <author>
      <name>Jiageng Liu</name>
    </author>
    <author>
      <name>Weijie Lyu</name>
    </author>
    <author>
      <name>Xueting Li</name>
    </author>
    <author>
      <name>Yejie Guo</name>
    </author>
    <author>
      <name>Ming-Hsuan Yang</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.25072v1</id>
    <title>Coordinated Humanoid Manipulation with Choice Policies</title>
    <updated>2025-12-31T18:59:53Z</updated>
    <link href="https://arxiv.org/abs/2512.25072v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.25072v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Humanoid robots hold great promise for operating in human-centric environments, yet achieving robust whole-body coordination across the head, hands, and legs remains a major challenge. We present a system that combines a modular teleoperation interface with a scalable learning framework to address this problem. Our teleoperation design decomposes humanoid control into intuitive submodules, which include hand-eye coordination, grasp primitives, arm end-effector tracking, and locomotion. This modularity allows us to collect high-quality demonstrations efficiently. Building on this, we introduce Choice Policy, an imitation learning approach that generates multiple candidate actions and learns to score them. This architecture enables both fast inference and effective modeling of multimodal behaviors. We validate our approach on two real-world tasks: dishwasher loading and whole-body loco-manipulation for whiteboard wiping. Experiments show that Choice Policy significantly outperforms diffusion policies and standard behavior cloning. Furthermore, our results indicate that hand-eye coordination is critical for success in long-horizon tasks. Our work demonstrates a practical path toward scalable data collection and learning for coordinated humanoid manipulation in unstructured environments.</summary>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-31T18:59:53Z</published>
    <arxiv:comment>Code and Website: https://choice-policy.github.io/</arxiv:comment>
    <arxiv:primary_category term="cs.RO"/>
    <author>
      <name>Haozhi Qi</name>
    </author>
    <author>
      <name>Yen-Jen Wang</name>
    </author>
    <author>
      <name>Toru Lin</name>
    </author>
    <author>
      <name>Brent Yi</name>
    </author>
    <author>
      <name>Yi Ma</name>
    </author>
    <author>
      <name>Koushil Sreenath</name>
    </author>
    <author>
      <name>Jitendra Malik</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.25059v1</id>
    <title>Reliable and Resilient Collective Communication Library for LLM Training and Serving</title>
    <updated>2025-12-31T18:53:11Z</updated>
    <link href="https://arxiv.org/abs/2512.25059v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.25059v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Modern ML training and inference now span tens to tens of thousands of GPUs, where network faults can waste 10--15\% of GPU hours due to slow recovery. Common network errors and link fluctuations trigger timeouts that often terminate entire jobs, forcing expensive checkpoint rollback during training and request reprocessing during inference. We present R$^2$CCL, a fault-tolerant communication library that provides lossless, low-overhead failover by exploiting multi-NIC hardware. R$^2$CCL performs rapid connection migration, bandwidth-aware load redistribution, and resilient collective algorithms to maintain progress under failures. We evaluate R$^2$CCL on two 8-GPU H100 InfiniBand servers and via large-scale ML simulators modeling hundreds of GPUs with diverse failure patterns. Experiments show that R$^2$CCL is highly robust to NIC failures, incurring less than 1\% training and less than 3\% inference overheads. R$^2$CCL outperforms baselines AdapCC and DejaVu by 12.18$\times$ and 47$\times$, respectively.</summary>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-31T18:53:11Z</published>
    <arxiv:primary_category term="cs.DC"/>
    <author>
      <name>Wei Wang</name>
    </author>
    <author>
      <name>Nengneng Yu</name>
    </author>
    <author>
      <name>Sixian Xiong</name>
    </author>
    <author>
      <name>Zaoxing Liu</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.25056v1</id>
    <title>Sequential Bayesian parameter-state estimation in dynamical systems with noisy and incomplete observations via a variational framework</title>
    <updated>2025-12-31T18:52:07Z</updated>
    <link href="https://arxiv.org/abs/2512.25056v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.25056v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Online joint estimation of unknown parameters and states in a dynamical system with uncertainty quantification is crucial in many applications. For example, digital twins dynamically update their knowledge of model parameters and states to support prediction and decision-making. Reliability and computational speed are vital for DTs. Online parameter-state estimation ensures computational efficiency, while uncertainty quantification is essential for making reliable predictions and decisions. In parameter-state estimation, the joint distribution of the state and model parameters conditioned on the data, termed the joint posterior, provides accurate uncertainty quantification. Because the joint posterior is generally intractable to compute, this paper presents an online variational inference framework to compute its approximation at each time step. The approximation is factorized into a marginal distribution over the model parameters and a state distribution conditioned on the parameters. This factorization enables recursive updates through a two-stage procedure: first, the parameter posterior is approximated via variational inference; second, the state distribution conditioned on the parameters is computed using Gaussian filtering based on the estimated parameter posterior. The algorithmic design is supported by a theorem establishing upper bounds on the joint posterior approximation error. Numerical experiments demonstrate that the proposed method (i) matches the performance of the joint particle filter in low-dimensional problems, accurately inferring both unobserved states and unknown parameters of dynamical and observation models; (ii) remains robust under noisy, partial observations and model discrepancies in a chaotic Lorenz 96 system; and (iii) scales effectively to a high-dimensional convection-diffusion system, where it outperforms the joint ensemble Kalman filter.</summary>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-31T18:52:07Z</published>
    <arxiv:comment>31 pages, 8 figures</arxiv:comment>
    <arxiv:primary_category term="stat.ME"/>
    <author>
      <name>Liliang Wang</name>
    </author>
    <author>
      <name>Alex Gorodetsky</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.25047v1</id>
    <title>Amplitude constraints on dark energy</title>
    <updated>2025-12-31T18:44:06Z</updated>
    <link href="https://arxiv.org/abs/2512.25047v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.25047v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>This talk gives a short introduction to the ``UV/EFT correspondence", which uses scattering amplitudes to relate the Effective Field Theory (EFT) coefficients probed by low-energy measurements to properties of the underlying high-energy (UV) completion. This includes recent ``positivity bounds" on EFT coefficients, which are the low-energy signatures of causality and unitarity in the UV. To illustrate their phenomenological impact, I apply these bounds to a simple EFT for dark energy and compare with recent cosmological observations.</summary>
    <category term="gr-qc" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-31T18:44:06Z</published>
    <arxiv:comment>4 pages, contribution to Moriond 2022, based on arXiv:1904.05874 and arXiv:2103.06855</arxiv:comment>
    <arxiv:primary_category term="gr-qc"/>
    <arxiv:journal_ref>Proceedings of the 56th Rencontres de Moriond on Cosmology (2022)</arxiv:journal_ref>
    <author>
      <name>Scott Melville</name>
    </author>
    <arxiv:doi>10.58027/3q8k-ew90</arxiv:doi>
    <link rel="related" href="https://doi.org/10.58027/3q8k-ew90" title="doi"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.25042v1</id>
    <title>Compound Estimation for Binomials</title>
    <updated>2025-12-31T18:38:01Z</updated>
    <link href="https://arxiv.org/abs/2512.25042v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.25042v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Many applications involve estimating the mean of multiple binomial outcomes as a common problem -- assessing intergenerational mobility of census tracts, estimating prevalence of infectious diseases across countries, and measuring click-through rates for different demographic groups. The most standard approach is to report the plain average of each outcome. Despite simplicity, the estimates are noisy when the sample sizes or mean parameters are small. In contrast, the Empirical Bayes (EB) methods are able to boost the average accuracy by borrowing information across tasks. Nevertheless, the EB methods require a Bayesian model where the parameters are sampled from a prior distribution which, unlike the commonly-studied Gaussian case, is unidentified due to discreteness of binomial measurements. Even if the prior distribution is known, the computation is difficult when the sample sizes are heterogeneous as there is no simple joint conjugate prior for the sample size and mean parameter.
  In this paper, we consider the compound decision framework which treats the sample size and mean parameters as fixed quantities. We develop an approximate Stein's Unbiased Risk Estimator (SURE) for the average mean squared error given any class of estimators. For a class of machine learning-assisted linear shrinkage estimators, we establish asymptotic optimality, regret bounds, and valid inference. Unlike existing work, we work with the binomials directly without resorting to Gaussian approximations. This allows us to work with small sample sizes and/or mean parameters in both one-sample and two-sample settings. We demonstrate our approach using three datasets on firm discrimination, education outcomes, and innovation rates.</summary>
    <category term="econ.EM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-31T18:38:01Z</published>
    <arxiv:primary_category term="econ.EM"/>
    <author>
      <name>Yan Chen</name>
    </author>
    <author>
      <name>Lihua Lei</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.25025v1</id>
    <title>Modewise Additive Factor Model for Matrix Time Series</title>
    <updated>2025-12-31T18:24:37Z</updated>
    <link href="https://arxiv.org/abs/2512.25025v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.25025v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>We introduce a Modewise Additive Factor Model (MAFM) for matrix-valued time series that captures row-specific and column-specific latent effects through an additive structure, offering greater flexibility than multiplicative frameworks such as Tucker and CP factor models. In MAFM, each observation decomposes into a row-factor component, a column-factor component, and noise, allowing distinct sources of variation along different modes to be modeled separately. We develop a computationally efficient two-stage estimation procedure: Modewise Inner-product Eigendecomposition (MINE) for initialization, followed by Complement-Projected Alternating Subspace Estimation (COMPAS) for iterative refinement. The key methodological innovation is that orthogonal complement projections completely eliminate cross-modal interference when estimating each loading space. We establish convergence rates for the estimated factor loading matrices under proper conditions. We further derive asymptotic distributions for the loading matrix estimators and develop consistent covariance estimators, yielding a data-driven inference framework that enables confidence interval construction and hypothesis testing. As a technical contribution of independent interest, we establish matrix Bernstein inequalities for quadratic forms of dependent matrix time series. Numerical experiments on synthetic and real data demonstrate the advantages of the proposed method over existing approaches.</summary>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="econ.EM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-31T18:24:37Z</published>
    <arxiv:primary_category term="stat.ME"/>
    <author>
      <name>Elynn Chen</name>
    </author>
    <author>
      <name>Yuefeng Han</name>
    </author>
    <author>
      <name>Jiayu Li</name>
    </author>
    <author>
      <name>Ke Xu</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.25023v1</id>
    <title>ResponseRank: Data-Efficient Reward Modeling through Preference Strength Learning</title>
    <updated>2025-12-31T18:21:52Z</updated>
    <link href="https://arxiv.org/abs/2512.25023v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.25023v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Binary choices, as often used for reinforcement learning from human feedback (RLHF), convey only the direction of a preference. A person may choose apples over oranges and bananas over grapes, but which preference is stronger? Strength is crucial for decision-making under uncertainty and generalization of preference models, but hard to measure reliably. Metadata such as response times and inter-annotator agreement can serve as proxies for strength, but are often noisy and confounded. We propose ResponseRank to address the challenge of learning from noisy strength signals. Our method uses relative differences in proxy signals to rank responses to pairwise comparisons by their inferred preference strength. To control for systemic variation, we compare signals only locally within carefully constructed strata. This enables robust learning of utility differences consistent with strength-derived rankings while making minimal assumptions about the strength signal. Our contributions are threefold: (1) ResponseRank, a novel method that robustly learns preference strength by leveraging locally valid relative strength signals; (2) empirical evidence of improved sample efficiency and robustness across diverse tasks: synthetic preference learning (with simulated response times), language modeling (with annotator agreement), and RL control tasks (with simulated episode returns); and (3) the Pearson Distance Correlation (PDC), a novel metric that isolates cardinal utility learning from ordinal accuracy.</summary>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-31T18:21:52Z</published>
    <arxiv:comment>NeurIPS 2025</arxiv:comment>
    <arxiv:primary_category term="cs.LG"/>
    <author>
      <name>Timo Kaufmann</name>
    </author>
    <author>
      <name>Yannick Metz</name>
    </author>
    <author>
      <name>Daniel Keim</name>
    </author>
    <author>
      <name>Eyke HÃ¼llermeier</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.25014v1</id>
    <title>Diffusion Language Models are Provably Optimal Parallel Samplers</title>
    <updated>2025-12-31T18:03:05Z</updated>
    <link href="https://arxiv.org/abs/2512.25014v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.25014v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Diffusion language models (DLMs) have emerged as a promising alternative to autoregressive models for faster inference via parallel token generation. We provide a rigorous foundation for this advantage by formalizing a model of parallel sampling and showing that DLMs augmented with polynomial-length chain-of-thought (CoT) can simulate any parallel sampling algorithm using an optimal number of sequential steps. Consequently, whenever a target distribution can be generated using a small number of sequential steps, a DLM can be used to generate the distribution using the same number of optimal sequential steps. However, without the ability to modify previously revealed tokens, DLMs with CoT can still incur large intermediate footprints. We prove that enabling remasking (converting unmasked tokens to masks) or revision (converting unmasked tokens to other unmasked tokens) together with CoT further allows DLMs to simulate any parallel sampling algorithm with optimal space complexity. We further justify the advantage of revision by establishing a strict expressivity gap: DLMs with revision or remasking are strictly more expressive than those without. Our results not only provide a theoretical justification for the promise of DLMs as the most efficient parallel sampler, but also advocate for enabling revision in DLMs.</summary>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-31T18:03:05Z</published>
    <arxiv:primary_category term="cs.LG"/>
    <author>
      <name>Haozhe Jiang</name>
    </author>
    <author>
      <name>Nika Haghtalab</name>
    </author>
    <author>
      <name>Lijie Chen</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.25008v1</id>
    <title>FoundationSLAM: Unleashing the Power of Depth Foundation Models for End-to-End Dense Visual SLAM</title>
    <updated>2025-12-31T17:57:45Z</updated>
    <link href="https://arxiv.org/abs/2512.25008v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.25008v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>We present FoundationSLAM, a learning-based monocular dense SLAM system that addresses the absence of geometric consistency in previous flow-based approaches for accurate and robust tracking and mapping. Our core idea is to bridge flow estimation with geometric reasoning by leveraging the guidance from foundation depth models. To this end, we first develop a Hybrid Flow Network that produces geometry-aware correspondences, enabling consistent depth and pose inference across diverse keyframes. To enforce global consistency, we propose a Bi-Consistent Bundle Adjustment Layer that jointly optimizes keyframe pose and depth under multi-view constraints. Furthermore, we introduce a Reliability-Aware Refinement mechanism that dynamically adapts the flow update process by distinguishing between reliable and uncertain regions, forming a closed feedback loop between matching and optimization. Extensive experiments demonstrate that FoundationSLAM achieves superior trajectory accuracy and dense reconstruction quality across multiple challenging datasets, while running in real-time at 18 FPS, demonstrating strong generalization to various scenarios and practical applicability of our method.</summary>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-31T17:57:45Z</published>
    <arxiv:primary_category term="cs.CV"/>
    <author>
      <name>Yuchen Wu</name>
    </author>
    <author>
      <name>Jiahe Li</name>
    </author>
    <author>
      <name>Fabio Tosi</name>
    </author>
    <author>
      <name>Matteo Poggi</name>
    </author>
    <author>
      <name>Jin Zheng</name>
    </author>
    <author>
      <name>Xiao Bai</name>
    </author>
  </entry>
</feed>
