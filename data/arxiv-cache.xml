<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-08-18T01:02:48Z -->
<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acausal%20inference%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:causal inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/SsRksLzRb0LuVhSmQ+N8WbAs+f8</id>
  <updated>2025-08-17T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">118971</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">10</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2508.10898v1</id>
    <updated>2025-08-14T17:59:31Z</updated>
    <published>2025-08-14T17:59:31Z</published>
    <title>Puppeteer: Rig and Animate Your 3D Models</title>
    <summary>  Modern interactive applications increasingly demand dynamic 3D content, yet
the transformation of static 3D models into animated assets constitutes a
significant bottleneck in content creation pipelines. While recent advances in
generative AI have revolutionized static 3D model creation, rigging and
animation continue to depend heavily on expert intervention. We present
Puppeteer, a comprehensive framework that addresses both automatic rigging and
animation for diverse 3D objects. Our system first predicts plausible skeletal
structures via an auto-regressive transformer that introduces a joint-based
tokenization strategy for compact representation and a hierarchical ordering
methodology with stochastic perturbation that enhances bidirectional learning
capabilities. It then infers skinning weights via an attention-based
architecture incorporating topology-aware joint attention that explicitly
encodes inter-joint relationships based on skeletal graph distances. Finally,
we complement these rigging advances with a differentiable optimization-based
animation pipeline that generates stable, high-fidelity animations while being
computationally more efficient than existing approaches. Extensive evaluations
across multiple benchmarks demonstrate that our method significantly
outperforms state-of-the-art techniques in both skeletal prediction accuracy
and skinning quality. The system robustly processes diverse 3D content, ranging
from professionally designed game assets to AI-generated shapes, producing
temporally coherent animations that eliminate the jittering issues common in
existing methods.
</summary>
    <author>
      <name>Chaoyue Song</name>
    </author>
    <author>
      <name>Xiu Li</name>
    </author>
    <author>
      <name>Fan Yang</name>
    </author>
    <author>
      <name>Zhongcong Xu</name>
    </author>
    <author>
      <name>Jiacheng Wei</name>
    </author>
    <author>
      <name>Fayao Liu</name>
    </author>
    <author>
      <name>Jiashi Feng</name>
    </author>
    <author>
      <name>Guosheng Lin</name>
    </author>
    <author>
      <name>Jianfeng Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Project page: https://chaoyuesong.github.io/Puppeteer/</arxiv:comment>
    <link href="http://arxiv.org/abs/2508.10898v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.10898v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.10895v1</id>
    <updated>2025-08-14T17:59:02Z</updated>
    <published>2025-08-14T17:59:02Z</published>
    <title>Stars Born in the Wind: M82's Outflow and Halo Star Formation</title>
    <summary>  Starburst galaxies, like M82, launch kiloparsec-scale galactic outflows that
interact with the circumgalactic medium (CGM) in complex ways. Apart from
enriching the CGM with metals and energy, these outflows may trigger star
formation in the halo -- either by driving shocks into the CGM or transporting
cold, star-forming gas. To investigate such processes, we analyze the star
formation history (SFH) of the Southern Arcs -- arc-like stellar features
located ~5 kpc from M82's star-forming disk along the minor axis -- using
Hubble Space Telescope Wide Field Camera 3 photometry. From resolved stellar
populations, we derive SFHs over the last ~500 Myr, finding that ~85% of the
stellar mass formed between ~150 and ~70 Myr ago, followed by a brief pause,
with the remaining ~15% forming since ~30 Myr ago. The two stellar populations
are co-spatial on scales of at least ~200 pc. The timing of the ~100 Myr burst
aligns with star formation in the M82 disk and the age distribution of its star
clusters, suggesting a causal link between the disk starburst and halo star
formation. We explore two mechanisms that could explain these observations. In
the first, shocks driven by the interaction between hot outflowing gas and
cooler CGM material compress dense clouds, triggering collapse and star
formation. In the second, stars form directly within massive, cool clouds
associated with the outflow. As these clouds move ballistically through the
halo, subsequent interactions with tidal debris may trigger additional star
formation, producing the observed episodic structure.
</summary>
    <author>
      <name>Vaishnav V. Rao</name>
    </author>
    <author>
      <name>Adam Smercina</name>
    </author>
    <author>
      <name>Eric F. Bell</name>
    </author>
    <author>
      <name>Benjamin Williams</name>
    </author>
    <author>
      <name>Julianne J. Dalcanton</name>
    </author>
    <author>
      <name>Andrew Dolphin</name>
    </author>
    <author>
      <name>Adam Leroy</name>
    </author>
    <author>
      <name>Antonela Monachesi</name>
    </author>
    <author>
      <name>Jeremy Bailin</name>
    </author>
    <author>
      <name>Roelof S. de Jong</name>
    </author>
    <author>
      <name>Fabian Walter</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages; 11 figures; 1 table; accepted for publication in The
  Astrophysical Journal</arxiv:comment>
    <link href="http://arxiv.org/abs/2508.10895v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.10895v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.GA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.GA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.10893v1</id>
    <updated>2025-08-14T17:58:05Z</updated>
    <published>2025-08-14T17:58:05Z</published>
    <title>STream3R: Scalable Sequential 3D Reconstruction with Causal Transformer</title>
    <summary>  We present STream3R, a novel approach to 3D reconstruction that reformulates
pointmap prediction as a decoder-only Transformer problem. Existing
state-of-the-art methods for multi-view reconstruction either depend on
expensive global optimization or rely on simplistic memory mechanisms that
scale poorly with sequence length. In contrast, STream3R introduces an
streaming framework that processes image sequences efficiently using causal
attention, inspired by advances in modern language modeling. By learning
geometric priors from large-scale 3D datasets, STream3R generalizes well to
diverse and challenging scenarios, including dynamic scenes where traditional
methods often fail. Extensive experiments show that our method consistently
outperforms prior work across both static and dynamic scene benchmarks.
Moreover, STream3R is inherently compatible with LLM-style training
infrastructure, enabling efficient large-scale pretraining and fine-tuning for
various downstream 3D tasks. Our results underscore the potential of causal
Transformer models for online 3D perception, paving the way for real-time 3D
understanding in streaming environments. More details can be found in our
project page: https://nirvanalan.github.io/projects/stream3r.
</summary>
    <author>
      <name>Yushi Lan</name>
    </author>
    <author>
      <name>Yihang Luo</name>
    </author>
    <author>
      <name>Fangzhou Hong</name>
    </author>
    <author>
      <name>Shangchen Zhou</name>
    </author>
    <author>
      <name>Honghua Chen</name>
    </author>
    <author>
      <name>Zhaoyang Lyu</name>
    </author>
    <author>
      <name>Shuai Yang</name>
    </author>
    <author>
      <name>Bo Dai</name>
    </author>
    <author>
      <name>Chen Change Loy</name>
    </author>
    <author>
      <name>Xingang Pan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">TL;DR: Streaming 4D reconstruction using causal transformer. Project
  page: https://nirvanalan.github.io/projects/stream3r</arxiv:comment>
    <link href="http://arxiv.org/abs/2508.10893v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.10893v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.10876v1</id>
    <updated>2025-08-14T17:47:41Z</updated>
    <published>2025-08-14T17:47:41Z</published>
    <title>Accelerating cosmological inference of interacting dark energy with
  neural emulators</title>
    <summary>  The present thesis aims to tackle two critical aspects of present and future
cosmological analysis of Large-Scale Structure (LSS): accurate modelling of the
nonlinear matter power spectrum beyond $\Lambda$CDM, and efficient
computational techniques for Bayesian parameter estimation. Both are crucial
for testing alternative cosmologies and avoiding spurious results. We focus on
the Dark Scattering (DS) model, describing pure momentum transfer between dark
matter -- dark energy through the parameter $A_{\rm ds}$. To capture DS
effects, we adopt the halo model reaction framework within $\tt{ReACT}$,
compute the nonlinear DS spectrum, and validate it against $N$-body
simulations. We further include baryonic feedback and massive neutrinos,
finding degeneracies between DS and baryonic effects but not with neutrinos. We
then constrain DS using cosmic shear from KiDS-1000, accelerated by neural
emulators from $\tt{CosmoPower}$, which speed up predictions by
$\mathcal{O}(10^4)$. Our DS emulator, trained on halo model reaction outputs,
preserves percent-level accuracy and incorporates baryonic feedback. Analysing
KiDS shear statistics, we obtain $\vert A_{\rm ds}\vert \lesssim 20$ b/GeV at
$68 \%$ C.L. Combining KiDS with Planck CMB and BAO data, we find $A_{\rm
ds}=10.6^{+4.5}_{-7.3}$ b/GeV at $68 \%$ C.L., suggesting the DS model as a
promising resolution to the $S_8$ tension. Finally, we present weak lensing
forecasts for Stage IV surveys using an automatically differentiable pipeline
with $\tt{jax-cosmo}$ and gradient-based samplers in $\tt{NumPyro}$, reducing
computational cost from months on CPUs to days on GPUs. Model evidence is
evaluated with $\tt{harmonic}$ under multiple scale cuts. To put things into
perspective, the modelling strategies and machine learning accelerations
developed here provide powerful tools for the next generation of LSS cosmology.
</summary>
    <author>
      <name>Karim Carrion</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Ph.D. thesis (defended July 2025). 138 pages + appendices, 38 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2508.10876v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.10876v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.10875v1</id>
    <updated>2025-08-14T17:47:22Z</updated>
    <published>2025-08-14T17:47:22Z</published>
    <title>A Survey on Diffusion Language Models</title>
    <summary>  Diffusion Language Models (DLMs) are rapidly emerging as a powerful and
promising alternative to the dominant autoregressive (AR) paradigm. By
generating tokens in parallel through an iterative denoising process, DLMs
possess inherent advantages in reducing inference latency and capturing
bidirectional context, thereby enabling fine-grained control over the
generation process. While achieving a several-fold speed-up, recent
advancements have allowed DLMs to show performance comparable to their
autoregressive counterparts, making them a compelling choice for various
natural language processing tasks. In this survey, we provide a holistic
overview of the current DLM landscape. We trace its evolution and relationship
with other paradigms, such as autoregressive and masked language models, and
cover both foundational principles and state-of-the-art models. Our work offers
an up-to-date, comprehensive taxonomy and an in-depth analysis of current
techniques, from pre-training strategies to advanced post-training methods.
Another contribution of this survey is a thorough review of DLM inference
strategies and optimizations, including improvements in decoding parallelism,
caching mechanisms, and generation quality. We also highlight the latest
approaches to multimodal extensions of DLMs and delineate their applications
across various practical scenarios. Furthermore, our discussion addresses the
limitations and challenges of DLMs, including efficiency, long-sequence
handling, and infrastructure requirements, while outlining future research
directions to sustain progress in this rapidly evolving field. Project GitHub
is available at https://github.com/VILA-Lab/Awesome-DLMs.
</summary>
    <author>
      <name>Tianyi Li</name>
    </author>
    <author>
      <name>Mingda Chen</name>
    </author>
    <author>
      <name>Bowei Guo</name>
    </author>
    <author>
      <name>Zhiqiang Shen</name>
    </author>
    <link href="http://arxiv.org/abs/2508.10875v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.10875v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.10874v1</id>
    <updated>2025-08-14T17:46:01Z</updated>
    <published>2025-08-14T17:46:01Z</published>
    <title>SSRL: Self-Search Reinforcement Learning</title>
    <summary>  We investigate the potential of large language models (LLMs) to serve as
efficient simulators for agentic search tasks in reinforcement learning (RL),
thereby reducing dependence on costly interactions with external search
engines. To this end, we first quantify the intrinsic search capability of LLMs
via structured prompting and repeated sampling, which we term Self-Search. Our
results reveal that LLMs exhibit strong scaling behavior with respect to the
inference budget, achieving high pass@k on question-answering benchmarks,
including the challenging BrowseComp task. Building on these observations, we
introduce Self-Search RL (SSRL), which enhances LLMs' Self-Search capability
through format-based and rule-based rewards. SSRL enables models to iteratively
refine their knowledge utilization internally, without requiring access to
external tools. Empirical evaluations demonstrate that SSRL-trained policy
models provide a cost-effective and stable environment for search-driven RL
training, reducing reliance on external search engines and facilitating robust
sim-to-real transfer. We draw the following conclusions: 1) LLMs possess world
knowledge that can be effectively elicited to achieve high performance; 2) SSRL
demonstrates the potential of leveraging internal knowledge to reduce
hallucination; 3) SSRL-trained models integrate seamlessly with external search
engines without additional effort. Our findings highlight the potential of LLMs
to support more scalable RL agent training.
</summary>
    <author>
      <name>Yuchen Fan</name>
    </author>
    <author>
      <name>Kaiyan Zhang</name>
    </author>
    <author>
      <name>Heng Zhou</name>
    </author>
    <author>
      <name>Yuxin Zuo</name>
    </author>
    <author>
      <name>Yanxu Chen</name>
    </author>
    <author>
      <name>Yu Fu</name>
    </author>
    <author>
      <name>Xinwei Long</name>
    </author>
    <author>
      <name>Xuekai Zhu</name>
    </author>
    <author>
      <name>Che Jiang</name>
    </author>
    <author>
      <name>Yuchen Zhang</name>
    </author>
    <author>
      <name>Li Kang</name>
    </author>
    <author>
      <name>Gang Chen</name>
    </author>
    <author>
      <name>Cheng Huang</name>
    </author>
    <author>
      <name>Zhizhou He</name>
    </author>
    <author>
      <name>Bingning Wang</name>
    </author>
    <author>
      <name>Lei Bai</name>
    </author>
    <author>
      <name>Ning Ding</name>
    </author>
    <author>
      <name>Bowen Zhou</name>
    </author>
    <link href="http://arxiv.org/abs/2508.10874v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.10874v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.10787v1</id>
    <updated>2025-08-14T16:14:05Z</updated>
    <published>2025-08-14T16:14:05Z</published>
    <title>Does fertility affect woman's labor force participation in low- and
  middle-income settings? Findings from a Bayesian nonparametric analysis</title>
    <summary>  Estimating the causal effect of fertility on women's employment is
challenging because fertility and labor decisions are jointly determined. The
difficulty is amplified in low- and middle-income countries, where longitudinal
data are scarce. In this study, we propose a novel approach to estimating the
causal effect of fertility on employment using widely available Demographic and
Health Survey (DHS) observational data. Using infecundity as an instrument for
family size, our approach combines principal stratification with Bayesian
Additive Regression Trees to flexibly account for covariate-dependent
instrument validity, work with count-valued intermediate variables, and produce
estimates of causal effects and effect heterogeneity, i.e., how effects vary
with covariates in the survey population. We apply the approach to DHS data
from Nigeria, Senegal, and Kenya. We find in the survey sample and general
population that an additional child significantly reduces employment among
women in Nigeria but has no clear average effect in Senegal or Kenya. Across
all three countries, however, there is strong evidence of effect heterogeneity:
younger, less-educated women experience large employment penalties, while older
or more advantaged women are largely unaffected. Robustness checks confirm that
these findings are not sensitive to key modeling assumptions. While limitations
remain due to the cross-sectional nature of the DHS data, our results
illustrate how flexible non-parametric models can uncover important effect
variation.
</summary>
    <author>
      <name>Lucas Godoy Garraza</name>
    </author>
    <author>
      <name>Leontine Alkema</name>
    </author>
    <link href="http://arxiv.org/abs/2508.10787v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.10787v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.10785v1</id>
    <updated>2025-08-14T16:12:15Z</updated>
    <published>2025-08-14T16:12:15Z</published>
    <title>Enhancing Fairness in Autoencoders for Node-Level Graph Anomaly
  Detection</title>
    <summary>  Graph anomaly detection (GAD) has become an increasingly important task
across various domains. With the rapid development of graph neural networks
(GNNs), GAD methods have achieved significant performance improvements.
However, fairness considerations in GAD remain largely underexplored. Indeed,
GNN-based GAD models can inherit and amplify biases present in training data,
potentially leading to unfair outcomes. While existing efforts have focused on
developing fair GNNs, most approaches target node classification tasks, where
models often rely on simple layer architectures rather than autoencoder-based
structures, which are the most widely used architecturs for anomaly detection.
To address fairness in autoencoder-based GAD models, we propose
\textbf{D}is\textbf{E}ntangled \textbf{C}ounterfactual \textbf{A}dversarial
\textbf{F}air (DECAF)-GAD, a framework that alleviates bias while preserving
GAD performance. Specifically, we introduce a structural causal model (SCM) to
disentangle sensitive attributes from learned representations. Based on this
causal framework, we formulate a specialized autoencoder architecture along
with a fairness-guided loss function. Through extensive experiments on both
synthetic and real-world datasets, we demonstrate that DECAF-GAD not only
achieves competitive anomaly detection performance but also significantly
enhances fairness metrics compared to baseline GAD methods. Our code is
available at https://github.com/Tlhey/decaf_code.
</summary>
    <author>
      <name>Shouju Wang</name>
    </author>
    <author>
      <name>Yuchen Song</name>
    </author>
    <author>
      <name>Sheng'en Li</name>
    </author>
    <author>
      <name>Dongmian Zou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted in ECAI-2025</arxiv:comment>
    <link href="http://arxiv.org/abs/2508.10785v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.10785v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.10777v1</id>
    <updated>2025-08-14T16:01:10Z</updated>
    <published>2025-08-14T16:01:10Z</published>
    <title>The Knowledge-Reasoning Dissociation: Fundamental Limitations of LLMs in
  Clinical Natural Language Inference</title>
    <summary>  Large language models are often assumed to acquire increasingly structured,
generalizable internal representations simply by scaling data and parameters.
We interrogate this assumption by introducing a Clinical Trial Natural Language
Inference benchmark comprising four reasoning families, Causal Attribution,
Compositional Grounding, Epistemic Verification, and Risk State Abstraction.
Each item is paired with a targeted Ground Knowledge and Meta-Level Reasoning
Verification (GKMRV) probe, allowing us to dissociate failures of factual
access from failures of inference. We evaluate six contemporary LLMs under both
direct and chain of thought prompting.
  Models achieve near-ceiling GKMRV accuracy (mean accuracy 0.918) yet perform
poorly on the main reasoning tasks (mean accuracy 0.25). Despite low accuracy,
output inferences are highly consistent across samples (mean 0.87), indicating
a systematic application of underlying heuristics and shortcuts.
  These results reveal fundamental structural and representational limitations:
current LLMs often possess the relevant clinical knowledge but lack the
structured, composable internal representations needed to deploy it reliably
(e.g., integrating constraints, weighing evidence, or simulating
counterfactuals). Decoupling knowledge from reasoning with GKMRV makes this
dissociation explicit and measurable, providing an effective framework for
probing the reliability of LLMs in high-stakes domains.
</summary>
    <author>
      <name>Maël Jullien</name>
    </author>
    <author>
      <name>Marco Valentino</name>
    </author>
    <author>
      <name>André Freitas</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2508.10777v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.10777v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2508.10774v1</id>
    <updated>2025-08-14T15:58:59Z</updated>
    <published>2025-08-14T15:58:59Z</published>
    <title>Video-BLADE: Block-Sparse Attention Meets Step Distillation for
  Efficient Video Generation</title>
    <summary>  Diffusion transformers currently lead the field in high-quality video
generation, but their slow iterative denoising process and prohibitive
quadratic attention costs for long sequences create significant inference
bottlenecks. While both step distillation and sparse attention mechanisms have
shown promise as independent acceleration strategies, effectively combining
these approaches presents critical challenges -- training-free integration
yields suboptimal results, while separately training sparse attention after
step distillation requires prohibitively expensive high-quality video data. To
overcome these limitations, we propose BLADE, an innovative data-free joint
training framework that introduces: (1) an Adaptive Block-Sparse Attention
(ASA) mechanism for dynamically generating content-aware sparsity masks to
focus computation on salient spatiotemporal features, and (2) a sparsity-aware
step distillation paradigm built upon Trajectory Distribution Matching (TDM)
that directly incorporates sparsity into the distillation process rather than
treating it as a separate compression step, with fast convergence. We validate
BLADE on text-to-video models like CogVideoX-5B and Wan2.1-1.3B. Our framework
demonstrates remarkable efficiency gains across different scales. On
Wan2.1-1.3B, BLADE achieves a 14.10x end-to-end inference acceleration over a
50-step baseline. Moreover, on models such as CogVideoX-5B with short video
sequence lengths, our framework delivers a robust 8.89x speedup. Crucially, the
acceleration is accompanied by a consistent quality improvement. On the
VBench-2.0 benchmark, BLADE boosts the score of CogVideoX-5B to 0.569 (from
0.534) and Wan2.1-1.3B to 0.570 (from 0.563), results that are further
corroborated by superior ratings in human evaluations. Our code and model
weights are publicly available at: http://ziplab.co/BLADE-Homepage/.
</summary>
    <author>
      <name>Youping Gu</name>
    </author>
    <author>
      <name>Xiaolong Li</name>
    </author>
    <author>
      <name>Yuhao Hu</name>
    </author>
    <author>
      <name>Bohan Zhuang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Tech report</arxiv:comment>
    <link href="http://arxiv.org/abs/2508.10774v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2508.10774v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
