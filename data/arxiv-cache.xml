<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-07-24T01:01:55Z -->
<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acausal%20inference%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:causal inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/SsRksLzRb0LuVhSmQ+N8WbAs+f8</id>
  <updated>2025-07-23T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">117405</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">10</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2507.16809v1</id>
    <updated>2025-07-22T17:57:44Z</updated>
    <published>2025-07-22T17:57:44Z</published>
    <title>LingBench++: A Linguistically-Informed Benchmark and Reasoning Framework
  for Multi-Step and Cross-Cultural Inference with LLMs</title>
    <summary>  We propose LingBench++, a linguistically-informed benchmark and reasoning
framework designed to evaluate large language models (LLMs) on complex
linguistic tasks inspired by the International Linguistics Olympiad (IOL).
Unlike prior benchmarks that focus solely on final answer accuracy, LingBench++
provides structured reasoning traces, stepwise evaluation protocols, and rich
typological metadata across over 90 low-resource and cross-cultural languages.
We further develop a multi-agent architecture integrating grammatical knowledge
retrieval, tool-augmented reasoning, and deliberate hypothesis testing. Through
systematic comparisons of baseline and our proposed agentic models, we
demonstrate that models equipped with external knowledge sources and iterative
reasoning outperform single-pass approaches in both accuracy and
interpretability. LingBench++ offers a comprehensive foundation for advancing
linguistically grounded, culturally informed, and cognitively plausible
reasoning in LLMs.
</summary>
    <author>
      <name>Da-Chen Lian</name>
    </author>
    <author>
      <name>Ri-Sheng Huang</name>
    </author>
    <author>
      <name>Pin-Er Chen</name>
    </author>
    <author>
      <name>Chunki Lim</name>
    </author>
    <author>
      <name>You-Kuan Lin</name>
    </author>
    <author>
      <name>Guan-Yu Tseng</name>
    </author>
    <author>
      <name>Zi-Cheng Yang</name>
    </author>
    <author>
      <name>Shu-Kai Hsieh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">41 pages, 17 figures, 10 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2507.16809v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2507.16809v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2507.16784v1</id>
    <updated>2025-07-22T17:30:04Z</updated>
    <published>2025-07-22T17:30:04Z</published>
    <title>Beyond Context Limits: Subconscious Threads for Long-Horizon Reasoning</title>
    <summary>  To break the context limits of large language models (LLMs) that bottleneck
reasoning accuracy and efficiency, we propose the Thread Inference Model (TIM),
a family of LLMs trained for recursive and decompositional problem solving, and
TIMRUN, an inference runtime enabling long-horizon structured reasoning beyond
context limits. Together, TIM hosted on TIMRUN supports virtually unlimited
working memory and multi-hop tool calls within a single language model
inference, overcoming output limits, positional-embedding constraints, and
GPU-memory bottlenecks. Performance is achieved by modeling natural language as
reasoning trees measured by both length and depth instead of linear sequences.
The reasoning trees consist of tasks with thoughts, recursive subtasks, and
conclusions based on the concept we proposed in Schroeder et al, 2025. During
generation, we maintain a working memory that retains only the key-value states
of the most relevant context tokens, selected by a rule-based subtask-pruning
mechanism, enabling reuse of positional embeddings and GPU memory pages
throughout reasoning. Experimental results show that our system sustains high
inference throughput, even when manipulating up to 90% of the KV cache in GPU
memory. It also delivers accurate reasoning on mathematical tasks and handles
information retrieval challenges that require long-horizon reasoning and
multi-hop tool use.
</summary>
    <author>
      <name>Hongyin Luo</name>
    </author>
    <author>
      <name>Nathaniel Morgan</name>
    </author>
    <author>
      <name>Tina Li</name>
    </author>
    <author>
      <name>Derek Zhao</name>
    </author>
    <author>
      <name>Ai Vy Ngo</name>
    </author>
    <author>
      <name>Philip Schroeder</name>
    </author>
    <author>
      <name>Lijie Yang</name>
    </author>
    <author>
      <name>Assaf Ben-Kish</name>
    </author>
    <author>
      <name>Jack O'Brien</name>
    </author>
    <author>
      <name>James Glass</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Research preview</arxiv:comment>
    <link href="http://arxiv.org/abs/2507.16784v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2507.16784v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2507.16777v1</id>
    <updated>2025-07-22T17:23:36Z</updated>
    <published>2025-07-22T17:23:36Z</published>
    <title>Silicate mineralogy and bulk composition of exoplanetary material in
  polluted white dwarfs</title>
    <summary>  White dwarf planetary systems uniquely link the bulk elemental composition of
exoplanetary material to the mineralogy as photospheric abundances can be
compared to circumstellar dust mineralogy. This study re-examines Spitzer/IRS
spectra of eight white dwarfs with both circumstellar dust and photospheric
metals. All systems show 10$\mu$m silicate emission features consistent with a
mixture of olivine and pyroxene silicates, with varying dominance. New Hubble
Space Telescope ultraviolet spectroscopic observations of two of these systems,
GD56 and WD1150-153, reveal that both are accreting dry, rocky material.
WD1150-153 is accreting material consistent with Bulk Earth, while GD56 is
accreting core-rich material with an inferred core mass fraction of
0.59$^{+0.08}_{-0.09}$ (0.37$^{+0.08}_{-0.08}$ by mole). A comparison between
the bulk elemental composition of the accreted planetary material and the dust
mineralogy of the eight systems reveals a tentative correlation between the
dominant silicate mineralogy and the Mg/Si ratio, indicating that the
circumstellar and photospheric material are compositionally similar. This
suggests that rapid and well-mixed accretion is occurring with minimal
compositional alteration. Furthermore, new GGCHEM equilibrium chemistry models
confirm that Mg-rich planetary material preferentially forms olivine-rich dust,
highlighting the importance of equilibrium in planetary chemistry and that a
host star or rock's Mg/Si can be used to predict whether its silicate
mineralogy is olivine- or pyroxene-dominated, influencing its capacity to
structurally store water, recycle key nutrients, and possibly habitability.
</summary>
    <author>
      <name>Laura K. Rogers</name>
    </author>
    <author>
      <name>Amy Bonsor</name>
    </author>
    <author>
      <name>Érika Le Bourdais</name>
    </author>
    <author>
      <name>Siyi Xu</name>
    </author>
    <author>
      <name>Kate Y. L. Su</name>
    </author>
    <author>
      <name>Benjamin Richards</name>
    </author>
    <author>
      <name>Andrew Buchan</name>
    </author>
    <author>
      <name>Nicholas P. Ballering</name>
    </author>
    <author>
      <name>Marc Brouwers</name>
    </author>
    <author>
      <name>Patrick Dufour</name>
    </author>
    <author>
      <name>Markus Kissler-Patig</name>
    </author>
    <author>
      <name>Carl Melis</name>
    </author>
    <author>
      <name>Ben Zuckerman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication in MNRAS</arxiv:comment>
    <link href="http://arxiv.org/abs/2507.16777v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2507.16777v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.EP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.EP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.SR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2507.16776v2</id>
    <updated>2025-07-23T10:28:12Z</updated>
    <published>2025-07-22T17:23:04Z</published>
    <title>Can we have it all? Non-asymptotically valid and asymptotically exact
  confidence intervals for expectations and linear regressions</title>
    <summary>  We contribute to bridging the gap between large- and finite-sample inference
by studying confidence sets (CSs) that are both non-asymptotically valid and
asymptotically exact uniformly (NAVAE) over semi-parametric statistical models.
NAVAE CSs are not easily obtained; for instance, we show they do not exist over
the set of Bernoulli distributions. We first derive a generic sufficient
condition: NAVAE CSs are available as soon as uniform asymptotically exact CSs
are. Second, building on that connection, we construct closed-form NAVAE
confidence intervals (CIs) in two standard settings -- scalar expectations and
linear combinations of OLS coefficients -- under moment conditions only. For
expectations, our sole requirement is a bounded kurtosis. In the OLS case, our
moment constraints accommodate heteroskedasticity and weak exogeneity of the
regressors. Under those conditions, we enlarge the Central Limit Theorem-based
CIs, which are asymptotically exact, to ensure non-asymptotic guarantees. Those
modifications vanish asymptotically so that our CIs coincide with the classical
ones in the limit. We illustrate the potential and limitations of our approach
through a simulation study.
</summary>
    <author>
      <name>Alexis Derumigny</name>
    </author>
    <author>
      <name>Lucas Girard</name>
    </author>
    <author>
      <name>Yannick Guyonvarch</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">69 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2507.16776v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2507.16776v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="econ.EM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62G15, 62J05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2507.16773v1</id>
    <updated>2025-07-22T17:21:36Z</updated>
    <published>2025-07-22T17:21:36Z</published>
    <title>When LLMs Copy to Think: Uncovering Copy-Guided Attacks in Reasoning
  LLMs</title>
    <summary>  Large Language Models (LLMs) have become integral to automated code analysis,
enabling tasks such as vulnerability detection and code comprehension. However,
their integration introduces novel attack surfaces. In this paper, we identify
and investigate a new class of prompt-based attacks, termed Copy-Guided Attacks
(CGA), which exploit the inherent copying tendencies of reasoning-capable LLMs.
By injecting carefully crafted triggers into external code snippets,
adversaries can induce the model to replicate malicious content during
inference. This behavior enables two classes of vulnerabilities: inference
length manipulation, where the model generates abnormally short or excessively
long reasoning traces; and inference result manipulation, where the model
produces misleading or incorrect conclusions. We formalize CGA as an
optimization problem and propose a gradient-based approach to synthesize
effective triggers. Empirical evaluation on state-of-the-art reasoning LLMs
shows that CGA reliably induces infinite loops, premature termination, false
refusals, and semantic distortions in code analysis tasks. While highly
effective in targeted settings, we observe challenges in generalizing CGA
across diverse prompts due to computational constraints, posing an open
question for future research. Our findings expose a critical yet underexplored
vulnerability in LLM-powered development pipelines and call for urgent advances
in prompt-level defense mechanisms.
</summary>
    <author>
      <name>Yue Li</name>
    </author>
    <author>
      <name>Xiao Li</name>
    </author>
    <author>
      <name>Hao Wu</name>
    </author>
    <author>
      <name>Yue Zhang</name>
    </author>
    <author>
      <name>Fengyuan Xu</name>
    </author>
    <author>
      <name>Xiuzhen Cheng</name>
    </author>
    <author>
      <name>Sheng Zhong</name>
    </author>
    <link href="http://arxiv.org/abs/2507.16773v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2507.16773v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2507.16756v1</id>
    <updated>2025-07-22T16:46:23Z</updated>
    <published>2025-07-22T16:46:23Z</published>
    <title>Efficient Bayesian Inference for Discretely Observed Continuous Time
  Markov Chains</title>
    <summary>  Inference for continuous-time Markov chains (CTMCs) becomes challenging when
the process is only observed at discrete time points. The exact likelihood is
intractable, and existing methods often struggle even in medium-dimensional
state-spaces. We propose a scalable Bayesian framework for CTMC inference based
on a pseudo-likelihood that bypasses the need for the full intractable
likelihood. Our approach jointly estimates the probability transition matrix
and a biorthogonal spectral decomposition of the generator, enabling an
efficient Gibbs sampling procedure that obeys embeddability. Existing methods
typically integrate out the unobserved transitions, which becomes
computationally burdensome as the number of data or dimensions increase. The
computational cost of our method is near-invariant in the number of data and
scales well to medium-high dimensions. We justify our pseudo-likelihood
approach by establishing theoretical guarantees, including a Bernstein-von
Mises theorem for the probability transition matrix and posterior consistency
for the spectral parameters of the generator. Through simulation and
applications, we showcase the flexibility and robustness of our approach,
offering a tractable and scalable approach to Bayesian inference for CTMCs.
</summary>
    <author>
      <name>Tao Tang</name>
    </author>
    <author>
      <name>Lachlan Astfalck</name>
    </author>
    <author>
      <name>David Dunson</name>
    </author>
    <link href="http://arxiv.org/abs/2507.16756v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2507.16756v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2507.16746v1</id>
    <updated>2025-07-22T16:35:36Z</updated>
    <published>2025-07-22T16:35:36Z</published>
    <title>Zebra-CoT: A Dataset for Interleaved Vision Language Reasoning</title>
    <summary>  Humans often use visual aids, for example diagrams or sketches, when solving
complex problems. Training multimodal models to do the same, known as Visual
Chain of Thought (Visual CoT), is challenging due to: (1) poor off-the-shelf
visual CoT performance, which hinders reinforcement learning, and (2) the lack
of high-quality visual CoT training data. We introduce $\textbf{Zebra-CoT}$, a
diverse large-scale dataset with 182,384 samples, containing logically coherent
interleaved text-image reasoning traces. We focus on four categories of tasks
where sketching or visual reasoning is especially natural, spanning scientific
questions such as geometry, physics, and algorithms; 2D visual reasoning tasks
like visual search and jigsaw puzzles; 3D reasoning tasks including 3D
multi-hop inference, embodied and robot planning; visual logic problems and
strategic games like chess. Fine-tuning the Anole-7B model on the Zebra-CoT
training corpus results in an improvement of +12% in our test-set accuracy and
yields up to +13% performance gain on standard VLM benchmark evaluations.
Fine-tuning Bagel-7B yields a model that generates high-quality interleaved
visual reasoning chains, underscoring Zebra-CoT's effectiveness for developing
multimodal reasoning abilities. We open-source our dataset and models to
support development and evaluation of visual CoT.
</summary>
    <author>
      <name>Ang Li</name>
    </author>
    <author>
      <name>Charles Wang</name>
    </author>
    <author>
      <name>Kaiyu Yue</name>
    </author>
    <author>
      <name>Zikui Cai</name>
    </author>
    <author>
      <name>Ollie Liu</name>
    </author>
    <author>
      <name>Deqing Fu</name>
    </author>
    <author>
      <name>Peng Guo</name>
    </author>
    <author>
      <name>Wang Bill Zhu</name>
    </author>
    <author>
      <name>Vatsal Sharan</name>
    </author>
    <author>
      <name>Robin Jia</name>
    </author>
    <author>
      <name>Willie Neiswanger</name>
    </author>
    <author>
      <name>Furong Huang</name>
    </author>
    <author>
      <name>Tom Goldstein</name>
    </author>
    <author>
      <name>Micah Goldblum</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">dataset link:
  https://huggingface.co/datasets/multimodal-reasoning-lab/Zebra-CoT</arxiv:comment>
    <link href="http://arxiv.org/abs/2507.16746v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2507.16746v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2507.16731v1</id>
    <updated>2025-07-22T16:13:43Z</updated>
    <published>2025-07-22T16:13:43Z</published>
    <title>Collaborative Inference and Learning between Edge SLMs and Cloud LLMs: A
  Survey of Algorithms, Execution, and Open Challenges</title>
    <summary>  As large language models (LLMs) evolve, deploying them solely in the cloud or
compressing them for edge devices has become inadequate due to concerns about
latency, privacy, cost, and personalization. This survey explores a
collaborative paradigm in which cloud-based LLMs and edge-deployed small
language models (SLMs) cooperate across both inference and training. We present
a unified taxonomy of edge-cloud collaboration strategies. For inference, we
categorize approaches into task assignment, task division, and mixture-based
collaboration at both task and token granularity, encompassing adaptive
scheduling, resource-aware offloading, speculative decoding, and modular
routing. For training, we review distributed adaptation techniques, including
parameter alignment, pruning, bidirectional distillation, and
small-model-guided optimization. We further summarize datasets, benchmarks, and
deployment cases, and highlight privacy-preserving methods and vertical
applications. This survey provides the first systematic foundation for LLM-SLM
collaboration, bridging system and algorithm co-design to enable efficient,
scalable, and trustworthy edge-cloud intelligence.
</summary>
    <author>
      <name>Senyao Li</name>
    </author>
    <author>
      <name>Haozhao Wang</name>
    </author>
    <author>
      <name>Wenchao Xu</name>
    </author>
    <author>
      <name>Rui Zhang</name>
    </author>
    <author>
      <name>Song Guo</name>
    </author>
    <author>
      <name>Jingling Yuan</name>
    </author>
    <author>
      <name>Xian Zhong</name>
    </author>
    <author>
      <name>Tianwei Zhang</name>
    </author>
    <author>
      <name>Ruixuan Li</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">35 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2507.16731v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2507.16731v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2507.16722v1</id>
    <updated>2025-07-22T16:01:34Z</updated>
    <published>2025-07-22T16:01:34Z</published>
    <title>Ballot Design and Electoral Outcomes: The Role of Candidate Order and
  Party Affiliation</title>
    <summary>  We use causal inference to study how designing ballots with and without party
designations impacts electoral outcomes when partisan voters rely on
party-order cues to infer candidate affiliation in races without designations.
If the party orders of candidates in races with and without party designations
differ, these voters might cast their votes incorrectly. We identify a
quasi-randomized natural experiment with contest-level treatment assignment
pertaining to North Carolina judicial elections and use double machine learning
to accurately capture the magnitude of such incorrectly cast votes. Using
precinct-level election and demographic data, we estimate that 11.8% (95%
confidence interval: [4.0%, 19.6%]) of democratic partisan voters and 15.4%
(95% confidence interval: [7.8%, 23.1%]) of republican partisan voters cast
their votes incorrectly due to the difference in party orders. Our results
indicate that ballots mixing contests with and without party designations
mislead many voters, leading to outcomes that do not reflect true voter
preferences. To accurately capture voter intent, such ballot designs should be
avoided.
</summary>
    <author>
      <name>Alessandro Arlotto</name>
    </author>
    <author>
      <name>Alexandre Belloni</name>
    </author>
    <author>
      <name>Fei Fang</name>
    </author>
    <author>
      <name>Saša Pekeč</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">27 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2507.16722v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2507.16722v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2507.16718v1</id>
    <updated>2025-07-22T15:59:21Z</updated>
    <published>2025-07-22T15:59:21Z</published>
    <title>Temporally-Constrained Video Reasoning Segmentation and Automated
  Benchmark Construction</title>
    <summary>  Conventional approaches to video segmentation are confined to predefined
object categories and cannot identify out-of-vocabulary objects, let alone
objects that are not identified explicitly but only referred to implicitly in
complex text queries. This shortcoming limits the utility for video
segmentation in complex and variable scenarios, where a closed set of object
categories is difficult to define and where users may not know the exact object
category that will appear in the video. Such scenarios can arise in operating
room video analysis, where different health systems may use different workflows
and instrumentation, requiring flexible solutions for video analysis. Reasoning
segmentation (RS) now offers promise towards such a solution, enabling natural
language text queries as interaction for identifying object to segment.
However, existing video RS formulation assume that target objects remain
contextually relevant throughout entire video sequences. This assumption is
inadequate for real-world scenarios in which objects of interest appear,
disappear or change relevance dynamically based on temporal context, such as
surgical instruments that become relevant only during specific procedural
phases or anatomical structures that gain importance at particular moments
during surgery. Our first contribution is the introduction of
temporally-constrained video reasoning segmentation, a novel task formulation
that requires models to implicitly infer when target objects become
contextually relevant based on text queries that incorporate temporal
reasoning. Since manual annotation of temporally-constrained video RS datasets
would be expensive and limit scalability, our second contribution is an
innovative automated benchmark construction method. Finally, we present
TCVideoRSBenchmark, a temporally-constrained video RS dataset containing 52
samples using the videos from the MVOR dataset.
</summary>
    <author>
      <name>Yiqing Shen</name>
    </author>
    <author>
      <name>Chenjia Li</name>
    </author>
    <author>
      <name>Chenxiao Fan</name>
    </author>
    <author>
      <name>Mathias Unberath</name>
    </author>
    <link href="http://arxiv.org/abs/2507.16718v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2507.16718v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
