<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-04-25T00:54:52Z -->
<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acausal%20inference%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:causal inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/SsRksLzRb0LuVhSmQ+N8WbAs+f8</id>
  <updated>2025-04-24T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">111149</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">10</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2504.16932v1</id>
    <updated>2025-04-23T17:59:56Z</updated>
    <published>2025-04-23T17:59:56Z</published>
    <title>Dispu$Ï„$able: the high cost of a low optical depth</title>
    <summary>  Recent Baryonic Acoustic Oscillation (BAO) measurements from the Dark Energy
Spectroscopic Instrument (DESI) are mildly discrepant ($2.2\sigma$) with the
Cosmic Microwave Background (CMB) when interpreted within $\Lambda$CDM. When
analyzing these data with extended cosmologies this inconsistency manifests as
a $\simeq3\sigma$ preference for sub-minimal neutrino mass or evolving dark
energy. It is known that the preference for sub-minimal neutrino mass from the
suppression of structure growth could be alleviated by increasing the optical
depth to reionization $\tau$. We show that, because the CMB-inferred $\tau$ is
negatively correlated with the matter fraction, a larger optical depth resolves
a similar preference from geometric constraints. Optical depths large enough to
resolve the neutrino mass tension ($\tau\sim0.09)$ also reduce the preference
for evolving dark energy from $\simeq3\sigma$ to $\simeq1.5\sigma$. Conversely,
within $\Lambda$CDM the combination of DESI BAO, high-$\ell$ CMB and CMB
lensing yields $\tau = 0.090 \pm 0.012$. The required increase in $\tau$ is in
$\simeq3-5\sigma$ tension with Planck low-$\ell$ polarization data when taken
at face value. While there is no evidence for systematics in the large-scale
Planck data, $\tau$ remains the least well-constrained $\Lambda$CDM parameter
and is far from its cosmic variance limit. The importance of $\tau$ for several
cosmological measurements strengthens the case for future large-scale CMB
experiments as well as direct probes of the epoch of reionization.
</summary>
    <author>
      <name>Noah Sailer</name>
    </author>
    <author>
      <name>Gerrit S. Farren</name>
    </author>
    <author>
      <name>Simone Ferraro</name>
    </author>
    <author>
      <name>Martin White</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 4 figures, comments welcome!</arxiv:comment>
    <link href="http://arxiv.org/abs/2504.16932v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.16932v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.16884v1</id>
    <updated>2025-04-23T17:00:45Z</updated>
    <published>2025-04-23T17:00:45Z</published>
    <title>Do Large Language Models know who did what to whom?</title>
    <summary>  Large Language Models (LLMs) are commonly criticized for not understanding
language. However, many critiques focus on cognitive abilities that, in humans,
are distinct from language processing. Here, we instead study a kind of
understanding tightly linked to language: inferring who did what to whom
(thematic roles) in a sentence. Does the central training objective of
LLMs-word prediction-result in sentence representations that capture thematic
roles? In two experiments, we characterized sentence representations in four
LLMs. In contrast to human similarity judgments, in LLMs the overall
representational similarity of sentence pairs reflected syntactic similarity
but not whether their agent and patient assignments were identical vs.
reversed. Furthermore, we found little evidence that thematic role information
was available in any subset of hidden units. However, some attention heads
robustly captured thematic roles, independently of syntax. Therefore, LLMs can
extract thematic roles but, relative to humans, this information influences
their representations more weakly.
</summary>
    <author>
      <name>Joseph M. Denning</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Hannah</arxiv:affiliation>
    </author>
    <author>
      <name> Xiaohan</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Hannah</arxiv:affiliation>
    </author>
    <author>
      <name> Guo</name>
    </author>
    <author>
      <name>Bryor Snefjella</name>
    </author>
    <author>
      <name>Idan A. Blank</name>
    </author>
    <link href="http://arxiv.org/abs/2504.16884v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.16884v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.16868v1</id>
    <updated>2025-04-23T16:44:24Z</updated>
    <published>2025-04-23T16:44:24Z</published>
    <title>Hint towards inconsistency between BAO and Supernovae Dataset: The
  Evidence of Redshift Evolving Dark Energy from DESI DR2 is Absent</title>
    <summary>  The combination of independent cosmological datasets is a route towards
precision and accurate inference of the cosmological parameters if these
observations are not contaminated by systematic effects. However, the presence
of unknown systematics present in differrent datasets can lead to a biased
inference of the cosmological parameters. In this work, we test the consistency
of the two independent tracers of the low-redshift cosmic expansion, namely the
supernovae dataset from Pantheon$+$ and the BAO dataset from DESI DR2 using the
distance duality relation which is a cornerstone relation in cosmology under
the framework of General Relativity. We find that these datasets violate the
distance duality relation and show a signature of redshift evolution, hinting
toward unaccounted physical effects or observational artifacts. Coincidentally
this effect mimics a redshift evolving dark energy scenario when supernovae
dataset and DESI datasets are combined without accounting for this
inconsistency. Accounting for this effect in the likelihood refutes the
previous claim of evidence of non-cosmological constant as dark energy model
from DESI DR2, and shows a result consistent with cosmological constant with
$w_0= -0.92\pm 0.08$ and $w_a= -0.49^{+0.33}_{-0.36}$. This indicates that the
current conclusion from DESI DR2 in combination with Pantheon$+$ is likely due
to the combination of two inconsistent datasets resulting in precise but
inaccurate inference of cosmological parameters. In the future, tests of this
kind for the consistency between different cosmological datasets will be
essential for robust inference of cosmological parameters and for deciphering
unaccounted physical effects or observational artifacts from supernovae and BAO
datasets.
</summary>
    <author>
      <name>Samsuzzaman Afroz</name>
    </author>
    <author>
      <name>Suvodip Mukherjee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 Pages, 7 figures, To be submitted to JCAP</arxiv:comment>
    <link href="http://arxiv.org/abs/2504.16868v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.16868v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="gr-qc" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.16856v1</id>
    <updated>2025-04-23T16:23:17Z</updated>
    <published>2025-04-23T16:23:17Z</published>
    <title>Emo Pillars: Knowledge Distillation to Support Fine-Grained
  Context-Aware and Context-Less Emotion Classification</title>
    <summary>  Most datasets for sentiment analysis lack context in which an opinion was
expressed, often crucial for emotion understanding, and are mainly limited by a
few emotion categories. Foundation large language models (LLMs) like GPT-4
suffer from over-predicting emotions and are too resource-intensive. We design
an LLM-based data synthesis pipeline and leverage a large model, Mistral-7b,
for the generation of training examples for more accessible, lightweight
BERT-type encoder models. We focus on enlarging the semantic diversity of
examples and propose grounding the generation into a corpus of narratives to
produce non-repetitive story-character-centered utterances with unique contexts
over 28 emotion classes. By running 700K inferences in 450 GPU hours, we
contribute with the dataset of 100K contextual and also 300K context-less
examples to cover both scenarios. We use it for fine-tuning pre-trained
encoders, which results in several Emo Pillars models. We show that Emo Pillars
models are highly adaptive to new domains when tuned to specific tasks such as
GoEmotions, ISEAR, IEMOCAP, and EmoContext, reaching the SOTA performance on
the first three. We also validate our dataset, conducting statistical analysis
and human evaluation, and confirm the success of our measures in utterance
diversification (although less for the neutral class) and context
personalization, while pointing out the need for improved handling of
out-of-taxonomy labels within the pipeline.
</summary>
    <author>
      <name>Alexander Shvets</name>
    </author>
    <link href="http://arxiv.org/abs/2504.16856v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.16856v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.16845v1</id>
    <updated>2025-04-23T16:09:33Z</updated>
    <published>2025-04-23T16:09:33Z</published>
    <title>An accreting dwarf star orbiting the S-type giant star pi1 Gru</title>
    <summary>  Aims. We aim to characterize the properties of the inner companion of the
S-type AGB star pi1 Gru, and to identify plausible future evolution scenarios
for this triple system. Methods. We observed pi1 Gru with ALMA and VLT/SPHERE.
In addition, we collected archival photometry data and used the Hipparcos-Gaia
proper motion anomaly. We derive the best orbital parameters from Bayesian
inference. Results. The inner companion, pi1 Gru C was located at 37.4 +/- 2.0
mas from the primary in June-July 2019 (projected separation of 6.05 +/- 0.55
au at 161.7 +/- 11.7 pc). The best orbital solution gives a companion mass of
0.86 (+0.22/-0.20) Msun (using the derived mass of the primary), and a
semi-major axis of 7.05 (+0.54/-0.57) au. This leads to an orbital period of
11.0 (+1.7/-1.5) yr. The best solution is an elliptical orbit with eccentricity
e = 0.35 (+0.18/-0.17), but a circular orbit cannot be totally excluded. The
close companion can either be a K1V (F9.5V/K7V) star or a white dwarf. The
ultraviolet and millimeter continuum photometry are consistent with the
presence of an accretion disk around the close companion. The ultraviolet
emission could then either originate in hot spots in an overall cooler disk, or
also from a hot disk in case the companion is a white dwarf. Conclusions.
Though the close companion and the AGB star are interacting, and an accretion
disk is observed around the companion, the mass-accretion rate is too low to
cause a Ia supernova but could produce novae every ~900 yr. Short wavelength
spatially resolved observations are needed to further constrain the nature of
the C companion. Searches for close-in companions similar to this system will
help to better understand the physics of mass- and angular-momentum transfer,
and orbital evolution in the late evolutionary stages.
</summary>
    <author>
      <name>M. MontargÃ¨s</name>
    </author>
    <author>
      <name>J. Malfait</name>
    </author>
    <author>
      <name>M. Esseldeurs</name>
    </author>
    <author>
      <name>A. de Koter</name>
    </author>
    <author>
      <name>F. Baron</name>
    </author>
    <author>
      <name>P. Kervella</name>
    </author>
    <author>
      <name>T. Danilovich</name>
    </author>
    <author>
      <name>A. M. S. Richards</name>
    </author>
    <author>
      <name>R. Sahai</name>
    </author>
    <author>
      <name>I. McDonald</name>
    </author>
    <author>
      <name>T. Khouri</name>
    </author>
    <author>
      <name>S. Shetye</name>
    </author>
    <author>
      <name>A. Zijlstra</name>
    </author>
    <author>
      <name>M. Van de Sande</name>
    </author>
    <author>
      <name>I. El Mellah</name>
    </author>
    <author>
      <name>F. Herpin</name>
    </author>
    <author>
      <name>L. Siess</name>
    </author>
    <author>
      <name>S. Etoka</name>
    </author>
    <author>
      <name>D. Gobrecht</name>
    </author>
    <author>
      <name>L. Marinho</name>
    </author>
    <author>
      <name>S. H. J. WallstrÃ¶m</name>
    </author>
    <author>
      <name>K. T. Wong</name>
    </author>
    <author>
      <name>aJ. Yates</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publications in Astronomy &amp; Astrophysics. 21 pages, 10+2
  figures, 3+4 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2504.16845v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.16845v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.SR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.SR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.16834v1</id>
    <updated>2025-04-23T15:56:28Z</updated>
    <published>2025-04-23T15:56:28Z</published>
    <title>Improving Significant Wave Height Prediction Using Chronos Models</title>
    <summary>  Accurate wave height prediction is critical for maritime safety and coastal
resilience, yet conventional physics-based models and traditional machine
learning methods face challenges in computational efficiency and nonlinear
dynamics modeling. This study introduces Chronos, the first implementation of a
large language model (LLM)-powered temporal architecture (Chronos) optimized
for wave forecasting. Through advanced temporal pattern recognition applied to
historical wave data from three strategically chosen marine zones in the
Northwest Pacific basin, our framework achieves multimodal improvements: (1)
14.3% reduction in training time with 2.5x faster inference speed compared to
PatchTST baselines, achieving 0.575 mean absolute scaled error (MASE) units;
(2) superior short-term forecasting (1-24h) across comprehensive metrics; (3)
sustained predictive leadership in extended-range forecasts (1-120h); and (4)
demonstrated zero-shot capability maintaining median performance (rank 4/12)
against specialized operational models. This LLM-enhanced temporal modeling
paradigm establishes a new standard in wave prediction, offering both
computationally efficient solutions and a transferable framework for complex
geophysical systems modeling.
</summary>
    <author>
      <name>Yilin Zhai</name>
    </author>
    <author>
      <name>Hongyuan Shi</name>
    </author>
    <author>
      <name>Chao Zhan</name>
    </author>
    <author>
      <name>Qing Wang</name>
    </author>
    <author>
      <name>Zaijin You</name>
    </author>
    <author>
      <name>Nan Wang</name>
    </author>
    <link href="http://arxiv.org/abs/2504.16834v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.16834v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.16800v1</id>
    <updated>2025-04-23T15:20:39Z</updated>
    <published>2025-04-23T15:20:39Z</published>
    <title>Array Partitioning Based Near-Field Attitude and Location Estimation</title>
    <summary>  This paper studies a passive source localization system, where a single base
station (BS) is employed to estimate the positions and attitudes of multiple
mobile stations (MSs). The BS and the MSs are equipped with uniform rectangular
arrays, and the MSs are located in the near-field region of the BS array. To
avoid the difficulty of tackling the problem directly based on the near-field
signal model, we establish a subarray-wise far-field received signal model. In
this model, the entire BS array is divided into multiple subarrays to ensure
that each MS is in the far-field region of each BS subarray. By exploiting the
angles of arrival (AoAs) of an MS antenna at different BS subarrays, we
formulate the attitude and location estimation problem under the Bayesian
inference framework. Based on the factor graph representation of the
probabilistic problem model, a message passing algorithm named array
partitioning based pose and location estimation (APPLE) is developed to solve
this problem. An estimation-error lower bound is obtained as a performance
benchmark of the proposed algorithm. Numerical results demonstrate that the
proposed APPLE algorithm outperforms other baseline methods in the accuracy of
position and attitude estimation.
</summary>
    <author>
      <name>Mingchen Zhang</name>
    </author>
    <author>
      <name>Xiaojun Yuan</name>
    </author>
    <author>
      <name>Boyu Teng</name>
    </author>
    <author>
      <name>Li Wang</name>
    </author>
    <link href="http://arxiv.org/abs/2504.16800v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.16800v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.16797v1</id>
    <updated>2025-04-23T15:18:34Z</updated>
    <published>2025-04-23T15:18:34Z</published>
    <title>The extended adjoint state and nonlinearity in correlation-based passive
  imaging</title>
    <summary>  This articles investigates physics-based passive imaging problem, wherein one
infers an unknown medium using ambient noise and correlation of the noise
signal. We develop a general backpropagation framework via the so-called
extended adjoint state, suitable for any linear PDE; crucially, this approach
reduces by half the number of required PDE solves. Applications to several
different PDE models demonstrate the universality of our method. In addition,
we analyze the nonlinearity of the correlated model, revealing a surprising
tangential cone condition-like structure, thereby advancing the state of the
art towards a convergence guarantee for regularized reconstruction in passive
imaging.
</summary>
    <author>
      <name>Tram Thi Ngoc Nguyen</name>
    </author>
    <link href="http://arxiv.org/abs/2504.16797v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.16797v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65M32, 65J22, 35R30" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.16795v1</id>
    <updated>2025-04-23T15:15:06Z</updated>
    <published>2025-04-23T15:15:06Z</published>
    <title>Random Long-Context Access for Mamba via Hardware-aligned Hierarchical
  Sparse Attention</title>
    <summary>  A key advantage of Recurrent Neural Networks (RNNs) over Transformers is
their linear computational and space complexity enables faster training and
inference for long sequences. However, RNNs are fundamentally unable to
randomly access historical context, and simply integrating attention mechanisms
may undermine their efficiency advantages. To overcome this limitation, we
propose \textbf{H}ierarchical \textbf{S}parse \textbf{A}ttention (HSA), a novel
attention mechanism that enhances RNNs with long-range random access
flexibility while preserving their merits in efficiency and length
generalization. HSA divides inputs into chunks, selecting the top-$k$ chunks
and hierarchically aggregates information. The core innovation lies in learning
token-to-chunk relevance based on fine-grained token-level information inside
each chunk. This approach enhances the precision of chunk selection across both
in-domain and out-of-domain context lengths. To make HSA efficient, we further
introduce a hardware-aligned kernel design. By combining HSA with Mamba, we
introduce RAMba, which achieves perfect accuracy in passkey retrieval across 64
million contexts despite pre-training on only 4K-length contexts, and
significant improvements on various downstream tasks, with nearly constant
memory footprint. These results show RAMba's huge potential in long-context
modeling.
</summary>
    <author>
      <name>Xiang Hu</name>
    </author>
    <author>
      <name>Jiaqi Leng</name>
    </author>
    <author>
      <name>Jun Zhao</name>
    </author>
    <author>
      <name>Kewei Tu</name>
    </author>
    <author>
      <name>Wei Wu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">preprint</arxiv:comment>
    <link href="http://arxiv.org/abs/2504.16795v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.16795v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.16792v1</id>
    <updated>2025-04-23T15:10:55Z</updated>
    <published>2025-04-23T15:10:55Z</published>
    <title>Preemption Aware Task Scheduling for Priority and Deadline Constrained
  DNN Inference Task Offloading in Homogeneous Mobile-Edge Networks</title>
    <summary>  This paper addresses the computational offloading of Deep Neural Networks
(DNNs) to nearby devices with similar processing capabilities, to avoid the
larger communication delays incurred for cloud offloading. We present a
preemption aware scheduling approach for priority and deadline constrained task
offloading in homogeneous edge networks. Our scheduling approach consists of
two distinct scheduling algorithms, designed to accommodate the differing
requirements of high and low priority tasks. To satisfy a task's deadline, our
scheduling approach considers the availability of both communication and
computational resources in the network when making placements in both the
current time-slot and future time-slots. The scheduler implements a
deadline-aware preemption mechanism to guarantee resource access to high
priority tasks. When low-priority tasks are selected for preemption, the
scheduler will attempt to reallocate them if possible before their deadline. We
implement this scheduling approach into a task offloading system which we
evaluate empirically in the real-world on a network of edge devices composed of
four Raspberry Pi 2 Model B's. We evaluate this system under against a version
without a task preemption mechanism as well as workstealing approaches to
compare the impact on high priority task completion and the ability to complete
overall frames. These solutions are evaluated under a workload of 1296 frames.
Our findings show that our scheduling approach allows for 99\% of high-priority
tasks to complete while also providing a 3 - 8\% increase in the number of
frames fully classified end-to-end over both workstealing approaches and
systems without a preemption mechanism.
</summary>
    <author>
      <name>Jamie Cotter</name>
    </author>
    <author>
      <name>Ignacio Castineiras</name>
    </author>
    <author>
      <name>Donna O'Shea</name>
    </author>
    <author>
      <name>Victor Cionca</name>
    </author>
    <link href="http://arxiv.org/abs/2504.16792v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.16792v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
