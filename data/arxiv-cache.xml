<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2026-01-21T01:03:50Z -->
<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/" xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns="http://www.w3.org/2005/Atom">
  <id>https://arxiv.org/api/p6EyKyP4fMY/66n9Ev8E79F7KlI</id>
  <title>arXiv Query: search_query=all:causal OR all:inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <updated>2026-01-21T01:03:50Z</updated>
  <link href="https://arxiv.org/api/query?search_query=all:causal+OR+all:inference&amp;start=0&amp;max_results=10&amp;id_list=" type="application/atom+xml"/>
  <opensearch:itemsPerPage>10</opensearch:itemsPerPage>
  <opensearch:totalResults>131065</opensearch:totalResults>
  <opensearch:startIndex>0</opensearch:startIndex>
  <entry>
    <id>http://arxiv.org/abs/2601.11520v1</id>
    <title>Empirical Coordination over Markov Channel with Independent Source</title>
    <updated>2026-01-16T18:59:06Z</updated>
    <link href="https://arxiv.org/abs/2601.11520v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.11520v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>We study joint source-channel coding over Markov channels through the empirical coordination framework. More specifically, we aim at determining the empirical distributions of source and channel symbols that can be induced by a coding scheme. We consider strictly causal encoders that generate channel inputs, without access to the past channel states, henceforth driving the current Markov state evolution. Our main result is the single-letter inner and outer bounds of the set of achievable joint distributions, coordinating all the symbols in the network. To establish the inner bound, we introduce a new notion of typicality, the input-driven Markov typicality, and develop its fundamental properties. Contrary to the classical block-Markov coding schemes that rely on blockwise independence for discrete memoryless channels, our analysis directly exploits the Markov channel structure and improves beyond the independence-based arguments.</summary>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-16T18:59:06Z</published>
    <arxiv:primary_category term="cs.IT"/>
    <author>
      <name>Mengyuan Zhao</name>
    </author>
    <author>
      <name>Maël Le Treust</name>
    </author>
    <author>
      <name>Tobias J. Oechtering</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.11518v1</id>
    <title>How Long Is a Piece of String? A Brief Empirical Analysis of Tokenizers</title>
    <updated>2026-01-16T18:58:29Z</updated>
    <link href="https://arxiv.org/abs/2601.11518v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.11518v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Frontier LLMs are increasingly utilised across academia, society and industry. A commonly used unit for comparing models, their inputs and outputs, and estimating inference pricing is the token. In general, tokens are used as a stable currency, assumed to be broadly consistent across tokenizers and contexts, enabling direct comparisons. However, tokenization varies significantly across models and domains of text, making naive interpretation of token counts problematic. We quantify this variation by providing a comprehensive empirical analysis of tokenization, exploring the compression of sequences to tokens across different distributions of textual data. Our analysis challenges commonly held heuristics about token lengths, finding them to be overly simplistic. We hope the insights of our study add clarity and intuition toward tokenization in contemporary LLMs.</summary>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-16T18:58:29Z</published>
    <arxiv:primary_category term="cs.CL"/>
    <author>
      <name>Jonathan Roberts</name>
    </author>
    <author>
      <name>Kai Han</name>
    </author>
    <author>
      <name>Samuel Albanie</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.11491v1</id>
    <title>Extractive summarization on a CMOS Ising machine</title>
    <updated>2026-01-16T18:14:02Z</updated>
    <link href="https://arxiv.org/abs/2601.11491v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.11491v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Extractive summarization (ES) aims to generate a concise summary by selecting a subset of sentences from a document while maximizing relevance and minimizing redundancy. Although modern ES systems achieve high accuracy using powerful neural models, their deployment typically relies on CPU or GPU infrastructures that are energy-intensive and poorly suited for real-time inference in resource-constrained environments. In this work, we explore the feasibility of implementing McDonald-style extractive summarization on a low-power CMOS coupled oscillator-based Ising machine (COBI) that supports integer-valued, all-to-all spin couplings. We first propose a hardware-aware Ising formulation that reduces the scale imbalance between local fields and coupling terms, thereby improving robustness to coefficient quantization: this method can be applied to any problem formulation that requires k of n variables to be chosen. We then develop a complete ES pipeline including (i) stochastic rounding and iterative refinement to compensate for precision loss, and (ii) a decomposition strategy that partitions a large ES problem into smaller Ising subproblems that can be efficiently solved on COBI and later combined. Experimental results on the CNN/DailyMail dataset show that our pipeline can produce high-quality summaries using only integer-coupled Ising hardware with limited precision. COBI achieves 3-4.5x runtime speedups compared to a brute-force method, which is comparable to software Tabu search, and two to three orders of magnitude reductions in energy, while maintaining competitive summary quality. These results highlight the potential of deploying CMOS Ising solvers for real-time, low-energy text summarization on edge devices.</summary>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.ET" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-16T18:14:02Z</published>
    <arxiv:primary_category term="cs.LG"/>
    <author>
      <name>Ziqing Zeng</name>
    </author>
    <author>
      <name>Abhimanyu Kumar</name>
    </author>
    <author>
      <name>Chris H. Kim</name>
    </author>
    <author>
      <name>Ulya R. Karpuzcu</name>
    </author>
    <author>
      <name>Sachin S. Sapatnekar</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.11487v1</id>
    <title>Space-Optimal, Computation-Optimal, Topology-Agnostic, Throughput-Scalable Causal Delivery through Hybrid Buffering</title>
    <updated>2026-01-16T18:08:09Z</updated>
    <link href="https://arxiv.org/abs/2601.11487v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.11487v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Message delivery respecting causal ordering (causal delivery) is one of the most classic and widely useful abstraction for inter-process communication in a distributed system. Most approaches tag messages with causality information and buffer them at the receiver until they can be safely delivered. Except for specific approaches that exploit communication topology, therefore not generally applicable, they incur a metadata overhead which is prohibitive for a large number of processes. Much less used are the approaches that enforce causal order by buffering messages at the sender, until it is safe to release them to the network, as the classic algorithm has too many drawbacks. In this paper, first we discuss the limitations of sender-only buffering approaches and introduce the Sender Permission to Send (SPS) enforcement strategy, showing that SPS + FIFO implies Causal. We analyze a recent sender-buffering algorithm, Cykas, which follows SPS + FIFO, albeit very conservatively, pointing out throughput scalability and liveness issues. Then, we introduce a novel SPS + FIFO based algorithm, which adopts a new hybrid approach: enforcing causality by combining sender-buffering to enforce SPS and receiver-buffering to enforce FIFO. The algorithm overcomes limitations of sender-only buffering, and achieves effectively constant metadata size per message. By a careful choice of data-structures, the algorithm is also computationally-optimal, with amortized effectively constant processing overhead. As far as we know, there is no other topology-agnostic causal delivery algorithm with these properties.</summary>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-16T18:08:09Z</published>
    <arxiv:comment>16 pages, 5 figures</arxiv:comment>
    <arxiv:primary_category term="cs.DC"/>
    <author>
      <name>Paulo Sérgio Almeida</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.11464v1</id>
    <title>MHA2MLA-VLM: Enabling DeepSeek's Economical Multi-Head Latent Attention across Vision-Language Models</title>
    <updated>2026-01-16T17:45:34Z</updated>
    <link href="https://arxiv.org/abs/2601.11464v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.11464v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>As vision-language models (VLMs) tackle increasingly complex and multimodal tasks, the rapid growth of Key-Value (KV) cache imposes significant memory and computational bottlenecks during inference. While Multi-Head Latent Attention (MLA) offers an effective means to compress the KV cache and accelerate inference, adapting existing VLMs to the MLA architecture without costly pretraining remains largely unexplored. In this work, we present MHA2MLA-VLM, a parameter-efficient and multimodal-aware framework for converting off-the-shelf VLMs to MLA. Our approach features two core techniques: (1) a modality-adaptive partial-RoPE strategy that supports both traditional and multimodal settings by selectively masking nonessential dimensions, and (2) a modality-decoupled low-rank approximation method that independently compresses the visual and textual KV spaces. Furthermore, we introduce parameter-efficient fine-tuning to minimize adaptation cost and demonstrate that minimizing output activation error, rather than parameter distance, substantially reduces performance loss. Extensive experiments on three representative VLMs show that MHA2MLA-VLM restores original model performance with minimal supervised data, significantly reduces KV cache footprint, and integrates seamlessly with KV quantization.</summary>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-16T17:45:34Z</published>
    <arxiv:primary_category term="cs.CV"/>
    <author>
      <name>Xiaoran Fan</name>
    </author>
    <author>
      <name>Zhichao Sun</name>
    </author>
    <author>
      <name>Tao Ji</name>
    </author>
    <author>
      <name>Lixing Shen</name>
    </author>
    <author>
      <name>Tao Gui</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.11447v1</id>
    <title>IMS: Intelligent Hardware Monitoring System for Secure SoCs</title>
    <updated>2026-01-16T17:10:17Z</updated>
    <link href="https://arxiv.org/abs/2601.11447v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.11447v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>In the modern Systems-on-Chip (SoC), the Advanced eXtensible Interface (AXI) protocol exhibits security vulnerabilities, enabling partial or complete denial-of-service (DoS) through protocol-violation attacks. The recent countermeasures lack a dedicated real-time protocol semantic analysis and evade protocol compliance checks. This paper tackles this AXI vulnerability issue and presents an intelligent hardware monitoring system (IMS) for real-time detection of AXI protocol violations. IMS is a hardware module leveraging neural networks to achieve high detection accuracy. For model training, we perform DoS attacks through header-field manipulation and systematic malicious operations, while recording AXI transactions to build a training dataset. We then deploy a quantization-optimized neural network, achieving 98.7% detection accuracy with &lt;=3% latency overhead, and throughput of &gt;2.5 million inferences/s. We subsequently integrate this IMS into a RISC-V SoC as a memory-mapped IP core to monitor its AXI bus. For demonstration and initial assessment for later ASIC integration, we implemented this IMS on an AMD Zynq UltraScale+ MPSoC ZCU104 board, showing an overall small hardware footprint (9.04% look-up-tables (LUTs), 0.23% DSP slices, and 0.70% flip-flops) and negligible impact on the overall design's achievable frequency. This demonstrates the feasibility of lightweight, security monitoring for resource-constrained edge environments.</summary>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-16T17:10:17Z</published>
    <arxiv:comment>The final version is accepted for publication at the Design, Automation &amp; Test in Europe Conference (DATE) 2026</arxiv:comment>
    <arxiv:primary_category term="cs.CR"/>
    <author>
      <name>Wadid Foudhaili</name>
    </author>
    <author>
      <name>Aykut Rencber</name>
    </author>
    <author>
      <name>Anouar Nechi</name>
    </author>
    <author>
      <name>Rainer Buchty</name>
    </author>
    <author>
      <name>Mladen Berekovic</name>
    </author>
    <author>
      <name>Andres Gomez</name>
    </author>
    <author>
      <name>Saleh Mulhem</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.11443v1</id>
    <title>Predict the Retrieval! Test time adaptation for Retrieval Augmented Generation</title>
    <updated>2026-01-16T17:07:01Z</updated>
    <link href="https://arxiv.org/abs/2601.11443v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.11443v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Retrieval-Augmented Generation (RAG) has emerged as a powerful approach for enhancing large language models' question-answering capabilities through the integration of external knowledge. However, when adapting RAG systems to specialized domains, challenges arise from distribution shifts, resulting in suboptimal generalization performance. In this work, we propose TTARAG, a test-time adaptation method that dynamically updates the language model's parameters during inference to improve RAG system performance in specialized domains. Our method introduces a simple yet effective approach where the model learns to predict retrieved content, enabling automatic parameter adjustment to the target domain. Through extensive experiments across six specialized domains, we demonstrate that TTARAG achieves substantial performance improvements over baseline RAG systems. Code available at https://github.com/sunxin000/TTARAG.</summary>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-16T17:07:01Z</published>
    <arxiv:primary_category term="cs.CL"/>
    <author>
      <name>Xin Sun</name>
    </author>
    <author>
      <name>Zhongqi Chen</name>
    </author>
    <author>
      <name>Qiang Liu</name>
    </author>
    <author>
      <name>Shu Wu</name>
    </author>
    <author>
      <name>Bowen Song</name>
    </author>
    <author>
      <name>Weiqiang Wang</name>
    </author>
    <author>
      <name>Zilei Wang</name>
    </author>
    <author>
      <name>Liang Wang</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.11442v1</id>
    <title>Map2Thought: Explicit 3D Spatial Reasoning via Metric Cognitive Maps</title>
    <updated>2026-01-16T17:02:46Z</updated>
    <link href="https://arxiv.org/abs/2601.11442v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.11442v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>We propose Map2Thought, a framework that enables explicit and interpretable spatial reasoning for 3D VLMs. The framework is grounded in two key components: Metric Cognitive Map (Metric-CogMap) and Cognitive Chain-of-Thought (Cog-CoT). Metric-CogMap provides a unified spatial representation by integrating a discrete grid for relational reasoning with a continuous, metric-scale representation for precise geometric understanding. Building upon the Metric-CogMap, Cog-CoT performs explicit geometric reasoning through deterministic operations, including vector operations, bounding-box distances, and occlusion-aware appearance order cues, producing interpretable inference traces grounded in 3D structure. Experimental results show that Map2Thought enables explainable 3D understanding, achieving 59.9% accuracy using only half the supervision, closely matching the 60.9% baseline trained with the full dataset. It consistently outperforms state-of-the-art methods by 5.3%, 4.8%, and 4.0% under 10%, 25%, and 50% training subsets, respectively, on the VSI-Bench.</summary>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-16T17:02:46Z</published>
    <arxiv:primary_category term="cs.CV"/>
    <author>
      <name>Xiangjun Gao</name>
    </author>
    <author>
      <name>Zhensong Zhang</name>
    </author>
    <author>
      <name>Dave Zhenyu Chen</name>
    </author>
    <author>
      <name>Songcen Xu</name>
    </author>
    <author>
      <name>Long Quan</name>
    </author>
    <author>
      <name>Eduardo Pérez-Pellitero</name>
    </author>
    <author>
      <name>Youngkyoon Jang</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.11436v1</id>
    <title>An Epidemiological Modeling Take on Religion Dynamics</title>
    <updated>2026-01-16T16:55:56Z</updated>
    <link href="https://arxiv.org/abs/2601.11436v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.11436v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Religions are among the most consequential social institutions, shaping collective identities, moral norms, and political organization across societies and historical periods. Nevertheless, despite extensive scholarship describing conversion, competition, and secularization, there is still no widely adopted formal model that captures religious dynamics over time within a unified, mechanistic framework. In this study, we propose an epidemiologically grounded model of religious change in which religions spread and compete analogously to co-circulating strains. The model extends multi-strain compartmental dynamics by distinguishing passive believers, active missionaries, and religious elites, and by incorporating demographic turnover and mutation-like splitting that endogenously generates new denominations. Using computer simulations, we show that the same mechanism reproduces canonical qualitative regimes, including emergence from rarity, rapid expansion, long-run coexistence, and transient rise-and-fall movements. A reduced calibration variant fits historical affiliation trajectories with parsimonious regime shifts in effective recruitment and disaffiliation, yielding interpretable signatures of changing social conditions. Finally, sensitivity analyses map sharp regime boundaries in parameter space, indicating that modest shifts in recruitment efficacy or retention among active spreaders can qualitatively alter long-run religious landscapes. These results establish a general, interpretable framework for studying religion as a dynamical diffusion process and provide a tool for comparative inference and counterfactual analysis in sociological research.</summary>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-16T16:55:56Z</published>
    <arxiv:primary_category term="physics.soc-ph"/>
    <author>
      <name>Bilge Taskin</name>
    </author>
    <author>
      <name>Teddy Lazebnik</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.11433v1</id>
    <title>Inter-patient ECG Arrhythmia Classification with LGNs and LUTNs</title>
    <updated>2026-01-16T16:55:36Z</updated>
    <link href="https://arxiv.org/abs/2601.11433v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.11433v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Deep Differentiable Logic Gate Networks (LGNs) and Lookup Table Networks (LUTNs) are demonstrated to be suitable for the automatic classification of electrocardiograms (ECGs) using the inter-patient paradigm. The methods are benchmarked using the MIT-BIH arrhythmia data set, achieving up to 94.28% accuracy and a $jκ$ index of 0.683 on a four-class classification problem. Our models use between 2.89k and 6.17k FLOPs, including preprocessing and readout, which is three to six orders of magnitude less compared to SOTA methods. A novel preprocessing method is utilized that attains superior performance compared to existing methods for both the mixed-patient and inter-patient paradigms. In addition, a novel method for training the Lookup Tables (LUTs) in LUTNs is devised that uses the Boolean equation of a multiplexer (MUX). Additionally, rate coding was utilized for the first time in these LGNs and LUTNs, enhancing the performance of LGNs. Furthermore, it is the first time that LGNs and LUTNs have been benchmarked on the MIT-BIH arrhythmia dataset using the inter-patient paradigm. Using an Artix 7 FPGA, between 2000 and 2990 LUTs were needed, and between 5 to 7 mW (i.e. 50 pJ to 70 pJ per inference) was estimated for running these models. The performance in terms of both accuracy and $jκ$-index is significantly higher compared to previous LGN results. These positive results suggest that one can utilize LGNs and LUTNs for the detection of arrhythmias at extremely low power and high speeds in heart implants or wearable devices, even for patients not included in the training set.</summary>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-16T16:55:36Z</published>
    <arxiv:primary_category term="cs.LG"/>
    <author>
      <name>Wout Mommen</name>
    </author>
    <author>
      <name>Lars Keuninckx</name>
    </author>
    <author>
      <name>Paul Detterer</name>
    </author>
    <author>
      <name>Achiel Colpaert</name>
    </author>
    <author>
      <name>Piet Wambacq</name>
    </author>
  </entry>
</feed>
