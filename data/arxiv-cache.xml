<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2026-01-14T01:04:14Z -->
<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/" xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns="http://www.w3.org/2005/Atom">
  <id>https://arxiv.org/api/p6EyKyP4fMY/66n9Ev8E79F7KlI</id>
  <title>arXiv Query: search_query=all:causal OR all:inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <updated>2026-01-14T01:04:15Z</updated>
  <link href="https://arxiv.org/api/query?search_query=all:causal+OR+all:inference&amp;start=0&amp;max_results=10&amp;id_list=" type="application/atom+xml"/>
  <opensearch:itemsPerPage>10</opensearch:itemsPerPage>
  <opensearch:totalResults>130722</opensearch:totalResults>
  <opensearch:startIndex>0</opensearch:startIndex>
  <entry>
    <id>http://arxiv.org/abs/2601.07826v1</id>
    <title>Histopathology-centered Computational Evolution of Spatial Omics: Integration, Mapping, and Foundation Models</title>
    <updated>2026-01-12T18:58:28Z</updated>
    <link href="https://arxiv.org/abs/2601.07826v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.07826v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Spatial omics (SO) technologies enable spatially resolved molecular profiling, while hematoxylin and eosin (H&amp;E) imaging remains the gold standard for morphological assessment in clinical pathology. Recent computational advances increasingly place H&amp;E images at the center of SO analysis, bridging morphology with transcriptomic, proteomic, and other spatial molecular modalities, and pushing resolution toward the single-cell level. In this survey, we systematically review the computational evolution of SO from a histopathology-centered perspective and organize existing methods into three paradigms: integration, which jointly models paired multimodal data; mapping, which infers molecular profiles from H&amp;E images; and foundation models, which learn generalizable representations from large-scale spatial datasets. We analyze how the role of H&amp;E images evolves across these paradigms from spatial context to predictive anchor and ultimately to representation backbone in response to practical constraints such as limited paired data and increasing resolution demands. We further summarize actionable modeling directions enabled by current architectures and delineate persistent gaps driven by data, biology, and technology that are unlikely to be resolved by model design alone. Together, this survey provides a histopathology-centered roadmap for developing and applying computational frameworks in SO.</summary>
    <category term="q-bio.GN" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-12T18:58:28Z</published>
    <arxiv:comment>30 pages, 5 figures</arxiv:comment>
    <arxiv:primary_category term="q-bio.GN"/>
    <author>
      <name>Ninghui Hao</name>
    </author>
    <author>
      <name>Xinxing Yang</name>
    </author>
    <author>
      <name>Boshen Yan</name>
    </author>
    <author>
      <name>Dong Li</name>
    </author>
    <author>
      <name>Junzhou Huang</name>
    </author>
    <author>
      <name>Xintao Wu</name>
    </author>
    <author>
      <name>Emily S. Ruiz</name>
    </author>
    <author>
      <name>Arlene Ruiz de Luzuriaga</name>
    </author>
    <author>
      <name>Chen Zhao</name>
    </author>
    <author>
      <name>Guihong Wan</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.07823v1</id>
    <title>Video Generation Models in Robotics -- Applications, Research Challenges, Future Directions</title>
    <updated>2026-01-12T18:57:34Z</updated>
    <link href="https://arxiv.org/abs/2601.07823v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.07823v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Video generation models have emerged as high-fidelity models of the physical world, capable of synthesizing high-quality videos capturing fine-grained interactions between agents and their environments conditioned on multi-modal user inputs. Their impressive capabilities address many of the long-standing challenges faced by physics-based simulators, driving broad adoption in many problem domains, e.g., robotics. For example, video models enable photorealistic, physically consistent deformable-body simulation without making prohibitive simplifying assumptions, which is a major bottleneck in physics-based simulation. Moreover, video models can serve as foundation world models that capture the dynamics of the world in a fine-grained and expressive way. They thus overcome the limited expressiveness of language-only abstractions in describing intricate physical interactions. In this survey, we provide a review of video models and their applications as embodied world models in robotics, encompassing cost-effective data generation and action prediction in imitation learning, dynamics and rewards modeling in reinforcement learning, visual planning, and policy evaluation. Further, we highlight important challenges hindering the trustworthy integration of video models in robotics, which include poor instruction following, hallucinations such as violations of physics, and unsafe content generation, in addition to fundamental limitations such as significant data curation, training, and inference costs. We present potential future directions to address these open research challenges to motivate research and ultimately facilitate broader applications, especially in safety-critical settings.</summary>
    <category term="eess.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-12T18:57:34Z</published>
    <arxiv:primary_category term="eess.SY"/>
    <author>
      <name>Zhiting Mei</name>
    </author>
    <author>
      <name>Tenny Yin</name>
    </author>
    <author>
      <name>Ola Shorinwa</name>
    </author>
    <author>
      <name>Apurva Badithela</name>
    </author>
    <author>
      <name>Zhonghe Zheng</name>
    </author>
    <author>
      <name>Joseph Bruno</name>
    </author>
    <author>
      <name>Madison Bland</name>
    </author>
    <author>
      <name>Lihan Zha</name>
    </author>
    <author>
      <name>Asher Hancock</name>
    </author>
    <author>
      <name>Jaime Fernández Fisac</name>
    </author>
    <author>
      <name>Philip Dames</name>
    </author>
    <author>
      <name>Anirudha Majumdar</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.07799v1</id>
    <title>Testing subhalo abundance matching with galaxy kinematics</title>
    <updated>2026-01-12T18:17:59Z</updated>
    <link href="https://arxiv.org/abs/2601.07799v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.07799v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>The rotation velocities of disc galaxies trace dark matter halo structure, providing direct constraints on the galaxy--halo connection. We construct a Bayesian forward model to connect the dark matter halo population predicted by $Λ$CDM with an observed sample of disc galaxies (SPARC) through their maximum rotation velocities. Our approach combines a subhalo abundance matching scheme (accounting for assembly bias) with a parameterised halo response to galaxy formation. When assuming no correlation between selection in the SPARC survey and halo properties, reproducing the observed velocities requires strong halo expansion, low abundance matching scatter ($&lt;0.15$ dex at $1σ$) and a halo proxy that strongly suppresses the stellar masses in satellite haloes. This is in clear tension with independent clustering constraints. Allowing for SPARC-like galaxies to preferentially populate low $\Vmax$ haloes at fixed virial mass greatly improves the goodness-of-fit and resolves these tensions: the preferred halo response shifts to mild contraction, the abundance matching scatter increases to $\sint = 0.19^{+0.13}_{-0.11}$ dex and the proxy becomes consistent with clustering. However, the inferred selection threshold is extreme, implying that SPARC galaxies occupy the lowest ${\sim}16$ per cent of the $\Vmaxhalo$ distribution at fixed $\Mvir$. Moreover, even with selection, the inferred scatter remains in statistical disagreement with the low-mass clustering constraints, which are most representative of the SPARC galaxies in our sample. Our analysis highlights the advantage of augmenting clustering-based constraints on the galaxy--halo connection with kinematics and suggests a possible tension using current data.</summary>
    <category term="astro-ph.GA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-12T18:17:59Z</published>
    <arxiv:comment>15 pages, 7 figures; submitted to MNRAS</arxiv:comment>
    <arxiv:primary_category term="astro-ph.GA"/>
    <author>
      <name>Fedir Boreiko</name>
    </author>
    <author>
      <name>Tariq Yasin</name>
    </author>
    <author>
      <name>Harry Desmond</name>
    </author>
    <author>
      <name>Richard Stiskalek</name>
    </author>
    <author>
      <name>Matt J. Jarvis</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.07794v1</id>
    <title>Kinship Data Benchmark for Multi-hop Reasoning</title>
    <updated>2026-01-12T18:07:41Z</updated>
    <link href="https://arxiv.org/abs/2601.07794v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.07794v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Large language models (LLMs) are increasingly evaluated on their ability to perform multi-hop reasoning, i.e., to combine multiple pieces of information into a coherent inference. We introduce KinshipQA, a benchmark designed to probe this capability through reasoning over kinship relations. The central contribution of our work is a generative pipeline that produces, on demand, large-scale, realistic, and culture-specific genealogical data: collections of interconnected family trees that satisfy explicit marriage constraints associated with different kinship systems. This allows task difficulty, cultural assumptions, and relational depth to be systematically controlled and varied. From these genealogies, we derive textual inference tasks that require reasoning over implicit relational chains. We evaluate the resulting benchmark using six state-of-the-art LLMs, spanning both open-source and closed-source models, under a uniform zero-shot protocol with deterministic decoding. Performance is measured using exact-match and set-based metrics. Our results demonstrate that KinshipQA yields a wide spread of outcomes and exposes systematic differences in multi-hop reasoning across models and cultural settings.</summary>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-12T18:07:41Z</published>
    <arxiv:comment>11 pages, 2 figures, 9 tables</arxiv:comment>
    <arxiv:primary_category term="cs.CL"/>
    <author>
      <name>Tianda Sun</name>
    </author>
    <author>
      <name>Dimitar Kazakov</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.07792v1</id>
    <title>Non-Convex Portfolio Optimization via Energy-Based Models: A Comparative Analysis Using the Thermodynamic HypergRaphical Model Library (THRML) for Index Tracking</title>
    <updated>2026-01-12T18:04:33Z</updated>
    <link href="https://arxiv.org/abs/2601.07792v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.07792v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Portfolio optimization under cardinality constraints transforms the classical Markowitz mean-variance problem from a convex quadratic problem into an NP-hard combinatorial optimization problem. This paper introduces a novel approach using THRML (Thermodynamic HypergRaphical Model Library), a JAX-based library for building and sampling probabilistic graphical models that reformulates index tracking as probabilistic inference on an Ising Hamiltonian. Unlike traditional methods that seek a single optimal solution, THRML samples from the Boltzmann distribution of high-quality portfolios using GPU-accelerated block Gibbs sampling, providing natural regularization against overfitting.
  We implement three key innovations: (1) dynamic coupling strength that scales inversely with market volatility (VIX), adapting diversification pressure to market regimes; (2) rebalanced bias weights prioritizing tracking quality over momentum for index replication; and (3) sector-aware post-processing ensuring institutional-grade diversification. Backtesting on a 100-stock S and P 500 universe from 2023 to 2025 demonstrates that THRML achieves 4.31 percent annualized tracking error versus 5.66 to 6.30 percent for baselines, while simultaneously generating 128.63 percent total return against the index total return of 79.61 percent. The Diebold-Mariano test confirms statistical significance with p less than 0.0001 across all comparisons. These results position energy-based models as a promising paradigm for portfolio construction, bridging statistical mechanics and quantitative finance.</summary>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-12T18:04:33Z</published>
    <arxiv:comment>10 pages, 5 figures. GPU-accelerated energy-based models for cardinality-constrained index tracking</arxiv:comment>
    <arxiv:primary_category term="q-fin.CP"/>
    <author>
      <name>Javier Mancilla</name>
    </author>
    <author>
      <name>Theodoros D. Bouloumis</name>
    </author>
    <author>
      <name>Frederic Goguikian</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.07790v1</id>
    <title>Benchmarking Small Language Models and Small Reasoning Language Models on System Log Severity Classification</title>
    <updated>2026-01-12T18:02:33Z</updated>
    <link href="https://arxiv.org/abs/2601.07790v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.07790v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>System logs are crucial for monitoring and diagnosing modern computing infrastructure, but their scale and complexity require reliable and efficient automated interpretation. Since severity levels are predefined metadata in system log messages, having a model merely classify them offers limited standalone practical value, revealing little about its underlying ability to interpret system logs. We argue that severity classification is more informative when treated as a benchmark for probing runtime log comprehension rather than as an end task. Using real-world journalctl data from Linux production servers, we evaluate nine small language models (SLMs) and small reasoning language models (SRLMs) under zero-shot, few-shot, and retrieval-augmented generation (RAG) prompting. The results reveal strong stratification. Qwen3-4B achieves the highest accuracy at 95.64% with RAG, while Gemma3-1B improves from 20.25% under few-shot prompting to 85.28% with RAG. Notably, the tiny Qwen3-0.6B reaches 88.12% accuracy despite weak performance without retrieval. In contrast, several SRLMs, including Qwen3-1.7B and DeepSeek-R1-Distill-Qwen-1.5B, degrade substantially when paired with RAG. Efficiency measurements further separate models: most Gemma and Llama variants complete inference in under 1.2 seconds per log, whereas Phi-4-Mini-Reasoning exceeds 228 seconds per log while achieving &lt;10% accuracy. These findings suggest that (1) architectural design, (2) training objectives, and (3) the ability to integrate retrieved context under strict output constraints jointly determine performance. By emphasizing small, deployable models, this benchmark aligns with real-time requirements of digital twin (DT) systems and shows that severity classification serves as a lens for evaluating model competence and real-time deployability, with implications for root cause analysis (RCA) and broader DT integration.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-12T18:02:33Z</published>
    <arxiv:comment>28 pages, 5 figures, 7 tables</arxiv:comment>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Yahya Masri</name>
    </author>
    <author>
      <name>Emily Ma</name>
    </author>
    <author>
      <name>Zifu Wang</name>
    </author>
    <author>
      <name>Joseph Rogers</name>
    </author>
    <author>
      <name>Chaowei Yang</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.07789v1</id>
    <title>Black holes and causal nonlinear electrodynamics</title>
    <updated>2026-01-12T18:01:55Z</updated>
    <link href="https://arxiv.org/abs/2601.07789v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.07789v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>For generic theories of nonlinear electrodynamics (NLED) we investigate the restrictions imposed by causality on spherically-symmetric charged black-hole solutions of the Einstein-NLED equations. For a large class of (acausal) Born-type NLED theories, we find that the Reissner-Nordstrom (RN) metric is an exact, but unstable, solution for some dyonic black holes. For all causal NLED we show that there are no regular black holes, and that the entropy of extremal black holes is less than the RN entropy for fixed charge. We also find the conditions for a parameter-space transition between RN-type and Schwarzschild-type global structure. For the transition from Schwarzschild-type to naked singularity, which occurs at finite mass, we show that the metric at the transition point is a Barriola-Vilenkin global monopole.</summary>
    <category term="hep-th" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-12T18:01:55Z</published>
    <arxiv:comment>42 pages, 5 figures</arxiv:comment>
    <arxiv:primary_category term="hep-th"/>
    <author>
      <name>Jorge G. Russo</name>
    </author>
    <author>
      <name>Paul K. Townsend</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.07778v1</id>
    <title>DT-ICU: Towards Explainable Digital Twins for ICU Patient Monitoring via Multi-Modal and Multi-Task Iterative Inference</title>
    <updated>2026-01-12T17:54:19Z</updated>
    <link href="https://arxiv.org/abs/2601.07778v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.07778v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>We introduce DT-ICU, a multimodal digital twin framework for continuous risk estimation in intensive care. DT-ICU integrates variable-length clinical time series with static patient information in a unified multitask architecture, enabling predictions to be updated as new observations accumulate over the ICU stay. We evaluate DT-ICU on the large, publicly available MIMIC-IV dataset, where it consistently outperforms established baseline models under different evaluation settings. Our test-length analysis shows that meaningful discrimination is achieved shortly after admission, while longer observation windows further improve the ranking of high-risk patients in highly imbalanced cohorts. To examine how the model leverages heterogeneous data sources, we perform systematic modality ablations, revealing that the model learnt a reasonable structured reliance on interventions, physiological response observations, and contextual information. These analyses provide interpretable insights into how multimodal signals are combined and how trade-offs between sensitivity and precision emerge. Together, these results demonstrate that DT-ICU delivers accurate, temporally robust, and interpretable predictions, supporting its potential as a practical digital twin framework for continuous patient monitoring in critical care. The source code and trained model weights for DT-ICU are publicly available at https://github.com/GUO-W/DT-ICU-release.</summary>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-12T17:54:19Z</published>
    <arxiv:primary_category term="cs.LG"/>
    <author>
      <name>Wen Guo</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.07768v1</id>
    <title>THETA: Triangulated Hand-State Estimation for Teleoperation and Automation in Robotic Hand Control</title>
    <updated>2026-01-12T17:50:02Z</updated>
    <link href="https://arxiv.org/abs/2601.07768v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.07768v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>The teleoperation of robotic hands is limited by the high costs of depth cameras and sensor gloves, commonly used to estimate hand relative joint positions (XYZ). We present a novel, cost-effective approach using three webcams for triangulation-based tracking to approximate relative joint angles (theta) of human fingers. We also introduce a modified DexHand, a low-cost robotic hand from TheRobotStudio, to demonstrate THETA's real-time application. Data collection involved 40 distinct hand gestures using three 640x480p webcams arranged at 120-degree intervals, generating over 48,000 RGB images. Joint angles were manually determined by measuring midpoints of the MCP, PIP, and DIP finger joints. Captured RGB frames were processed using a DeepLabV3 segmentation model with a ResNet-50 backbone for multi-scale hand segmentation. The segmented images were then HSV-filtered and fed into THETA's architecture, consisting of a MobileNetV2-based CNN classifier optimized for hierarchical spatial feature extraction and a 9-channel input tensor encoding multi-perspective hand representations. The classification model maps segmented hand views into discrete joint angles, achieving 97.18% accuracy, 98.72% recall, F1 Score of 0.9274, and a precision of 0.8906. In real-time inference, THETA captures simultaneous frames, segments hand regions, filters them, and compiles a 9-channel tensor for classification. Joint-angle predictions are relayed via serial to an Arduino, enabling the DexHand to replicate hand movements. Future research will increase dataset diversity, integrate wrist tracking, and apply computer vision techniques such as OpenAI-Vision. THETA potentially ensures cost-effective, user-friendly teleoperation for medical, linguistic, and manufacturing applications.</summary>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-12T17:50:02Z</published>
    <arxiv:comment>The 11th International Conference on Engineering and Emerging Technologies (ICEET) 2025</arxiv:comment>
    <arxiv:primary_category term="cs.RO"/>
    <author>
      <name>Alex Huang</name>
    </author>
    <author>
      <name>Akshay Karthik</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.07765v1</id>
    <title>Contrastive Learning with Narrative Twins for Modeling Story Salience</title>
    <updated>2026-01-12T17:48:46Z</updated>
    <link href="https://arxiv.org/abs/2601.07765v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.07765v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Understanding narratives requires identifying which events are most salient for a story's progression. We present a contrastive learning framework for modeling narrative salience that learns story embeddings from narrative twins: stories that share the same plot but differ in surface form. Our model is trained to distinguish a story from both its narrative twin and a distractor with similar surface features but different plot. Using the resulting embeddings, we evaluate four narratologically motivated operations for inferring salience (deletion, shifting, disruption, and summarization). Experiments on short narratives from the ROCStories corpus and longer Wikipedia plot summaries show that contrastively learned story embeddings outperform a masked-language-model baseline, and that summarization is the most reliable operation for identifying salient sentences. If narrative twins are not available, random dropout can be used to generate the twins from a single story. Effective distractors can be obtained either by prompting LLMs or, in long-form narratives, by using different parts of the same story.</summary>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-12T17:48:46Z</published>
    <arxiv:comment>EACL 2026</arxiv:comment>
    <arxiv:primary_category term="cs.CL"/>
    <author>
      <name>Igor Sterner</name>
    </author>
    <author>
      <name>Alex Lascarides</name>
    </author>
    <author>
      <name>Frank Keller</name>
    </author>
  </entry>
</feed>
