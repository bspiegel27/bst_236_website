<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-12-24T00:59:54Z -->
<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/" xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns="http://www.w3.org/2005/Atom">
  <id>https://arxiv.org/api/p6EyKyP4fMY/66n9Ev8E79F7KlI</id>
  <title>arXiv Query: search_query=all:causal OR all:inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <updated>2025-12-24T00:59:55Z</updated>
  <link href="https://arxiv.org/api/query?search_query=all:causal+OR+all:inference&amp;start=0&amp;max_results=10&amp;id_list=" type="application/atom+xml"/>
  <opensearch:itemsPerPage>10</opensearch:itemsPerPage>
  <opensearch:totalResults>129326</opensearch:totalResults>
  <opensearch:startIndex>0</opensearch:startIndex>
  <entry>
    <id>http://arxiv.org/abs/2512.19695v1</id>
    <title>Ionizing Photon Production Efficiencies and Chemical Abundances at Cosmic Dawn Revealed by Ultra-Deep Rest-Frame Optical Spectroscopy of JADES-GS-z14-0</title>
    <updated>2025-12-22T18:59:58Z</updated>
    <link href="https://arxiv.org/abs/2512.19695v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.19695v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>JWST has discovered an early period of galaxy formation that was more vigorous than expected, which has challenged our understanding of the early Universe. In this work, we present the longest spectroscopic integration ever acquired by JWST/MIRI. This spectrum covers the brightest rest-frame optical nebular emission lines for the luminous galaxy JADES-GS-z14-0 at $z &gt; 14$. Most notably, we detect $[\mathrm{OIII}] λλ4959,5007$ at $\approx 11 σ$ and $\mathrm{H}α$ at $\approx 4 σ$ with these ultra-deep observations. These lines reveal that JADES-GS-z14-0 has low dust attenuation with a recent star-formation rate of $\mathrm{SFR} \approx 10 \pm 2\ M_{\odot} / \mathrm{yr}$, star-formation rate surface density of $Σ_{\mathrm{SFR}} \approx 23 \pm 5\ M_{\odot}/\mathrm{yr}/\mathrm{kpc}^{2}$, and ionizing photon production efficiency of $ξ_{\mathrm{ion}} \approx 10^{25.3 \pm 0.1}\ \mathrm{Hz/erg}$. Using standard strong-line diagnostics, we infer a gas-phase oxygen abundance of $[\mathrm{O/H}] \approx -1.1 \pm 0.4$ ($\approx 10\%\ Z_{\odot}$), carbon-to-oxygen ratio of $[\mathrm{C/O}] \approx -0.4 \pm 0.4$, ionization parameter of $\mathrm{log}_{10}(U) \gtrsim -2.4$, and density of $n_{\mathrm{H}} \approx 720 \pm 210\ \mathrm{cm}^{-3}$. Using detailed photoionization modeling, we instead derive $[\mathrm{O/H}] \approx -0.3_{-0.4}^{+0.4}$ ($\approx 50\%\ Z_{\odot}$) and $\mathrm{log}_{10}(U) \approx -1.5_{-0.4}^{+0.3}$. The inferred properties of JADES-GS-z14-0 are similar to those measured for similarly luminous galaxies at $z &gt; 10$ with previous MIRI/Spectroscopy, such as GHZ2/GLASSz12, GN-z11, and MACS0647-JD1. Existing simulations are unable to reproduce the empirical and inferred properties of JADES-GS-z14-0. This work demonstrates an important step toward understanding the formation of the first stars and heavy elements in the Universe. [Abridged]</summary>
    <category term="astro-ph.GA" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-22T18:59:58Z</published>
    <arxiv:comment>Submitted to ApJL; main text has 23 pages, 8 figures, and 2 tables; comments are welcome!</arxiv:comment>
    <arxiv:primary_category term="astro-ph.GA"/>
    <author>
      <name>Jakob M. Helton</name>
    </author>
    <author>
      <name>Jane E. Morrison</name>
    </author>
    <author>
      <name>Kevin N. Hainline</name>
    </author>
    <author>
      <name>Francesco D'Eugenio</name>
    </author>
    <author>
      <name>George H. Rieke</name>
    </author>
    <author>
      <name>Stacey Alberts</name>
    </author>
    <author>
      <name>Stefano Carniani</name>
    </author>
    <author>
      <name>Joel Leja</name>
    </author>
    <author>
      <name>Yijia Li</name>
    </author>
    <author>
      <name>Pierluigi Rinaldi</name>
    </author>
    <author>
      <name>Jan Scholtz</name>
    </author>
    <author>
      <name>Meredith Stone</name>
    </author>
    <author>
      <name>Christopher N. A. Willmer</name>
    </author>
    <author>
      <name>Zihao Wu</name>
    </author>
    <author>
      <name>William M. Baker</name>
    </author>
    <author>
      <name>Andrew J. Bunker</name>
    </author>
    <author>
      <name>Stephane Charlot</name>
    </author>
    <author>
      <name>Jacopo Chevallard</name>
    </author>
    <author>
      <name>Nikko J. Cleri</name>
    </author>
    <author>
      <name>Mirko Curti</name>
    </author>
    <author>
      <name>Emma Curtis-Lake</name>
    </author>
    <author>
      <name>Eiichi Egami</name>
    </author>
    <author>
      <name>Daniel J. Eisenstein</name>
    </author>
    <author>
      <name>Peter Jakobsen</name>
    </author>
    <author>
      <name>Zhiyuan Ji</name>
    </author>
    <author>
      <name>Benjamin D. Johnson</name>
    </author>
    <author>
      <name>Nimisha Kumari</name>
    </author>
    <author>
      <name>Xiaojing Lin</name>
    </author>
    <author>
      <name>Jianwei Lyu</name>
    </author>
    <author>
      <name>Roberto Maiolino</name>
    </author>
    <author>
      <name>Michael Maseda</name>
    </author>
    <author>
      <name>Pablo G. Pérez-González</name>
    </author>
    <author>
      <name>Marcia J. Rieke</name>
    </author>
    <author>
      <name>Brant Robertson</name>
    </author>
    <author>
      <name>Aayush Saxena</name>
    </author>
    <author>
      <name>Fengwu Sun</name>
    </author>
    <author>
      <name>Sandro Tacchella</name>
    </author>
    <author>
      <name>Hannah Übler</name>
    </author>
    <author>
      <name>Giacomo Venturi</name>
    </author>
    <author>
      <name>Christina C. Williams</name>
    </author>
    <author>
      <name>Chris Willott</name>
    </author>
    <author>
      <name>Joris Witstok</name>
    </author>
    <author>
      <name>Yongda Zhu</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.19652v1</id>
    <title>High-Precision Differential Radial Velocities of C3PO Wide Binaries: A Test of Modified Newtonian Dynamics (MOND)</title>
    <updated>2025-12-22T18:26:53Z</updated>
    <link href="https://arxiv.org/abs/2512.19652v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.19652v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Wide-binary stars, separated by thousands of AU, reside in low-acceleration regimes where Modified Newtonian Dynamics (MOND) predicts deviation from Newtonian gravity. However, Gaia radial velocities (RVs) lack the precision to resolve the small velocity differences expected in these systems, limiting previous MOND analyses to two-dimensional kinematics. In this paper, we introduce a technique to measure differential RVs of wide binary stars using high resolution, high signal-to-noise spectra. We apply this method to measure differential RVs of 100 wide-binaries from the C3PO survey and achieved precisions of $8-15$ m/s per binary pair, a $\sim 10-100 \times$ improvement (median $\sim 24 \times$) over Gaia DR3. Combining these measurements with Gaia astrometry, we construct a hierarchical Bayesian model to infer the orbital elements of all wide-binary pairs and the global MOND acceleration scale ($a_0$). We test two commonly used interpolating functions in MOND formulation: the simple form ($b=1, μ= x/(1+x)$) and the standard form ($b=2, μ= x/\sqrt{1+x^2}$). Our results indicate tension with MOND at the presently accepted $a_0$ value: for $b=1$, the canonical value is excluded at $3.1σ$, while for $b=2$, the exclusion is at $1.9σ$.</summary>
    <category term="astro-ph.SR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.GA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-22T18:26:53Z</published>
    <arxiv:comment>22 Pages, 12 figures, 5 tables. To be submitted. Comments are welcome</arxiv:comment>
    <arxiv:primary_category term="astro-ph.SR"/>
    <author>
      <name>Serat Mahmud Saad</name>
    </author>
    <author>
      <name>Yuan-Sen Ting</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.19643v1</id>
    <title>The Best of Both Worlds: Hybridizing Neural Operators and Solvers for Stable Long-Horizon Inference</title>
    <updated>2025-12-22T18:17:28Z</updated>
    <link href="https://arxiv.org/abs/2512.19643v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.19643v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Numerical simulation of time-dependent partial differential equations (PDEs) is central to scientific and engineering applications, but high-fidelity solvers are often prohibitively expensive for long-horizon or time-critical settings. Neural operator (NO) surrogates offer fast inference across parametric and functional inputs; however, most autoregressive NO frameworks remain vulnerable to compounding errors, and ensemble-averaged metrics provide limited guarantees for individual inference trajectories. In practice, error accumulation can become unacceptable beyond the training horizon, and existing methods lack mechanisms for online monitoring or correction. To address this gap, we propose ANCHOR (Adaptive Numerical Correction for High-fidelity Operator Rollouts), an online, instance-aware hybrid inference framework for stable long-horizon prediction of nonlinear, time-dependent PDEs. ANCHOR treats a pretrained NO as the primary inference engine and adaptively couples it with a classical numerical solver using a physics-informed, residual-based error estimator. Inspired by adaptive time-stepping in numerical analysis, ANCHOR monitors an exponential moving average (EMA) of the normalized PDE residual to detect accumulating error and trigger corrective solver interventions without requiring access to ground-truth solutions. We show that the EMA-based estimator correlates strongly with the true relative L2 error, enabling data-free, instance-aware error control during inference. Evaluations on four canonical PDEs: 1D and 2D Burgers', 2D Allen-Cahn, and 3D heat conduction, demonstrate that ANCHOR reliably bounds long-horizon error growth, stabilizes extrapolative rollouts, and significantly improves robustness over standalone neural operators, while remaining substantially more efficient than high-fidelity numerical solvers.</summary>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-22T18:17:28Z</published>
    <arxiv:comment>18 pages, 7 figures</arxiv:comment>
    <arxiv:primary_category term="cs.LG"/>
    <author>
      <name>Rajyasri Roy</name>
    </author>
    <author>
      <name>Dibyajyoti Nayak</name>
    </author>
    <author>
      <name>Somdatta Goswami</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.19606v1</id>
    <title>RAPID-LLM: Resilience-Aware Performance analysis of Infrastructure for Distributed LLM Training and Inference</title>
    <updated>2025-12-22T17:42:51Z</updated>
    <link href="https://arxiv.org/abs/2512.19606v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.19606v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>RAPID-LLM is a unified performance modeling framework for large language model (LLM) training and inference on GPU clusters. It couples a DeepFlow-based frontend that generates hardware-aware, operator-level Chakra execution traces from an abstract LLM specification (model shape, batch/sequence settings, training vs. inference, and hybrid parallelism choices) with an extended Astra-Sim backend that executes those traces on explicit multi-dimensional network topologies with congestion-aware routing and support for degraded and faulty links. The frontend assigns per-operator latency using a tile-based model that accounts for SM under-utilization and multi-level memory traffic (SRAM/ L2/ HBM), and prunes memory-infeasible configurations using an activation-liveness traversal under recomputation, parallelism and ZeRO/FDSP sharding policies.
  Across A100-based validation cases, RAPID-LLM predicts Llama inference step latency and GPT-scale training time per batch within 10.4\% relative to published measurements, and matches ns-3 packet-level results within 8\% on representative communication workloads. Case studies demonstrate how RAPID-LLM enables fast, exhaustive sweeps over hybrid-parallel configurations, quantifies sensitivity to soft link faults under realistic routing and congestion, and evaluates hypothetical GPU design variants including HBM bandwidth throttling effects.</summary>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-22T17:42:51Z</published>
    <arxiv:comment>11 pages, 12 figures</arxiv:comment>
    <arxiv:primary_category term="cs.PF"/>
    <author>
      <name>George Karfakis</name>
    </author>
    <author>
      <name>Faraz Tahmasebi</name>
    </author>
    <author>
      <name>Binglu Chen</name>
    </author>
    <author>
      <name>Lime Yao</name>
    </author>
    <author>
      <name>Saptarshi Mitra</name>
    </author>
    <author>
      <name>Tianyue Pan</name>
    </author>
    <author>
      <name>Hyoukjun Kwon</name>
    </author>
    <author>
      <name>Puneet Gupta</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.19602v1</id>
    <title>No Data? No Problem: Robust Vision-Tabular Learning with Missing Values</title>
    <updated>2025-12-22T17:35:32Z</updated>
    <link href="https://arxiv.org/abs/2512.19602v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.19602v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Large-scale medical biobanks provide imaging data complemented by extensive tabular information, such as demographics or clinical measurements. However, this abundance of tabular attributes does not reflect real-world datasets, where only a subset of attributes may be available. This discrepancy calls for methods that can leverage all the tabular data during training while remaining robust to missing values at inference. To address this challenge, we propose RoVTL (Robust Vision-Tabular Learning), a framework designed to handle any level of tabular data availability, from 0% to 100%. RoVTL comprises two key stages: contrastive pretraining, where we introduce tabular attribute missingness as data augmentation to promote robustness, and downstream task tuning using a gated cross-attention module for multimodal fusion. During fine-tuning, we employ a novel Tabular More vs. Fewer loss that ranks performance based on the amount of available tabular data. Combined with disentangled gradient learning, this enables consistent performance across all tabular data completeness scenarios. We evaluate RoVTL on cardiac MRI scans from the UK Biobank, demonstrating superior robustness to missing tabular data compared to prior methods. Furthermore, RoVTL successfully generalizes to an external cardiac MRI dataset for multimodal disease classification, and extends to the natural images domain, achieving robust performance on a car advertisements dataset. The code is available at https://github.com/marteczkah/RoVTL.</summary>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-22T17:35:32Z</published>
    <arxiv:primary_category term="cs.CV"/>
    <author>
      <name>Marta Hasny</name>
    </author>
    <author>
      <name>Laura Daza</name>
    </author>
    <author>
      <name>Keno Bressem</name>
    </author>
    <author>
      <name>Maxime Di Folco</name>
    </author>
    <author>
      <name>Julia Schnabel</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.19588v1</id>
    <title>Possibilistic Inferential Models for Post-Selection Inference in High-Dimensional Linear Regression</title>
    <updated>2025-12-22T17:14:27Z</updated>
    <link href="https://arxiv.org/abs/2512.19588v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.19588v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Valid uncertainty quantification after model selection remains challenging in high-dimensional linear regression, especially within the possibilistic inferential model (PIM) framework. We develop possibilistic inferential models for post-selection inference based on a regularized split possibilistic construction (RSPIM) that combines generic high-dimensional selectors with PIM validification through sample splitting. A first subsample is used to select a sparse model; ordinary least-squares refits on an independent inference subsample yield classical t/F pivots, which are then turned into consonant plausibility contours. In Gaussian linear models this leads to coor-dinatewise intervals with exact finite-sample strong validity conditional on the split and selected model, uniformly over all selectors that use only the selection data. We further analyze RSPIM in a sparse p &gt;&gt; n regime under high-level screening conditions, develop orthogonalized and bootstrap-based extensions for low-dimensional targets with high-dimensional nuisance, and study a maxitive multi-split aggregation that stabilizes inference across random splits while preserving strong validity. Simulations and a riboflavin gene-expression example show that calibrated RSPIM intervals are well behaved under both Gaussian and heteroskedastic errors and are competitive with state-of-the-art post-selection methods, while plausibility contours provide transparent diagnostics of post-selection uncertainty.</summary>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-22T17:14:27Z</published>
    <arxiv:primary_category term="stat.ME"/>
    <author>
      <name>Yaohui Lin</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.19584v1</id>
    <title>Patlak Parametric Image Estimation from Dynamic PET Using Diffusion Model Prior</title>
    <updated>2025-12-22T17:11:33Z</updated>
    <link href="https://arxiv.org/abs/2512.19584v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.19584v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Dynamic PET enables the quantitative estimation of physiology-related parameters and is widely utilized in research and increasingly adopted in clinical settings. Parametric imaging in dynamic PET requires kinetic modeling to estimate voxel-wise physiological parameters based on specific kinetic models. However, parametric images estimated through kinetic model fitting often suffer from low image quality due to the inherently ill-posed nature of the fitting process and the limited counts resulting from non-continuous data acquisition across multiple bed positions in whole-body PET. In this work, we proposed a diffusion model-based kinetic modeling framework for parametric image estimation, using the Patlak model as an example. The score function of the diffusion model was pre-trained on static total-body PET images and served as a prior for both Patlak slope and intercept images by leveraging their patch-wise similarity. During inference, the kinetic model was incorporated as a data-consistency constraint to guide the parametric image estimation. The proposed framework was evaluated on total-body dynamic PET datasets with different dose levels, demonstrating the feasibility and promising performance of the proposed framework in improving parametric image quality.</summary>
    <category term="eess.IV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.med-ph" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-22T17:11:33Z</published>
    <arxiv:comment>10 pages, 9 figures</arxiv:comment>
    <arxiv:primary_category term="eess.IV"/>
    <author>
      <name>Ziqian Huang</name>
    </author>
    <author>
      <name>Boxiao Yu</name>
    </author>
    <author>
      <name>Siqi Li</name>
    </author>
    <author>
      <name>Savas Ozdemir</name>
    </author>
    <author>
      <name>Sangjin Bae</name>
    </author>
    <author>
      <name>Jae Sung Lee</name>
    </author>
    <author>
      <name>Guobao Wang</name>
    </author>
    <author>
      <name>Kuang Gong</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.19563v1</id>
    <title>On Network-Aware Semantic Communication and Edge-Cloud Collaborative Intelligence Systems</title>
    <updated>2025-12-22T16:44:32Z</updated>
    <link href="https://arxiv.org/abs/2512.19563v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.19563v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Semantic communication and edge-cloud collaborative intelligence are increasingly recognized as foundational enablers for next-generation intelligent services operating under stringent bandwidth, latency, and resource constraints. By shifting the communication objective from bit-perfect delivery toward the transmission of task-relevant semantic representations, semantic communication enables adaptive tradeoffs among communication overhead, inference accuracy, computational load, and end-to-end latency. This survey provides a comprehensive and system-level synthesis of recent advances in semantic communication at the edge-cloud interface, encompassing architectural models for collaborative intelligence, representation learning and semantic abstraction techniques, network-aware and resource-adaptive semantic encoding strategies, and learning-driven optimization and orchestration mechanisms. Beyond efficiency considerations, the survey situates semantic communication within practical operational contexts, including security, trust, resilience, and scalability, drawing connections to zero-trust networking, physical-layer security, and emerging edge-cloud control paradigms. Finally, open challenges and research directions are identified, highlighting the role of semantic communication as a key building block for AI-native networking and 6G-ready intelligent systems.</summary>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-22T16:44:32Z</published>
    <arxiv:primary_category term="cs.NI"/>
    <author>
      <name>Murdadha Nasif</name>
    </author>
    <author>
      <name>Ahmed Refaey Hussein</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.19553v1</id>
    <title>A Statistical Framework for Understanding Causal Effects that Vary by Treatment Initiation Time in EHR-based Studies</title>
    <updated>2025-12-22T16:33:32Z</updated>
    <link href="https://arxiv.org/abs/2512.19553v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.19553v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Comparative effectiveness studies using electronic health records (EHR) consider data from patients who could ``enter'' the study cohort at any point during an interval that spans many years in calendar time. Unlike treatments in tightly controlled trials, real-world treatments can evolve over calendar time, especially if comparators include standard of care, or procedures where techniques may improve. Efforts to assess whether treatment efficacy itself is changing are complicated by changing patient populations, with potential covariate shift in key effect modifiers. In this work, we propose a statistical framework to estimate calendar-time specific average treatment effects and describe both how and why effects vary across treatment initiation time in EHR-based studies. Our approach projects doubly robust, time-specific treatment effect estimates onto candidate marginal structural models and uses a model selection procedure to best describe how effects vary by treatment initiation time. We further introduce a novel summary metric, based on standardization analysis, to quantify the role of covariate shift in explaining observed effect changes and disentangle changes in treatment effects from changes in the patient population receiving treatment. Extensive simulations using EHR data from Kaiser Permanente are used to validate the utility of the framework, which we apply to study changes in relative weight loss following two bariatric surgical interventions versus no surgery among patients with severe obesity between 2005-2011.</summary>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-22T16:33:32Z</published>
    <arxiv:primary_category term="stat.ME"/>
    <author>
      <name>Luke Benz</name>
    </author>
    <author>
      <name>Rajarshi Mukherjee</name>
    </author>
    <author>
      <name>Rui Wang</name>
    </author>
    <author>
      <name>David Arterburn</name>
    </author>
    <author>
      <name>Heidi Fischer</name>
    </author>
    <author>
      <name>Catherine Lee</name>
    </author>
    <author>
      <name>Susan M. Shortreed</name>
    </author>
    <author>
      <name>Alexander W. Levis</name>
    </author>
    <author>
      <name>Sebastien Haneuse</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.19551v1</id>
    <title>Towards Closed-Loop Embodied Empathy Evolution: Probing LLM-Centric Lifelong Empathic Motion Generation in Unseen Scenarios</title>
    <updated>2025-12-22T16:31:30Z</updated>
    <link href="https://arxiv.org/abs/2512.19551v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.19551v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>In the literature, existing human-centric emotional motion generation methods primarily focus on boosting performance within a single scale-fixed dataset, largely neglecting the flexible and scale-increasing motion scenarios (e.g., sports, dance), whereas effectively learning these newly emerging scenarios can significantly enhance the model's real-world generalization ability. Inspired by this, this paper proposes a new LLM-Centric Lifelong Empathic Motion Generation (L^2-EMG) task, which aims to equip LLMs with the capability to continually acquire emotional motion generation knowledge across different unseen scenarios, potentially contributing to building a closed-loop and self-evolving embodied agent equipped with both empathy and intelligence. Further, this paper poses two key challenges in the L^2-EMG task, i.e., the emotion decoupling challenge and the scenario adapting challenge. To this end, this paper proposes an Emotion-Transferable and Scenario-Adapted Mixture of Experts (ES-MoE) approach which designs a causal-guided emotion decoupling block and a scenario-adapted expert constructing block to address the two challenges, respectively. Especially, this paper constructs multiple L^2-EMG datasets to validate the effectiveness of the ES-MoE approach. Extensive evaluations show that ES-MoE outperforms advanced baselines.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-22T16:31:30Z</published>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Jiawen Wang</name>
    </author>
    <author>
      <name>Jingjing Wang Tianyang Chen</name>
    </author>
    <author>
      <name>Min Zhang</name>
    </author>
    <author>
      <name>Guodong Zhou</name>
    </author>
  </entry>
</feed>
