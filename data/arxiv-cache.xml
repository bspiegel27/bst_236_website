<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2026-01-12T01:05:19Z -->
<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/" xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns="http://www.w3.org/2005/Atom">
  <id>https://arxiv.org/api/p6EyKyP4fMY/66n9Ev8E79F7KlI</id>
  <title>arXiv Query: search_query=all:causal OR all:inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <updated>2026-01-12T01:05:20Z</updated>
  <link href="https://arxiv.org/api/query?search_query=all:causal+OR+all:inference&amp;start=0&amp;max_results=10&amp;id_list=" type="application/atom+xml"/>
  <opensearch:itemsPerPage>10</opensearch:itemsPerPage>
  <opensearch:totalResults>130432</opensearch:totalResults>
  <opensearch:startIndex>0</opensearch:startIndex>
  <entry>
    <id>http://arxiv.org/abs/2601.05251v1</id>
    <title>Mesh4D: 4D Mesh Reconstruction and Tracking from Monocular Video</title>
    <updated>2026-01-08T18:59:56Z</updated>
    <link href="https://arxiv.org/abs/2601.05251v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.05251v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>We propose Mesh4D, a feed-forward model for monocular 4D mesh reconstruction. Given a monocular video of a dynamic object, our model reconstructs the object's complete 3D shape and motion, represented as a deformation field. Our key contribution is a compact latent space that encodes the entire animation sequence in a single pass. This latent space is learned by an autoencoder that, during training, is guided by the skeletal structure of the training objects, providing strong priors on plausible deformations. Crucially, skeletal information is not required at inference time. The encoder employs spatio-temporal attention, yielding a more stable representation of the object's overall deformation. Building on this representation, we train a latent diffusion model that, conditioned on the input video and the mesh reconstructed from the first frame, predicts the full animation in one shot. We evaluate Mesh4D on reconstruction and novel view synthesis benchmarks, outperforming prior methods in recovering accurate 3D shape and deformation.</summary>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-08T18:59:56Z</published>
    <arxiv:comment>15 pages, 8 figures, project page: https://mesh-4d.github.io/</arxiv:comment>
    <arxiv:primary_category term="cs.CV"/>
    <author>
      <name>Zeren Jiang</name>
    </author>
    <author>
      <name>Chuanxia Zheng</name>
    </author>
    <author>
      <name>Iro Laina</name>
    </author>
    <author>
      <name>Diane Larlus</name>
    </author>
    <author>
      <name>Andrea Vedaldi</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.05248v1</id>
    <title>LaST$_{0}$: Latent Spatio-Temporal Chain-of-Thought for Robotic Vision-Language-Action Model</title>
    <updated>2026-01-08T18:59:53Z</updated>
    <link href="https://arxiv.org/abs/2601.05248v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.05248v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Vision-Language-Action (VLA) models have recently demonstrated strong generalization capabilities in robotic manipulation. Some existing VLA approaches attempt to improve action accuracy by explicitly generating linguistic reasoning traces or future visual observations before action execution. However, explicit reasoning typically incurs non-negligible inference latency, which constrains the temporal resolution required for robotic manipulation. Moreover, such reasoning is confined to the linguistic space, imposing a representational bottleneck that struggles to faithfully capture ineffable physical attributes. To mitigate these limitations, we propose LaST$_0$, a framework that enables efficient reasoning before acting through a Latent Spatio-Temporal Chain-of-Thought (CoT), capturing fine-grained physical and robotic dynamics that are often difficult to verbalize. Specifically, we introduce a token-efficient latent CoT space that models future visual dynamics, 3D structural information, and robot proprioceptive states, and further extends these representations across time to enable temporally consistent implicit reasoning trajectories. Furthermore, LaST$_0$ adopts a dual-system architecture implemented via a Mixture-of-Transformers design, where a reasoning expert conducts low-frequency latent inference and an acting expert generates high-frequency actions conditioned on robotics-oriented latent representations. To facilitate coordination, LaST$_0$ is trained with heterogeneous operation frequencies, enabling adaptive switching between reasoning and action inference rates during deployment. Across ten simulated and six real-world manipulation tasks, LaST$_0$ improves mean success rates by 8% and 13% over prior VLA methods, respectively, while achieving substantially faster inference. Project website: https://sites.google.com/view/last0</summary>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-08T18:59:53Z</published>
    <arxiv:primary_category term="cs.RO"/>
    <author>
      <name>Zhuoyang Liu</name>
    </author>
    <author>
      <name>Jiaming Liu</name>
    </author>
    <author>
      <name>Hao Chen</name>
    </author>
    <author>
      <name>Ziyu Guo</name>
    </author>
    <author>
      <name>Chengkai Hou</name>
    </author>
    <author>
      <name>Chenyang Gu</name>
    </author>
    <author>
      <name>Jiale Yu</name>
    </author>
    <author>
      <name>Xiangju Mi</name>
    </author>
    <author>
      <name>Renrui Zhang</name>
    </author>
    <author>
      <name>Zhengping Che</name>
    </author>
    <author>
      <name>Jian Tang</name>
    </author>
    <author>
      <name>Pheng-Ann Heng</name>
    </author>
    <author>
      <name>Shanghang Zhang</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.05240v1</id>
    <title>Robust Reasoning as a Symmetry-Protected Topological Phase</title>
    <updated>2026-01-08T18:58:34Z</updated>
    <link href="https://arxiv.org/abs/2601.05240v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.05240v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Large language models suffer from "hallucinations"-logical inconsistencies induced by semantic noise. We propose that current architectures operate in a "Metric Phase," where causal order is vulnerable to spontaneous symmetry breaking. Here, we identify robust inference as an effective Symmetry-Protected Topological phase, where logical operations are formally isomorphic to non-Abelian anyon braiding, replacing fragile geometric interpolation with robust topological invariants. Empirically, we demonstrate a sharp topological phase transition: while Transformers and RNNs exhibit gapless decay, our Holonomic Network reveals a macroscopic "mass gap," maintaining invariant fidelity below a critical noise threshold. Furthermore, in a variable-binding task on $S_{10}$ ($3.6 \times 10^6$ states) representing symbolic manipulation, we demonstrate holonomic generalization: the topological model maintains perfect fidelity extrapolating $100\times$ beyond training ($L=50 \to 5000$), consistent with a theoretically indefinite causal horizon, whereas Transformers lose logical coherence. Ablation studies indicate this protection emerges strictly from non-Abelian gauge symmetry. This provides strong evidence for a new universality class for logical reasoning, linking causal stability to the topology of the semantic manifold.</summary>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-th" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-08T18:58:34Z</published>
    <arxiv:primary_category term="cs.LG"/>
    <author>
      <name>Ilmo Sung</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.05233v1</id>
    <title>Three-dimensional scene reconstruction using Roman slitless spectra</title>
    <updated>2026-01-08T18:57:07Z</updated>
    <link href="https://arxiv.org/abs/2601.05233v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.05233v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>The Nancy Grace Roman Space Telescope will carry out a wide-field imaging and slitless spectroscopic survey of Type Ia Supernovae to improve our understanding of dark energy. Crucial to this endeavor is obtaining supernova spectra uncontaminated by light from their host galaxies. However, obtaining such spectra is made more difficult by the inherent problem in wide-field slitless spectroscopic surveys: the blending of spectra of close objects. The spectrum of a supernova will blend with the host galaxy, even from regions distant from the supernova on the sky. If not properly removed, this contamination will introduce systematic bias when the supernova spectra are later used to determine intrinsic supernova parameters and to infer the parameters of dark energy. To address this problem we developed an algorithm that makes use of the spectroscopic observations of the host galaxy at all available observatory roll angles to reconstruct a three-dimensional (3d; 2d spatial, 1d spectral) representation of the underlying host galaxy that accurately matches the 2d slitless spectrum of the host galaxy when projected to an arbitrary rotation angle. We call this ``scene reconstruction''. The projection of the reconstructed scene can be subtracted from an observation of a supernova to remove the contamination from the underlying host. Using simulated Roman data, we show that our method has extremely small systematic errors and significantly less random noise than if we subtracted a single perfectly aligned spectrum of the host obtained before or after the supernova was visible.</summary>
    <category term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-08T18:57:07Z</published>
    <arxiv:comment>57 pages, 52 figures. Accepted for publication in The Astrophysical Journal (ApJ). Reconstruction and simulation source code available at https://gitlab.com/astraatmadja/Ilia</arxiv:comment>
    <arxiv:primary_category term="astro-ph.IM"/>
    <author>
      <name>Tri L. Astraatmadja</name>
    </author>
    <author>
      <name>Andrew S. Fruchter</name>
    </author>
    <author>
      <name>Susana E. Deustua</name>
    </author>
    <author>
      <name>Helen Qu</name>
    </author>
    <author>
      <name>Masao Sako</name>
    </author>
    <author>
      <name>Russell E. Ryan</name>
    </author>
    <author>
      <name>Yannick Copin</name>
    </author>
    <author>
      <name>Greg Aldering</name>
    </author>
    <author>
      <name>Rebekah A. Hounsell</name>
    </author>
    <author>
      <name>David Rubin</name>
    </author>
    <author>
      <name>Lluís Galbany</name>
    </author>
    <author>
      <name>Saul Perlmutter</name>
    </author>
    <author>
      <name>Benjamin M. Rose</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.05229v1</id>
    <title>Mitigating Simulator Dependence in AI Parameter Inference for the Epoch of Reionization: The Importance of Simulation Diversity</title>
    <updated>2026-01-08T18:55:01Z</updated>
    <link href="https://arxiv.org/abs/2601.05229v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.05229v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>The 21cm signal of neutral hydrogen contains a wealth of information about the poorly constrained era of cosmological history, the Epoch of Reionization (EoR). Recently, AI models trained on EoR simulations have gained significant attention as a powerful and flexible option for inferring parameters from 21cm observations. However, previous works show that AI models trained on data from one simulator fail to generalize to data from another, raising doubts about AI models' ability to accurately infer parameters from observation. We develop a new strategy for training AI models on cosmological simulations based on the principle that increasing the diversity of the training dataset improves model robustness by averaging out spurious and contradictory information. We train AI models on data from different combinations of four simulators, then compare the models' performance when predicting on data from held-out simulators acting as proxies for the real universe. We find that models trained on data from multiple simulators perform better on data from a held-out simulator than models trained on data from a single simulator, indicating that increasing the diversity of the training dataset improves a model's ability to generalize. This result suggests that future EoR parameter inference methods can mitigate simulator-specific bias by incorporating multiple simulation approaches into their analyses.</summary>
    <category term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-08T18:55:01Z</published>
    <arxiv:comment>Submitted for review to the Monthly Notices of the Royal Astronomical Society</arxiv:comment>
    <arxiv:primary_category term="astro-ph.CO"/>
    <author>
      <name>Jasper Solt</name>
    </author>
    <author>
      <name>Jonathan C. Pober</name>
    </author>
    <author>
      <name>Stephen H. Bach</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.05227v1</id>
    <title>Stochastic Deep Learning: A Probabilistic Framework for Modeling Uncertainty in Structured Temporal Data</title>
    <updated>2026-01-08T18:53:59Z</updated>
    <link href="https://arxiv.org/abs/2601.05227v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.05227v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>I propose a novel framework that integrates stochastic differential equations (SDEs) with deep generative models to improve uncertainty quantification in machine learning applications involving structured and temporal data. This approach, termed Stochastic Latent Differential Inference (SLDI), embeds an Itô SDE in the latent space of a variational autoencoder, allowing for flexible, continuous-time modeling of uncertainty while preserving a principled mathematical foundation. The drift and diffusion terms of the SDE are parameterized by neural networks, enabling data-driven inference and generalizing classical time series models to handle irregular sampling and complex dynamic structure.
  A central theoretical contribution is the co-parameterization of the adjoint state with a dedicated neural network, forming a coupled forward-backward system that captures not only latent evolution but also gradient dynamics. I introduce a pathwise-regularized adjoint loss and analyze variance-reduced gradient flows through the lens of stochastic calculus, offering new tools for improving training stability in deep latent SDEs. My paper unifies and extends variational inference, continuous-time generative modeling, and control-theoretic optimization, providing a rigorous foundation for future developments in stochastic probabilistic machine learning.</summary>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="econ.EM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-08T18:53:59Z</published>
    <arxiv:comment>20 pages, 6330 words</arxiv:comment>
    <arxiv:primary_category term="stat.ML"/>
    <author>
      <name>James Rice</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.05214v1</id>
    <title>Internal Representations as Indicators of Hallucinations in Agent Tool Selection</title>
    <updated>2026-01-08T18:38:45Z</updated>
    <link href="https://arxiv.org/abs/2601.05214v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.05214v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Large Language Models (LLMs) have shown remarkable capabilities in tool calling and tool usage, but suffer from hallucinations where they choose incorrect tools, provide malformed parameters and exhibit 'tool bypass' behavior by performing simulations and generating outputs instead of invoking specialized tools or external systems. This undermines the reliability of LLM based agents in production systems as it leads to inconsistent results, and bypasses security and audit controls. Such hallucinations in agent tool selection require early detection and error handling. Unlike existing hallucination detection methods that require multiple forward passes or external validation, we present a computationally efficient framework that detects tool-calling hallucinations in real-time by leveraging LLMs' internal representations during the same forward pass used for generation. We evaluate this approach on reasoning tasks across multiple domains, demonstrating strong detection performance (up to 86.4\% accuracy) while maintaining real-time inference capabilities with minimal computational overhead, particularly excelling at detecting parameter-level hallucinations and inappropriate tool selections, critical for reliable agent deployment.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-08T18:38:45Z</published>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Kait Healy</name>
    </author>
    <author>
      <name>Bharathi Srinivasan</name>
    </author>
    <author>
      <name>Visakh Madathil</name>
    </author>
    <author>
      <name>Jing Wu</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.05212v1</id>
    <title>FlowLet: Conditional 3D Brain MRI Synthesis using Wavelet Flow Matching</title>
    <updated>2026-01-08T18:36:29Z</updated>
    <link href="https://arxiv.org/abs/2601.05212v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.05212v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Brain Magnetic Resonance Imaging (MRI) plays a central role in studying neurological development, aging, and diseases. One key application is Brain Age Prediction (BAP), which estimates an individual's biological brain age from MRI data. Effective BAP models require large, diverse, and age-balanced datasets, whereas existing 3D MRI datasets are demographically skewed, limiting fairness and generalizability. Acquiring new data is costly and ethically constrained, motivating generative data augmentation. Current generative methods are often based on latent diffusion models, which operate in learned low dimensional latent spaces to address the memory demands of volumetric MRI data. However, these methods are typically slow at inference, may introduce artifacts due to latent compression, and are rarely conditioned on age, thereby affecting the BAP performance. In this work, we propose FlowLet, a conditional generative framework that synthesizes age-conditioned 3D MRIs by leveraging flow matching within an invertible 3D wavelet domain, helping to avoid reconstruction artifacts and reducing computational demands. Experiments show that FlowLet generates high-fidelity volumes with few sampling steps. Training BAP models with data generated by FlowLet improves performance for underrepresented age groups, and region-based analysis confirms preservation of anatomical structures.</summary>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-08T18:36:29Z</published>
    <arxiv:primary_category term="cs.CV"/>
    <author>
      <name>Danilo Danese</name>
    </author>
    <author>
      <name>Angela Lombardi</name>
    </author>
    <author>
      <name>Matteo Attimonelli</name>
    </author>
    <author>
      <name>Giuseppe Fasano</name>
    </author>
    <author>
      <name>Tommaso Di Noia</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.05200v1</id>
    <title>Multivector Reranking in the Era of Strong First-Stage Retrievers</title>
    <updated>2026-01-08T18:22:18Z</updated>
    <link href="https://arxiv.org/abs/2601.05200v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.05200v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Learned multivector representations power modern search systems with strong retrieval effectiveness, but their real-world use is limited by the high cost of exhaustive token-level retrieval. Therefore, most systems adopt a \emph{gather-and-refine} strategy, where a lightweight gather phase selects candidates for full scoring. However, this approach requires expensive searches over large token-level indexes and often misses the documents that would rank highest under full similarity. In this paper, we reproduce several state-of-the-art multivector retrieval methods on two publicly available datasets, providing a clear picture of the current multivector retrieval field and observing the inefficiency of token-level gathering. Building on top of that, we show that replacing the token-level gather phase with a single-vector document retriever -- specifically, a learned sparse retriever (LSR) -- produces a smaller and more semantically coherent candidate set. This recasts the gather-and-refine pipeline into the well-established two-stage retrieval architecture. As retrieval latency decreases, query encoding with two neural encoders becomes the dominant computational bottleneck. To mitigate this, we integrate recent inference-free LSR methods, demonstrating that they preserve the retrieval effectiveness of the dual-encoder pipeline while substantially reducing query encoding time. Finally, we investigate multiple reranking configurations that balance efficiency, memory, and effectiveness, and we introduce two optimization techniques that prune low-quality candidates early. Empirical results show that these techniques improve retrieval efficiency by up to 1.8$\times$ with no loss in quality. Overall, our two-stage approach achieves over $24\times$ speedup over the state-of-the-art multivector retrieval systems, while maintaining comparable or superior retrieval quality.</summary>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-08T18:22:18Z</published>
    <arxiv:comment>17 pages, 2 figures, ECIR 2026</arxiv:comment>
    <arxiv:primary_category term="cs.IR"/>
    <author>
      <name>Silvio Martinico</name>
    </author>
    <author>
      <name>Franco Maria Nardini</name>
    </author>
    <author>
      <name>Cosimo Rulli</name>
    </author>
    <author>
      <name>Rossano Venturini</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.05193v1</id>
    <title>Cell size control in bacteria is modulated through extrinsic noise, single-cell- and population-growth</title>
    <updated>2026-01-08T18:17:17Z</updated>
    <link href="https://arxiv.org/abs/2601.05193v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.05193v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Living cells maintain size homeostasis by actively compensating for size fluctuations. Here, we present two stochastic maps that unify phenomenological models by integrating fluctuating single-cell growth rates and size-dependent noise mechanisms with cell size control. One map is applicable to mother machine lineages and the other to lineage trees of exponentially-growing cell populations, which reveals that population dynamics alter size control measured in mother machine experiments. For example, an adder can become more sizer-like or more timer-like at the population level depending on the noise statistics. Our analysis of bacterial data identifies extrinsic noise as the dominant mechanism of size variability, characterized by a quadratic conditional variance-mean relationship for division size across growth conditions. This finding contradicts the reported independence of added size relative to birth size but is consistent with the adder property in terms of the independence of the mean added size. Finally, we derive a trade-off between population-growth-rate gain and division-size noise. Correlations between size control quantifiers and single-cell growth rates inferred from data indicate that bacteria prioritize a narrow division-size distribution over growth rate maximisation.</summary>
    <category term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.CB" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-08T18:17:17Z</published>
    <arxiv:primary_category term="q-bio.PE"/>
    <author>
      <name>Arthur Genthon</name>
    </author>
    <author>
      <name>Philipp Thomas</name>
    </author>
  </entry>
</feed>
