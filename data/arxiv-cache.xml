<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-11-21T00:56:11Z -->
<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/" xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns="http://www.w3.org/2005/Atom">
  <id>https://arxiv.org/api/p6EyKyP4fMY/66n9Ev8E79F7KlI</id>
  <title>arXiv Query: search_query=all:causal OR all:inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <updated>2025-11-21T00:56:11Z</updated>
  <link href="https://arxiv.org/api/query?search_query=all:causal+OR+all:inference&amp;start=0&amp;max_results=10&amp;id_list=" type="application/atom+xml"/>
  <opensearch:itemsPerPage>10</opensearch:itemsPerPage>
  <opensearch:totalResults>126617</opensearch:totalResults>
  <opensearch:startIndex>0</opensearch:startIndex>
  <entry>
    <id>http://arxiv.org/abs/2511.15703v1</id>
    <title>Think Visually, Reason Textually: Vision-Language Synergy in ARC</title>
    <updated>2025-11-19T18:59:04Z</updated>
    <link href="https://arxiv.org/abs/2511.15703v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2511.15703v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Abstract reasoning from minimal examples remains a core unsolved problem for frontier foundation models such as GPT-5 and Grok 4. These models still fail to infer structured transformation rules from a handful of examples, which is a key hallmark of human intelligence. The Abstraction and Reasoning Corpus for Artificial General Intelligence (ARC-AGI) provides a rigorous testbed for this capability, demanding conceptual rule induction and transfer to novel tasks. Most existing methods treat ARC-AGI as a purely textual reasoning task, overlooking the fact that humans rely heavily on visual abstraction when solving such puzzles. However, our pilot experiments reveal a paradox: naively rendering ARC-AGI grids as images degrades performance due to imprecise rule execution. This leads to our central hypothesis that vision and language possess complementary strengths across distinct reasoning stages: vision supports global pattern abstraction and verification, whereas language specializes in symbolic rule formulation and precise execution. Building on this insight, we introduce two synergistic strategies: (1) Vision-Language Synergy Reasoning (VLSR), which decomposes ARC-AGI into modality-aligned subtasks; and (2) Modality-Switch Self-Correction (MSSC), which leverages vision to verify text-based reasoning for intrinsic error correction. Extensive experiments demonstrate that our approach yields up to a 4.33% improvement over text-only baselines across diverse flagship models and multiple ARC-AGI tasks. Our findings suggest that unifying visual abstraction with linguistic reasoning is a crucial step toward achieving generalizable, human-like intelligence in future foundation models. Source code will be released soon.</summary>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-11-19T18:59:04Z</published>
    <arxiv:primary_category term="cs.CV"/>
    <author>
      <name>Beichen Zhang</name>
    </author>
    <author>
      <name>Yuhang Zang</name>
    </author>
    <author>
      <name>Xiaoyi Dong</name>
    </author>
    <author>
      <name>Yuhang Cao</name>
    </author>
    <author>
      <name>Haodong Duan</name>
    </author>
    <author>
      <name>Dahua Lin</name>
    </author>
    <author>
      <name>Jiaqi Wang</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2511.15701v1</id>
    <title>The Atacama Cosmology Telescope: Cross-correlation of kSZ and continuity equation velocity reconstruction with photometric DESI LRGs</title>
    <updated>2025-11-19T18:57:34Z</updated>
    <link href="https://arxiv.org/abs/2511.15701v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2511.15701v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Over the last year, kinematic Sunyaev--Zel'dovich (kSZ) velocity reconstruction -- the measurement of the large-scale velocity field using the anisotropic statistics of the small-scale kSZ-galaxy overdensity correlation -- has emerged as a statistically significant probe of the large-scale Universe. In this work, we perform a 2-dimensional tomographic reconstruction using ACT DR6 CMB data and DESI legacy luminous red galaxies (LRGs). We measure the cross-correlation of the kSZ-reconstructed velocity $v^{\mathrm{kSZ}}$ with the velocity inferred from the continuity equation applied to the DESI LRGs $v^{\mathrm{cont}}$ at the $\sim 10 σ$ level, detecting the signal with an amplitude with respect to our theory of $b_v = 0.339\pm 0.034$. We fit a scale-dependent galaxy bias model to our measurement in order to constrain local primordial non-Gaussianity $f_{\mathrm{NL}}^{\mathrm{loc}}$, finding {$f_{\mathrm{NL}}^{\mathrm{loc}}=-180^{+61}_{-86}$} at 67\% confidence, with $f_{\mathrm{NL}}^{\mathrm{loc}}$ consistent with zero at 95\% confidence. We also measure an auto spectrum at $2.1σ$ significance which provides a constraint on $b_v$ of $b_v=0.26_{-0.05}^{+0.11}$, which is consistent with the measurement from the cross spectrum. Our combined measurement is $b_v=0.33\pm0.03$, an $11σ$ measurement. We find a good fit of our model to the data in all cases. Finally, we use different ACT frequency combinations to explore foreground contamination, finding no evidence for foreground contamination in our velocity cross correlation. We compare to a similar measurement where $v^{\mathrm{kSZ}}$ is directly cross correlated with the large-scale galaxy field, and find signs of foreground contamination which is contained in the equal-redshift spectra.</summary>
    <category term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-11-19T18:57:34Z</published>
    <arxiv:comment>37 pages</arxiv:comment>
    <arxiv:primary_category term="astro-ph.CO"/>
    <author>
      <name>Fiona McCarthy</name>
    </author>
    <author>
      <name>Boryana Hadzhiyska</name>
    </author>
    <author>
      <name>J. Richard Bond</name>
    </author>
    <author>
      <name>William R. Coulton</name>
    </author>
    <author>
      <name>Jo Dunkley</name>
    </author>
    <author>
      <name>Carmen Embil Villagra</name>
    </author>
    <author>
      <name>Matthew C. Johnson</name>
    </author>
    <author>
      <name>Kavilan Moodley</name>
    </author>
    <author>
      <name>Toshiya Namikawa</name>
    </author>
    <author>
      <name>Bernardita Ried Guachalla</name>
    </author>
    <author>
      <name>Blake D. Sherwin</name>
    </author>
    <author>
      <name>Cristóbal Sifón</name>
    </author>
    <author>
      <name>Alexander van Engelen</name>
    </author>
    <author>
      <name>Eve M. Vavagiakis</name>
    </author>
    <author>
      <name>Edward J. Wollack</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2511.15690v1</id>
    <title>MoDES: Accelerating Mixture-of-Experts Multimodal Large Language Models via Dynamic Expert Skipping</title>
    <updated>2025-11-19T18:48:27Z</updated>
    <link href="https://arxiv.org/abs/2511.15690v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2511.15690v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Mixture-of-Experts (MoE) Multimodal large language models (MLLMs) excel at vision-language tasks, but they suffer from high computational inefficiency. To reduce inference overhead, expert skipping methods have been proposed to deactivate redundant experts based on the current input tokens. However, we find that applying these methods-originally designed for unimodal large language models (LLMs)-to MLLMs results in considerable performance degradation. This is primarily because such methods fail to account for the heterogeneous contributions of experts across MoE layers and modality-specific behaviors of tokens within these layers. Motivated by these findings, we propose MoDES, the first training-free framework that adaptively skips experts to enable efficient and accurate MoE MLLM inference. It incorporates a globally-modulated local gating (GMLG) mechanism that integrates global layer-wise importance into local routing probabilities to accurately estimate per-token expert importance. A dual-modality thresholding (DMT) method is then applied, which processes tokens from each modality separately, to derive the skipping schedule. To set the optimal thresholds, we introduce a frontier search algorithm that exploits monotonicity properties, cutting convergence time from several days to a few hours. Extensive experiments for 3 model series across 13 benchmarks demonstrate that MoDES far outperforms previous approaches. For instance, when skipping 88% experts for Qwen3-VL-MoE-30B-A3B-Instruct, the performance boost is up to 10.67% (97.33% vs. 86.66%). Furthermore, MoDES significantly enhances inference speed, improving the prefilling time by 2.16$\times$ and the decoding time by 1.26$\times$.</summary>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-11-19T18:48:27Z</published>
    <arxiv:comment>Code will be released upon acceptance</arxiv:comment>
    <arxiv:primary_category term="cs.CV"/>
    <author>
      <name>Yushi Huang</name>
    </author>
    <author>
      <name>Zining Wang</name>
    </author>
    <author>
      <name>Zhihang Yuan</name>
    </author>
    <author>
      <name>Yifu Ding</name>
    </author>
    <author>
      <name>Ruihao Gong</name>
    </author>
    <author>
      <name>Jinyang Guo</name>
    </author>
    <author>
      <name>Xianglong Liu</name>
    </author>
    <author>
      <name>Jun Zhang</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2511.15687v1</id>
    <title>Impact of cosmic expansion on gravitational wave spectra from strongly supercooled first-order phase transitions</title>
    <updated>2025-11-19T18:41:19Z</updated>
    <link href="https://arxiv.org/abs/2511.15687v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2511.15687v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>We compute the gravitational wave spectra from strongly supercooled first-order phase transitions, explicitly incorporating the evolution of the background metric across the transition from thermal inflation to radiation domination. We find that the spectral shape remains largely unchanged apart from a causality-induced super-horizon tail. However, in contrast to standard expectations, for slow transitions we show that the peak amplitude and frequency exhibit a weaker dependence on the transition rate $β$ than the usual scaling of $\propto β^{-2}$ and $\proptoβ$, respectively.</summary>
    <category term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-ph" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-11-19T18:41:19Z</published>
    <arxiv:comment>6 pages, 4 figures</arxiv:comment>
    <arxiv:primary_category term="astro-ph.CO"/>
    <author>
      <name>Marek Lewicki</name>
    </author>
    <author>
      <name>Ville Vaskonen</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2511.15679v1</id>
    <title>Front-door Reducibility: Reducing ADMGs to the Standard Front-door Setting via a Graphical Criterion</title>
    <updated>2025-11-19T18:26:55Z</updated>
    <link href="https://arxiv.org/abs/2511.15679v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2511.15679v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Front-door adjustment provides a simple closed-form identification formula under the classical front-door criterion, but its applicability is often viewed as narrow and strict. Although ID algorithm is very useful and is proved effective for causal relation identification in general causal graphs (if it is identifiable), performing ID algorithm does not guarantee to obtain a practical, easy-to-estimate interventional distribution expression. We argue that the applicability of the front-door criterion is not as limited as it seems: many more complicated causal graphs can be reduced to the front-door criterion. In this paper, We introduce front-door reducibility (FDR), a graphical condition on acyclic directed mixed graphs (ADMGs) that extends the applicability of the classic front-door criterion to reduce a large family of complicated causal graphs to a front-door setting by aggregating variables into super-nodes (FDR triple) $\left(\boldsymbol{X}^{*},\boldsymbol{Y}^{*},\boldsymbol{M}^{*}\right)$. After characterizing FDR criterion, we prove a graph-level equivalence between the satisfication of FDR criterion and the applicability of FDR adjustment. Meanwhile, we then present FDR-TID, an exact algorithm that detects an admissible FDR triple, together with established the algorithm's correctness, completeness, and finite termination. Empirically-motivated examples illustrate that many graphs outside the textbook front-door setting are FDR, yielding simple, estimable adjustments where general ID expressions would be cumbersome. FDR thus complements existing identification method by prioritizing interpretability and computational simplicity without sacrificing generality across mixed graphs.</summary>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-11-19T18:26:55Z</published>
    <arxiv:comment>16 pages, 3 figures</arxiv:comment>
    <arxiv:primary_category term="stat.ML"/>
    <author>
      <name>Jianqiao Mao</name>
    </author>
    <author>
      <name>Max A. Little</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2511.15626v1</id>
    <title>A Latency-Constrained, Gated Recurrent Unit (GRU) Implementation in the Versal AI Engine</title>
    <updated>2025-11-19T17:12:54Z</updated>
    <link href="https://arxiv.org/abs/2511.15626v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2511.15626v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>This work explores the use of the AMD Xilinx Versal Adaptable Intelligent Engine(AIE) to accelerate Gated Recurrent Unit (GRU) inference for latency-Constrained applications. We present a custom workload distribution framework across the AIE's vector processors and propose a hybrid AIE - Programmable Logic (PL) design to optimize computational efficiency. Our approach highlights the potential of deploying adaptable neural networks in real-time environments such as online preprocessing in the readout chain of a physics experiment, offering a flexible alternative to traditional fixed-function algorithms.</summary>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-11-19T17:12:54Z</published>
    <arxiv:primary_category term="cs.PF"/>
    <author>
      <name>M. Sapkas</name>
    </author>
    <author>
      <name>A. Triossi</name>
    </author>
    <author>
      <name>M. Zanetti</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2511.15623v1</id>
    <title>Sufficient Explanations in Databases and their Connections to Necessary Explanations and Repairs</title>
    <updated>2025-11-19T17:07:16Z</updated>
    <link href="https://arxiv.org/abs/2511.15623v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2511.15623v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>The notion of cause, as formalized by Halpern and Pearl, has been recently applied to relational databases, to characterize and compute causal explanations for query answers. In this work we consider the alternative notion of sufficient explanation. We investigate its connections with database repairs as used for dealing with inconsistent databases, and with causality-based necessary explanations. We also obtain some computational results.</summary>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-11-19T17:07:16Z</published>
    <arxiv:primary_category term="cs.DB"/>
    <author>
      <name>Leopoldo Bertossi</name>
    </author>
    <author>
      <name>Nina Pardal</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2511.15618v1</id>
    <title>FlashMesh: Faster and Better Autoregressive Mesh Synthesis via Structured Speculation</title>
    <updated>2025-11-19T17:03:49Z</updated>
    <link href="https://arxiv.org/abs/2511.15618v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2511.15618v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Autoregressive models can generate high-quality 3D meshes by sequentially producing vertices and faces, but their token-by-token decoding results in slow inference, limiting practical use in interactive and large-scale applications. We present FlashMesh, a fast and high-fidelity mesh generation framework that rethinks autoregressive decoding through a predict-correct-verify paradigm. The key insight is that mesh tokens exhibit strong structural and geometric correlations that enable confident multi-token speculation. FlashMesh leverages this by introducing a speculative decoding scheme tailored to the commonly used hourglass transformer architecture, enabling parallel prediction across face, point, and coordinate levels. Extensive experiments show that FlashMesh achieves up to a 2 x speedup over standard autoregressive models while also improving generation fidelity. Our results demonstrate that structural priors in mesh data can be systematically harnessed to accelerate and enhance autoregressive generation.</summary>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-11-19T17:03:49Z</published>
    <arxiv:primary_category term="cs.CV"/>
    <author>
      <name>Tingrui Shen</name>
    </author>
    <author>
      <name>Yiheng Zhang</name>
    </author>
    <author>
      <name>Chen Tang</name>
    </author>
    <author>
      <name>Chuan Ping</name>
    </author>
    <author>
      <name>Zixing Zhao</name>
    </author>
    <author>
      <name>Le Wan</name>
    </author>
    <author>
      <name>Yuwang Wang</name>
    </author>
    <author>
      <name>Ronggang Wang</name>
    </author>
    <author>
      <name>Shengfeng He</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2511.15572v1</id>
    <title>From Low-Rank Features to Encoding Mismatch: Rethinking Feature Distillation in Vision Transformers</title>
    <updated>2025-11-19T16:03:21Z</updated>
    <link href="https://arxiv.org/abs/2511.15572v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2511.15572v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Feature-map knowledge distillation (KD) is highly effective for convolutional networks but often fails for Vision Transformers (ViTs). To understand this failure and guide method design, we conduct a two-view representation analysis of ViTs. First, a layer-wise Singular Value Decomposition (SVD) of full feature matrices shows that final-layer representations are globally low-rank: for CaiT-S24, only $121/61/34/14$ dimensions suffice to capture $99\%/95\%/90\%/80\%$ of the energy. In principle, this suggests that a compact student plus a simple linear projector should be enough for feature alignment, contradicting the weak empirical performance of standard feature KD. To resolve this paradox, we introduce a token-level Spectral Energy Pattern (SEP) analysis that measures how each token uses channel capacity. SEP reveals that, despite the global low-rank structure, individual tokens distribute energy over most channels, forming a high-bandwidth encoding pattern. This results in an encoding mismatch between wide teachers and narrow students. Motivated by this insight, we propose two minimal, mismatch-driven strategies: (1) post-hoc feature lifting with a lightweight projector retained during inference, or (2) native width alignment that widens only the student's last block to the teacher's width. On ImageNet-1K, these strategies reactivate simple feature-map distillation in ViTs, raising DeiT-Tiny accuracy from $74.86\%$ to $77.53\%$ and $78.23\%$ when distilling from CaiT-S24, while also improving standalone students trained without any teacher. Our analysis thus explains why ViT feature distillation fails and shows how exploiting low-rank structure yields effective, interpretable remedies and concrete design guidance for compact ViTs.</summary>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-11-19T16:03:21Z</published>
    <arxiv:primary_category term="cs.CV"/>
    <author>
      <name>Huiyuan Tian</name>
    </author>
    <author>
      <name>Bonan Xu</name>
    </author>
    <author>
      <name>Shijian Li</name>
    </author>
    <author>
      <name>Xin Jin</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2511.15520v1</id>
    <title>Theoretical Closed-loop Stability Bounds for Dynamical System Coupled with Diffusion Policies</title>
    <updated>2025-11-19T15:13:08Z</updated>
    <link href="https://arxiv.org/abs/2511.15520v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2511.15520v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Diffusion Policy has shown great performance in robotic manipulation tasks under stochastic perturbations, due to its ability to model multimodal action distributions. Nonetheless, its reliance on a computationally expensive reverse-time diffusion (denoising) process, for action inference, makes it challenging to use for real-time applications where quick decision-making is mandatory. This work studies the possibility of conducting the denoising process only partially before executing an action, allowing the plant to evolve according to its dynamics in parallel to the reverse-time diffusion dynamics ongoing on the computer. In a classical diffusion policy setting, the plant dynamics are usually slow and the two dynamical processes are uncoupled. Here, we investigate theoretical bounds on the stability of closed-loop systems using diffusion policies when the plant dynamics and the denoising dynamics are coupled. The contribution of this work gives a framework for faster imitation learning and a metric that yields if a controller will be stable based on the variance of the demonstrations.</summary>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-11-19T15:13:08Z</published>
    <arxiv:comment>5 pages, 3 figures</arxiv:comment>
    <arxiv:primary_category term="cs.RO"/>
    <author>
      <name>Gabriel Lauzier</name>
    </author>
    <author>
      <name>Alexandre Girard</name>
    </author>
    <author>
      <name>François Ferland</name>
    </author>
  </entry>
</feed>
