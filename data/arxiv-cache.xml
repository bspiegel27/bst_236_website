<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-12-05T00:59:08Z -->
<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/" xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns="http://www.w3.org/2005/Atom">
  <id>https://arxiv.org/api/p6EyKyP4fMY/66n9Ev8E79F7KlI</id>
  <title>arXiv Query: search_query=all:causal OR all:inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <updated>2025-12-05T00:59:08Z</updated>
  <link href="https://arxiv.org/api/query?search_query=all:causal+OR+all:inference&amp;start=0&amp;max_results=10&amp;id_list=" type="application/atom+xml"/>
  <opensearch:itemsPerPage>10</opensearch:itemsPerPage>
  <opensearch:totalResults>127807</opensearch:totalResults>
  <opensearch:startIndex>0</opensearch:startIndex>
  <entry>
    <id>http://arxiv.org/abs/2512.04075v1</id>
    <title>On distance and velocity estimation in cosmology</title>
    <updated>2025-12-03T18:56:08Z</updated>
    <link href="https://arxiv.org/abs/2512.04075v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.04075v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Scatter in distance indicators introduces two conceptually distinct systematic biases when reconstructing peculiar velocity fields from redshifts and distances. The first is distance Malmquist bias (dMB) that affects individual distance estimates and can in principle be approximately corrected. The second is velocity Malmquist bias (vMB) that arises when constructing continuous velocity fields from scattered distance measurements: random scatter places galaxies at noisy spatial positions, introducing spurious velocity gradients that persist even when distances are corrected for dMB. Considering the Tully-Fisher relation as a concrete example, both inverse and forward formulations yield unbiased individual peculiar velocities for galaxies with the same true distance (the forward relation requires a selection-dependent correction), but neither eliminates vMB when galaxies are placed at their inferred distances. We develop a modified Wiener filter that properly encodes correlations between directly observed distance $d$ and true distance $r$ through the conditional probability $P(r|d)$, accounting for the distribution of true distances sampled by galaxies at observed distance $d$. Nonetheless, this modified filter yields suppressed amplitude estimates. Since machine learning autoencoders converge to the Wiener filter for Gaussian fields, they are unlikely to significantly improve velocity field estimation. We therefore argue that optimal reconstruction places galaxies at their observed redshifts rather than inferred distances; an approach effective when distance errors exceed $Ïƒ_v/H_0$, a condition satisfied for most galaxies in typical surveys beyond the nearby volume.</summary>
    <category term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.GA" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-03T18:56:08Z</published>
    <arxiv:comment>21 pages, 6 figures</arxiv:comment>
    <arxiv:primary_category term="astro-ph.CO"/>
    <author>
      <name>Adi Nusser</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.04059v1</id>
    <title>Inference for location and height of peaks of a standardized field after selection</title>
    <updated>2025-12-03T18:44:45Z</updated>
    <link href="https://arxiv.org/abs/2512.04059v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.04059v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Peak inference concerns the use of local maxima ("peaks") of a noisy random field to detect and localize regions where underlying signal is present. We propose a peak inference method that first subjects observed peaks to a significance test of the null hypothesis that no signal is present, and then uses the peaks that are declared significant to construct post-selectively valid confidence regions for the location and height of nearby true peaks. We analyze the performance of this method in a smooth signal plus constant variance noise model under a high-curvature asymptotic assumption, and prove that it asymptotically controls both the number of false discoveries, and the number of confidence regions that do not contain a true peak, relative to the number of points at which inference is conducted. An important intermediate theoretical result uses the Kac-Rice formula to derive a novel approximation to the intensity function of a point process that counts local maxima, which is second-order accurate under the alternative, nearby high-curvature true peaks.</summary>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-03T18:44:45Z</published>
    <arxiv:primary_category term="stat.ME"/>
    <author>
      <name>Alden Green</name>
    </author>
    <author>
      <name>Jonathan Taylor</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.04058v1</id>
    <title>Closing the problem of which causal structures of up to six total nodes have a classical-quantum gap</title>
    <updated>2025-12-03T18:44:25Z</updated>
    <link href="https://arxiv.org/abs/2512.04058v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.04058v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>The discovery of Bell that there exist quantum correlations that cannot be reproduced classically is one of the most important in the foundations of quantum mechanics, as well as having practical implications. Bell's result was originally proven in a simple bipartite causal structure, but analogous results have also been shown in further causal structures. Here we study the only causal structure with six or fewer nodes in which the question of whether or not there exist quantum correlations that cannot be achieved classically was open. In this causal structure we show that such quantum correlations exist using a method that involves imposing additional restrictions on the correlations. This hence completes the picture of which causal structures of up to six nodes support non-classical quantum correlations. We also provide further illustrations of our method using other causal structures.</summary>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-03T18:44:25Z</published>
    <arxiv:comment>5 pages, 3 figures, 1 table</arxiv:comment>
    <arxiv:primary_category term="quant-ph"/>
    <author>
      <name>Shashaank Khanna</name>
    </author>
    <author>
      <name>Matthew Pusey</name>
    </author>
    <author>
      <name>Roger Colbeck</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.04045v1</id>
    <title>Machine Learning Pipeline for Denoising Low Signal-To-Noise Ratio and Out-of-Distribution Transmission Electron Microscopy Datasets</title>
    <updated>2025-12-03T18:32:32Z</updated>
    <link href="https://arxiv.org/abs/2512.04045v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.04045v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>High-resolution transmission electron microscopy (HRTEM) is crucial for observing material's structural and morphological evolution at Angstrom scales, but the electron beam can alter these processes. Devices such as CMOS-based direct-electron detectors operating in electron-counting mode can be utilized to substantially reduce the electron dosage. However, the resulting images often lead to low signal-to-noise ratio, which requires frame integration that sacrifices temporal resolution. Several machine learning (ML) models have been recently developed to successfully denoise HRTEM images. Yet, these models are often computationally expensive and their inference speeds on GPUs are outpaced by the imaging speed of advanced detectors, precluding in situ analysis. Furthermore, the performance of these denoising models on datasets with imaging conditions that deviate from the training datasets have not been evaluated. To mitigate these gaps, we propose a new self-supervised ML denoising pipeline specifically designed for time-series HRTEM images. This pipeline integrates a blind-spot convolution neural network with pre-processing and post-processing steps including drift correction and low-pass filtering. Results demonstrate that our model outperforms various other ML and non-ML denoising methods in noise reduction and contrast enhancement, leading to improved visual clarity of atomic features. Additionally, the model is drastically faster than U-Net-based ML models and demonstrates excellent out-of-distribution generalization. The model's computational inference speed is in the order of milliseconds per image, rendering it suitable for application in in-situ HRTEM experiments.</summary>
    <category term="cond-mat.mtrl-sci" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-03T18:32:32Z</published>
    <arxiv:primary_category term="cond-mat.mtrl-sci"/>
    <author>
      <name>Brian Lee</name>
    </author>
    <author>
      <name>Meng Li</name>
    </author>
    <author>
      <name>Judith C Yang</name>
    </author>
    <author>
      <name>Dmitri N Zakharov</name>
    </author>
    <author>
      <name>Xiaohui Qu</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.04044v1</id>
    <title>MarkTune: Improving the Quality-Detectability Trade-off in Open-Weight LLM Watermarking</title>
    <updated>2025-12-03T18:32:19Z</updated>
    <link href="https://arxiv.org/abs/2512.04044v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.04044v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Watermarking aims to embed hidden signals in generated text that can be reliably detected when given access to a secret key. Open-weight language models pose acute challenges for such watermarking schemes because the inference-time interventions that dominate contemporary approaches cannot be enforced once model weights are public. Existing watermaking techniques for open-weight models, such as the recently proposed GaussMark, typically rely on small modifications to model weights, which can yield signals detectable to those equipped with a secret key, but achieving detection power comparable to inference-time watermarks generally requires weight perturbations that noticeably reduce generation quality. We introduce MarkTune, a theoretically principled, on-policy fine-tuning framework that treats the GaussMark signal as a reward while simultaneously regularizing against degradation in text quality. We derive MarkTune as an improvement on GaussMark and demonstrate that MarkTune consistently improves the quality-detectability trade-off over GaussMark by steering finer-grained, watermark-aware weight updates within the model's representation space while preserving generation quality. Empirically, we show that MarkTune pushes the quality-detectability frontier of GaussMark close to that of inference-time watermarking, remains robust to paraphrasing and fine-tuning attacks, and exhibits strong generalization: a model fine-tuned on one dataset retains substantial watermark detection power on unseen datasets. Together, these results establish MarkTune as a general strategy for embedding robust, high-quality watermarks into open-weight LMs.</summary>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-03T18:32:19Z</published>
    <arxiv:primary_category term="cs.LG"/>
    <author>
      <name>Yizhou Zhao</name>
    </author>
    <author>
      <name>Zhiwei Steven Wu</name>
    </author>
    <author>
      <name>Adam Block</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.04040v1</id>
    <title>RELIC: Interactive Video World Model with Long-Horizon Memory</title>
    <updated>2025-12-03T18:29:20Z</updated>
    <link href="https://arxiv.org/abs/2512.04040v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.04040v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>A truly interactive world model requires three key ingredients: real-time long-horizon streaming, consistent spatial memory, and precise user control. However, most existing approaches address only one of these aspects in isolation, as achieving all three simultaneously is highly challenging-for example, long-term memory mechanisms often degrade real-time performance. In this work, we present RELIC, a unified framework that tackles these three challenges altogether. Given a single image and a text description, RELIC enables memory-aware, long-duration exploration of arbitrary scenes in real time. Built upon recent autoregressive video-diffusion distillation techniques, our model represents long-horizon memory using highly compressed historical latent tokens encoded with both relative actions and absolute camera poses within the KV cache. This compact, camera-aware memory structure supports implicit 3D-consistent content retrieval and enforces long-term coherence with minimal computational overhead. In parallel, we fine-tune a bidirectional teacher video model to generate sequences beyond its original 5-second training horizon, and transform it into a causal student generator using a new memory-efficient self-forcing paradigm that enables full-context distillation over long-duration teacher as well as long student self-rollouts. Implemented as a 14B-parameter model and trained on a curated Unreal Engine-rendered dataset, RELIC achieves real-time generation at 16 FPS while demonstrating more accurate action following, more stable long-horizon streaming, and more robust spatial-memory retrieval compared with prior work. These capabilities establish RELIC as a strong foundation for the next generation of interactive world modeling.</summary>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-03T18:29:20Z</published>
    <arxiv:comment>22 pages</arxiv:comment>
    <arxiv:primary_category term="cs.CV"/>
    <author>
      <name>Yicong Hong</name>
    </author>
    <author>
      <name>Yiqun Mei</name>
    </author>
    <author>
      <name>Chongjian Ge</name>
    </author>
    <author>
      <name>Yiran Xu</name>
    </author>
    <author>
      <name>Yang Zhou</name>
    </author>
    <author>
      <name>Sai Bi</name>
    </author>
    <author>
      <name>Yannick Hold-Geoffroy</name>
    </author>
    <author>
      <name>Mike Roberts</name>
    </author>
    <author>
      <name>Matthew Fisher</name>
    </author>
    <author>
      <name>Eli Shechtman</name>
    </author>
    <author>
      <name>Kalyan Sunkavalli</name>
    </author>
    <author>
      <name>Feng Liu</name>
    </author>
    <author>
      <name>Zhengqi Li</name>
    </author>
    <author>
      <name>Hao Tan</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.04013v1</id>
    <title>AugServe: Adaptive Request Scheduling for Augmented Large Language Model Inference Serving</title>
    <updated>2025-12-03T17:49:38Z</updated>
    <link href="https://arxiv.org/abs/2512.04013v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.04013v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>As augmented large language models (LLMs) with external tools become increasingly popular in web applications, improving augmented LLM inference serving efficiency and optimizing service-level objectives (SLOs) are critical for enhancing user experience. To achieve this, inference systems must maximize request handling within latency constraints, referred to as increasing effective throughput. However, existing systems face two major challenges: (i) reliance on first-come-first-served (FCFS) scheduling causes severe head-of-line blocking, leading to queuing delays exceeding the SLOs for many requests; and (ii) static batch token limit, which fails to adapt to fluctuating loads and hardware conditions. Both of these factors degrade effective throughput and service quality.
  This paper presents AugServe, an efficient inference framework designed to reduce queueing latency and enhance effective throughput for augmented LLM inference services. The core idea of AugServe is a two-stage adaptive request scheduling strategy. Specifically, AugServe combines the inference features of augmented LLM requests to optimize the order of scheduling decisions (stage I). These decisions are continuously refined with runtime information (stage II), adapting to both request characteristics and system capabilities. In addition, AugServe dynamically adjusts the token batching mechanism based on hardware status and real-time load, further enhancing throughput performance. Experimental results show that AugServe achieves 4.7-33.1x and 3.3-13.2x higher effective throughput than vLLM and InferCept, while reducing time-to-first-token (TTFT) by up to 96.3% and 95.0%, respectively.</summary>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-03T17:49:38Z</published>
    <arxiv:primary_category term="cs.CL"/>
    <author>
      <name>Ying Wang</name>
    </author>
    <author>
      <name>Zhen Jin</name>
    </author>
    <author>
      <name>Jiexiong Xu</name>
    </author>
    <author>
      <name>Wenhai Lin</name>
    </author>
    <author>
      <name>Yiquan Chen</name>
    </author>
    <author>
      <name>Wenzhi Chen</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.03981v1</id>
    <title>DirectDrag: High-Fidelity, Mask-Free, Prompt-Free Drag-based Image Editing via Readout-Guided Feature Alignment</title>
    <updated>2025-12-03T17:12:00Z</updated>
    <link href="https://arxiv.org/abs/2512.03981v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.03981v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Drag-based image editing using generative models provides intuitive control over image structures. However, existing methods rely heavily on manually provided masks and textual prompts to preserve semantic fidelity and motion precision. Removing these constraints creates a fundamental trade-off: visual artifacts without masks and poor spatial control without prompts. To address these limitations, we propose DirectDrag, a novel mask- and prompt-free editing framework. DirectDrag enables precise and efficient manipulation with minimal user input while maintaining high image fidelity and accurate point alignment. DirectDrag introduces two key innovations. First, we design an Auto Soft Mask Generation module that intelligently infers editable regions from point displacement, automatically localizing deformation along movement paths while preserving contextual integrity through the generative model's inherent capacity. Second, we develop a Readout-Guided Feature Alignment mechanism that leverages intermediate diffusion activations to maintain structural consistency during point-based edits, substantially improving visual fidelity. Despite operating without manual mask or prompt, DirectDrag achieves superior image quality compared to existing methods while maintaining competitive drag accuracy. Extensive experiments on DragBench and real-world scenarios demonstrate the effectiveness and practicality of DirectDrag for high-quality, interactive image manipulation. Project Page: https://frakw.github.io/DirectDrag/. Code is available at: https://github.com/frakw/DirectDrag.</summary>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-03T17:12:00Z</published>
    <arxiv:primary_category term="cs.CV"/>
    <author>
      <name>Sheng-Hao Liao</name>
    </author>
    <author>
      <name>Shang-Fu Chen</name>
    </author>
    <author>
      <name>Tai-Ming Huang</name>
    </author>
    <author>
      <name>Wen-Huang Cheng</name>
    </author>
    <author>
      <name>Kai-Lung Hua</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.03966v1</id>
    <title>A CMOS+X Spiking Neuron With On-Chip Machine Learning</title>
    <updated>2025-12-03T16:58:37Z</updated>
    <link href="https://arxiv.org/abs/2512.03966v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.03966v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>We present the design and numerical simulation of a spiking neuron capable of on-chip machine learning. Built within the CMOS+X framework, the spiking neuron consists of an NMOS transistor combined with a magnetic tunnel junction (MTJ). This NMOS+MTJ unit, when simulated in the industry-standard circuit simulation software LTspice, reproduces multiple functions of a biological neuron, including threshold spiking, latency, refractory periods, synaptic integration, inhibition, and adaptation. These behaviors arise from the intrinsic magnetization dynamics of the MTJ and do not require any additional control circuitry. By interconnecting the NMOS+MTJ neurons, we construct a model of an analog multilayer network that learns through spike-timing-dependent weight updates derived from a gradient-descent rule, with both training and inference modeled in the analog domain. The simulated CMOS+X network achieves reliable spike propagation and successful training on a nonlinear task, indicating a feasible path toward compact, low-power, in-memory neuromorphic hardware for edge applications.</summary>
    <category term="physics.app-ph" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-03T16:58:37Z</published>
    <arxiv:comment>12 pages, 7 figures</arxiv:comment>
    <arxiv:primary_category term="physics.app-ph"/>
    <author>
      <name>Steven Louis</name>
    </author>
    <author>
      <name>Matthew Blake Abramson</name>
    </author>
    <author>
      <name>Hannah Bradley</name>
    </author>
    <author>
      <name>Cody Trevillian</name>
    </author>
    <author>
      <name>Gene David Nelson</name>
    </author>
    <author>
      <name>Andrei Slavin</name>
    </author>
    <author>
      <name>Artem Litvinenko</name>
    </author>
    <author>
      <name>Jason Gorski</name>
    </author>
    <author>
      <name>Ilya N. Krivorotov</name>
    </author>
    <author>
      <name>Darrin Hanna</name>
    </author>
    <author>
      <name>Vasyl Tyberkevych</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2512.03964v1</id>
    <title>Training for Identity, Inference for Controllability: A Unified Approach to Tuning-Free Face Personalization</title>
    <updated>2025-12-03T16:57:50Z</updated>
    <link href="https://arxiv.org/abs/2512.03964v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2512.03964v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Tuning-free face personalization methods have developed along two distinct paradigms: text embedding approaches that map facial features into the text embedding space, and adapter-based methods that inject features through auxiliary cross-attention layers. While both paradigms have shown promise, existing methods struggle to simultaneously achieve high identity fidelity and flexible text controllability. We introduce UniID, a unified tuning-free framework that synergistically integrates both paradigms. Our key insight is that when merging these approaches, they should mutually reinforce only identity-relevant information while preserving the original diffusion prior for non-identity attributes. We realize this through a principled training-inference strategy: during training, we employ an identity-focused learning scheme that guides both branches to capture identity features exclusively; at inference, we introduce a normalized rescaling mechanism that recovers the text controllability of the base diffusion model while enabling complementary identity signals to enhance each other. This principled design enables UniID to achieve high-fidelity face personalization with flexible text controllability. Extensive experiments against six state-of-the-art methods demonstrate that UniID achieves superior performance in both identity preservation and text controllability. Code will be available at https://github.com/lyuPang/UniID</summary>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-12-03T16:57:50Z</published>
    <arxiv:comment>17 pages, 13 figures</arxiv:comment>
    <arxiv:primary_category term="cs.CV"/>
    <author>
      <name>Lianyu Pang</name>
    </author>
    <author>
      <name>Ji Zhou</name>
    </author>
    <author>
      <name>Qiping Wang</name>
    </author>
    <author>
      <name>Baoquan Zhao</name>
    </author>
    <author>
      <name>Zhenguo Yang</name>
    </author>
    <author>
      <name>Qing Li</name>
    </author>
    <author>
      <name>Xudong Mao</name>
    </author>
  </entry>
</feed>
