<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2026-01-17T00:59:56Z -->
<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/" xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns="http://www.w3.org/2005/Atom">
  <id>https://arxiv.org/api/p6EyKyP4fMY/66n9Ev8E79F7KlI</id>
  <title>arXiv Query: search_query=all:causal OR all:inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <updated>2026-01-17T00:59:56Z</updated>
  <link href="https://arxiv.org/api/query?search_query=all:causal+OR+all:inference&amp;start=0&amp;max_results=10&amp;id_list=" type="application/atom+xml"/>
  <opensearch:itemsPerPage>10</opensearch:itemsPerPage>
  <opensearch:totalResults>130995</opensearch:totalResults>
  <opensearch:startIndex>0</opensearch:startIndex>
  <entry>
    <id>http://arxiv.org/abs/2601.10714v1</id>
    <title>Alterbute: Editing Intrinsic Attributes of Objects in Images</title>
    <updated>2026-01-15T18:59:53Z</updated>
    <link href="https://arxiv.org/abs/2601.10714v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.10714v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>We introduce Alterbute, a diffusion-based method for editing an object's intrinsic attributes in an image. We allow changing color, texture, material, and even the shape of an object, while preserving its perceived identity and scene context. Existing approaches either rely on unsupervised priors that often fail to preserve identity or use overly restrictive supervision that prevents meaningful intrinsic variations. Our method relies on: (i) a relaxed training objective that allows the model to change both intrinsic and extrinsic attributes conditioned on an identity reference image, a textual prompt describing the target intrinsic attributes, and a background image and object mask defining the extrinsic context. At inference, we restrict extrinsic changes by reusing the original background and object mask, thereby ensuring that only the desired intrinsic attributes are altered; (ii) Visual Named Entities (VNEs) - fine-grained visual identity categories (e.g., ''Porsche 911 Carrera'') that group objects sharing identity-defining features while allowing variation in intrinsic attributes. We use a vision-language model to automatically extract VNE labels and intrinsic attribute descriptions from a large public image dataset, enabling scalable, identity-preserving supervision. Alterbute outperforms existing methods on identity-preserving object intrinsic attribute editing.</summary>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-15T18:59:53Z</published>
    <arxiv:comment>Project page is available at https://talreiss.github.io/alterbute/</arxiv:comment>
    <arxiv:primary_category term="cs.CV"/>
    <author>
      <name>Tal Reiss</name>
    </author>
    <author>
      <name>Daniel Winter</name>
    </author>
    <author>
      <name>Matan Cohen</name>
    </author>
    <author>
      <name>Alex Rav-Acha</name>
    </author>
    <author>
      <name>Yael Pritch</name>
    </author>
    <author>
      <name>Ariel Shamir</name>
    </author>
    <author>
      <name>Yedid Hoshen</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.10708v1</id>
    <title>High-accuracy and dimension-free sampling with diffusions</title>
    <updated>2026-01-15T18:58:50Z</updated>
    <link href="https://arxiv.org/abs/2601.10708v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.10708v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Diffusion models have shown remarkable empirical success in sampling from rich multi-modal distributions. Their inference relies on numerically solving a certain differential equation. This differential equation cannot be solved in closed form, and its resolution via discretization typically requires many small iterations to produce \emph{high-quality} samples.
  More precisely, prior works have shown that the iteration complexity of discretization methods for diffusion models scales polynomially in the ambient dimension and the inverse accuracy $1/\varepsilon$. In this work, we propose a new solver for diffusion models relying on a subtle interplay between low-degree approximation and the collocation method (Lee, Song, Vempala 2018), and we prove that its iteration complexity scales \emph{polylogarithmically} in $1/\varepsilon$, yielding the first ``high-accuracy'' guarantee for a diffusion-based sampler that only uses (approximate) access to the scores of the data distribution. In addition, our bound does not depend explicitly on the ambient dimension; more precisely, the dimension affects the complexity of our solver through the \emph{effective radius} of the support of the target distribution only.</summary>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-15T18:58:50Z</published>
    <arxiv:primary_category term="cs.LG"/>
    <author>
      <name>Khashayar Gatmiry</name>
    </author>
    <author>
      <name>Sitan Chen</name>
    </author>
    <author>
      <name>Adil Salim</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.10702v1</id>
    <title>Grounding Agent Memory in Contextual Intent</title>
    <updated>2026-01-15T18:55:13Z</updated>
    <link href="https://arxiv.org/abs/2601.10702v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.10702v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Deploying large language models in long-horizon, goal-oriented interactions remains challenging because similar entities and facts recur under different latent goals and constraints, causing memory systems to retrieve context-mismatched evidence. We propose STITCH (Structured Intent Tracking in Contextual History), an agentic memory system that indexes each trajectory step with a structured retrieval cue, contextual intent, and retrieves history by matching the current step's intent. Contextual intent provides compact signals that disambiguate repeated mentions and reduce interference: (1) the current latent goal defining a thematic segment, (2) the action type, and (3) the salient entity types anchoring which attributes matter. During inference, STITCH filters and prioritizes memory snippets by intent compatibility, suppressing semantically similar but context-incompatible history.
  For evaluation, we introduce CAME-Bench, a benchmark for context-aware retrieval in realistic, dynamic, goal-oriented trajectories. Across CAME-Bench and LongMemEval, STITCH achieves state-of-the-art performance, outperforming the strongest baseline by 35.6%, with the largest gains as trajectory length increases. Our analysis shows that intent indexing substantially reduces retrieval noise, supporting intent-aware memory for robust long-horizon reasoning.</summary>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-15T18:55:13Z</published>
    <arxiv:primary_category term="cs.CL"/>
    <author>
      <name>Ruozhen Yang</name>
    </author>
    <author>
      <name>Yucheng Jiang</name>
    </author>
    <author>
      <name>Yueqi Jiang</name>
    </author>
    <author>
      <name>Priyanka Kargupta</name>
    </author>
    <author>
      <name>Yunyi Zhang</name>
    </author>
    <author>
      <name>Jiawei Han</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.10700v1</id>
    <title>LIBERTy: A Causal Framework for Benchmarking Concept-Based Explanations of LLMs with Structural Counterfactuals</title>
    <updated>2026-01-15T18:54:50Z</updated>
    <link href="https://arxiv.org/abs/2601.10700v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.10700v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Concept-based explanations quantify how high-level concepts (e.g., gender or experience) influence model behavior, which is crucial for decision-makers in high-stakes domains. Recent work evaluates the faithfulness of such explanations by comparing them to reference causal effects estimated from counterfactuals. In practice, existing benchmarks rely on costly human-written counterfactuals that serve as an imperfect proxy. To address this, we introduce a framework for constructing datasets containing structural counterfactual pairs: LIBERTy (LLM-based Interventional Benchmark for Explainability with Reference Targets). LIBERTy is grounded in explicitly defined Structured Causal Models (SCMs) of the text generation, interventions on a concept propagate through the SCM until an LLM generates the counterfactual. We introduce three datasets (disease detection, CV screening, and workplace violence prediction) together with a new evaluation metric, order-faithfulness. Using them, we evaluate a wide range of methods across five models and identify substantial headroom for improving concept-based explanations. LIBERTy also enables systematic analysis of model sensitivity to interventions: we find that proprietary LLMs show markedly reduced sensitivity to demographic concepts, likely due to post-training mitigation. Overall, LIBERTy provides a much-needed benchmark for developing faithful explainability methods.</summary>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-15T18:54:50Z</published>
    <arxiv:primary_category term="cs.CL"/>
    <author>
      <name>Gilat Toker</name>
    </author>
    <author>
      <name>Nitay Calderon</name>
    </author>
    <author>
      <name>Ohad Amosy</name>
    </author>
    <author>
      <name>Roi Reichart</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.10690v1</id>
    <title>Data-driven stochastic reduced-order modeling of parametrized dynamical systems</title>
    <updated>2026-01-15T18:50:18Z</updated>
    <link href="https://arxiv.org/abs/2601.10690v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.10690v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Modeling complex dynamical systems under varying conditions is computationally intensive, often rendering high-fidelity simulations intractable. Although reduced-order models (ROMs) offer a promising solution, current methods often struggle with stochastic dynamics and fail to quantify prediction uncertainty, limiting their utility in robust decision-making contexts. To address these challenges, we introduce a data-driven framework for learning continuous-time stochastic ROMs that generalize across parameter spaces and forcing conditions. Our approach, based on amortized stochastic variational inference, leverages a reparametrization trick for Markov Gaussian processes to eliminate the need for computationally expensive forward solvers during training. This enables us to jointly learn a probabilistic autoencoder and stochastic differential equations governing the latent dynamics, at a computational cost that is independent of the dataset size and system stiffness. Additionally, our approach offers the flexibility of incorporating physics-informed priors if available. Numerical studies are presented for three challenging test problems, where we demonstrate excellent generalization to unseen parameter combinations and forcings, and significant efficiency gains compared to existing approaches.</summary>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-15T18:50:18Z</published>
    <arxiv:primary_category term="cs.LG"/>
    <author>
      <name>Andrew F. Ilersich</name>
    </author>
    <author>
      <name>Kevin Course</name>
    </author>
    <author>
      <name>Prasanth B. Nair</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.10679v1</id>
    <title>Are Your Reasoning Models Reasoning or Guessing? A Mechanistic Analysis of Hierarchical Reasoning Models</title>
    <updated>2026-01-15T18:42:50Z</updated>
    <link href="https://arxiv.org/abs/2601.10679v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.10679v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Hierarchical reasoning model (HRM) achieves extraordinary performance on various reasoning tasks, significantly outperforming large language model-based reasoners. To understand the strengths and potential failure modes of HRM, we conduct a mechanistic study on its reasoning patterns and find three surprising facts: (a) Failure of extremely simple puzzles, e.g., HRM can fail on a puzzle with only one unknown cell. We attribute this failure to the violation of the fixed point property, a fundamental assumption of HRM. (b) "Grokking" dynamics in reasoning steps, i.e., the answer is not improved uniformly, but instead there is a critical reasoning step that suddenly makes the answer correct; (c) Existence of multiple fixed points. HRM "guesses" the first fixed point, which could be incorrect, and gets trapped there for a while or forever. All facts imply that HRM appears to be "guessing" instead of "reasoning". Leveraging this "guessing" picture, we propose three strategies to scale HRM's guesses: data augmentation (scaling the quality of guesses), input perturbation (scaling the number of guesses by leveraging inference randomness), and model bootstrapping (scaling the number of guesses by leveraging training randomness). On the practical side, by combining all methods, we develop Augmented HRM, boosting accuracy on Sudoku-Extreme from 54.5% to 96.9%. On the scientific side, our analysis provides new insights into how reasoning models "reason".</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-15T18:42:50Z</published>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Zirui Ren</name>
    </author>
    <author>
      <name>Ziming Liu</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.10637v1</id>
    <title>Measuring the Coronal Magnetic Field with 2D Coronal Seismology: A Forward-Modeling Validation</title>
    <updated>2026-01-15T17:57:47Z</updated>
    <link href="https://arxiv.org/abs/2601.10637v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.10637v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>In recent years, a two-dimensional (2D) coronal seismology technique applied to spectral-imaging data from the Coronal Multi-channel Polarimeter (CoMP) and UCoMP has enabled routine measurement of the global coronal magnetic field. The technique combines coronal transverse wave phase speed from Doppler measurements with electron densities from the Fe \sc{xiii}\rm{} 10798/10747 Å intensity ratio to infer the magnetic field strength, while the wave propagation directions from Doppler measurements trace the magnetic field direction. To validate the accuracy and robustness of this method, we use forward modeling of a MURaM simulation that produces open and closed magnetic structures with excited waves. From the synthetic Doppler velocity, Fe \sc{xiii}\rm{} infrared line intensities, and linear polarization signals, we apply the 2D coronal seismology technique to estimate the magnetic field strength and direction. A comparison with the simulation ground truth shows close agreement, indicating that the technique can recover the line-of-sight emissivity-weighted magnetic field direction and strength with high accuracy. We also perform a parameter-space analysis to quantify sensitivities of the method to parameter choice. These findings provide practical guidance for CoMP/UCoMP-like analysis and demonstrate that 2D coronal seismology can deliver reliable, LOS emissivity-weighted measurements of the coronal magnetic field from coronal wave observations.</summary>
    <category term="astro-ph.SR" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-15T17:57:47Z</published>
    <arxiv:comment>17 pages, 10 figures, accepted for publication in ApJS</arxiv:comment>
    <arxiv:primary_category term="astro-ph.SR"/>
    <author>
      <name>Zihao Yang</name>
    </author>
    <author>
      <name>Sarah Gibson</name>
    </author>
    <author>
      <name>Matthias Rempel</name>
    </author>
    <author>
      <name>Giuliana de Toma</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.10631v1</id>
    <title>Circumplanetary Disk Candidate in the Disk of HD 163296 Traced by Localized Emission from Simple Organics</title>
    <updated>2026-01-15T17:50:13Z</updated>
    <link href="https://arxiv.org/abs/2601.10631v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.10631v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Atacama Large Millimeter/submillimeter Array observations suggest that the disc of HD 163296 is being actively shaped by embedded, yet unseen protoplanets, as indicated by numerous gas and dust substructures consistent with planet-disc interaction models. We report the first detection of simple organic molecules, HCN and C2H, tracing a candidate circumplanetary disc (CPD) in the HD 163296 system, located at an orbital radius of $R=88\pm7$ au and azimuth $φ=46\pm3^\circ$ (or $R=0.75''$, $\rm{PA}=350^\circ$ in projected sky coordinates), and originating near the midplane of the circumstellar disc. The signature is localised but spectrally resolved, and it overlaps with a previously reported planet candidate, P94, identified through kinematic perturbations traced by CO lines. We propose a scenario in which the observed chemical anomalies arise from increased heating driven by the forming planet and ongoing accretion through its CPD, facilitating the thermal desorption of species that would otherwise remain frozen out in the disc midplane, and potentially triggering the activation barriers of chemical reactions that lead to enhanced molecular production. Based on a first-order dynamical analysis of the HCN spectrum from the CPD--isolated with a 7$σ$ significance--we infer an upper limit on the planet mass of 1.8 $M_{\rm Jup}$, consistent with predictions from CO kinematics and constraints from direct imaging studies. By comparing the CPD sizes derived from our models with theoretical expectations where the CPD radius corresponds to roughly one-third of the planet's Hill radius, we favor CPD gas temperatures $T &gt; 150$ K, planet masses $M_{\rm p} &lt; 1.0$ $M_{\rm Jup}$, and CPD radii $R_{\rm CPD} &lt; 2$ au.</summary>
    <category term="astro-ph.EP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.SR" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-15T17:50:13Z</published>
    <arxiv:comment>18 pages, 11 figures, 2 tables. Accepted for publication in ApJL</arxiv:comment>
    <arxiv:primary_category term="astro-ph.EP"/>
    <author>
      <name>Andres F. Izquierdo</name>
    </author>
    <author>
      <name>Jaehan Bae</name>
    </author>
    <author>
      <name>Maria Galloway-Sprietsma</name>
    </author>
    <author>
      <name>Ewine F. van Dishoeck</name>
    </author>
    <author>
      <name>Stefano Facchini</name>
    </author>
    <author>
      <name>Giovanni Rosotti</name>
    </author>
    <author>
      <name>Jochen Stadler</name>
    </author>
    <author>
      <name>Myriam Benisty</name>
    </author>
    <author>
      <name>Leonardo Testi</name>
    </author>
    <arxiv:doi>10.3847/2041-8213/ae2f59</arxiv:doi>
    <link rel="related" href="https://doi.org/10.3847/2041-8213/ae2f59" title="doi"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.10626v1</id>
    <title>Differentially Private Inference for Longitudinal Linear Regression</title>
    <updated>2026-01-15T17:47:02Z</updated>
    <link href="https://arxiv.org/abs/2601.10626v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.10626v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Differential Privacy (DP) provides a rigorous framework for releasing statistics while protecting individual information present in a dataset. Although substantial progress has been made on differentially private linear regression, existing methods almost exclusively address the item-level DP setting, where each user contributes a single observation. Many scientific and economic applications instead involve longitudinal or panel data, in which each user contributes multiple dependent observations. In these settings, item-level DP offers inadequate protection, and user-level DP - shielding an individual's entire trajectory - is the appropriate privacy notion. We develop a comprehensive framework for estimation and inference in longitudinal linear regression under user-level DP. We propose a user-level private regression estimator based on aggregating local regressions, and we establish finite-sample guarantees and asymptotic normality under short-range dependence. For inference, we develop a privatized, bias-corrected covariance estimator that is automatically heteroskedasticity- and autocorrelation-consistent. These results provide the first unified framework for practical user-level DP estimation and inference in longitudinal linear regression under dependence, with strong theoretical guarantees and promising empirical performance.</summary>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-15T17:47:02Z</published>
    <arxiv:comment>68 pages, 3 figures</arxiv:comment>
    <arxiv:primary_category term="math.ST"/>
    <author>
      <name>Getoar Sopa</name>
    </author>
    <author>
      <name>Marco Avella Medina</name>
    </author>
    <author>
      <name>Cynthia Rush</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.10615v1</id>
    <title>A Bayesian Discrete Framework for Enhancing Decision-Making Processes in Clinical Trial Designs and Evaluations</title>
    <updated>2026-01-15T17:30:30Z</updated>
    <link href="https://arxiv.org/abs/2601.10615v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.10615v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>This study examines the application of Bayesian approach in the context of clinical trials, emphasizing their increasing importance in contemporary biomedical research. While conventional frequentist approach provides a foundational basis for analysis, it often lacks the flexibility to integrate prior knowledge, which can constrain its effectiveness in adaptive settings. In contrast, Bayesian methods enable continual refinement of statistical inferences through the assimilation of accumulating evidence, thereby supporting more informed decision-making and improving the reliability of trial findings. This paper also considers persistent challenges in clinical investigations, including replication difficulties and the misinterpretation of statistical results, suggesting that Bayesian strategies may offer a path toward enhanced analytical robustness. Moreover, discrete probability models, specifically the Binomial, Poisson, and Negative Binomial distributions are explored for their suitability in modeling clinical endpoints, particularly in trials involving binary responses or data with overdispersion. The discussion further incorporates Bayesian networks and Bayesian estimation techniques, with a comparative evaluation against maximum likelihood estimation to elucidate differences in inferential behavior and practical implementation.</summary>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-15T17:30:30Z</published>
    <arxiv:comment>44 pages, 5 figures, 4 tables</arxiv:comment>
    <arxiv:primary_category term="stat.ME"/>
    <author>
      <name>Paramahansa Pramanik</name>
    </author>
    <author>
      <name>Arnab Kumar Maity</name>
    </author>
    <author>
      <name>Anjan Mandal</name>
    </author>
    <author>
      <name>Haley Kate Robinson</name>
    </author>
  </entry>
</feed>
