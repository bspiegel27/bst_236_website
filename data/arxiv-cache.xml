<?xml version="1.0" encoding="UTF-8"?>
<!-- Last updated: 2025-09-12T00:51:31Z -->
<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acausal%20inference%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:causal inference&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/SsRksLzRb0LuVhSmQ+N8WbAs+f8</id>
  <updated>2025-09-11T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">120689</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">10</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2509.08822v1</id>
    <updated>2025-09-10T17:53:39Z</updated>
    <published>2025-09-10T17:53:39Z</published>
    <title>A Survey of TinyML Applications in Beekeeping for Hive Monitoring and
  Management</title>
    <summary>  Honey bee colonies are essential for global food security and ecosystem
stability, yet they face escalating threats from pests, diseases, and
environmental stressors. Traditional hive inspections are labor-intensive and
disruptive, while cloud-based monitoring solutions remain impractical for
remote or resource-limited apiaries. Recent advances in Internet of Things
(IoT) and Tiny Machine Learning (TinyML) enable low-power, real-time monitoring
directly on edge devices, offering scalable and non-invasive alternatives. This
survey synthesizes current innovations at the intersection of TinyML and
apiculture, organized around four key functional areas: monitoring hive
conditions, recognizing bee behaviors, detecting pests and diseases, and
forecasting swarming events. We further examine supporting resources, including
publicly available datasets, lightweight model architectures optimized for
embedded deployment, and benchmarking strategies tailored to field constraints.
Critical limitations such as data scarcity, generalization challenges, and
deployment barriers in off-grid environments are highlighted, alongside
emerging opportunities in ultra-efficient inference pipelines, adaptive edge
learning, and dataset standardization. By consolidating research and
engineering practices, this work provides a foundation for scalable, AI-driven,
and ecologically informed monitoring systems to support sustainable pollinator
management.
</summary>
    <author>
      <name>Willy Sucipto</name>
    </author>
    <author>
      <name>Jianlong Zhou</name>
    </author>
    <author>
      <name>Ray Seung Min Kwon</name>
    </author>
    <author>
      <name>Fang Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">30 pages, 8 figures, 3 tables. Survey of TinyML and IoT applications
  in beekeeping (datasets, benchmarking, deployment). Submitted to ACM
  Computing Surveys (under review)</arxiv:comment>
    <link href="http://arxiv.org/abs/2509.08822v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.08822v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6; I.2.9; C.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.08811v1</id>
    <updated>2025-09-10T17:44:04Z</updated>
    <published>2025-09-10T17:44:04Z</published>
    <title>Teamwork as Linear Interpersonal Dynamics</title>
    <summary>  Successful teamwork depends on interpersonal dynamics, the ways in which
individuals coordinate, influence, and adapt to one another over time. Existing
measures of interpersonal dynamics, such as CRQA, correlation, Granger
causality, and transfer entropy, typically capture only a single dimension:
either the synchrony/coordination or the direction of influence between
individuals. What is missing is a psychologically meaningful representation
that unifies these dimensions and varies systematically with behavior. We
propose the context matrix as one such representation. The context matrix is
the transition matrix in a linear dynamical system, with entries specifying how
much each individual's current behavior is attributable to their own versus
every other group member's past behaviors. Its values can be distilled into
psychologically interpretable summary features of synchrony and directional
influence. Evidence for the context matrix as psychologically meaningful is
provided in two steps. First, we develop a sequential Bayesian model that
infers context matrices from timeseries data and show that it accurately
recovers them in noisy simulations. Second, applying the model to human
eyetracking data, we show that summary features of the inferred context
matrices capture expected task-based differences in interpersonal dynamics (or
lack thereof), predict task accuracy in psychologically reasonable ways, and
show some correspondence with existing measures (CRQA and Granger causality).
We conclude by situating the context matrix within a broader agenda for
modeling interpersonal dynamics.
</summary>
    <author>
      <name>Andrew Jun Lee</name>
    </author>
    <author>
      <name>Grace Qiyuan Miao</name>
    </author>
    <author>
      <name>Rick Dale</name>
    </author>
    <author>
      <name>Alexia Galati</name>
    </author>
    <author>
      <name>Hongjing Lu</name>
    </author>
    <link href="http://arxiv.org/abs/2509.08811v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.08811v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.08808v1</id>
    <updated>2025-09-10T17:41:08Z</updated>
    <published>2025-09-10T17:41:08Z</published>
    <title>Handling Open-Vocabulary Constructs in Formalizing Specifications:
  Retrieval-Augmented Parsing with Expert Knowledge</title>
    <summary>  We study the problem of Open-Vocabulary Constructs(OVCs) -- ones not known
beforehand -- in the context of converting natural language (NL) specifications
into formal languages (e.g., temporal logic or code). Models fare poorly on
OVCs due to a lack of necessary knowledge a priori. In such situations, a
domain expert can provide correct constructs at inference time based on their
preferences or domain knowledge. Our goal is to effectively reuse this
inference-time, expert-provided knowledge for future parses without retraining
the model. We present dynamic knowledge-augmented parsing(DKAP), where in
addition to the input sentence, the model receives (dynamically growing) expert
knowledge as a key-value lexicon that associates NL phrases with correct OVC
constructs. We propose ROLex, a retrieval-augmented parsing approach that uses
this lexicon. A retriever and a generator are trained to find and use the
key-value store to produce the correct parse. A key challenge lies in curating
data for this retrieval-augmented parser. We utilize synthetic data generation
and the data augmentation techniques on annotated (NL sentence, FL statement)
pairs to train the augmented parser. To improve training effectiveness, we
propose multiple strategies to teach models to focus on the relevant subset of
retrieved knowledge. Finally, we introduce a new evaluation paradigm modeled
after the DKAP problem and simulate the scenario across three formalization
tasks (NL2LTL, NL2Code, and NL2CMD). Our evaluations show that DKAP is a
difficult challenge, and ROLex helps improve the performance of baseline models
by using dynamic expert knowledge effectively.
</summary>
    <author>
      <name>Mohammad Saqib Hasan</name>
    </author>
    <author>
      <name>Sayontan Ghosh</name>
    </author>
    <author>
      <name>Dhruv Verma</name>
    </author>
    <author>
      <name>Geoff Kuenning</name>
    </author>
    <author>
      <name>Erez Zadok</name>
    </author>
    <author>
      <name>Scott A. Smolka</name>
    </author>
    <author>
      <name>Niranjan Balasubramanian</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to COLM 2024</arxiv:comment>
    <link href="http://arxiv.org/abs/2509.08808v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.08808v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.08806v1</id>
    <updated>2025-09-10T17:39:02Z</updated>
    <published>2025-09-10T17:39:02Z</published>
    <title>Evolution, the mother of age-related diseases</title>
    <summary>  The evolutionary origins of ageing and age-associated diseases continue to
pose a fundamental question in biology. This study is concerned with a recently
proposed framework, which conceptualises development and ageing as a continuous
process, driven by genetically encoded epigenetic changes in target sets of
cells. According to the Evolvable Soma Theory of Ageing (ESTA), ageing reflects
the cumulative manifestation of epigenetic changes that are predominantly
expressed during the post-reproductive phase. These late-acting modifications
are not yet evolutionarily optimised but are instead subject to ongoing
selection, functioning as somatic "experiments" through which evolution
explores novel phenotypic variation. These experiments are often detrimental,
leading to progressive physical decline and eventual death, while a small
subset may produce beneficial adaptations, that evolution can exploit to shape
future developmental trajectories. According to ESTA, ageing can be understood
as evolution in action, yet old age is also the strongest risk factor for major
diseases such as cardiovascular diseases, cancer, neurodegenerative disorders,
and metabolic syndrome. We argue that this association is not merely
correlational but causal: the same epigenetic process that drive development
and ageing also underlie age-associated diseases. Growing evidence points to
epigenetic regulation as a central factor in these pathologies, since no
consistent patterns of genetic mutations have been identified, whereas
widespread regulatory and epigenetic disruptions are observed. From this
perspective, evolution is not only the driver of ageing but also the ultimate
source of the diseases that accompany it, making it the root cause of most
age-related pathologies.
</summary>
    <author>
      <name>Alessandro Fontana</name>
    </author>
    <link href="http://arxiv.org/abs/2509.08806v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.08806v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.08788v1</id>
    <updated>2025-09-10T17:15:46Z</updated>
    <published>2025-09-10T17:15:46Z</published>
    <title>Doubly robust average treatment effect estimation for survival data</title>
    <summary>  Considering censored outcomes in survival analysis can lead to quite complex
results in the model setting of causal inference. Causal inference has
attracted a lot of attention over the past few years, but little research has
been done on survival analysis. Even for the only research conducted, the
machine learning method was considered assuming a large sample, which is not
suitable in that the actual data are high dimensional low sample size (HDLSS)
method. Therefore, penalty is considered for numerous covariates, and the
relationship between these covariates and treatment variables is reflected as a
covariate balancing property score (CBPS). It also considers censored results.
To this end, we will try to solve the above-mentioned problems by using
penalized empirical likelihood, which considers both estimating equation and
penalty. The proposed average treatment effect (ATE) estimator possesses the
oracle property, exhibiting key characteristics such as double robustness for
unbiasedness, sparsity in model selection, and asymptotic normality.
</summary>
    <author>
      <name>Byeonghee Lee</name>
    </author>
    <author>
      <name>Joonsung Kang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2509.08788v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.08788v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.08757v1</id>
    <updated>2025-09-10T16:47:00Z</updated>
    <published>2025-09-10T16:47:00Z</published>
    <title>SocialNav-SUB: Benchmarking VLMs for Scene Understanding in Social Robot
  Navigation</title>
    <summary>  Robot navigation in dynamic, human-centered environments requires
socially-compliant decisions grounded in robust scene understanding. Recent
Vision-Language Models (VLMs) exhibit promising capabilities such as object
recognition, common-sense reasoning, and contextual understanding-capabilities
that align with the nuanced requirements of social robot navigation. However,
it remains unclear whether VLMs can accurately understand complex social
navigation scenes (e.g., inferring the spatial-temporal relations among agents
and human intentions), which is essential for safe and socially compliant robot
navigation. While some recent works have explored the use of VLMs in social
robot navigation, no existing work systematically evaluates their ability to
meet these necessary conditions. In this paper, we introduce the Social
Navigation Scene Understanding Benchmark (SocialNav-SUB), a Visual Question
Answering (VQA) dataset and benchmark designed to evaluate VLMs for scene
understanding in real-world social robot navigation scenarios. SocialNav-SUB
provides a unified framework for evaluating VLMs against human and rule-based
baselines across VQA tasks requiring spatial, spatiotemporal, and social
reasoning in social robot navigation. Through experiments with state-of-the-art
VLMs, we find that while the best-performing VLM achieves an encouraging
probability of agreeing with human answers, it still underperforms simpler
rule-based approach and human consensus baselines, indicating critical gaps in
social scene understanding of current VLMs. Our benchmark sets the stage for
further research on foundation models for social robot navigation, offering a
framework to explore how VLMs can be tailored to meet real-world social robot
navigation needs. An overview of this paper along with the code and data can be
found at https://larg.github.io/socialnav-sub .
</summary>
    <author>
      <name>Michael J. Munje</name>
    </author>
    <author>
      <name>Chen Tang</name>
    </author>
    <author>
      <name>Shuijing Liu</name>
    </author>
    <author>
      <name>Zichao Hu</name>
    </author>
    <author>
      <name>Yifeng Zhu</name>
    </author>
    <author>
      <name>Jiaxun Cui</name>
    </author>
    <author>
      <name>Garrett Warnell</name>
    </author>
    <author>
      <name>Joydeep Biswas</name>
    </author>
    <author>
      <name>Peter Stone</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Conference on Robot Learning (CoRL) 2025 Project site:
  https://larg.github.io/socialnav-sub</arxiv:comment>
    <link href="http://arxiv.org/abs/2509.08757v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.08757v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.08753v1</id>
    <updated>2025-09-10T16:43:01Z</updated>
    <published>2025-09-10T16:43:01Z</published>
    <title>Streaming Sequence-to-Sequence Learning with Delayed Streams Modeling</title>
    <summary>  We introduce Delayed Streams Modeling (DSM), a flexible formulation for
streaming, multimodal sequence-to-sequence learning. Sequence-to-sequence
generation is often cast in an offline manner, where the model consumes the
complete input sequence before generating the first output timestep.
Alternatively, streaming sequence-to-sequence rely on learning a policy for
choosing when to advance on the input stream, or write to the output stream.
DSM instead models already time-aligned streams with a decoder-only language
model. By moving the alignment to a pre-processing step,and introducing
appropriate delays between streams, DSM provides streaming inference of
arbitrary output sequences, from any input combination, making it applicable to
many sequence-to-sequence problems. In particular, given text and audio
streams, automatic speech recognition (ASR) corresponds to the text stream
being delayed, while the opposite gives a text-to-speech (TTS) model. We
perform extensive experiments for these two major sequence-to-sequence tasks,
showing that DSM provides state-of-the-art performance and latency while
supporting arbitrary long sequences, being even competitive with offline
baselines. Code, samples and demos are available at
https://github.com/kyutai-labs/delayed-streams-modeling
</summary>
    <author>
      <name>Neil Zeghidour</name>
    </author>
    <author>
      <name>Eugene Kharitonov</name>
    </author>
    <author>
      <name>Manu Orsini</name>
    </author>
    <author>
      <name>Václav Volhejn</name>
    </author>
    <author>
      <name>Gabriel de Marmiesse</name>
    </author>
    <author>
      <name>Edouard Grave</name>
    </author>
    <author>
      <name>Patrick Pérez</name>
    </author>
    <author>
      <name>Laurent Mazaré</name>
    </author>
    <author>
      <name>Alexandre Défossez</name>
    </author>
    <link href="http://arxiv.org/abs/2509.08753v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.08753v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.08752v1</id>
    <updated>2025-09-10T16:42:22Z</updated>
    <published>2025-09-10T16:42:22Z</published>
    <title>Learning Turbulent Flows with Generative Models: Super-resolution,
  Forecasting, and Sparse Flow Reconstruction</title>
    <summary>  Neural operators are promising surrogates for dynamical systems but when
trained with standard L2 losses they tend to oversmooth fine-scale turbulent
structures. Here, we show that combining operator learning with generative
modeling overcomes this limitation. We consider three practical turbulent-flow
challenges where conventional neural operators fail: spatio-temporal
super-resolution, forecasting, and sparse flow reconstruction. For Schlieren
jet super-resolution, an adversarially trained neural operator (adv-NO) reduces
the energy-spectrum error by 15x while preserving sharp gradients at neural
operator-like inference cost. For 3D homogeneous isotropic turbulence, adv-NO
trained on only 160 timesteps from a single trajectory forecasts accurately for
five eddy-turnover times and offers 114x wall-clock speed-up at inference than
the baseline diffusion-based forecasters, enabling near-real-time rollouts. For
reconstructing cylinder wake flows from highly sparse Particle Tracking
Velocimetry-like inputs, a conditional generative model infers full 3D velocity
and pressure fields with correct phase alignment and statistics. These advances
enable accurate reconstruction and forecasting at low compute cost, bringing
near-real-time analysis and control within reach in experimental and
computational fluid mechanics. See our project page:
https://vivekoommen.github.io/Gen4Turb/
</summary>
    <author>
      <name>Vivek Oommen</name>
    </author>
    <author>
      <name>Siavash Khodakarami</name>
    </author>
    <author>
      <name>Aniruddha Bora</name>
    </author>
    <author>
      <name>Zhicheng Wang</name>
    </author>
    <author>
      <name>George Em Karniadakis</name>
    </author>
    <link href="http://arxiv.org/abs/2509.08752v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.08752v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.08727v1</id>
    <updated>2025-09-10T16:17:31Z</updated>
    <published>2025-09-10T16:17:31Z</published>
    <title>Securing Cryptographic Software via Typed Assembly Language (Extended
  Version)</title>
    <summary>  Authors of cryptographic software are well aware that their code should not
leak secrets through its timing behavior, and, until 2018, they believed that
following industry-standard constant-time coding guidelines was sufficient.
However, the revelation of the Spectre family of speculative execution attacks
injected new complexities.
  To block speculative attacks, prior work has proposed annotating the
program's source code to mark secret data, with hardware using this information
to decide when to speculate (i.e., when only public values are involved) or not
(when secrets are in play). While these solutions are able to track secret
information stored on the heap, they suffer from limitations that prevent them
from correctly tracking secrets on the stack, at a cost in performance.
  This paper introduces SecSep, a transformation framework that rewrites
assembly programs so that they partition secret and public data on the stack.
By moving from the source-code level to assembly rewriting, SecSep is able to
address limitations of prior work. The key challenge in performing this
assembly rewriting stems from the loss of semantic information through the
lengthy compilation process. The key innovation of our methodology is a new
variant of typed assembly language (TAL), Octal, which allows us to address
this challenge. Assembly rewriting is driven by compile-time inference within
Octal. We apply our technique to cryptographic programs and demonstrate that it
enables secure speculation efficiently, incurring a low average overhead of
$1.2\%$.
</summary>
    <author>
      <name>Shixin Song</name>
    </author>
    <author>
      <name>Tingzhen Dong</name>
    </author>
    <author>
      <name>Kosi Nwabueze</name>
    </author>
    <author>
      <name>Julian Zanders</name>
    </author>
    <author>
      <name>Andres Erbsen</name>
    </author>
    <author>
      <name>Adam Chlipala</name>
    </author>
    <author>
      <name>Mengjia Yan</name>
    </author>
    <link href="http://arxiv.org/abs/2509.08727v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.08727v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.08721v1</id>
    <updated>2025-09-10T16:14:20Z</updated>
    <published>2025-09-10T16:14:20Z</published>
    <title>Sharing is Caring: Efficient LM Post-Training with Collective RL
  Experience Sharing</title>
    <summary>  Post-training language models (LMs) with reinforcement learning (RL) can
enhance their complex reasoning capabilities without supervised fine-tuning, as
demonstrated by DeepSeek-R1-Zero. However, effectively utilizing RL for LMs
requires significant parallelization to scale-up inference, which introduces
non-trivial technical challenges (e.g. latency, memory, and reliability)
alongside ever-growing financial costs. We present Swarm sAmpling Policy
Optimization (SAPO), a fully decentralized and asynchronous RL post-training
algorithm. SAPO is designed for decentralized networks of heterogenous compute
nodes, where each node manages its own policy model(s) while "sharing" rollouts
with others in the network; no explicit assumptions about latency, model
homogeneity, or hardware are required and nodes can operate in silo if desired.
As a result, the algorithm avoids common bottlenecks in scaling RL
post-training while also allowing (and even encouraging) new possibilities. By
sampling rollouts "shared" across the network, it enables "Aha moments" to
propagate, thereby bootstrapping the learning process. In this paper we show
SAPO achieved cumulative reward gains of up to 94% in controlled experiments.
We also share insights from tests on a network with thousands of nodes
contributed by Gensyn community members running the algorithm on diverse
hardware and models during an open-source demo.
</summary>
    <author>
      <name>Jeffrey Amico</name>
    </author>
    <author>
      <name>Gabriel Passamani Andrade</name>
    </author>
    <author>
      <name>John Donaghy</name>
    </author>
    <author>
      <name>Ben Fielding</name>
    </author>
    <author>
      <name>Tristin Forbus</name>
    </author>
    <author>
      <name>Harry Grieve</name>
    </author>
    <author>
      <name>Semih Kara</name>
    </author>
    <author>
      <name>Jari Kolehmainen</name>
    </author>
    <author>
      <name>Yihua Lou</name>
    </author>
    <author>
      <name>Christopher Nies</name>
    </author>
    <author>
      <name>Edward Phillip Flores Nuño</name>
    </author>
    <author>
      <name>Diogo Ortega</name>
    </author>
    <author>
      <name>Shikhar Rastogi</name>
    </author>
    <author>
      <name>Austin Virts</name>
    </author>
    <author>
      <name>Matthew J. Wright</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2509.08721v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2509.08721v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
